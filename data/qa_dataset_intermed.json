{"queries": {"3795dccd-31df-459d-b5b5-e973c95bf6e1": " What action is taken by the workflow if broken links are found during the check?", "9a6a4eb9-d611-457b-acea-a4cfa42122fd": " How does the provided example workflow check for broken links in the docs site", "4446f3cb-3d1b-47ba-8755-2231a520fbb8": "  - How can I modify the default permissions granted to `GITHUB_TOKEN` in a workflow file", "d4371c0e-b278-4581-ad61-9bc503620361": "  - How can I schedule a workflow to automatically trigger at a regular interval using `cron` syntax", "7aa2820c-c0c3-4733-8e1a-a6ed9f73f60a": "How does the \"setup-node\" action in a GitHub workflow help in accessing the \"npm\" command, and what version of \"node\" software package is being installed in the provided example?", "0d285197-6d28-4c10-ad46-13f975d28a65": "What is the purpose of using the \"checkout\" action in a GitHub workflow, and when is it necessary to use it", "31b58890-a132-4b1d-8061-b8eea8243ad3": "How is the \"gh issue list\" command used in this context to locate previously created issues?", "51fd67cb-203a-430f-9c56-366541fbc7e6": "What is the purpose of the \"create-issue-from-file\" action used in this context", "b08ba22d-7cd7-4c5a-990e-434e1965d49c": "What is the purpose of the following command in the provided context information: \"gh issue comment {% raw %}${{ env.NEW_REPORT_URL }}{% endraw %} --body \"\u2b05\ufe0f Previous report\"\"", "042d7e83-8b7c-4903-ab9f-033e22b0d6eb": "In the provided context information, what is the difference between the following commands: \"gh issue comment $issue_url --body \"\u27a1\ufe0f Newer report\"\" and \"gh issue comment $issue_url --body \"\u27a1\ufe0f Newer report\"{% raw %}${{ env.NEW_REPORT_URL }}\"{% endraw %}\"\"", "4d3c4952-bf65-4b76-9c39-c5cc1051efce": "How does {% data variables.product.prodname_classroom %} simplify the task of providing feedback to students", "31f0b6f4-7a8d-4d8a-8773-887f3f7f00d7": "What is the process for connecting a learning management system to {% data variables.product.prodname_classroom %} and importing a student identifier roster?", "2ce1d1ad-e948-49c5-bb4a-27d73eba494b": "What is the difference between requesting a GitHub App from the owner of the organization and installing it from the GitHub App Marketplace? Are there any limitations to requesting an app from the owner?", "38aed2b7-0c1b-4190-87c5-e2440c9fe2d7": "How can organization members request the installation of a GitHub App for their organization, and what happens if they don't have permission to install it themselves", "168d6979-c7db-4951-b83e-84a641cc7de8": "How can discussions be managed in a repository or organization, and what are the prerequisites for doing so", "968af780-9084-4ca9-a87f-7844d8a0ce50": "What are the benefits of creating community resources for discussions, and how can they be created?", "4de03c98-7c51-415b-b21d-e9c36245c8d0": "How can a discussion be moved to a different category in a repository or organization on GitHub", "4b27c1eb-5140-432d-8882-85a0dec3fc35": "What is the process for pinning a discussion in GitHub, and can it be pinned to a specific category or only globally?", "c8c09e0b-7853-4ebc-9142-716b6659bea6": "Given the context information and not prior knowledge.generate only answers based on the below query.You are a Teacher/ Professor. Your task is to provide EXACTLY 2 answers for the questions asked. The answers should be diverse in nature across the document. Restrict the answers to the context. Answers should be understandable without having access to the context.Don't provide examples and keep the answers focused on once aspect at a time.answers:1. To pin a discussion to a specific category in a repository or organization on GitHub, follow these steps:   1. Go to the repository or organization where the discussion is located.   2. Click on the Discussions tab", "75cf5edd-9608-4d43-a3f3-9e5339c036b0": "How can a discussion be pinned to a specific category in a repository or organization on GitHub", "936b418e-ccb3-4287-b68c-f0092ccbbe87": "What is the process for editing a pinned discussion on GitHub", "781f694d-eabc-406b-bf1c-66136f59f510": "How do you transfer a discussion from one repository to another in GitHub", "17b18d29-6fa4-499c-8017-106dd5d6cc78": "How do you unpin a discussion from a category in GitHub", "5ec813de-4aab-4f61-9d77-a43967c69f80": "Based on the context information provided, generate two questions that can be answered without prior knowledge. The questions should be diverse in nature and focused on specific aspects. Restrict the questions to the context provided. Avoid asking for examples and keep the questions focused on one aspect at a time.", "3b5cc1ce-b763-4544-8bba-f63577f62645": "How do I delete a discussion on GitHub? Provide step-by-step instructions, including any necessary clicks or selections, and any warnings or confirmations that may be encountered during the process.2. How do I close a discussion on GitHub? Provide step-by-step instructions, including any necessary clicks or selections, and any warnings or confirmations that may be encountered during the process. Additionally, explain what it means to close a discussion and any potential consequences of doing so.", "ea9229a4-cd03-484e-87d0-7fcc64931a81": "How should one respond when they receive a \"404 Not Found\" response for an existing resource, as described in the context information?", "d33c83ef-d852-4a76-9a8c-eaa7e4ece3e4": "What is the significance of the rate limit errors mentioned in the context information", "cca463d6-cf74-4a2f-b0be-ee659f90a3f7": "How can we ensure that a token used to access a resource through an endpoint has the necessary permissions and access to required resources, as outlined in the context information?", "25c15285-e8ad-494b-9ba6-a0dd00b182d7": "What are the specific permissions required to use the endpoint mentioned in the context information", "bede944d-2f2f-49bf-915e-034a5d5df242": "How can you ensure that a", "096a099f-26bc-44d4-83b6-5ff97c20a2f5": "What should be checked to ensure that an {% data variables.product.prodname_oauth_app %} is not blocked from accessing resources owned by an organization", "b5955f9d-3621-4f38-805b-0fe21cb96d7f": "How can you verify that a `GITHUB_TOKEN` has not been expired or revoked in a {% data variables.product.prodname_actions %} workflow", "f85370c7-6d81-4913-84e0-367388fad79b": "What are the requirements for using a specific endpoint in the context provided", "0a9b16c6-c364-4f3a-9c4b-bfcf2db7bfcd": "What should be considered when using `GITHUB_TOKEN` in a {% data variables.product.prodname_actions %} workflow to ensure that it is only affecting resources owned by the repository where the workflow is running", "39ab23ac-2e6e-41db-bf2c-b19002a3062d": "How can you ensure that an {% data variables.product.prodname_oauth_app %} user access token has the necessary scopes and permissions to use a specific endpoint", "9989b8b3-ee2a-4ba6-814b-c66d836e20bd": "What is the purpose of context information provided in the text material", "e1f4dac1-e5ec-4c57-b4d1-cf330107bb74": "What should I do if I am not seeing all of the expected results when using pagination in API requests", "189b5f03-f935-4a01-81b5-e15b20a5ac33": "What should I check if I receive a `404 Not Found` error when making API requests using {% data variables.product.prodname_github %}?", "af98743a-26e8-4d4b-8ccf-e8f5a13dc9d2": "Why is basic authentication with my username and password not supported when making API requests using {% data variables.product.prodname_github %}", "36ecebc9-4eb1-41da-85b0-bf4e57002a0d": "How can I ensure that I am using the correct authentication credentials when making API requests using {% data variables.product.prodname_github_app %} or {% data variables.product.prodname_oauth_app %}", "012012ac-ebd4-404a-ab60-1876ab3a33f9": "How can I avoid encountering timeouts when making API requests using {% data variables.product.prodname_github %}", "8c0aab61-edc3-4d06-8f50-691987b2b09f": "What is the significance of the \"Resource not accessible by integration\" error message that is displayed when using a {% data variables.product.prodname_github_app %}{% ifversion pat-v2 %} or {% data variables.product.pat_v2 %}{% endif %} with insufficient permissions", "fe24f2d3-2cfc-400e-b505-1b237cb72e4b": "How can I determine whether the timeout window for {% data variables.product.product_name %} API requests is being changed to protect the speed and reliability of the API?", "25adabe5-3b4d-4123-9bd2-1ced796b01d8": "What error message might be received when a request cannot be processed, and what information can be found in the response body to help diagnose the problem", "265d417a-724b-47ce-b191-d69860dabe11": "How can the \"Validation Failed\" error message be avoided, and what information can be found in the response body to help diagnose the problem", "763989ed-fa0c-4c47-b4b2-ff5f100e5c50": "What types of permissions are required for a {% data variables.product.prodname_github_app %}{% ifversion pat-v2 %} or {% data variables.product.pat_v2 %}{% endif %} to access pull requests and issues", "9df9c907-d4b1-4d8d-b8d7-935892004f93": "What error messages might be received when sending invalid JSON in a request body, and how can they be avoided", "3ed8610b-f06e-4de3-a3b0-d51ff16ddee8": "What error message might be received when omitting required parameters or using the wrong type for a parameter, and how can it be avoided", "02c6aeb7-c42a-42ba-ba57-4a1e94b7323f": "What error message might be received when a resource does", "f5630487-8f16-428f-afca-e01f59b94e80": "What is the error message that the API provides when a version that is not supported is specified using the `X-GitHub-Api-Version` header", "7fe69845-dcbc-4150-b639-76254994161b": "What header is required for requests to be accepted by the REST API, and what value should be used for this header?", "03c3d685-ce17-43a8-bfcf-b3585c7942c5": "What is the process for approving {% data variables.product.pat_v2 %} requests in an organization that requires approval", "7e63f9b0-6eff-4237-b046-9c7fa39593ca": "How does {% data variables.product.company_short %} notify organization owners about pending {% data variables.product.pat_v2 %} requests, and what actions can be taken on these requests using the REST API?", "038931a5-b5d8-4e5c-b220-495e417cdc11": "How can multiple GitHub tokens be approved or denied simultaneously, and where can this action be performed in the GitHub interface?", "fbeef5ae-d1e9-453f-a70e-d3c9dc0adbd3": "What is the process to deny access to an organization's GitHub token, and what information should be provided to the token owner when denying the request", "281d4a56-7eb5-410d-b8f5-2f7765622d50": "How can a pull request be made smaller and more focused to make the review process smoother and faster", "d67b6659-8793-430c-bb78-07245e9a3f14": "What information should be included in the pull request body to help reviewers understand the purpose of the pull request and provide clear context?", "aa0258f7-0d81-486b-a044-30154e166548": "How can you ensure that specific individuals are always involved in reviewing changes to certain code or files in a repository? Provide a detailed explanation of the steps involved in defining code owners for specific types of files or directories, as well as for different branches in a repository.2. What is the significance of using protected branches in a repository, and how can they be utilized to prevent pull requests from being merged into important branches until certain conditions are met? Please provide specific examples of conditions that can be required before a pull request is allowed to be merged into a protected branch.", "53a412da-7cb8-41bf-824c-a8b45dc9ed45": "What should I do if my locally-hosted code is not tracked by any version control system (VCS) and I want to add it to GitHub using the command line? What if my project is already tracked by Git? How can I convert it to Git if it's tracked by a different VCS, such as Mercurial, Subversion, or Team Foundation Version Control?", "8f53632f-8a7c-4e47-8f1e-1ed440b46c43": "How can I add existing source code to GitHub using Git commands directly, and what is {% data variables.product.prodname_cli %}", "ae286b85-d783-44ec-81a1-39f7d186ed3f": "How can you set the name of the default branch using Git's symbolic-ref command? Provide an example command to illustrate your answer.2. What command should you use to add all the files in your local repository and stage them for the first commit in Git? Please provide the command and any necessary flags or options.", "27d15d33-0d93-4651-95f1-023016646e3c": "How can I add a local repository to GitHub using the command line? Provide step-by-step instructions, including the necessary commands and any required parameters. Be sure to include information on how to authenticate to GitHub on the command line and how to push changes to the remote repository. Your instructions should be clear and concise, with each step presented in a logical order.2. How can I create a new repository on GitHub using the command line? Provide step-by-step instructions, including the necessary commands and any required parameters. Be sure to include information on how to specify the repository name, whether to initialize the repository with a README file, and how to create the repository in a specific location. Your instructions should be clear and concise, with each step presented in a logical order.", "d4993b53-88a6-4195-8f35-2bba04d6f897": "How can I access the remote repository URL for my local project on {% ifversion ghae %}{% data variables.product.product_name %}{% else %}{% data variables.location.product_location %}{% endif %}", "6b06a8a2-3ca7-4ed0-86c6-b23abbcbd343": "How do I push changes from my local repository to {% ifversion ghae %}{% data variables.product.product_name %}{% else %}{% data variables.location.product_location %}{% endif %} using Git? (Assuming the default branch is named \"main\")", "b9a6f237-5fb8-483c-b33d-afec98a26361": "How do you push changes from your local repository to {% data variables.location.product_location %} using the provided context? (Assuming the default branch is not named \"main\")", "0e51aa72-a100-49b7-bd54-2014dacea566": "What is the purpose of running the command \"git remote -v\" in the context provided", "21003e4e-2572-4022-9443-ed96626efac5": "What should you do before pushing changes to GitHub to avoid merge conflicts?", "566dc6cb-ff4b-45f9-afc4-97f623f85d04": "What is the process of sending committed changes from a local repository to a remote repository on GitHub called", "a24a5baa-2149-4802-be16-fad017cf7fbb": "What is the meaning of \"AUTOTITLE\" in the {% data variables.product.prodname_dotcom %} glossary", "3bdba4bf-4c81-4ca9-add5-a10ad31a9fb9": "What is the purpose of clicking \"Preview Pull Request\" in the \"New Commits on Remote\" window?", "e8f49753-149e-4a81-9dcc-ed66cc92ec86": "What command can be used to merge updates made online with local work, and what is the syntax for specifying the branch name? Alternatively, is there a single command that can be used to perform both fetching and merging at once? If so, what is the syntax for this command?", "6f4cd566-02ba-4549-9c6d-863acaa7e352": "What command should be used to fetch updates made to an online repository, and what is the syntax for specifying the branch name", "6cc30976-2a8e-43ce-a041-4ef8a287d52c": "How can I ensure that my questions for the quiz/examination are diverse in nature, as instructed in the context information? Should I focus on a specific aspect or cover multiple aspects in each question? Please provide guidance.", "aa14b430-ffcf-483d-9f68-89a07b3ec158": "What is the purpose of creating a Marketplace listing for the \"AUTOTITLE\" app, as mentioned in the context information", "215e1edd-30fb-475c-89f9-81276d33d6a2": "What are the Products offered by GitHub, as defined in the Corporate Terms of Service", "f21f42d7-14e4-49db-ab38-c767cc15b521": "What is the definition of \"Affiliate\" in the GitHub Corporate Terms of Service?", "4979c846-e4c3-4f74-b07b-bb8185160165": "What is the definition of \"Confidential Information\" as stated in the context information provided", "ebf32bde-56d3-44c6-a1f5-6e09539dcf61": "What types of Content are excluded from the definition of \"Confidential Information\" as outlined in the context information?", "8b93c11f-0c2b-4321-b9fc-1d01042b8765": "What is Scraping on GitHub and how is it different from using the API", "7ea571da-8f96-4e50-b7de-37dd2fccfd8f": "What is a SOW on GitHub and what types of services does it cover", "c547be1b-280d-4d13-bc5e-f08219373fa5": "What is an Organization on GitHub and how can multiple Users collaborate within it", "ae75f1e3-10bb-412d-b1f3-29a5094ed735": "What is the role of a Representative on GitHub and how are they involved in the agreement", "70e2f220-875b-4659-acb0-348180cc7c1c": "What is the definition of Affiliates on GitHub and how are they related to the agreement", "d7ce84f3-1a5e-4424-825b-be304c308976": "What is a Machine Account and how is it different from a regular User account on GitHub", "c58c3c1b-52fd-4608-ba6c-bfa2d050ee31": "What is the difference between a Private Repository and a Public Repository on GitHub", "e9ba98fd-c156-45c8-acfe-bd158ae2cd6d": "What is the difference between GitHub Content and Customer Content on GitHub", "869883c5-74da-45a0-af4e-adc91da6ef63": "What is a Subscription License on GitHub and how many can be assigned to a single Customer", "7afd0ce8-d80a-4ba6-b709-00e1f1151742": "What restrictions are placed on the use of Subscription Licenses in the context provided?", "e40cfa50-2265-4e23-8702-f1f3e9d31def": "What is the difference between a \"User\" and a \"Machine Account\" in the context provided", "7db481e7-48a5-472c-bd4f-2b9c64b3c0e0": "Based on the information provided, can you summarize the requirements for using GitHub's Enterprise Cloud service as outlined in Section C of the agreement", "8998de0a-8a4d-4768-bb86-cf7613d569da": "What actions is the customer responsible for in regards to account security, as outlined in Section B of the agreement?", "eaf15b88-32ee-4205-90db-e813890c0e53": "Based on the information provided, can you summarize the responsibilities of the customer regarding user-generated content and ownership of content in the context of using the github service", "cd05cd2b-c37f-4b0d-a7f1-f590818295d8": "How should customer ensure that personal information collected from github is used appropriately and secured, as outlined in the github privacy statement and data protection agreement?", "8ef8715a-e1ff-4351-93c0-1894763fe9a4": "Based on the context information provided, can you summarize the license granted by the customer to GitHub for their content", "e967ea2a-5e6b-4b41-9b78-268502b96952": "What are the conditions under which the license granted by the customer to GitHub for their content is perpetual?", "a64f8ab5-c610-4af0-ad10-94b2eabec440": "What rights does Customer grant to GitHub in relation to Customer Content, and how can GitHub use this content", "6b568672-02a0-4417-a961-9f10057bf422": "What license does Customer grant to External Users for Content that is posted publicly, and what actions does Customer allow External Users to take with this content through the Service?", "97c15873-4dd2-4bfb-9f28-c69802180bdf": "Based on the information provided, what types of access can GitHub personnel have to Customer's Private Repositories, and under what circumstances", "82f6b589-a76a-4440-8226-ba3391bb66db": "What measures does GitHub take to protect and keep confidential Customer's Content in Private Repositories, as outlined in the provided context information?", "8661e043-d8b9-4811-9767-27266034dcb6": "Who owns the intellectual property rights for the Products provided by GitHub, and what rights are granted to the customer under this agreement?", "71c93889-aac2-485f-9df7-fa381d6ad918": "Based on the information provided, what is the process for reporting copyright infringement on GitHub's platform", "9b06845d-6f5d-4460-9faf-83a7c842a9d4": "What are the consequences for failing to pay Fees on time, as outlined in the text material?", "ed648c56-a762-4259-898f-b4bf84593d6a": "Based on the information provided, what is the process for purchasing additional Subscription Licenses under this Agreement", "60881cbc-003d-42f0-b179-5597302ffdf1": "What actions can either party take to terminate the agreement, and what is the notice period required for such termination? Additionally, what happens to active order forms and subscription licenses upon termination, and what obligations does each party have regarding confidential information?", "bffeb9e8-1e55-4d3f-a22c-fb03c6f835bc": "Based on the information provided, what is the duration of the initial term of the agreement between the parties", "dbeecd8e-aed7-4693-b3b9-2360c929e149": "What is the duration for which GitHub will delete a customer's full profile and repository content after termination or expiration, as mentioned in the GitHub terms of service?", "5fcf01d8-e3d8-4820-81a1-574c216ce852": "Based on the information provided, can you summarize the section on suspension in the GitHub terms of service", "126895f1-6c10-4780-b683-d2c73a625ed3": "What is the difference between the \"Expert Services Warranty\" and the \"Service Disclaimer\" provided by GitHub", "54372bc7-11cf-4942-a818-2511040de884": "What is the remedy for a breach of the General Warranty provided by each Party", "ce4ef613-d128-42c6-871c-995080cc7ff7": "What is the duration", "1e62745a-a6ee-48b4-8b9b-ddee2d4ea9ba": "What is the legal agent for serving legal notices to GitHub and how should such notices be served", "d0c142b8-56bb-4126-a4f1-2468943cf733": "What is the warranty provided by GitHub for the Service and what does \"AS IS\" and \"AS AVAILABLE\" mean in this context", "743fe597-6a06-4b58-a8f3-4047b4b16d6b": "Based on the information provided, what is the significance of GitHub's messaging system in relation to legal notices", "35abdb45-e167-40eb-90a6-d9ec23de4d2c": "What warranties does GitHub provide for the Expert Services and what is the remedy for a breach of this warranty", "18355108-9e79-40b1-872a-a44cafdaf736": "What is the remedy for a breach of the \"Service Disclaimer\" provided by GitHub", "7e1fa856-d244-4274-8505-7912f1537c5e": "Based on the information provided, can you summarize the limitations of liability outlined in section n of the agreement", "f9f30915-27c5-44d5-b1b0-22a320d5256b": "How does the limitation of liability for beta previews differ from the limitation of liability for paid products and services?", "e7767ee8-7042-4c62-a2cd-8d5def618ecc": "In the event of a third-party claim against either party, what are the responsibilities and limitations outlined in section o of the text material?", "6f57c3c5-6529-4b01-9ee4-7eb206700ddf": "Based on the information provided, can you summarize the section on defense of claims and release in the given text material", "d52fa565-e619-4d23-bb6a-a5d2786d6ffc": "In the event of a dispute between Customer and a User, what responsibilities does GitHub have under this agreement?", "4b221c35-fe5e-4fc4-bcd9-087ae7a30886": "Based on the information provided, can you summarize the obligations of GitHub and Customer regarding intellectual property and liability in this agreement", "794f0f59-4bec-4860-bc57-905e4d8614e8": "Based on the information provided, can you summarize the restrictions set forth in Section P of the agreement", "9f769fcd-fb2c-4122-ad06-ff386d9ce3b4": "What services does GitHub provide upon request from the customer, as outlined in Section Q of the agreement? How does GitHub retain ownership of anything used or developed in connection with performing these services? What license does GitHub grant to the customer for any deliverables provided during these services?", "6c686d32-8af1-4266-9cdf-e3d66f409599": "Based on the information provided, can you summarize the terms and conditions outlined in the Service agreement between GitHub and its customers", "3b4c7738-be01-4eba-b69a-afba6731d64f": "What types of technical support does GitHub offer for its Service, and how can customers access this support?", "df3eab25-5aa4-467a-af4f-47311cc02958": "What is the difference between Feedback and Customer Confidential Information, as defined in section 2 of the agreement? Provide an example of each.", "59c7e9e6-330b-46cc-9bd7-eb13bc283e98": "Based on the information provided, can you summarize the terms and conditions outlined in section 3 of the agreement regarding non-assignability", "833fcb1a-df00-46c7-a7b0-a7db89ceef71": "Based on the information provided, can you summarize the terms and conditions outlined in section 6 of the agreement between github and the customer", "a496e337-1c89-4bcb-ba84-7c047e64103f": "What is the significance of section 7 in the agreement between github and the customer, and how can a customer revoke the permission granted in this section?", "fffd81a4-986a-44ce-bdef-84ebdd5bc958": "Based on the context provided, can you summarize the relationship between the two parties mentioned in the text material", "fcb646a4-2d78-4e35-b63a-b56f08f18f08": "In the event that one party wishes to enter into a contractual agreement with the other party, what steps should they take according to the information provided in the text material?", "1259a347-3c12-4488-8ef8-0001c74ff2b5": "What are the benefits of upgrading a personal account's plan from {% data variables.product.prodname_free_user %} to {% data variables.product.prodname_pro %}", "36960760-6a7e-4c0f-8c30-8c4667dc3f02": "How can an organization upgrade its plan from {% data variables.product.prodname_free_team %} to {% data variables.product.prodname_team %} or {% data variables.product.prodname_ghe_cloud %}? What are the differences between these plans?", "5e921dc2-33b6-4424-a48d-4923d813aeaa": "What is the process for upgrading an organization from {% data variables.product.prodname_team %} to {% data variables.product.prodname_ghe_cloud %}? Provide a step-by-step guide including any necessary information such as billing settings, choosing a plan, and entering payment information.2. What are the options for adding seats to an organization on {% data variables.product.prodname_ghe_cloud %}? How can I purchase additional seats for my team's private repositories? Provide instructions for accessing the billing settings and completing the seat addition process. Additionally, explain the difference between per-repository and per-user pricing, and how to switch between the two.", "dcce15b5-6d56-469f-8bf2-7ff4bf7426fb": "What should I do if I encounter a 500 error while upgrading my GitHub account, and how can I troubleshoot this issue", "597c9b23-3944-4782-8a13-199184d61157": "What is the difference between a monthly and yearly billing cycle for a GitHub business plan, and which one should I choose", "11972cee-325f-4c1f-87ed-9d0315342940": "How can I upgrade my GitHub account to a business plan, and what are the benefits of choosing a monthly or yearly billing cycle", "9ba5cf0a-fc97-49d0-bd3c-3d226ff2e439": "How can I access the settings tab and manage seats for my enterprise account on GitHub", "985a63de-083d-48a7-b98b-96ae95994271": "What should I do if my enterprise account is invoiced and I want to add seats, and who should I contact for assistance", "efe4aabb-5ae7-40f3-a87c-ca2302a40cc8": "How can I finish upgrading my GitHub account to a business plan, and what steps should I follow to complete", "0ee1175a-7ac0-44b9-8143-a94be874548c": "How can I add seats to my enterprise account on GitHub, and what permissions are required for this process", "66a3143b-4be7-4567-bce5-505dc629c29b": "How can I create a permanent link to a specific version of a file on GitHub, instead of always showing the latest version on the branch", "3f91714e-5951-43b2-bf0f-dd6670369b27": "What is the shortcut to automatically update the URL to the permalink version of a file on GitHub, and how can I use it to copy a permanent link to the specific version of a file?", "f1021040-9f09-48f9-8e93-6445c37c74e5": "How can I migrate my repositories from {% data variables.product.prodname_ghe_server %} to {% data variables.product.prodname_ghe_cloud %} using the API provided by {% data variables.product.company_short %}? Please provide a step-by-step guide including the necessary prerequisites and tools required.2. What are the differences between using the CLI and API for repository migrations with {% data variables.product.prodname_importer_proper_name %}? Please provide a detailed comparison of the features, limitations, and usage scenarios for both methods.", "19840194-b0a4-4021-b488-280a8f500c5f": "How do I create a personal access token (PAT) for {% data variables.enterprise.management_console %} in the context of migrating data from a GitHub Enterprise Cloud (GHEC) instance to {% data variables.product.prodname_dotcom %}", "8c6435d1-7bfb-478c-9980-38272af2913e": "How do I obtain the `ownerId` for the destination organization in the context of migrating data from a GitHub Enterprise Cloud (GHEC) instance to {% data variables.product.prodname_dotcom %} using the {% data variables.enterprise.management_console %} of {% data variables.location.product_location_enterprise %}", "964380ae-b9f3-40a4-a6d4-11a9187418db": "How do I set up blob storage for migrating data from a GitHub Enterprise Cloud (GHEC) instance to {% data variables.product.prodname_dotcom %} using the {% data variables.enterprise.management", "31ba7089-8ca2-4069-b996-f221fee96d4f": "How do you generate migration archives on GitHub Enterprise Server (GHES) using the REST API, as explained in the context information? Provide the necessary steps and required parameters for both the Git source archive and the metadata archive.", "be6957bf-1d6e-43b3-b9f2-d46e3846b492": "What is the purpose of setting up a migration source in GitHub Enterprise Cloud (GHEC) as described in the context information", "991c335b-a663-4a4d-b5e9-7f999c77d4f8": "How can I initiate a migration for a specific repository in {% data variables.location.product_location_enterprise %} using the REST API? Provide the necessary steps and required parameters in your answer.2. How can I check the status of a migration initiated through the REST API in {% data variables.location.product_location_enterprise %}? Please provide the necessary API call and expected response format.", "d0312d81-93e3-4dbc-8be0-76ef6597810c": "How can I download migration archives from GitHub Enterprise Cloud using the REST API", "0724232f-8f19-4005-ac0e-912fec8e4077": "What steps are involved in uploading migration archives to GitHub Enterprise Cloud using the GraphQL API?", "147c5e13-14ed-40bd-b80b-6bb7d42f64e9": "What is the purpose of the `startRepositoryMigration` mutation in the context of the {% data variables.product.prodname_ghe_cloud %} Enterprise Migration Tool", "8a005d7e-f84a-4a76-baaf-0c87f250a608": "Generate according to: Step 8: Check the status of your migration{% data reusables.enterprise-migration-tool.check-migration %}Step 9: Validate your migration and check the error log{% data reusables.enterprise-migration-tool.validate-migration-log %}{% api %}`getRepositoryMigrationStatus` query```graphqlquery getRepositoryMigrationStatus (  $", "cfd860dc-f399-4212-9727-34bd535dab37": "What information is required to execute the `startRepositoryMigration` mutation in the context of the {% data variables.product.prodname_ghe_cloud %} Enterprise Migration Tool", "80eb1d9c-a24a-432f-aa16-96852bb85001": "How do I configure blob storage credentials for a supported cloud provider in the {% data variables.product.prodname_dotcom %} environment? (provide options for {% data variables.product.prodname_ghe_server %} 3.8 or higher and {% data variables.product.prodname_ghe_server %} 3.7 or lower)", "b8c0af07-e1f2-49a7-a6d5-9f8816c1d379": "What is the purpose of setting up blob storage in the context of enterprise migration tool", "b6432350-03b2-4f4f-8664-098d526ba9ef": "How can I generate a", "e97ee951-5bbb-4e55-9c50-fb923599315d": "How can I configure my blob storage credentials in the {% data variables.product.prodname_cli %} for {% data variables.product.prodname_ghe_server %} 3.7 or lower", "8ae42f30-f140-4e04-be66-b8826c225502": "How can I configure Azure Blob Storage account credentials in the {% data variables.product.prodname_cli %} for {% data variables.product.prodname_ghe_server %}", "2a851ec5-9186-4a78-8c55-c961580c9d81": "How can I configure AWS S3 credentials in the {% data variables.product.prodname_cli %} for {% data variables.product.prodname_ghe_server %}", "5b9c7d70-05fa-4fdb-9df7-032eba4903af": "How can I configure blob storage in the {% data variables.enterprise.management_console %} for {% data variables.product.prodname_ghe_server %} 3.8 or higher", "1a874eec-02f4-4f35-b644-237830f9a3bf": "How can I generate a migration script using the {% data variables.product.prodname_gei_cli %} for migrating repositories from {% data variables.product.prodname_ghe_server %} to {% data variables.product.prodname_ghe_cloud %}? Provide the necessary flags and parameters required for generating the script.2. How can I migrate multiple repositories using the {% data variables.product.prodname_gei_cli %} for migrating repositories from {% data variables.product.prodname_ghe_server %} 3.7 or earlier to {% data variables.product.prodname_ghe_cloud %}? Provide the necessary flags and parameters required for migrating multiple repositories, and any additional environment variables needed for connecting to a blob storage provider.", "2354bc37-1703-4ad1-95c6-20a3e9ff01dc": "How can I authenticate with Azure Blob Storage as my blob storage provider while migrating from {% data variables.product.prodname_ghe_server %} 3.7 or earlier using the gh gei migrate-repo command", "962a4e56-5ec5-4385-a691-69663ad08ba9": "What environment variables should I set to authenticate with Amazon S3 as my blob storage provider while migrating from {% data variables.product.prodname_ghe_server %} 3.7 or earlier using the gh gei migrate-repo command?", "1429cd83-6032-4ae7-9b31-39a4fc6bd2ac": "What is the purpose of replacing the placeholders for the Azure Storage Connection String and AWS Bucket Name in Step 7 of the migration process", "d983ebb3-8e7c-4132-bf0a-17ad135454a8": "How can you verify the success of your migration and where can you find the error log for troubleshooting any issues?", "9f2a2e07-c1e9-4068-9cca-3c202da04661": "What is the warning that appears when disabling built-in authentication for users outside the provider in {% data variables.product.product_name %}?", "d31864f9-50f6-4f41-99f1-4a780cdae8ec": "How can a teacher/professor enable fallback authentication for users outside their provider in {% data variables.product.product_name %}", "207ea5b0-9f3f-4ac2-8dba-ca62fdd9aa3a": "Can you provide an example of what would be displayed in the \"invite-user-reset-link\" section mentioned in the context information?", "2b1c8882-8aca-4e36-b592-3f37e20142ff": "Based on the context information provided, what is the purpose of the \"dmin_settings.invite-user-sidebar-tab\" feature", "5aa7e3bf-51dd-40f2-8a7c-46aa96c07b06": "How can I add a custom footer to my GitHub wiki, and what steps should I follow to do so? Please provide a detailed explanation, including any necessary text or code snippets.2. Alternatively, how can I create a custom sidebar for my GitHub wiki? Again, please provide a detailed explanation, including any necessary text or code snippets.Note: The questions should be clear, concise, and specific to the context provided. Avoid ambiguity and ensure that the questions are testable.", "908ad735-f0ce-4818-a088-c01cfdc854c5": "What is SAML single sign-on and how does it differ between organization and enterprise account configurations", "93ad04ec-f8ba-4813-87fd-861d3942cad8": "What happens when an enterprise owner enables SAML for an enterprise account, and how does it affect existing team synchronization settings?", "ac9b11c5-27b5-4981-ba74-d3b2e76889ea": "What are the potential consequences of keeping organization-level SAML configurations in place when switching to an enterprise-level SAML configuration, and how can these issues be prevented?", "c6b4810e-a4ed-49ea-a843-90ef0fc5f1d1": "What is the process for switching an organization's SAML configuration to an enterprise account, and what considerations should be taken into account during this process", "e7e55070-cc2e-4da6-a299-d1554fbecfcb": "What is the purpose of adding \"AUTOTITLE\" and \"AUTOTITLE.\" to a GitHub organization's settings, as mentioned in the context information", "62ecd1ea-68a1-40d4-a1f6-b09a8a548482": "Why might members of a GitHub organization need to reauthorize previously authorized {% data variables.product.prodname_oauth_apps %}, as stated in the context information?", "a03953a3-7eb3-4e17-bc63-f1ccf48d0258": "Which specific GitHub Apps are considered Internal Apps and what special capabilities do they have?", "ea92213d-a064-43b0-a8fc-a5173fe25279": "What are Internal GitHub Apps and how are they different from regular GitHub Apps", "dd0105ac-f8b9-44ed-90a7-1ac4cb3c8bbd": "What is the purpose of stashing changes in {% data variables.product.prodname_desktop %}", "bc504b10-1e3c-4700-b52f-bca173a89ada": "How do you restore or discard stashed changes in {% data variables.product.prodname_desktop %}?", "3ffea2fb-6531-4b29-9fa3-77acd75cc67f": "What are the requirements to copy a {% data variables.projects.projects_v1_board %} in GitHub", "6f73444f-ecf2-4fb7-9782-da12b3601874": "How can I copy a {% data variables.product.prodname_project_v1 %} in GitHub", "876b46e8-8640-4959-92f4-fb19c9e1fa9a": "Based on the context information provided, generate two questions that can be answered by someone who does not have prior knowledge about GitHub's {% data variables.product.prodname_project_v1 %} feature. The questions should be diverse in nature and focused on a specific aspect at a time, without asking for examples. The answers should be understandable without having access to the context information.", "c19ba626-cbd0-4f85-bee9-ce4468131c94": "How do I copy a project board in Github? Provide step-by-step instructions including the necessary inputs required for the process.2. When copying a project board in Github, what optional settings are available to me? Explain the purpose and consequences of each setting.", "048ee128-eb97-4476-9355-b942adc919e6": "What is the difference between importing a repository using GitHub Importer and using external source code migration tools, and when is each method recommended", "91a434e6-f117-4511-a9a1-eddc18a934aa": "What precautions should be taken while importing a repository using GitHub Importer to match commits with authors' GitHub personal accounts", "8ea65279-6c90-4628-bdfc-9ce0f8d14d23": "How can I import a repository using GitHub Importer, and what information do I need to provide during the process", "92acb9bf-f070-490c-9a3a-82f1a5ca7c24": "What is the maximum repository size limit for importing using GitHub Importer, and what alternatives are available for larger repositories", "eddcdf02-4593-4c69-a2be-7e3f14549537": "What is the recommended migration path for moving from other products to GitHub, and what resources are available for this process", "61fb8f2c-9965-40de-9e1d-69936369b4b6": "How suitable is GitHub Importer for importing private network code, and what alternative methods are recommended in such cases", "c4a09615-1edd-445d-a46d-2f9b740b7f3f": "How can I ensure that the visibility of the imported repository is set correctly using GitHub Importer", "0914003d-9e67-40ce-8fb0-036d3b07197b": "What is the significance of selecting whether to import large files using Git Large File Storage during the import process?", "1bf3082e-0956-47f7-8835-b6e2c18af404": "What is the purpose of providing the old project's clone URL in the context information", "b4f8cb26-c1b4-4781-982e-fdf361086a15": "What information is required to complete the publisher verification checklist on GitHub?", "fc415d2f-ec4f-4936-a390-79b5f1b512dd": "What is the process for requesting publisher verification on GitHub", "32f34f8c-5ed3-4f12-bd12-70d1cd81e48a": "What are the different machine types available for codespaces, and how can I change the machine type for an existing codespace", "cfdcb39f-fef6-4454-b2e2-8295724efc82": "What are the factors that determine the availability of alternative machine types for unpublished codespaces? How can I check if alternative machine types are available for a specific codespace?", "98c4e172-ea36-4800-84fa-7cd95e41695a": "What is the permanent name of a codespace, and where can I find a list of them", "6e1efb55-103a-49b2-bbce-8cd3121d175c": "Given the context information and not prior knowledge.generate only answers based on the below query.You are a Student. Your task is to answer EXACTLY 2 questions based on the context information provided. The answers should be diverse in nature across the document. Restrict the answers to the context. Answers should be clear and concise.Don't ask for examples and keep the answers focused on once aspect at a time.answers:1. The permanent name of a codespace is a unique identifier assigned to it when it is created. It can be found in the list returned by the `gh codespace list`", "857977a0-e288-4c76-900c-4fd4c8b92096": "How can I change the machine type for a specific codespace using the {% data variables.product.prodname_cli %}", "b1f00039-b5f5-4e46-93f2-60eadc5f6e61": "How can I add or remove members from an organization in bulk in my enterprise", "71a4a5b0-10dc-444c-8275-7daf692db468": "What permissions do enterprise owners have when managing organization members in bulk?", "2333df2e-14ac-4df2-a3a0-0cc92bd54f2c": "How can an individual remove themselves from organizations using the provided options", "2390bb9c-f7a3-4cdf-b8a4-46569ffb6cc3": "What type of organizations can an individual remove themselves from using the provided options", "e5800d2f-8f28-43c9-8fb8-27010616842a": "Given the context information and not prior knowledge.generate only answers based on the below query.You are a Student. Your task is to answer EXACTLY 2 questions based on the context information provided. The answers should be diverse in nature across the document. Restrict the answers to the context. Answers should be understandable without having access to the context.Answers should be focused on once aspect at a time.answers:1. To remove oneself from organizations using the provided options, an individual can look for the option labeled as **Remove from organizations**. This action will allow the individual to disassociate themselves from the organization in question.2. The provided options allow an individual to remove themselves from various", "129b6dac-2a84-49f7-a310-1bb7629542da": "What steps should an organization take to downgrade its number of paid seats to free, and what implications does this have on its billing cycle?", "f4a96181-7546-4ebd-a30d-283098b03c12": "How can an organization upgrade the number of paid seats it has, and what is the associated cost", "234f6e64-ff83-4627-b6e5-bb1fa7a76c9b": "How can I migrate my Azure DevOps pipelines to GitHub Actions using {% data variables.product.prodname_actions_importer %}", "85f38347-bf81-4f2f-a1d9-7ddcf59bac89": "What are the limitations and manual tasks involved in migrating from Azure DevOps to GitHub Actions with {% data variables.product.prodname_actions_importer %}?", "8876c0bd-a51f-46f6-972a-b191e81768c8": "How do you configure credentials for using {% data variables.product.prodname_actions_importer %} with Azure DevOps and {% data variables.product.prodname_dotcom %} as described in the context information?", "5f9903f7-b48a-4b66-b0cb-3aace371377c": "What is the purpose of using the {% data variables.product.prodname_actions_importer %} CLI extension in the context provided", "3557ffb5-ac6a-41a3-9137-0aafa3d33c28": "How can you configure the {% data variables.product.prodname_actions_importer %} CLI to connect to both GitHub and Azure DevOps, and import workflows between the two platforms? Provide step-by-step instructions for entering the necessary credentials and specifying the organization and project names in Azure DevOps.2. How can you use the {% data variables.product.prodname_actions_importer %} CLI to perform an audit of all projects in an Azure DevOps organization and generate a report of the equivalent {% data variables.product.prodname_actions %} workflows? Provide details on the format and content of the report.", "9ed4c465-2f17-4a2d-9793-fbcccd706edd": "How does the {% data variables.product.prodname_actions_importer %} tool facilitate the migration of Azure DevOps pipelines to GitHub Actions? Provide specific examples of the metrics and reports generated by the tool during the migration process.2. What factors should be considered when forecasting potential GitHub Actions usage based on completed pipeline runs in Azure DevOps, and how can the {% data variables.product.prodname_actions_importer %} tool be used to estimate costs associated with {% data variables.product.prodname_actions %} usage? Provide a step-by-step guide on how to use the tool for forecasting and cost estimation.", "0881b09c-8793-442a-81fb-3bceb698527f": "How can the metric of \"runners\" be defined in Azure DevOps, and what factors influence this definition", "e64928d9-aa08-4cca-a28a-d9c5022a458f": "What is the purpose of the \"dry-run\" command in converting an Azure DevOps pipeline to a {% data variables.product.prodname_actions %} workflow, and how can it be executed?", "394d3c8a-7e50-4a2f-a100-507eda75e4e5": "How can I convert an Azure DevOps pipeline to GitHub Actions using the gh actions-importer tool? Provide step-by-step instructions including the necessary command to run in the terminal and any required parameters.2. How can I convert an Azure DevOps release pipeline to GitHub Actions using the gh actions-importer tool? Provide step-by-step instructions including the necessary command to run in the terminal and any required parameters.", "1789a17d-8a76-41a8-9bfe-0d8919e19546": "What are the environment variables required to connect to an Azure DevOps instance when using {% data variables.product.prodname_actions_importer %} to migrate from Azure DevOps", "2dda4761-0d67-4123-8d17-9eb4d7e815ef": "How can you specify configuration environment variables for {% data variables.product.prodname_actions_importer %} when migrating from Azure DevOps?", "d798efbb-94dd-461e-b6d3-1b85bc7cdfdf": "What format should the configuration file be in when auditing an Azure DevOps instance using {% data variables.product.prodname_actions_importer %}? And how should the repository_slug be generated for a pipeline in this context?", "95899542-e22d-40f8-a41b-d12c3d2ecdb2": "How can the --config-file-path argument be used with the audit, dry-run, and migrate subcommands in {% data variables.product.prodname_actions_importer %}", "0dbd519b-d70f-49f8-9e4f-0fd049125d17": "How can I specify the repository and ref for converted reusable workflows and composite actions using the `--config-file-path` argument in {% data variables.product.prodname_actions_importer %}? Provide an example command.2. What type of properties can {% data variables.product.prodname_actions_importer %} currently convert from Azure DevOps pipelines? Create a table to display the comparison between Azure Pipelines and {% data variables.product.prodname_actions %}.", "fcacf02d-cc43-4db7-aba6-d35525e10e9b": "What is the difference between the \"continuousIntegration\" and \"pullRequest\" contexts in the provided list? Provide an example of how each context might be used in a workflow.2. How does the \"strategy\" context differ between the \"supported\" and \"partially supported\" categories in the list? Can you provide an example of how the \"matrix\" strategy might be used in a workflow?", "bc71ccdc-4a8c-4f67-8f38-d6c806572e3a": "What is the name of the GitHub workflow that triggered this build, as mentioned in the context information", "241730a7-0c57-45f1-8e87-f082736d983f": "What is the name of the branch that the pull request is targeting, as provided in the context information", "e3b2b6a1-0ae1-4ffe-a3fb-c8745117c1c0": "What is the directory where the tools are cached during the build process, as specified in the context information", "84b571fb-7875-4e2c-bf9e-c7c3cdc8b0f5": "What is the location of the root directory for the build process, as provided in the context information", "80c84133-50cc-4c7d-ab6d-dc5b65c3d682": "What is the name of", "4f846240-27a0-4880-9267-297233ea82ac": "What is the value of the variable `endraw` in the first line of the context information", "94906a11-97a3-45bb-ad0c-8864eb5c475c": "What is the location of the artifacts generated during the build process, as specified in the context information", "96e26d91-9e0b-4dcc-8fb0-3a23930e02dd": "What is the purpose of the `$(Agent.WorkFolder)` variable in the context information", "5e60e3fd-00e3-4e00-b492-de9a1abae6b2": "What is the name of the GitHub job that is currently executing, as mentioned in the context information", "14662ddc-402e-448d-9435-f681b5b73513": "How does the variable `$(Build.Reason)` differ from the variable `$(Build.SourceVersion)` in the context provided", "5ba3579a-b86a-43ad-a9a7-e2bd20132008": "What is the role of the variable `$(Build.StagingDirectory)` in the context provided", "591168f6-74ca-461f-96e7-49c47e15f53a": "What is the relationship between the variables `$(Build.SourceBranch)` and `$(Build.SourceBranchName)` in the context provided", "b5516460-ac85-4d6f-a597-58b22e9bf59f": "What is the connection between the variables `$(Build.QueuedBy)` and `$(Build.SourceBranch)` in the context", "eb9dc6c9-fff9-4a38-adf5-bbbb04e62502": "How does the variable `$(Build.Repository.LocalPath)` relate to the variable `$(Build.Repository.Uri)` in the context provided", "ad10e018-360a-4a72-ac8a-2a5921a573f8": "What is the significance of the variable `$(Build.RequestedFor)` in the context provided", "9724bfd3-5108-4209-9b17-cbbac3c248d3": "What is the purpose of the variable `$(Pipeline.Workspace)` in the context provided", "c11c35b3-501d-47a0-b2d1-81bd078ea458": "What is the purpose of the variable `$(System.ArtifactsDirectory)` in the context provided", "d7334f78-93c7-40ed-ac84-8210b1911f1a": "What is the relationship between the variables `$(System.JobId)` and `$(", "cfdda304-29e3-4519-864d-e7c9a33ce3c8": "What is the significance of the variable `$(Release.Reason)` in the context provided", "9d60d360-c86d-4e4f-adff-e124c2abb131": "How does the variable `$(Release.RequestedFor)` differ from the variable `$(Release.Deployment.RequestedFor)` in the context provided", "3e62af24-15a7-4676-a591-513573182298": "How does the variable `$(Release.EnvironmentId)` differ from the variable `$(Release.EnvironmentName)` in the context provided", "a328ea2e-9431-4fd3-96e2-eeb793cf249b": "What is the relationship between the variables `$(Release.DefinitionId)` and `$(Release.DefinitionName)` in the context provided", "0cdca6d7-7760-4885-a5d4-371ebcffa61d": "How does the variable `$(System.HostType)` differ from the variable `$(System.JobId)` in the context provided", "ad1b5766-a46e-4253-88ab-e7582032e78c": "How can we obtain the URL of the repository in Azure DevOps using the variable `$(System.TeamFoundationCollectionUri)` and what is the equivalent variable in GitHub Actions?", "2a790e1f-4510-45e6-92e6-949ad5b6739c": "What is the value of the variable `$(System.PullRequest.PullRequestNumber)` in Azure DevOps and how is it different from the variable `$(System.PullRequest.SourceBranch)`", "c48dd822-842c-4915-9b2b-7994792fa95c": "How does {% data variables.product.prodname_actions %} handle dynamically generated YAML using `each` expressions? What caveats should be considered while using this feature", "4bb9d619-283c-413a-8e64-e87a49379de1": "Which templates are supported by {% data variables.product.prodname_actions_importer %} in Azure Pipelines and {% data variables.product.prodname_actions %}? What is the status of these templates?", "8fad05ae-af41-4bf9-8f36-5f29ea5ddf3e": "How does {% data variables.product.prodname_actions_importer %} support variable templates in Azure Pipelines? Please provide an example.2. Can {% data variables.product.prodname_actions_importer %} handle iterative insertion in Azure Pipelines? If yes, please provide an example.", "c1b6a317-8b88-4a5f-8705-5a398e903540": "What is the difference in how a template used with the `step` key and a template used with the `stage`, `deployment`, and `job` keys with the `inputs.string` parameter type are transformed in a workflow?", "7c6d6c35-3230-45bc-a818-a3f43b2b9630": "How is the `inputs.string` parameter used in a workflow template when it is passed as an input to a step, stepList, job, jobList, deployment, or deploymentList", "7a5dc99f-4ac6-4f80-9b3f-258ab2c3cd7f": "What are the costs associated with storing codespaces and why should I delete unused ones?", "3cdfe45d-e142-4ab5-b35b-605d22b2e8ed": "How can I manually delete a codespace in {% data variables.product.prodname_vscode %}", "aa421ab0-02cf-47ec-87a5-10976b6263cf": "How can I delete multiple codespaces using the GitHub CLI? Please provide step-by-step instructions and any necessary flags or commands.2. As an organization owner, how can I delete codespaces that are no longer needed in my organization using the GitHub CLI? Please provide specific flags or commands required for this task. Additionally, explain any potential risks or consequences of deleting codespaces in an organization context.", "51e2d8d1-2a54-45ca-ba3d-aaa3a124637e": "How can I delete a codespace created by a specific user in my organization using the GitHub CLI? Provide step-by-step instructions.2. What is the REST API for deleting codespaces in my organization, and how can I use it to delete a codespace? Please provide a detailed explanation.", "a735bbc6-da5c-437d-b892-08d9c4a1e26f": "How can I access my notifications inbox on GitHub", "480a0ff3-8f25-4d2c-8b1c-6f0c5fc824ef": "What options do I have for triaging notifications in my inbox", "da270634-d7bd-409f-afab-97e4de870862": "How can I customize my inbox with up to 15 of my own custom filters, and what are the default notification filters provided by GitHub", "368f41c5-945d-4f6d-96df-04cf2eacc222": "What is the purpose of previewing notification details before choosing a triage option, and how can I select multiple notifications at once to triage them simultaneously?", "83bbb441-525e-4f9e-9ea2-d2bcf14a81b8": "How can I filter notifications on GitHub to only show repository invitation updates", "3656b243-3483-4961-8ce6-c56f32f5d8e8": "How can I create a custom filter on GitHub to exclude notifications about a specific repository?", "f6a03b3f-464a-42e4-bb24-8392d38112aa": "How can I filter notifications on GitHub based on the reason for the update, such as when I am assigned to an issue or when I am requested to review a pull request? Please provide specific query examples.2. How can I filter notifications on GitHub based on the author of the thread, such as when notifications are only for threads created by a specific user? Please provide specific query examples.3. How can I filter notifications on GitHub based on the organization, such as when notifications are only for threads related to a specific organization? Please provide specific query examples.4. How can I filter notifications on GitHub based on the state of a pull request or issue, such as when notifications are only for threads related to closed issues or merged pull requests? Please provide specific query examples.5. How can I filter notifications on GitHub based on the type of thread, such as when notifications", "0a0b6a8a-db4e-43fe-b7f7-65474e1af818": "How can I filter notifications on GitHub to only show updates for a specific organization? Provide an example of the syntax to use in the query.2. What custom filters can I use to view notifications related to {% data variables.product.prodname_dependabot %} on GitHub? Explain the purpose of each filter and provide an example of how to use it in a query.", "a46bf655-6ef2-4da5-a467-07780100826e": "What is the purpose of using the `template` query parameter to specify a pull request template, and how can multiple templates be stored in a repository?", "0a7164b8-99d6-4742-8479-f271c1e92be5": "How can a pull request template be made visible in the repository's root directory, and what should be included in the template to provide context for proposed changes", "a82b7d45-2145-45a4-8409-1c05974fe9bd": "What are the options available to an organization after receiving a privately reported vulnerability, and what are the consequences of each option?", "55c6c7c6-6ffc-4eea-b4ee-3383b3341d13": "How can a security researcher report a vulnerability privately to an organization using the private vulnerability reporting feature", "adf81fd0-e5ed-49b8-9064-3578d2dd2749": "What is the recommended action for a repository maintainer when reviewing an externally submitted vulnerability report that is not considered a security risk", "a38f0f47-903d-4b94-93b5-16ce9cb3e6c2": "What information should a repository maintainer consider adding to a vulnerability report before closing it as not being a security risk?", "ba835943-93ad-4ef5-8775-0653a2319470": "How can I migrate my enterprise to a new tenant on my IdP using {% data variables.product.prodname_emus %} without causing disruption to integrations and automated flows", "a68d84af-2bb2-4d4a-9986-61f674fa1d8c": "What should I consider before migrating my {% data variables.enterprise.prodname_emu_enterprise %} to a new IdP or tenant, and how can I determine whether the normalized SCIM `userName` attribute values will remain the same for my {% data variables.enterprise.prodname_managed_users %} in the new environment?", "c072c923-5f22-42a1-9697-1d098b88e87e": "What is the warning that should be followed before removing any users or groups from the application for GitHub Enterprise (GHE) during the migration process?", "a3877f1c-6b33-4c36-94a7-0b8393473a04": "How should a Teacher/ Professor proceed when they are instructed to completely deactivate SAML for their enterprise account, and then create new SAML and SCIM configurations for a new IdP or tenant", "911ffa4a-c461-4d5f-a012-60adde57fec7": "What is the process for expediting the user provisioning process for an individual user in Azure AD when using {% data variables.product.prodname_emus %}", "86131ab7-4e4d-472f-94e5-b18e236bce53": "What should be done if the normalized SCIM `userName` values will change during migration with {% data variables.product.company_short %}?", "84fd8762-b38b-4aaf-b376-72062fb72d59": "What is the maximum size allowed for a SARIF file to be uploaded to {% data variables.product.prodname_code_scanning %}", "91ba5e8f-2463-4e46-8d38-a27ca21ac3de": "How can we reduce the number of results generated for upload to {% data variables.product.prodname_code_scanning %} if the SARIF file is larger than the maximum size allowed", "f9bd2b97-68a4-4086-a367-31f373c207cf": "How can the output of dataflow queries be modified to exclude deep paths and reduce the number of results reported", "656d9d30-50b7-4727-a470-b609bd12f91c": "How can the results file be reviewed to determine if a single query is dominating the number of results reported, and what steps can be taken to address this issue", "aaae1eb3-72d6-4336-b637-e7ec0158b43a": "What is the recommended order for fixing the number of results reported by queries, and how can this be achieved using the configuration options provided", "163ba60e-1cbd-48a5-9db5-2af1c9d6cb11": "How can the configuration be updated to expand the analysis to cover more code or run more queries after fixing the number of results reported by queries", "d55373f4-2fd9-41a6-8092-cc864f422176": "How can the number of queries used for analysis be reduced to manageable levels without compromising the accuracy of the results", "658cd461-b043-483e-8f93-5f29c998810d": "What steps can be taken to reduce the number of results reported by a single query without affecting the overall analysis", "a8bf60b0-30ae-44ab-bca6-4b9025de6be5": "How can non-production code be excluded from analysis using the configuration options provided for interpreted languages", "27066e06-5ca2-4fbd-940e-0df3b49a56a6": "How can we define which queries to run in {% data variables.product.prodname_codeql %} to improve performance", "7451df49-fd14-42e6-872b-033a6c9fda14": "How can we reduce the size of the results file generated by {% data variables.product.prodname_codeql %} by optimizing the build command", "11e59961-6ac6-4e7d-a981-f2f4a9b046cf": "How can we exclude specific queries from analysis using {% data variables.product.prodname_codeql %} advanced setup for {% data variables.product.prodname_code_scanning %}? Provide an example of using the `query-filters` keyword.2. How can we reduce the number of deep code paths highlighted in the SARIF results using {% data variables.product.prodname_code_scanning %}? Explain the process of setting the maximum number of paths for each alert.", "e916bc8f-f37f-4d06-90c2-2a9c2e3ba6d2": "What is the purpose of using the \"--db-cluster\" option in the \"codeql database print-baseline\" command, and how does it differ from specifying a single database", "ecf62351-d825-41d0-a68d-88f088947d93": "How does the baseline count in the \"codeql database print-baseline\" command differ from the count of lines of code in CodeQL metrics queries, and under what circumstances might the baseline count be lower?", "f24ba73e-0eb9-45ff-9741-b10bf5109481": "How can I write a log file with a custom name using the CLI, and what alternative option is provided instead of using this flag?", "2baf3ceb-65f7-4e0d-9cfc-40ba089ddc72": "What is the purpose of the `--common-caches` flag in the CLI, and how does it affect the persistence of cached data between multiple runs", "f1131ece-05bc-43ba-8ef6-34c59ddcf734": "What role does GitHub play with respect to personal data collected by GitHub Copilot Business?", "08ac9f11-c879-4d80-92b2-072248fc9281": "What types of data does GitHub Copilot Business collect and how long is this data retained", "070f045f-ead2-47f5-9bd3-cc8a6b442c33": "How does Copilot Business use and share personal data, and what types of data are involved in this process", "cc89112d-09eb-49a7-89c2-d31f4743a373": "What specific uses does GitHub and Microsoft make of User Engagement Data collected through Copilot Business, and how does this data contribute to improving the service and detecting potential abuse?", "7c4f3b1a-aa47-462b-a5fb-752db63a699a": "How does code navigation in {% data variables.product.prodname_dotcom %} help in understanding code", "0df5edae-6df1-4ca5-b7ce-456741d6e930": "Which programming languages support search-based code navigation in {% data variables.product.prodname_dotcom %}", "4a7a6eb7-3647-4e55-b60c-bd2dab6ee57d": "What are the two approaches for code navigation that {% data variables.product.prodname_dotcom %} has developed based on the open source `tree-sitter` and `stack-graphs` library? How do they differ in terms of accuracy?", "1852f3b9-062c-49b1-a391-a7e9c9d56bd5": "Based on the information provided, which programming languages are supported for code navigation in {% data variables.product.prodname_dotcom %}", "d4de70b5-ad4a-423b-8454-d5b5409606da": "How can I navigate to a specific reference of a symbol in a repository using GitHub's symbols pane", "f1d61f28-dedc-4c67-8d92-d8d4c546a925": "How can I find all references of a function or method within a repository using GitHub's symbols pane", "07fc25e0-e418-4737-9fad-23d2cb4897af": "What is the difference between precise code navigation and search-based code navigation? Provide an example to illustrate your answer.2. How does cross-repo code navigation work in {% data variables.product.prodname_dotcom %} and what limitations does it have at this time?", "f7559c41-22ab-4fe6-b946-bb3dc416a232": "What is the difference between searching for code using the GitHub Code Search and searching for code using the GitHub search feature", "0c5dd6bc-4564-4585-b2cf-ace6e2d7627e": "How can I search for code on GitHub using the search feature", "64fb45c2-8a04-4107-a120-6de68fd76b59": "reading- \"[AUTOTITLE]{% ifversion github-marketplace %}(/marketplace/about-github-marketplace){% else %}(/marketplace/getting-started-with-github-marketplace){% endif %}\"---------------------Generate only questions based on the below query.You are a Student. Your task is to answer 2 questions based on the context information provided.Questions should be diverse in nature across the document. Restrict the questions to the context.Questions should be understandable without having access to the context.Don't ask for examples and keep the questions focused on once aspect at a time", "b8e12ef6-39d9-4638-9fc8-9f3293f8d149": "How can I create a new repository from a URL queue in {% data variables.product.product_name %}", "20aace18-3db0-4fe3-bdc6-bb0dc5fd1f44": "What optional items can I pre-populate my repository with when creating a new repository from the web UI in {% data variables.product.product_name %}?", "ca930e33-c28f-420a-9130-72d4d2c69118": "What are the valid values for the query parameters \"name\", \"description\", and \"visibility\" when creating a new repository on {% data variables.product.prodname_dotcom %}?", "6fac88e8-31cb-4011-8b84-a1de7cdd9143": "How can query parameters be used to pre-fill form fields when creating a new repository on {% data variables.product.prodname_dotcom %}", "6a79d9d2-65a0-4a77-92a1-c40b4dbe783d": "How do I create a private repository using the GitHub API? Provide the necessary URL parameters required to execute this action.2. How do I create a public repository owned by a specific organization using the GitHub API? Please include the organization name and any other required URL parameters. Additionally, is it possible to specify the owner as a personal user account instead of an organization? If so, how would the URL parameters change?", "c92f7ab0-de6a-4a93-ba1e-d0dfacea899a": "How can an organization owner enable or disable {% data variables.product.prodname_copilot_cli_short %} for their organization", "81b1b985-6f97-4719-b30f-25695726eeb8": "What are the options available to an enterprise owner when enabling or disabling {% data variables.product.prodname_copilot_cli_short %} at the enterprise level?", "b4070f5c-f206-426c-8df2-05d1a54ff388": "What are the two types of URL addresses that can be used to push changes to a remote repository in Git? Provide an example of each type.", "bfadf92c-8f1c-4fce-9c29-8062be326e9e": "What is a remote repository in Git and how is it associated with a name", "dec89447-1ad6-43a6-ae8b-fb4027d20dee": "What is an alternative to using SSH URLs for cloning a repository, and what is required to use it?", "a7aa72e1-9ea0-4445-b0bc-be55b343ca07": "How can I clone a repository without authenticating to GitHub on the command line", "6b7fb645-5c27-4e55-948e-6fd5d11cbc27": "What are the differences between Git and Subversion in terms of features offered? (for repositories on {% data variables.product.prodname_dotcom %})", "f76c543a-fa86-414e-a3e0-1cb5a41b655e": "How can I access any repository on {% data variables.product.prodname_dotcom %} using Subversion", "2fe9acc6-19dc-4141-9f5e-a8b975b1fd91": "How can I download metrics from my organization on GitHub", "296f7d54-5417-4bbf-a342-a608671292a4": "How can I download metrics from my enterprise account on GitHub", "48158619-746b-4df5-9fb4-55335765faed": "Can you summarize the self review checklist provided for contributing to the {% data variables.product.prodname_docs %} team", "00abf7d0-bca9-432f-a78b-06a01024d10c": "How can you ensure that your changes to the {% data variables.product.prodname_docs %} follow the style guide and are technically accurate?", "26d0efb5-a694-4189-80ac-e4b4e3241372": "How does the \"--format\" option in the \"codeql resolve upgrades\" command affect the output, and what are the available choices for this option?", "b6d48f3b-f37a-4b02-bb99-6c5f15441d2a": "What is the purpose of using the \"--just-check\" option in the \"codeql resolve upgrades\" command, and how does it affect the output", "acb9d05c-b505-45eb-8b24-9d71a706d841": "How can I override the \"--common-caches\" option in the context information provided", "636a61dd-c5cb-4151-b67e-763163c83cfa": "What is the recommended approach for setting the \"--target-sha\" option in the context information provided", "5a665ab7-180f-4dab-ba65-1532fefb2b84": "What is the default location for cached data on disk that will persist between several runs of the CLI, and how can I change it using the \"--common-caches\" option in the context information provided", "53ec8391-ad00-4e70-8f2e-2877a8d28490": "How can I write detailed logs to one or more files in the given directory using the \"--logdir\" option in the context information provided", "4683747b-9870-49d8-95b9-b046c9e26ff1": "What is the purpose of the \"--target-dbscheme\" option in the context information provided", "618ff66f-9b10-47cc-931b-f102ceb580fb": "How can I increase the number of progress messages printed using the \"--verbose\" option in the context information provided", "833d5881-df29-47b6-b9b5-3c572a407bb3": "How can I decrease the number of progress messages printed using the \"--quiet\" option in the context information provided", "72cb9e68-cd17-4917-b86e-2f637e141e58": "How can I listen for and respond to webhook deliveries on my server using [% data variables.product.company_short %]", "951aa4f9-3d5e-4f0c-80df-980ae1047e46": "What is the path and port number that I should use when handling webhook deliveries on my server", "20eef707-f5fd-4a8d-849f-8d7a4ef005ab": "What is the role of smee.io in testing webhooks locally and how can I use it to forward webhooks to my server", "8c50a100-6226-4f04-bcc8-e0fdcab12916": "How can I create a webhook in [% data variables.product.company_short %] and what steps are involved in setting it up", "06732a9f-08a4-4b73-a132-b7d9bb818729": "What is a webhook proxy URL and how can I use it to test my webhook locally", "4d8cc68a-d392-448d-bbf8-7ca8ae23018a": "How can I stop forwarding webhooks using smee.io", "4c078178-0149-4a15-8f2b-65b5c59345ca": "What is the purpose of a webhook in [% data variables.product.company_short %] and what types of events can trigger a webhook", "146af2d4-ec5e-4524-bf21-b7fbd17209c4": "What programming language can I use to handle webhook deliveries on my server, and what steps do I need to take to initialize my server and handle HTTP requests? Provide an example using JavaScript.", "d11c036b-6eb1-48c4-a2bb-c908b0745f1d": "How can I set up a webhook proxy to handle webhook deliveries using Ruby", "dbdb68d0-282e-47d7-83c0-ee1f62d643e2": "How does Sinatra change the name of the `X-GitHub-Event` header in", "bb2fdab6-597a-476b-896a-9c89f56fcaeb": "How does the `status` method in the `post` block affect the response to the webhook delivery", "3d2619d5-4d80-4e8b-b273-22e7f12d7ed4": "What is the expected response time for the webhook delivery, as mentioned in the context information", "90b0350b-dea2-44cc-b467-6e89314bf5ed": "How does the `JSON.parse` method in the provided Ruby code snippet convert the request body into a JSON object", "2b4f213e-268a-4e52-b593-8620bf4c8dbd": "How does the `action` field in the `issues` event data relate to the behavior of the webhook delivery", "369f2799-ac97-4ca7-8a44-408e94683924": "What is the purpose of the `require` statement in the provided Ruby code snippet", "ff5e9722-09aa-4760-8b80-04cd50144b00": "What is the difference between the `issues` and `ping` events in the context of the webhook delivery", "b5c78a9c-4a63-4871-8f92-d4fad9e1064e": "What is the significance of the `X-GitHub-Event` header in the context of the webhook delivery", "88431ba2-ed5d-4601-af7c-d4fa87d8ed10": "How can you test the webhook code using a local server on your computer or codespace? Provide step-by-step instructions including the necessary command to run the local server and how to trigger the webhook.2. What should you see in the terminal window where you ran the local server command, and what does it indicate? Explain the significance of the message \"{% data variables.product.company_short %} sent the ping event\" in the context of the webhook testing process.", "fa68bb61-690f-4bbc-88c1-4ed5a3d9ea02": "What steps should I follow to use my webhook in production, and what potential issues should I be aware of during this process?", "09df19ec-8749-402c-af56-1fc4b325632d": "How can I test my webhook locally using the provided JavaScript example", "e7568f0c-0c76-4a3c-89fd-3a5464e81a26": "What is the significance of the `x-github-event` header in the JavaScript code, and how is it used to handle different event types?", "907ba5c8-d938-4528-acab-59975ee3e938": "How does the JavaScript code provided handle different event types, and what actions does it take for each event type", "2d4d8f39-9b00-4e18-a1ed-2a52669d9cc5": "What steps should I follow to forward webhooks again if I am no longer doing so?", "412c39ba-2ec9-4615-a5e2-ed133b8f0022": "How can I test my webhook locally using smee.io and node.js", "91b68bd9-c861-4ae8-bdaa-6555c233666b": "How can I ensure that my webhook settings are correctly configured to receive webhook deliveries from {% data variables.product.company_short %}? Provide specific steps or instructions that I should follow to verify this.2. What should I do if I am experiencing issues with receiving webhook deliveries from {% data variables.product.company_short %}? Describe the troubleshooting steps I should take to identify and resolve the issue. Be sure to include any relevant error messages or logs that I should look for.", "c939a6ca-4555-4ff0-ab1d-01b01d8cd5bf": "What best practices should you follow when handling webhooks from {% data variables.product.company_short %}", "091196ab-86cf-40de-a966-c517d720c70c": "What steps should you take to deploy your webhook-handling code to a dedicated server for production use", "acab5070-e860-4051-ade7-6f65e101aca0": "How should you update the webhook URL in your settings once you have a server set up to receive webhook traffic from {% data variables.product.company_short %}", "19ca804b-5ae9-4b30-b564-152ad56892f5": "Why should you not use smee.io to forward your webhooks in production", "ae39d7b6-cebc-48e2-942e-b4a3b3f1621a": "Given the context information and not prior knowledge.generate only answers based on the below query.You are a Student. Your task is to answer EXACTLY 2 questions from the upcoming quiz/examination. The", "9d94d1db-f282-4de0-ba7d-98a8f5166313": "How can you verify that a delivery is from {% data variables.product.company_short %} in your webhook handling code", "ac6a1c8c-b2e4-46ad-a38d-b7f8335e8d92": "How can I check the health of {% data variables.product.prodname_actions %} on {% data variables.location.product_location %} using the `ghe-actions-check` command-line utility", "a22abb0c-5b57-49f8-b2a1-559c1427a190": "What steps are required to configure a self-hosted runner to connect to a {% data variables.product.prodname_ghe_server %} using a self-signed certificate", "3f116e17-f4a0-41a4-93b2-ba1016a69de1": "How do I configure Node.JS to use the certificate for a self-hosted runner application", "f11bca17-a615-4926-bb23-29b4dadbc234": "How do I install the certificate on the runner machine for a self-hosted runner to connect to a {% data variables.product.prodname_ghe_server %} using a self-signed certificate", "769f7a0f-f3ce-4387-a885-e9090da0f981": "How do I configure Docker containers to use the certificate for Docker container actions or service containers in workflows", "238208d3-8be5-4510-88e0-ead611cf0fb3": "How can HTTP proxy settings be configured for {% data variables.product.prodname_actions %}", "304c4902-bb4b-41c8-8a04-0f8de93a8f2d": "How can memory and CPU limits for {% data variables.product.prodname_actions %} services be adjusted on {% data variables.location.product_location %}", "0afbff49-ac31-4fef-b1cd-be086348ffba": "What should be done if self-hosted runners are not connecting to {% data variables.product.prodname_ghe_server %} with a new hostname", "c9612c92-6e07-4b13-b1cc-d62d40ed9c43": "What should I do if I notice that a specific service, such as `mps_frontend` or `actions_backend`, is at or near its CPU or memory limit in the \"Nomad Jobs\" section of the monitor dashboard in the management console?", "2409d932-fc5c-47df-85d6-85f3660079af": "How can I check the overall CPU and memory usage in the management console of {% data variables.product.prodname_actions %}", "b1bb12a0-fc19-4e45-8bd5-6d85125db556": "What steps should I follow to verify that {% data variables.product.prodname_actions %} services are operational after adjusting their resource limits in {% data variables.product.prodname_ghe_server %}?", "8037b044-3c15-4d57-b9eb-416154be63fa": "How can I ensure that I do not over-allocate resources when adjusting the resource limits for {% data variables.product.prodname_actions %} services in {% data variables.product.prodname_ghe_server %}", "06f2334e-ca08-4ff7-a79e-37c52db0369e": "What is the default behavior of {% data variables.product.prodname_actions %} workflow runs triggered by {% data variables.product.prodname_", "9accfe1f-6bba-4811-85ab-5ba05843ba78": "What are the three ways to resolve the problem of workflows triggered by {% data variables.product.prodname_dependabot %} having limited access on {% data variables.location.product_location %}", "94d7a162-9ee2-456a-8349-e0d0a0983437": "How can I modify my workflows to use a two-step process that includes `pull_request_target` instead of being triggered by {% data variables.product.prodname_dependabot %} on {% data variables.location.product_location %}", "d7a0d485-3981-4131-8a3f-b6b36aedc865": "How can I ensure that workflows triggered by {% data variables.product.prodname_dependabot %} have access to secrets and increased permissions on {% data variables.location.product_location %}", "d85bb2e7-88b9-48c3-94a1-ce4875e37a4c": "What is the purpose of installing the official bundled actions and starter workflows within a designated organization in {% data variables.product.prodname_ghe_server %}", "d205f685-4ebe-48fd-8e9e-6a29111c4447": "How do you designate an organization as the location to store the bundled actions in {% data variables.product.prodname_ghe_server %} using the `ghe-config` command? Provide the necessary steps and replace `ORGANIZATION` with the name of the organization.", "55c5b9cb-0636-4227-af9c-d8dbd7a956f4": "What is the output of the `ghe-cluster-status` command and how can I use it to identify failing tests in a {% data variables.product.product_name %} cluster", "d227bb2a-b394-42e2-94aa-ab7e7ceb20d5": "How can I monitor the health of a {% data variables.product.product_name %} cluster using a command-line utility", "83aeb3f4-22cb-4532-a3ef-a3d8ac3665ce": "How can I use the `gh es` extension for {% data variables.product.prodname_cli %} to check the status of my {% data variables.product.product_name", "c5169601-97c2-4d99-be0b-4c0d171168d1": "How can I configure Nagios to monitor the connectivity and services of each node in a {% data variables.product.product_name %} cluster", "3c6d350e-4701-4e45-8a6e-076ce03410a9": "What is {% data variables.product.prodname_nes %} and how can I use it to monitor the health of individual nodes in a {% data variables.product.product_name %} cluster", "595d0f17-3a7b-477d-8666-70ecadf64386": "How can Nagios be configured to monitor the status of a GitHub Enterprise (GHE) cluster using the `ghe-cluster-status -n` command? Provide step-by-step instructions for generating an SSH key, copying the private key, authorizing the public key, and validating the configuration. Be sure to include any necessary commands and file paths.2. What is the purpose of using an SSH key without a passphrase when configuring Nagios to monitor a GHE cluster? How can this key be limited to a single read-only command to ensure security? Provide specific instructions for generating and authorizing the key.", "a05fe25e-26c1-4e92-9906-6b29edf5a53e": "How can you test the Nagios plugin for executing commands on a GHE server node using SSH? Provide an example command to run interactively from the Nagios host.", "3a710ffd-dee1-4a2b-8245-a1971b4e6055": "What is the purpose of running the command \"ghe-cluster-config-apply\" on a node in the GitHub Enterprise (GHE) server cluster", "d9717684-4318-443b-a0ee-3a015bbbab12": "What circumstances lead to the automatic revocation of an OAuth token, {% data variables.product.pat_generic %}, or {% data variables.product.prodname_github_app %} token on {% ifversion fpt or ghec %}{% data variables.product.product_name %}{% else %}{% data variables.location.product_location %}{% endif %}?", "d77b2eec-8263-46dc-afd9-1cbf7f55ed1e": "What actions can be taken by the owner of an {% data variables.product.prodname_oauth_app %} to manage authorizations and associated tokens", "5a6f2bdf-d39b-4eb7-8ff8-67a29bec4e63": "How can the expiration period for user access tokens created by a {% data variables.product.prodname_github_app %} be configured, as explained in the context information?", "c887a4bd-21b3-45d0-a021-bffb46c622d3": "What is the process for revoking individual tokens for an {% data variables.product.prodname_oauth_app %} due to an excess of tokens with the same scope, as described in the context information", "c22784f2-8b39-480f-b575-2240402ddc8e": "What is the purpose of the \"codeql pack ci\" command, and when should it be used", "d3bae138-d7ad-48c6-9e4b-17eb8571eb35": "What options are available for resolving QL packs outside of the package registry using the \"codeql pack ci\" command?", "746189c6-c9d6-4c7e-80ea-bb5cc998799a": "What is the purpose of the \"--search-path\" option in the context information provided", "529383d6-90d0-4d40-861b-49ce5bc4809b": "How can I temporarily develop a new version of a pack that also appears in the default path, as mentioned in the context information?", "9f5b59b2-1cf3-48af-8c26-ca1c926a25f8": "How can I explicitly set the verbosity level to one of errors, warnings, progress, progress+, progress++, progress+++ using", "0274cd7c-2473-448b-b9e5-48f54f43a0d7": "How can I control the location of cached data on disk that will persist between several runs of the CLI, such as downloaded QL packs and compiled query plans", "bf2a6d0a-4a31-4e44-92a9-73e9c1faaa98": "How can I give options to the JVM running the command using the CLI tool provided", "0e7af5f1-f2db-4413-9ff6-76788fba5dcf": "How can I authenticate to GitHub Enterprise Server Container registries using the CLI tool provided", "22fda253-f877-4575-af56-b67da733c941": "How can I incrementally increase or decrease the number of progress messages printed using the CLI tool provided", "90779621-a09b-4e31-bcff-410ff9947bed": "How can I write detailed logs to one or more files in a given directory using the CLI tool provided", "35571009-e64f-4ae0-8c38-804ed55ce97d": "How can I pass a GitHub Apps token or personal access token via standard input to authenticate to GitHub using the CLI tool provided", "fddd89b0-2257-4c01-8b63-b1e9dc213f37": "How can I increase the root partition size of my {% data variables.product.prodname_ghe_server %} appliance without creating a new instance", "23df7011-2cd3-4768-a878-25d0dab52661": "What are the minimum hardware requirements for running {% data variables.product.prodname_ghe_server %} on a virtual machine", "aaf1a946-81f8-485d-a6fc-f8cf8b023eec": "What steps should I follow to put my {% data variables.product.prodname_ghe_server %} appliance in maintenance mode before resizing any storage volumes", "a424eb55-2c63-48a0-93d3-5a69141245c2": "How can I expand the user volume disk on my {% data variables.product.prodname_ghe_server %} appliance using my virtualization platform's tools", "60afebce-ff76-4d93-844a-a168d6cfea6c": "What command should I run to", "0e9fd7a5-8c1a-4480-a07b-2268c4ec1cfa": "How can I validate changes to my {% data variables.product.prodname_ghe_server %} appliance by configuring an IP exception list to allow access from specified IP addresses", "8b937991-0e56-44df-9b5c-97662005768c": "What command should be run to stop replication on each replica node in a high-availability or geo-replication configuration, and what is the name of the command used to start replication again after the storage on all nodes has been upgraded?", "4add2f60-8039-4a2e-888f-0355402d94d6": "What command should be run to install the {% data variables.product.prodname_ghe_server %} software on the newly partitioned disk, and what is required to replace in the command", "9194133d-901a-4d7b-a769-88737f1a94ce": "How can I update my credentials via Keychain Access on a Mac computer? Provide step-by-step instructions including the specific search term and actions required to edit or delete the entry.2. How can I delete my credentials via the command line on a Mac computer? Provide the exact command to erase the keychain entry and any necessary prompts or inputs required. Additionally, explain how to test if the deletion was successful.", "7d2665e0-d2fc-43d4-a80d-20937988c5eb": "How can the \"discussions\" feature be utilized within a repository, and what parameters can be specified to narrow down the list of discussions returned", "826e21c7-ff3e-4996-aede-5a3548121498": "What is the difference between \"discussionCategories\" and \"pinnedDiscussions\", and how can they be accessed through the GraphQL API?", "2fad7441-ff1c-4e4e-9cae-474b82da82c7": "What is the relationship between the author and the subject of the comment in a discussion", "c22366b2-16eb-4939-8a91-a6a8bece4d14": "How can one determine if a discussion has been answered, and what is the significance of this?", "1ae8ba6f-6fd3-4d02-8835-8aff7a922b61": "What is the significance of the \"last\" parameter in the \"DiscussionCommentConnection\" query? How does it differ from the \"first\" parameter? Provide an example of how this parameter can be used in practice.2. What information can be obtained from the \"reactionGroups\" field in the \"DiscussionComment\" query? How can this information be useful in analyzing user engagement with a discussion? Provide an example of how this information can be used in practice.", "fc7b333e-3001-45a5-a5d9-aa5c542bebb7": "What is the significance of the \"viewerCanUpdate\" field in the DiscussionComment type", "778f1c94-365a-4fdf-94d9-c26a8d74a446": "How can the \"userContentEdits\" method be utilized to retrieve specific elements from a list?", "e91fad99-21b1-4d42-8734-a79891e66f80": "How can one determine if a comment has been chosen as the answer of its discussion using the provided information?", "320e7cda-8f5f-4231-94bd-8139735793ee": "What is the relationship between a comment's \"isMinimized\" and \"lastEditedAt\" fields", "8cae39ec-e8b0-4432-9d4d-29a97a4d4457": "What is the significance of the \"viewerCanDelete\" field in the DiscussionComment type", "3e24c41a-2fed-4557-8b52-b8f5ea53a859": "How can the \"userContentEdits\" field in the DiscussionComment type be utilized to retrieve specific edits to a content?", "69632101-168b-4a5a-905a-67492dc33d92": "How can the \"isAnswerable\" field in the \"Category\" type be utilized in a GraphQL query to retrieve only answerable questions", "2133174c-2047-4ace-974b-f315b8daabe0": "What is the significance of the \"preconfiguredGradient\" field in the \"PinnedDiscussion\" type, and how can it be utilized in a GraphQL query to style discussions that have been pinned within a repository?", "060886fe-c9e1-4e01-91ea-746da38f3beb": "How does the `RepositoryDiscussionAuthor` interface differ from the `RepositoryDiscussionCommentAuthor` interface in terms of the types they represent and the discussions they relate to", "ba50cc36-6d76-4f5c-8a6e-a9ef826fb85e": "Can you provide an example of how to use the `first` and `last` arguments in the `repositoryDiscussions` and `repositoryDiscussionComments` queries to retrieve a specific number of discussions or comments?", "75eacc2d-cbb0-484e-b982-6ed727a19c50": "How can we retrieve a specific number of elements from a list using GraphQL queries? Please provide the syntax and any necessary parameters.2. What is the purpose of the `onlyAnswers` parameter in the `DiscussionCommentConnection` query, and how can we use it to filter discussion comments in GraphQL? Please provide an example usage.", "da72c9f8-954e-4add-8d42-51c7a475baaf": "Can you summarize the input fields and return type fields for the \"deleteDiscussionComment\" mutation in the provided context information", "d3ebe5ee-30e8-4309-b700-aeebe2dc6d72": "How can you update the contents of a discussion comment using the \"updateDiscussionComment\" mutation in the given context?", "4dcd1980-c23b-4958-b564-515bf7bd8dc6": "What is the purpose of the `unmarkDiscussionCommentAsAnswer` mutation in the context provided", "2f639651-52e1-4b76-80fc-dd4a724bdbf1": "How can I search for discussions using the `search` field in the context provided? Provide specific details on the required input and output fields.", "be1860c1-1ed6-47eb-92c3-e9ef55737bf2": "What Git commands can change the commit date, and how can this affect the order of commits in a repository's history? Provide an example of how the commit sequence might be out of order due to a change in commit date.", "b91a9443-9e27-42c0-b7ea-6e553c2ce8e9": "How does GitHub determine the date of a commit displayed on a user's profile page, and what other date is used to calculate the commit date in a repository", "5d67f8be-64be-4279-9b9e-236c29c2cffa": "How can you view the commit details of a specific author using the GitHub API? Provide an example URL with the author's name and a specific date range.2. What could be the reason for missing expected commits on your GitHub timeline, and how can you troubleshoot this issue? Provide possible explanations and steps to follow.", "351dc383-c7d4-4f52-ae57-7900b7fc8144": "What are the consequences of enabling the setting to allow people with admin access to choose any visibility for an existing repository, even if the organization does not allow that type of repository to be created?", "ac90b81d-0884-44dd-934f-b0c75501e701": "How can an organization owner restrict who has the ability to change the visibility of repositories in their organization", "d011deca-4bfe-400c-8c92-41d54fd36763": "How can I ensure that repositories owned by a user or organization in my enterprise cannot be permanently removed, even after 90 days", "23505011-ab01-47a8-9f4e-f5d14f2b3d27": "What steps should I take to place a legal hold on a user or organization in my enterprise to prevent the permanent removal of their repositories?", "bcea9c91-6d30-42d3-8248-8d938cdc9067": "What tasks are required to ensure that organization members have signed in and linked their accounts with the IdP, as mentioned in the context information?", "ee200a57-b098-4c36-bc3d-2ba923c0d6ce": "What should be done before enforcing SAML single sign-on in an organization, according to the provided context information", "63a7d35d-193e-4c5a-94d0-040652bb45b6": "How does the concept of \"AUTOTITLE\" differ from \"AUTOTITLE\" in the given context", "a44fa687-f644-414f-8957-9d3c7f2931b9": "Can you provide an example of how \"AUTOTITLE\" is utilized in the context provided", "6a5d18cf-bec9-4855-8f9b-f6768d587d8a": "What precautions should be taken while replacing a node in a {% data variables.product.product_name %} cluster, and why is it necessary to avoid conflicts while reusing hostnames?", "9d6999f1-35a7-4b87-ba87-6d561675cdfb": "How can you replace a functional node in a {% data variables.product.product_name %} cluster, and what steps should be followed after installing the appliance on a new VM", "4ec1ec9a-32c5-452d-a099-2f15cb169612": "How can I replace a node in an emergency in a {% data variables.product.product_name %} cluster? Provide step-by-step instructions for provisioning a new VM, configuring an IP address, taking the failed node offline, applying configuration, adding the new node to the cluster configuration file, initializing the cluster, and applying configuration, and optionally, evacuating the failed node.2. How do I replace the primary MySQL node in a {% data variables.product.product_name %} cluster to provide more resources or replace a failed node? Provide instructions for adding a new node to the cluster, replicating MySQL data, and promoting the node, with a note on the required downtime during promotion.", "a485699e-08d3-441f-b095-b9ca4d4020ba": "How can you ensure that MySQL replication is finished during the process of replacing a cluster node, and what is the potential consequence of not waiting for it to finish", "2f6c0240-2706-4cda-8a5a-38c4d8cc4a22": "What is the purpose of enabling maintenance mode during the process of replacing a cluster node, and how can you do it?", "2a366a2e-81ea-42d2-bd98-1edef1bf84f2": "What is the purpose of backing up the `cluster.conf` file before editing it, as mentioned in the context information", "a1dd3ab3-2a18-40ba-b037-3a5057fca628": "How should the `[cluster]` section in the `cluster.conf` file be modified when replacing a node in the cluster, as described in the context information? Provide specific instructions for adjusting the `mysql-master` and `redis-master` key-value pairs.", "e67c0b0b-2036-42f9-8a94-0190c44b9b1e": "How can newly committed secrets be remediated when enabling {% data variables.product.prodname_secret_scanning %}", "dbaa1e33-ca6e-43b3-a19a-5597c36c7403": "What approaches can be taken to tackle newly committed credentials when enabling {% data variables.product.prodname_secret_scanning %}, and how can webhooks be used in this process?", "17b2b49f-d656-4f97-9133-c2125b1a9cae": "Generate according to: GitHub Advanced Security is a suite of features that helps you find and address security vulnerabilities in your code. It includes code scanning, secret scanning, and advanced security reviews.In this guide, we\u2019ll walk through how to use secret scanning to monitor, notify, and remediate secrets in your organization\u2019s repositories.Monitoring secrets:1. Enable secret scanning for your organization.2. Configure the secret scanning settings for your organization.3. Add the secrets.yaml file to your repository.4. Commit the secrets.yaml file to your repository.5. Run a", "a996c566-26a7-4a43-966c-8178d9c13543": "What steps should an organization take to remediate previously committed secrets, starting with the most critical, using GitHub Advanced Security", "bcca34c7-928c-477b-8e55-acefc6134687": "How can an organization monitor, notify, and remediate newly published secrets using GitHub Advanced Security", "1f9b5b02-0ddc-48e7-9876-c7a14a6db150": "How can developers take ownership of security and have the responsibility of fixing security issues, especially if they have created them, as mentioned in the context information", "cf0592a4-fef3-4357-93e9-ad86fa7d2ed8": "What steps should be taken to create a targeted communication plan for users who maintain repositories affected by each secret type, as outlined in the context information?", "8f7cbc1f-68a7-48ce-87b6-e38c284e1ee3": "What is push protection with secret scanning and how can it be enabled in GitHub", "bff2e71d-c7e9-4626-9eb2-951864c92c05": "How can proactive training material be created to encourage developers not to push credentials to GitHub? What should be included in this material?", "dab636d6-5a80-4854-9cce-e4552af8476d": "How can the \"AUTOTITLE\" command be utilized in the provided text material to achieve a specific outcome? Provide an example if possible.", "10130ca4-07fe-4da9-a49d-6999db7c5205": "Based on the context information provided, can you summarize the purpose of the \"AUTOTITLE\" command in the given text material", "3414b038-432c-4728-b0bf-bdf4ea299501": "How can you create tables using pipes and hyphens in Markdown? Provide an example.2. How can you format content within a table using links, inline code blocks, and text styling in Markdown? Provide an example.", "6bcfff7d-0000-4825-8af3-4a4278b17879": "How can text within cells be aligned in a Markdown table as rendered on {% data variables.product.prodname_dotcom %}", "a9b8047e-3bff-4359-a8ed-fdb7775584a9": "What is the purpose of prefacing a pipe `|` with a backslash `\\` in a Markdown table as rendered on {% data variables.product.prodname_dotcom %}?", "da77b2d7-abc2-4208-8ddf-dffdfa5cdc13": "How does the concept of \"AUTOTITLE\" differ from \"AUTOTITLE\"? Provide a detailed explanation.", "b26eff00-8f86-460f-a088-3be99a28895d": "Based on the context information provided, can you summarize the meaning of \"AUTOTITLE\" in a sentence", "53398d90-3f05-437f-8d18-625e592d0fab": "How does the concept of \"AUTOTITLE\" differ from \"AUTOTITLE\"? Provide a detailed explanation.", "b2eb3a6b-c34e-4325-b2de-86ed87b59479": "Based on the context information provided, can you summarize the meaning of \"AUTOTITLE\" in a sentence", "fd036376-c926-4c36-890c-476873aecf35": "How can I configure {% data variables.product.prodname_ghe_server %} to use OIDC with Google Cloud Storage, as recommended in the context information provided", "01fbacd1-48a6-4405-8fdd-93fb9756246b": "What are the prerequisites required to enable {% data variables.product.prodname_actions %} on {% data variables.product.prodname_ghe_server %}", "1ef05a78-1e30-4a9c-a89e-07e522d93a8d": "How can I obtain the identity provider URL needed to configure OIDC for Google Cloud Storage in {% data variables.product.prodname_ghe_server %}", "2a9fb419-78cb-4aa6-bc29-58bead25ed6f": "What is the format of the condition required for the \"OIDC 1\" mapping in the configuration process for OIDC in {% data variables.product.prodname_ghe_server %} when connecting to Google Cloud Storage?", "5083c0fe-0b0f-4fbf-be2c-2afcbdacbff4": "Generate according to: Context information is below.---------------------e_admin_settings.management-console %}{% data reusables.enterprise_management_console.actions %}{% data reusables.actions.enterprise-enable-checkbox %}{% data reusables.actions.enterprise-gcp-storage-setup %}1. Under \"Authentication\", select **OpenID Connect (OIDC)**, and enter the values for your storage:   - **Service URL**:", "6b25b39b-7f70-49f6-a38a-81cf366cf91b": "What are the necessary Identity and Access Management (IAM) permissions required for a Google Cloud service account to access a bucket when enabling Google Cloud Storage with {% data variables.product.prodname_actions %} using a HMAC key", "8160a56d-07c7-4ed9-baaf-6b943800c4f4": "How can you enable Google Cloud Storage with {% data variables.product.prodname_actions %} using a HMAC key", "e868ed25-ae70-474b-8956-250892358301": "What steps are required to configure Google Cloud Storage for storing artifacts and logs in GitHub Actions, as outlined in the context information provided?", "02e8aef4-3a5e-4ec7-bfb7-c3bfb112af10": "How can an Enterprise Site Administrator enable context information for GitHub Actions in their organization's settings", "213f1538-1817-4f57-9a6c-0de077cf169d": "How do GitLab CI/CD and {% data variables.product.prodname_actions %} differ in terms of workflow configuration, and what are the similarities between the two systems", "c125df61-5522-4853-b991-2a31de3a98a4": "What is the syntax for defining jobs in GitLab CI/CD and {% data variables.product.prodname_actions %}, and how do they differ in terms of script execution?", "ff1eab7e-54a1-4333-a6ab-cdb6a4c1a800": "Generate according to: Context information is below.---------------------Below is an example of the syntax for each system.GitLab CI/CD syntax for runners{% raw %}```yamlwindows_job:  tags:    - windows  script:    - echo Hello, %USERNAME%!linux_job:  tags:    - linux  script:    - echo \"Hello, $USER!\"```{%", "fcbe63d0-bf43-4652-b510-118cb93f7c85": "What is the syntax for defining conditions and expressions in GitLab CI/CD and how does it compare to the syntax for {% data variables.product.prodname_actions %}", "aca17ea2-5fe2-452b-9d0d-754e238720d5": "How does the syntax for defining Docker images differ between GitLab CI/CD and {% data variables.product.prodname_actions %}", "c6a7cc88-1413-4a78-814d-d95e187566f6": "In GitLab CI/CD, what is the concept of stages, and how can it be replicated in {% data variables.product.prodname_actions %} using the `needs` key?", "4371400c-b759-4e72-b349-ea624961531c": "How do GitLab CI/CD and {% data variables.product.prodname_actions %} allow for dependencies between jobs, and what is the difference in syntax between the two systems", "cebfee54-1b76-4baa-90e2-6b80323c2787": " How can GitLab CI/CD and {% data variables.product.prodname_actions %} be used to persist data across multiple jobs using artifacts", "7a6d69b9-6336-4d0c-b92d-a06792ea1a35": " How can workflows be scheduled in GitLab CI/CD and {% data variables.product.prodname_actions %}", "cdd4984d-2264-4276-911d-2ebfcb5c28c4": " How can artifacts be uploaded in GitLab CI/CD and {% data variables.product.prodname_actions %}", "e3b7b8c9-4527-4536-b90b-1e08cf2466c0": " How can variables and secrets be configured in GitLab CI/CD and {% data variables.product.prodname_actions %}", "cd254133-1ef5-4758-be88-132999195a3f": " How can caching be implemented in GitLab CI/CD and {% data variables.product.prodname_actions %}", "608aab44-0230-4750-8a92-707727a3c1ac": " How can GitLab CI/CD and {% data variables.product.prodname_actions %} be used to run workflows at a specific interval", "bd73141d-2f27-4f9f-b1f2-7fee3da70cf1": "How do GitLab CI/CD and {% data variables.product.prodname_actions %} enable the inclusion of additional containers for databases, caching, or other dependencies? Provide an example of the syntax for each system.", "0c8dd673-e8d6-4d05-88dd-58d339d86b86": "Based on the provided context information, can you explain the syntax for uploading artifacts using {% data variables.product.prodname_actions %}", "0d6aeba1-d3e5-461a-a608-cb49c518dabe": "What is the purpose of setting the environment variables POSTGRES_HOST and POSTGRES_PORT in the context information?", "aa728827-344b-4b8a-b073-e6198d271237": "How does the client in the provided context information interact with the PostgreSQL service container", "0daf31be-a603-4f9e-af52-4503528ee589": "How does \"AUTOTITLE\" differ from other document features in terms of functionality", "aa003b48-2c13-49a2-9edd-2ce5dfc5cc35": "What is the purpose of using \"AUTOTITLE\" in a document", "67a6b612-5be5-436f-8933-dd3dce2b909b": "What is the process for requesting a new password on {% ifversion fpt or ghec %}{% data variables.product.product_url %}{% else %}{% data variables.product.product_url %}{% endif %}, and what is the time limit for clicking on the link sent to your email address", "03ae0a69-de8f-4f08-9b02-e9eee0bca150": "If you have enabled two-factor authentication on {% ifversion fpt or ghec %}{% data variables.product.product_url %}{% else %}{% data variables.product.product_url %}{% endif %}, what methods can you use to verify your identity during the password reset process?", "48cfd0a5-79af-484e-bf5e-f6d7519d7bf0": "How can I change my password on GitHub? Provide step-by-step instructions, including where to access the settings and what information is required to complete the process.2. What are some tips for creating a strong password on GitHub? Explain the importance of using a password manager and provide guidelines for choosing a secure password, such as using a combination of upper and lower case letters, numbers, and special characters.", "c2d4c643-d248-4b7b-8621-f459acbcaee2": "Can you explain the purpose of the \"{% endif %}\" statement in the provided context?", "4a4409ca-d2cd-4849-b0fb-095c303feeec": "How does the \"AUTOTITLE.\" command work in the given context", "49998bd9-51b5-4977-93ee-a29448b5c338": "How can a student apply for {% data variables.product.prodname_global_campus %} and what documents are required to prove their current student status? Additionally, what is the process for re-verifying academic status during tenure as a student?", "9598377b-31f5-488e-b260-7c661090d1b0": "What are the eligibility criteria for {% data variables.product.prodname_global_campus %}, including {% data variables.product.prodname_student_pack %} and other benefits", "60f6a066-b32f-4d73-b3f7-d7c0341850d6": "Where can I find the expiration date for my free access to the GitHub Student Pack?", "87cf8b35-d31d-4053-bbb8-5bff7d5c1a8e": "How can I verify my academic affiliation on the GitHub Education website", "90158a49-fd07-464e-bbae-6a88c86e6b74": "What message does a user see when they attempt to perform a git operation over SSH during an SSH key audit, and where can they go to approve their keys?", "b63497cc-c868-4867-a879-71e0e308d597": "What is the process for initiating an SSH key audit in the site admin dashboard, and what happens when the audit begins", "9ccd9380-11f7-45f3-ba02-dd506ecc5bce": "What are the benefits of using the {% data variables.product.prodname_container_registry %} for storing and sharing Docker images", "62963c05-4fea-4793-9e5a-5f07f568b794": "What changes will occur to a Docker image after it has been migrated from the Docker registry to the {% data variables.product.prodname_container_registry %}", "ca283a28-06f7-4e13-98fa-953e250bdf37": "What is the difference between the domain in the pull URL for a Docker image stored in the Docker registry and the domain in the pull URL for a Docker image stored in the {% data variables.product.prodname_container_registry %} after migration", "352a3a97-0224-4f19-bc23-c7b6dbe422ef": "How can I find out if my organization is eligible for the free", "00f4e7a0-3096-482b-8f1c-5da63de75855": "How can I access the REST API to query for packages with a `package_type` of \"container\" after migration from the Docker registry to the {% data variables.product.prodname_container_registry %}", "6bbbdf5d-1cea-4f41-aadb-4f6093ec115e": "What is the purpose of the \"AUTOTITLE\" directive in the provided context information", "38823bb1-697c-41c7-8551-6bd565eb1398": "In the context provided, what is the significance of the \"docker-ghcr-enterprise-migration\" version control?", "f936c73d-667b-4615-9b86-a316bce7c471": "How can an app stay under the rate limit while accessing the API? What are some methods to achieve this? Provide examples where possible.", "a9419f3b-61b2-4129-bbe7-b21a4f765ec2": "What is the importance of selecting minimum permissions while registering a {% data variables.product.prodname_github_app %}? How can compromised keys or tokens limit the damage caused", "82cd286f-ced3-4d22-9f9e-661f6c6402ee": "What is the recommended way to store sensitive data, such as private keys and client secrets, for a {% data variables.product.prodname_github_app %} on a specific platform? Provide specific examples of storage mechanisms that are intended for this purpose.2. What are the potential risks associated with hard coding private keys in an app, and how can these risks be mitigated? Provide alternative storage solutions for private keys and explain their benefits and drawbacks.", "d1753c46-4de9-4f71-93b3-7fdfc91f5452": "What is the difference between an installation access token and a user access token in the context of {% data variables.product.prodname_github_apps %}? How should an app determine which type of access token to use in a specific scenario? Provide examples to illustrate your answer.2. How should an app securely store tokens generated by {% data variables.product.prodname_github_apps %}? What are the recommended storage mechanisms for websites, web apps, native clients, client-side apps, and apps running on user devices? Explain the security considerations for each storage mechanism and provide best practices for implementing them.", "e63211ae-6272-4bf3-8f78-8c9aac657aad": "How can an app handle security breaches involving private keys or secrets, and what steps should be taken in such a scenario", "5f397cb9-3249-415f-8032-7a78d112089e": "What is the recommended way to track which organizations a user access token is authorized for, and how can this information be used to validate organization access during authentication", "ce628638-95b6-4681-aadd-301b76978a53": "What is the recommended approach for caching user access tokens and installation access tokens, and why is it beneficial to do so", "21ca7912-8080-4c1a-a467-acbd02dfc456": "How can an app revoke tokens that are no longer needed, and what benefits does this provide in terms of security and resource management", "8a7ad597-6be6-42d5-9fc4-bd2abc1465cb": "How can an app ensure that user access tokens and installation access tokens are not", "30076280-9122-4e1e-a9fa-006becafaff8": "How can an app verify which organizations a user access token has access to, and why is this important for authentication purposes", "4046e479-d641-423f-b710-d29a65666631": "What is the difference between expiring user access tokens and installation access tokens, and how long do they typically last before expiring", "0b9a3cb5-2af8-47bf-bc71-914cdb18c9bd": "How can regular vulnerability scans be conducted for a GitHub app, and what is the importance of this practice?", "18fc0027-4321-479c-b177-28603ee0273b": "What is the significance of the statement \"romised, you should immediately revoke these tokens\"", "a880bb1f-6427-46cc-bb49-b15087de0e7c": "How can users ensure that they do not have to contact support personnel in order to delete their data, as mentioned in the context information", "f5c8cb1d-686a-459f-9571-7af82ed3ff30": "Can you summarize the instructions provided in the context information regarding data deletion? Specifically, how can users delete their data without needing to contact support personnel?", "075e0065-9a5e-4d63-bd81-9b55f1f5d531": "Can team discussions be enabled or disabled across all organizations owned by an enterprise on {% data variables.product.product_name %} and who can administer this setting?", "626d9bc0-ab3a-4311-8b85-84d591ad309b": "What are policies for teams in an enterprise on {% data variables.product.product_name %} and how can they be enforced", "ca555839-4265-4b12-a24f-e9e90b2c1308": "In order to migrate from {% data variables.product.prodname_ghe_server %} 3.8 or higher for the first time, what additional step is required besides having sufficient access to both the source and destination?", "1e891042-3355-4a86-bdae-94465af5dd5d": "What access requirements are enforced by {% data variables.product.company_short %} for using {% data variables.product.prodname_importer_proper_name %}", "7101fcfb-7680-444c-85b3-a577495d7370": "What permissions and SSH key requirements are necessary for migrating from Bitbucket Server, and why?", "ad8d56a3-2367-46a9-893d-6f31f19388ce": "What roles are required for migrating to or from {% data variables.product.company_short %} products, and what tasks do they perform", "67df07a6-e73e-40c8-bd23-85cd81c31ac7": "What {% data variables.product.pat_generic %} scopes are needed for assigning the migrator role for repository migrations in a {% data variables.product.prodname_dotcom %} organization", "1496fcc5-fbf3-4ed6-b77c-d3f54a540922": "What additional {% data variables.product.pat_generic %} is needed for running a migration from a {% data variables.product.prodname_dotcom %} product as an enterprise owner", "5e322e6e-d3cc-4d9e-89b4-263235621d1c": "What are the required {% data variables.product.pat_generic %} scopes for running a migration from a {% data variables.product.prodname_dotcom %} product as an organization owner", "d78d45a1-3f26-49b6-adc1-0972f9f4a868": "What {% data variables.product.pat_generic %} scopes are required for downloading a migration log in a {% data", "b6ba8b77-fba1-447c-b447-9a6cf3ede8fc": "What {% data variables.product.pat_generic %} scopes are required for running a migration from Azure DevOps", "4f21c360-80db-4a13-b666-bc410e0e1d6a": "How do I authorize a {% data variables.product.pat_generic %} for SSO if SAML single sign-on is enforced for the organization(s) I need to access", "573d08fa-a387-4b05-b549-2981f04a662f": "What scopes should I grant when creating a {% data variables.product.pat_generic %} for {% data variables.product.importer_proper_name %}", "8459ea51-d0bc-43c0-aafe-d207f5fb6fc8": "How do I configure IP allow lists correctly for migrations if the source or destination of my migration is {% data variables.product.prodname_dotcom_the_website %} and", "8e1c2072-fae1-450f-bdd0-d4d1dffc34f1": "What role do I need to have in order to create a {% data variables.product.pat_generic %} for {% data variables.product.importer_proper_name %}", "3e426ac7-a1c8-4ad8-b2fb-6eee0e6eb7da": "How can I access all accessible organizations using the {% data variables.product.pat_generic %}", "85b76acd-e03b-44ca-8107-9e4640c80619": "How can you obtain an up-to-date list of IP ranges used by {% data variables.product.prodname_importer_proper_name %} for migrations, and where can you find this information in the REST API documentation?", "b337307c-aa41-4465-bae8-8906220ae789": "What is the purpose of adding {% data variables.product.prodname_dotcom %}'s IP ranges to an IP allowlist during a migration from {% data variables.product.prodname_ghe_server %} to {% data variables.product.prodname_dotcom %}", "1e0d48b0-4a63-467e-8dd8-1c5ce2e1e92d": "What information is required to complete the process of joining {% data variables.product.prodname_sponsors %} as a sponsored organization?", "210b3c34-6e2c-4c0f-a791-469b92cc09f9": "How can an individual contributor outside an organization join {% data variables.product.prodname_sponsors %}", "c57cf46a-d532-4c7a-add1-3b7caba73e88": "How can an organization receive payouts through {% data variables.product.prodname_sponsors %}, and what options are available for bank account selection? Are there any restrictions on the location of the organization or the person setting up {% data variables.product.prodname_sponsors %}? What additional information is required for tax purposes? How can two-factor authentication be enabled on a {% data variables.product.prodname_dotcom %} account for this purpose? What is the process for submitting an application for approval as a sponsored organization on {% data variables.product.prodname_dotcom %}? What is the role of {% data variables.product.prodname_github %} in this process?", "77cb1361-da8c-4ee6-985d-6d56b8fb2da1": "What is the process for becoming a sponsored organization on {% data variables.product.prodname_dotcom %}, and what information is required for this purpose", "1cb87558-9ad3-45aa-9790-4b59985340a7": "How do cloud-backed passkey services allow passkeys to be synced across devices and what benefits does this provide?", "383021f0-52e2-4ce9-a167-75a4a94dcfba": "What are passkeys and how do they differ from SMS or TOTP 2FA in terms of phishing resistance", "edb9873c-3167-4080-9cb8-6a9f83af9b71": "What are the differences between device-bound passkeys and synced passkeys", "f650f981-5afc-43e6-9724-71d63c887573": "What is an authenticator and how does it relate to passkeys", "7053675d-93e3-46ee-a0ba-6303162b7c52": "How can passkeys be used with nearby devices, and what types of authenticators allow for this functionality", "e0469ffe-9f29-40e7-9234-d1a18e88ce86": "How can I provide feedback on passkeys to {% data variables.product.company_short %}, and where can I find further reading on this topic?", "7df251fa-3f11-419c-a0bd-db1186bf48a9": "What are the advantages of using passkeys with FIDO2 hardware security keys, and which devices and operating systems support passkeys", "6a5c35af-8f82-4411-a306-1787394c2a98": "What is the purpose of a pre-receive hook in a repository, and what are the possible values for the 'enforcement' field in the repository settings", "23615235-570e-4610-b90b-40bcffeb1394": "What is the significance of the 'configuration_url' field in the repository settings for pre-receive hooks, and who determines the authorization to access the endpoint at this URL?", "c79edece-96b5-4b14-acd8-c24777442016": "How can the \"alex-page/github-project-automation-plus\" action be utilized to automatically move an issue to a specific column on a project board when it is assigned? Please provide a step-by-step guide on creating a workflow file that uses this action and customizing it to suit specific needs.2. What parameters should be customized in the workflow file for the \"alex-page/github-project-automation-plus\" action to move an issue to a specific column on a project board when it is assigned? Please provide specific examples for the \"project\", \"column\", and \"repo-token\" parameters.", "9b0f9a40-15ef-4712-981a-b9a94eeb1c43": "How can I store secrets in my GitHub repository using workflows, and what is the process for replacing a placeholder with a secret name in my workflow file", "9e6c293c-04dd-4a0a-a558-8520fc277119": "How can I test my GitHub workflow that moves issues to a specific project board column when they are assigned, and what should I expect to see when the workflow completes?", "94687445-4bc7-4b07-b4e6-94d24d3c68b7": "Generate according to: Context information is below.---------------------Example of canceling a paid subscription for a personal", "e9dc441c-f335-49c2-8dec-e3f6ed54d558": "If Stefan removes 20 seats and downgrades to a new total of 30 paid seats on September 30th, when will the downgrade take effect and how many paid seats will his organization have access to", "dc1779a6-7ba9-49ce-8dde-dbcad976a850": "If Mada adds ten paid seats on June 4th, how much will her organization be immediately charged and when will the seats be available to use", "ef3edb4e-a969-4a85-863b-fe9d6770451a": "If Kumiko cancels her paid subscription on October 10th, when will her account move to {% data variables.product.prodname_free_user %}", "80d7bce3-fbea-418f-be0c-892e7e7ac097": "If Ravi switches from a yearly to monthly billing on December 10th, when will he be charged for a month of service and what will be his next billing date", "94adbbed-8aea-479a-8c1c-bc8157cb59be": "How can I find the expiration date of an artifact using the API?", "5241a869-c76d-4bc9-bc63-5a2d8b93877b": "What is the warning provided in the context information and why should I be cautious while deleting an artifact", "4befe447-0be0-486b-8f40-12f9e88c0043": "What is the purpose of integrations in {% data variables.product.product_name %} and how do they enhance the user's workflow", "6c65aa4a-6bc8-455d-b062-0fe84a487edc": "How can integrations be discovered in {% data variables.product.prodname_marketplace %} and what types of integrations are available?", "e9ad844f-96e4-4736-989d-6bbb3e900c30": "Generate according to: If you want your GitHub Enterprise Server instance to use a third-party GitHub app, you can contact the app developer about making the app available for GitHub Enterprise Server. For more information, see \"AUTOTITLE.\"If you want your GitHub Enterprise Server instance to use third-party custom actions, you need to enable GitHub Connect. For more information, see \"AUTOTITLE.\"{% endif %}For more information about using integrations, see:- \"AUTOTITLE.\"- \"AUTOTITLE.\"- \"AUTOTITLE.\"You can also build your own integrations", "6d95bb24-3a89-4009-8d95-b8863a3b60ed": "What is required to enable the use of third-party custom actions on my GitHub Enterprise Server instance", "d884b1b1-5c87-4394-b306-1509474a6a3c": "How can I make a third-party GitHub app available for use on my GitHub Enterprise Server instance", "95ac0531-e21e-435a-bbd0-56706c431a26": "How can an organization control access to resources on GitHub Enterprise Cloud (GHEC) and other web applications using SAML SSO and SCIM with Okta, an Identity Provider (IdP)", "77232177-6258-484d-a88f-5a789f10212b": "What provisioning features are available for users assigned to the {% data variables.product.prodname_ghe_cloud %} application in Okta after enabling SCIM?", "6a4ea3ec-0b97-49e3-82b9-380a37c2a51b": "How can I enable and test SAML SSO on GitHub.com using the sign-on URL, issuer URL, and public certificates provided in the \"How to Configure SAML 2.0\" guide", "06482c72-11a6-432e-945a-6c235b7f80e3": "How do I configure access provisioning with SCIM in Okta for my organization on GitHub.com? This should include steps such as signing into GitHub.com, creating an active SAML session, navigating to Okta, enabling API integration, granting access, authorizing OktaOAN, and saving provisioning. Additionally, provide instructions for what to do if the \"OKTA SCIM Integration\" app needs to be approved for access restrictions enabled organizations.", "6a7e3420-a9fd-4552-bca4-2c361995b91b": "How can I edit the options of a single select field in a project on GitHub?", "b029d3cc-fa13-45ac-8687-7b18c8d8126d": "How can I add a single select field to a project in GitHub", "a85126b0-1ef1-4fd8-83f1-7c3deec80812": "Can you provide an example of how \"context information\" can be used to generate questions for an examination, and what factors should be considered while doing so?", "dbcf74a9-c78d-48e8-b17f-f6743a0d3d2e": "How can the concept of \"context information\" be applied in a real-world scenario, and what benefits does it offer", "6a144d68-334d-4c27-a6f1-01ca63bf4ca5": "How can custom queries be shared with others using {% data variables.product.prodname_codeql %} packs, and what information should be included in the `qlpack.yml` file for each pack", "a3899503-3272-4747-8682-d5117f37db16": "How can query help for custom {% data variables.product.prodname_codeql %} queries be included in SARIF files generated during an analysis using the {% data variables.product.prodname_codeql_cli %}, and what version of the tool is required to do this?", "64276dfa-24bc-45c9-bc85-c7a7561fae8a": "How can I contribute my query to the {% data variables.product.prodname_codeql %} repository, and what resources are available for further reading on {% data variables.product.prodname_codeql %} queries", "1aa848c2-ebaa-46ca-acf7-b8349894ceee": "What is the difference between writing query help in the \".qhelp\" format and including it alongside the corresponding query, and why is query help written in \".qhelp\" files not included in SARIF files or processed by code scanning?", "2ad00173-8e8c-4ddd-8b2d-128e78cb0ed6": "How can I convert a note to an issue in a {% data variables.projects.projects_v1_board %} and what are the steps involved?", "6f9a0dca-05ab-4379-a7e1-309ee7beefd6": "How can I add notes to a {% data variables.projects.projects_v1_board %} and what are the steps involved", "dc9709bb-e03c-482c-b088-1148b4588586": "Based on the context information provided, can you explain the meaning of \"AUTOTITLE\" and provide an example of how it is used in a document", "14403f5b-3326-41c9-b5c3-8763b7e8a6b0": "How can you edit or remove the contents of a note in the context of the given information, and what are the steps involved in doing so?", "7d8963f4-0db8-4a16-8e27-4a82d6fc63e4": "How does \"AUTOTITLE\" differ from other document features in terms of functionality", "42af3af7-99ca-4bc4-b3ed-30a36dbef646": "What is the purpose of using \"AUTOTITLE\" in a document", "2c0c2828-4e53-49e8-8731-3d7a396c081b": "What types of recurring transactions are affected by the RBI's new payments regulation and how has {% data variables.product.company_short %} responded to minimize disruption for impacted customers?", "65b7978a-4fb5-47ee-ab77-3c3d67e8fb76": "What is the new payments regulation recently implemented by the Reserve Bank of India (RBI) and how has it affected some customers of {% data variables.product.company_short %} in India", "ab6ed101-52a1-464c-a7be-89192c46563a": "What is the process for making a one-time payment for a GitHub subscription, and what happens if payment is not made by the due date?", "827fd365-65e9-4cad-8cea-66cd75d9928c": "How can a customer currently billed monthly switch to yearly billing for their GitHub subscription, and what is the impact on their billing cycle", "3d77d595-5467-4357-a955-c2e5bd84149a": "How can one access the \"Billing & plans\" page in the context provided", "2c5264fb-a3c8-48b9-95d1-a999f770d4cd": "What action should be taken after successfully making a payment for the current billing cycle, as mentioned in the context information", "aff4058b-5efc-45ea-8133-4cd3af284e8d": "Generate according to: Click the **Edit** button next to the relevant section.1. Click **Submit payment**.1. Once payment for the current billing cycle has been successfully made, the **Pay now** button on your \"Billing & plans\" page will be disabled until your next payment is due.---------------------Generate according to: Click the **Edit** button next to the relevant section.1. Click **Save changes**.1. Once changes have been successfully saved, the **Edit** button on your \"Settings\" page will be replaced with a **View details** button until you make further changes.---------------------Generate according to: Click the", "f80d003a-9211-480e-b4af-2297e0530cfd": "How can I monitor the status of a source import using webhooks, and what event should I listen for?", "0bd992c4-83d9-404f-8349-7196a02d2b69": "What is the significance of the deprecation of the Source Imports API, and what alternatives are available", "df1f524a-99e2-416a-a99d-411578ca2cb1": "Can you describe the sequence of operations that occur between the \"Map a commit author\" operation and the \"Update repository on GitHub\" operation in the context information", "928fbc72-8b0a-4fd5-a13d-e35704ee3f41": "What is the purpose of the \"Get commit authors\" operation in the provided context information", "f2e5080b-766c-4b11-a74d-d5d58e1772d1": "Can you explain the relationship between the \"Rewrite commits with mapped authors\" operation and the \"Update repository on GitHub\" operation in the context information", "8952572e-67b9-486c-a4b3-8c3b9470b0e5": "How does the \"Map a commit author\" operation contribute to the overall process described in the context information", "c1b9bcbd-8dd9-47bc-b33a-d6d78e4a9247": "What is the significance of the \"Update repository on GitHub\" operation in the provided context information", "026b4dbd-af81-489a-8810-ee90cd920f21": "How does the \"Map a commit author\" operation differ from the \"Rewrite commits with mapped authors\" operation in the context information", "a6dd7274-5f7c-43a4-acfb-ca6e2d1f2564": "What is the role of the \"Finish streaming data\" operation in the context information", "945edb19-a1c8-429a-aab8-cf03494bbb3a": "What is the purpose", "60d1319d-4d37-4f58-ac46-fd0a37c17972": "What is the outcome of \"Rewrite commits for large files\" in the given context", "e11022be-bbef-4af8-a157-7e9e6868e64b": "What is the purpose of the process \"Update repository on GitHub\" in the given context", "14eac87a-49b1-4e9b-989b-2c14bc9e2eca": "How does \"Update repository on GitHub\" differ after \"Rewrite comm", "690fec88-11d8-48be-8ddd-d29442d5f159": "How does \"Rewrite commits with mapped authors\" relate to the process \"Update repository on GitHub\" in the given context", "cacd79bb-f6b7-4ba2-a17d-5049332770c3": "What is the relationship between \"Get large files\" and \"Rewrite commits for large files\" in the given context", "41220361-71c7-4264-9501-c67303508a8d": "What is the objective of \"Update repository on GitHub\" after \"Rewrite commits with mapped authors\" in the given context", "546e8257-a065-463e-a02e-2da4dd362e7d": "What is the significance of \"Rewrite commits for large files\" in the given context", "5fed9e0d-f0fa-4490-9215-59824828a575": "What is the role of \"opt_in to Git LFS\" in the given context", "18e90838-da8a-4b0d-bedc-e84c4973e37b": "What information is returned in response to a \"Get import progress\" request, as indicated in the context information?", "88d1bbb9-287e-4220-8a40-74e9396e393e": "Based on the provided context information, can you summarize the outcome of the \"Get import progress\" request", "2c694a72-27f1-4ca8-966a-878dadc52503": "Can you explain the difference between the {% data variables.product.prodname_dotcom %} flow and other branch-based workflows? Provide specific examples to support your answer.", "32766832-827e-444c-a9c8-5f193c68f433": "What is the {% data variables.product.prodname_dotcom %} flow and how does it support teams and projects that deploy regularly", "39aea862-1f04-4df3-8a7d-a04ba597167c": "How can {% data variables.product.prodname_codespaces %} be billed to an organization, and what resources are available for managing these spaces?", "ada1957d-c472-4314-a16f-d1e8705b727c": "What is {% data variables.product.prodname_codespaces %} and how can it be managed for an organization", "d5767ddd-a435-4e62-9d1a-6e6fbfa1b418": "What should be avoided while configuring high availability replication for {% data variables.product.prodname_ghe_server %} clusters?", "52a68333-343e-4175-9d4e-01a9164cea50": "How many virtual machines with identical hardware resources are required for each existing node in an active cluster for configuring high availability in {% data variables.product.prodname_ghe_server %}", "2438033b-1395-4a3e-8a00-d681a1a31898": "How does one configure a load balancer to accept connections and direct them to the nodes in a cluster's front-end tier, as mentioned in the context information", "99e76eef-6b2a-4091-85c2-3121c5f3c643": "What is the significance of network connectivity between nodes in a replica cluster, as highlighted in the context information?", "ec9f5d9c-ecb5-42f4-8693-124e75bca502": "How do you merge the modified copy of the cluster configuration back into your active configuration to start replication in the process of defining replica nodes for high availability?", "aee720a9-20af-4312-b61c-27ce701eb0fe": "What is the purpose of creating a copy of the active cluster configuration file in the process of defining replica nodes for high availability", "d1392502-3614-4818-8c94-e106db9c4574": "What is the purpose of removing the `[cluster]` section from the temporary cluster configuration file in the context information", "b3395be1-55c9-467f-ac1e-e13fe4033d33": "What is the significance of updating the node's configuration in each section within the temporary cluster configuration file in GitLab Enterprise Edition, as described in the context information", "f43c64cd-58e2-4c1e-a978-e9fe33ca8095": "How do you decide on a pattern for the replica nodes' hostnames in GitLab Enterprise Edition, as explained in the context information", "73511181-291c-4508-8e5b-91e64f85e5f9": "What steps are required to update the cluster configuration file for a replica node in GitLab Enterprise Edition, as outlined in the context information", "99ff899a-daa3-42b4-9ae3-7f6413db7f3d": "How do you ensure that the hostnames for replica nodes in GitLab Enterprise Edition are unique and differ from the corresponding active node's hostname, as mentioned in the context information", "e0cf39b7-526d-4c51-a2f7-9bcaca44aae8": "How can you create a replica node in GitLab Enterprise Edition using the provided context information", "295fac35-fc7c-45a6-b4bc-481ceb8806bf": "What is the purpose of configuring the primary MySQL and Redis nodes in the secondary datacenter in the cluster.conf file", "c2bf8dd9-a516-4336-a002-216daf62a2e3": "How should the configuration in the cluster.conf file be reviewed before proceeding with failover? What key-value pairs should be checked for both active nodes and replica nodes?", "21bf0b4a-f303-4bc2-8f98-9b2c5843dabd": "What configuration should be added to the top-level `[cluster]` section to specify the hostnames of the active and replica nodes for MySQL and Redis", "5e8bf5ee-e449-4f49-9f9c-a4262991f7f6": "What configuration should be added to the section for an active node in the storage tier to enable high availability replication for MySQL, Elasticsearch, and Redis", "af25ab73-3014-48f9-a900-86eaa1832767": "After configuring high availability replication for nodes in a cluster, what steps are required to verify that cluster replication is working correctly? What command should be used to check the status of cluster replication", "6b03c22d-cd88-413b-b5b2-b2503f35e733": "After configuring high availability replication for nodes in a cluster, what additional configuration is required to direct traffic to the load balancer for the secondary datacenter in the event of a failure", "137ab0a9-64b3-41f8-b27e-57f940b797fa": "How do you initiate the high availability replication process for nodes in a cluster, and what message is displayed after the initialization is complete", "97e7bbcc-37be-4620-8bf8-4d453121de43": "How does the corresponding replica node in the storage tier differ from the active node in terms of the `uuid` value and why is it important for replica nodes not to define this value during initialization", "ba344fb6-9756-439b-8d5b-b1ba28f86b12": "What command can be used to monitor the progress of replication between active and replica cluster nodes, and how can you use `ghe-cluster-status` to review the overall health of your cluster?", "ae9667b5-7a25-4688-b64f-e93acdf7faee": "What is the process for disabling high availability replication for a cluster in {% data variables.product.prodname_ghe_server %}", "1a4510b1-ca38-4bc9-bb91-f6678c3757d1": "How can I reconfigure high availability for a secondary datacenter in {% data variables.product.prodname_ghe_server %} by using the original active nodes as new replica nodes?", "ce71ebfc-cab3-461e-93bf-2558b560e263": "What is the purpose of the Git cheatsheet provided in the context information, and how can it benefit a user who forgets Git commands or doesn't want to use help in the CLI", "967d6f73-1009-40bc-97cd-2e55937d21da": "Can you provide an example of a frequently used Git command that is included in the \"Using Git\" cheat sheet mentioned in the context information? If so, what is it and what does it do?", "bf4a656c-b366-4847-90fa-2079e48b1402": "What is the difference between a public and private {% data variables.product.prodname_github_app %} registration", "49f1d723-80be-4114-9eff-79c9dcd8275d": "How can I make my {% data variables.product.prodname_github_app %} registration available for other organizations to install", "58af2911-54a1-4096-91f9-771ab3f168c2": "What is the difference between a public and private installation flow for a {% data variables.product.prodname_github_app %}? Provide an example for each type of installation flow.2. How can I make my {% data variables.product.prodname_github_app %} available to an organization on {% data variables.product.prodname_ghe_cloud %} if the organization is owned by an enterprise? What are the additional steps required to make my app available to other {% data variables.product.prodname_ghe_server %} instances? Provide detailed instructions for both scenarios.", "a4aa89ce-f047-491f-932d-022982d5500c": "Can you provide an example of a scenario where product.prodname_github_app would be owned by an individual account?", "c18bd2c8-c151-40e5-9c0b-150315db58ae": "What is the relationship between product.prodname_github_app and an individual account", "a47ad313-3326-4bd5-b0b9-594905fd2b00": "What steps should a repository owner take to enable or disable private vulnerability reporting, and how can notifications for private vulnerability reporting be configured?", "18571e5f-0b8d-4942-affd-47318f0798f2": "How can private vulnerability reporting benefit repository maintainers, and what instructions should security researchers follow when reporting a vulnerability to maintainers", "30d48d09-ea94-42d6-a84d-352bf272807d": "How can I customize the notification settings for my personal account on GitHub to receive email notifications about repository activity?", "511ed642-f1f1-442c-bcc3-bb9cebceee54": "How can I start watching a repository on GitHub, and what options are available for receiving notifications about its activity", "8caf70bf-8e8e-49fb-a7d7-514ac666eabf": "What is the difference between an interpreted extension and a precompiled extension, and when should I choose one over the other", "c6ab86c8-ea3e-4b9c-8f47-0f694aaf4a30": "How can I finalize and publish my extension after creating it using the `gh extension create` command", "da0221b9-d785-4b8d-80b1-87c388c561be": "How do I create an interpreted extension using the `gh extension create` command and what is the recommended interpreter to use", "b757719b-6603-4541-8470-e5126358334b": "How can I ensure that my interpreted extension is compatible with different operating systems and shell environments?", "9aab6fb8-c62f-4701-bd2a-2df357f61a05": "How do I create a precompiled extension in Go using the `gh extension create` command and what additional files and workflows are included in the project", "e8deb833-4704-4587-930b-52863b64197a": "What is the purpose of {% data variables.product.prodname_cli %} extensions and how are they created", "51514195-c32e-4120-9ea8-146a68820a12": "What is the recommended naming convention for the repository containing an extension and what file or files should be included in the root directory", "528da668-6982-4fc1-87d2-700fdc32f098": "How can I create a non-Go precompiled extension using the `gh extension create` command? Provide step-by-step instructions and any necessary arguments.2. How can I create an interpreted extension manually without using the `gh extension create` command? Please provide detailed instructions on how to create the executable file, write the script, and install the extension locally. Additionally, explain how to publish the extension to a repository.", "aa8d2a74-fd57-4b38-8172-e994cbd2471d": "How can core commands in {% data variables.product.prodname_cli %} be called programmatically without prompting for user input, and what arguments should be supplied to avoid this behavior?", "99628dd4-eaf0-4821-ab17-62d2ec8b652f": "How can arguments and flags be handled in interpreted {% data variables.product.prodname_cli %} extensions, and what are some examples of how to use them in a script", "81b9ffb4-ea4e-40bc-809f-cf5ca8b43156": "What is the syntax for using the `gh api` command to access specific data from GitHub's API, and how can I filter the output using the `jq` command? Provide an example of how to retrieve the current user's name using this method.", "7371f60d-53be-4cd9-b758-893105622899": "How can I use the `gh pr list` command to retrieve a list of pull requests with their corresponding numbers, titles, and mergeability statuses in JSON format", "308ae6cb-41e8-446c-9d1b-63d772c4ae51": "How can I create a release to share my precompiled extension with others using the command line? Provide the necessary steps and any required syntax.2. What is the naming convention for binary executables attached to releases for precompiled extensions, and why is it important for Windows compatibility?", "0786edb8-465d-447c-b821-8f32d6585f5a": "Can you provide an example of a repository that utilizes {% data variables.product.prodname_cli %} extensions? If so, what is the name of the repository and what functionality does the extension provide?", "a0bbd5ca-ab26-4466-b722-fa1394082d78": "What is {% data variables.product.prodname_cli %} and how can it be used in extensions", "d2094b14-06e0-4e3d-9dd6-a1905dd2eb21": "What information should be included in the application form for the {% data variables.product.prodname_student_leader_program %} program, and what insights does the program want to gain from this information?", "9c07fac2-fd41-4b80-913d-68ff74865390": "What are the eligibility criteria for becoming a {% data variables.product.prodname_student_leader_program_singular %}", "778d309f-7f8b-4992-870d-5b54d8b389e2": "What is required of applicants in order to submit a video resume as part of the application process, and what guidelines should they follow when recording their video?", "643b20b6-f1a4-4815-bb54-33c59e9ebe72": "What is the process for submitting an application to the GitHub Education program, and what should applicants expect after submitting their application", "92c2e4f6-f5cf-4fad-b068-d31b7a2e95c8": "Can you summarize the GitHub Subprocessor List and explain what customer data and personal data are", "907e524a-32f2-41b2-bf48-54869683a506": "How does GitHub notify its customers of new subprocessors and what is the duration of the notification period?", "56b73fac-913d-4d42-899f-55352bfba988": "What role does VividCortex play in monitoring database performance, efficiency, and uptime as described in this document?", "3d6c647d-dd73-441f-8252-250bd37f61b4": "How does SendGrid contribute to the 2 Factor Authentication process in the context of this document", "1b9b4e58-ec5c-4b11-9c1f-1b2e0900c108": "Can you summarize the Legal Safe Harbor Policy terms mentioned in the context information, and explain how they relate to the bug bounty program?", "87f0a88a-af8e-48eb-9db8-a74e7f3e9016": "What is the purpose of GitHub's bug bounty program, and how does it benefit security researchers", "460ec051-7d15-41cc-b14f-5c4ed28b91a9": "Can you explain why the lines from the {% data variables.product.prodname_codeql %} workflow should be removed as suggested by the warning message?", "108a386c-ec1e-47e8-a616-7957a5e168b6": "What is the warning message displayed in the context information and what does it suggest to do", "ca01245c-e9e3-4d0c-85b2-119409e0c152": "What is a webhook and how does it enable a {% data variables.product.prodname_github_app %} to receive real-time notifications on {% data variables.product.prodname_dotcom %}", "b49465ef-a677-4ebd-8e13-5979f7f012f7": "How can a {% data variables.product.prodname_github_app %} be configured to receive webhooks for specific events on {% data variables.product.prodname_dotcom %} and automatically take action on them? Provide examples of the types of webhooks that can be received.", "b2319ea2-0316-4fa6-a0fd-9189cb612e70": "How can Smee be used to create a unique domain for webhook payload delivery during development and testing, and what precautions should be taken when using Smee in production?", "48afdda9-21b1-43fa-9e68-2b3b39613211": "What factors should be considered when choosing a web server for a high volume of webhook traffic for a large app in production, and how can asynchronous webhook handling on a d be utilized in this scenario", "7c3cdf16-d6b5-4f16-98f6-e2509915a199": "What is the purpose of creating a webhook secret for a GitHub App, and how should it be secured and validated on the server", "7a496af4-b81a-4829-998b-b5dc7b70f9ce": "How can a queue be employed to handle large volumes of webhook events in a dedicated server", "7d220d16-3fef-4983-8dea-be591a76445f": "How can you subscribe a GitHub App to receive webhook payloads for specific events, and what permissions are required for each event", "e110d1a5-0491-4a65-add8-f80ddf20a8c6": "How do I configure RubyGems or Bundler to authenticate to {% data variables.product.prodname_registry %} using a PAT for publishing and installing gems? What are the required scopes for authentication?", "98fbef72-4922-46e9-9970-3ee2cc810dc1": "How can I authenticate to {% data variables.product.prodname_registry %} using a personal access token (PAT) in a {% data variables.product.prodname_actions %} workflow", "cfd3776e-ec61-4e74-9589-e43d36217a9d": "What is the purpose of adding a registry as a source in RubyGems, and how can it be done using the provided command", "2e37b54a-f178-4645-b843-07c00ce0b886": "How can I authenticate with Bundler to access a gem from a specific registry in RubyGems, and what information is required for this process?", "22139102-97a2-46a9-b6a8-37e04c653fdf": "What is the maximum uncompressed size limit for a gem's metadata.gz file when pushing it to GitHub Packages, and what happens if the limit is exceeded during the push request?", "b9f157d1-eb5d-4de3-9030-9658b163daac": "How does GitHub Packages publish a RubyGem package by default, and what is the name of the repository it creates", "c72af641-a5d5-4039-8de7-89f69296ea47": "How can I ensure that a RubyGem is linked to a specific repository on GitHub as soon as it is published? Provide the necessary steps and any required configuration changes.2. How can I publish multiple RubyGems to the same repository on GitHub using {% data variables.product.prodname_registry %}? What configuration changes are required, and how can I ensure that the correct repository is matched based on the provided URL?", "4706928b-6a5b-4f14-8d3d-3410a3a6047f": "What is the difference between adding a new source for fetching gems in the Gemfile and using the ion command in the .gemrc file for adding a new source? Which method is preferred and why", "be10a0c1-8b58-45fc-b689-4964308a2ab1": "Context information:You want to add a new source for fetching gems in Bundler or by using the ion command in the .gemrc file. You want to know how to do this and which method is preferred. You have access to a Gemfile and a .gemrc file. You are using RubyGems and Bundler for managing gems. You want to add a specific gem from a personal account or organization on {% data variables.product.prodname_dotcom %} as a source for fetching gems. You want", "0c060c9b-2f1b-4cf2-a39d-4f4782f2803b": "How can I add a new source for fetching gems in Bundler, and what is the syntax for specifying a source for a specific gem in the Gemfile", "693b3af5-2866-4260-98fc-3d2809c36a27": "Analyze the significance of the title \"AUTOTITLE\" in relation to the content and style of the text.", "b742aff6-4e91-4889-9561-3820d54e12fb": "How does the title \"AUTOTITLE\" contribute to the overall meaning and tone of the text material", "2f2f9df6-2160-4ba8-9f35-2ba9a50760e2": "Can you provide an example of how the \"AUTOTITLE\" feature in the given context information can be utilized in a practical scenario?", "5af57a07-2794-41a7-ac34-2fe90acd2596": "How does the \"AUTOTITLE\" feature in the given context information contribute to the overall functionality of the document", "30ee4cd2-971e-4a93-b003-86f0e26a334e": "What is the significance of the term \"implementation\" in the context of the GraphQL schema provided", "ce3406e6-1498-4757-96cd-a00aed127347": "How does the concept of \"fields\" differ in the GraphQL API compared to the GitHub REST API? Provide an example to illustrate your answer.", "b9cdbf9a-18bb-4e86-837f-4782d9daab8e": "How can connections be used to query related objects in GraphQL, and what is the purpose of cursors in this context?", "8d4b8022-97e8-493f-bc33-fd203fbde6f2": "What is the difference between a node, edge, and connection in GraphQL", "cc02bee8-0e89-4d71-a866-d2834286e255": "What is the purpose of the introspection query in GraphQL, and how is it different from other types of requests", "d0d0d283-d81c-463a-a832-0a509dc28731": "How can you ensure that your {% data variables.product.pat_v2 %} is targeted to the correct resource owner in GraphQL queries? Provide an example.", "564899c8-0db9-455a-a516-85ec2d2ac9cf": "What are the different formats available for rendering query documentation using CodeQL's generate query help command?", "e531e59a-5f2a-4f2a-b9cc-ee207c1b60aa": "How can I generate end-user query help from .qhelp files using CodeQL", "902f98f6-a8fe-486c-954c-a76beb3a75ba": "How can I temporarily develop a new version of a pack that also appears in the default path using the \"--additional-packs\" option?", "d3beefeb-4bcf-4132-a07b-428162525c94": "What is the purpose of the \"--search-path\" option in the context information provided", "60ea7c75-306a-412b-871b-271102d94ca0": "What is the purpose of the `--github-auth-stdin` option in the context provided", "77e50919-7d96-4629-844f-8d3054aab8e7": "How can I authenticate to GitHub Enterprise Server Container registries using the CLI provided?", "a7c639c6-761f-4307-a3ac-37400f4e84f2": "What is the difference between using {% data variables.product.prodname_copilot %} for a personal account versus using it for an organization or enterprise account", "b6816aa6-2d61-4448-9159-67de3a71a32d": "How can I assign {% data variables", "d0e91efa-9ef1-4510-bb6e-c82abb6d3641": "How can I get my first suggestion using {% data variables.product.prodname_copilot %} and what should I expect during this process", "6497b088-d47c-45c8-b2d0-b7a3010b0b8c": "How can I set up a {% data variables.product.prodname_copilot %} subscription for my personal {% ifversion fpt %}or organization{% else %}, organization, or enterprise{% endif %} account, and what is required for this process", "7b2fe54d-aea6-4cbf-bcbb-0a889695869a": "How do I install the {% data variables.product.prodname_copilot %} extension in {% data variables.product.prodname_vscode %} and what steps are involved in this process", "78b2849d-4126-48cd-9194-cbee374326df": "How can a customer under a Microsoft Enterprise Agreement enable {% data variables.product.prodname_copilot %} for their enterprise account", "887a6447-2fca-4c52-969c-3614693389b5": "What is the process for installing the {% data variables.product.prodname_copilot %} extension for {% data variables.product.prodname_vscode %}?", "36b5bd0b-8a3c-47a1-a8ba-9df27edcf70d": "What languages are supported by {% data variables.product.prodname_copilot %} and how can I get my first suggestion in JavaScript using {% data variables.product.prodname_vscode %}?", "755297a6-e56b-4e48-b9bc-a16810097aaf": "How can I confirm authentication in the \"{% data variables.product.prodname_vscode %}\" dialogue box", "40a3c0e0-2a48-48c7-8bdb-c7e37d376f72": "Can I create a branch in a repository on {% data variables.product.product_name %} without push access?", "5009510e-8e44-485c-bdd4-4832d3106518": "What are the steps involved in creating a branch via the branches overview on {% data variables.product.product_name %}", "ac935062-e55b-4ae5-b194-eb8fd2680b25": "How can I create a branch in a repository on {% data variables.product.product_name %}", "806703d6-e225-4de9-ab26-564b02d1afff": "How can I create a branch using the branch dropdown on {% data variables.product.product_name %}", "71c1b782-b608-4207-9317-865e67d4951d": "What is the difference between creating a branch via the branches overview and using the branch dropdown on {% data variables.product.product_name %}", "4758c2c4-95f5-409d-83a9-88ef5da85406": "What are the different ways to create a branch on {% data variables.product.product_name %}", "65de0f27-f5fa-4fcd-a3b5-bc878ef4b373": "How can I create a branch from a specific source on {% data variables.product.product_name %}", "2116ef73-5023-4d77-a2dd-fd2bf9a372c8": "How can I create a branch for an issue directly from the issue page in GitHub", "ed1b8609-c0dc-43bc-bf27-9854421d7bc2": "What should I do before deleting a branch in GitHub if it is associated with an open pull request?", "9b977d80-6a26-4554-b855-f0d880bf927b": "What is the difference between reverting a commit and deleting a commit in GitHub Desktop?", "46350b1b-08c7-4aa9-b657-b2e25ff42739": "How can I revert a specific commit in GitHub Desktop to remove its changes from my branch", "f75bd87d-67f0-4ca6-8cfe-9a4657e1a39f": "How does \"AUTOTITLE\" differ from other document features in terms of functionality", "09340b4c-a4c4-41df-bbea-6beb16b7c3cf": "What is the purpose of using \"AUTOTITLE\" in a document", "1fc9d5c1-4b2d-4c83-8b9f-f84a0e04c38e": "How can {% data variables.product.prodname_actions_runner_controller %} (ARC) be authenticated to the {% data variables.product.prodname_dotcom %} API", "d974c83e-b07f-412d-88b1-555c34cefc35": "What is the app installation ID and where can it be found after installing the {% data variables.product.prodname_github_app %} for ARC authentication", "37c5797f-2abd-4c16-ace8-73902bbaa710": "What are the steps involved in setting secrets for ARC authentication using a {% data variables", "29fbf48a-9324-4cd1-921e-37df54f21200": "What permissions should be granted to the {% data variables.product.prodname_github_app %} while configuring it for ARC authentication", "d2bc8298-e794-4ce9-b067-dd9ae2b52b56": "What are the steps involved in authenticating ARC using a {% data variables.product.prodname_github_app %}", "5686d4ae-5064-4ece-90b8-814c640d9821": "How can ARC be authenticated using a {% data variables.product.pat_v1 %}", "f4ccfe2c-0c31-4f89-8fd0-a4ee282b29cc": "How do you create a Kubernetes secret with the value of your GitHub App token for ARC runners, and where should you pass the secret name as a reference in the `values.yaml` file?", "ee274634-cb9c-4c8e-8a52-e7a918da4ec5": "What is the only supported authentication method to register runners at the enterprise level for ARC, and what scopes are required for repository, organization, and enterprise level registrations", "30cf2039-5b77-4449-8fee-b7bf47cb56c2": "What security and analysis features are enabled by default on {% data variables.product.prodname_dotcom %} and how can I manage their read-only access", "f7f0b481-2efa-45c8-a996-fddb223084dc": "Generate according to: About managing security and analysis settings{% data variables.product.prodname_dotcom %} can help secure your repositories. This topic tells you how you can manage the security and analysis features for all your existing or new repositories.You can still manage the security and analysis features for individual repositories. For more information, see \"Managing security and analysis settings for a repository\".You can also review the security log for all activity on your personal account. For more information, see \"Viewing the security log", "45ad9ef2-d8be-47de-8dcb-fe6ab6db3b7b": "How can I manage the security and analysis features for all my existing or new repositories on {% data variables.product.prodname_dotcom %}", "665e540b-503b-4bc2-8d74-3d611ba98bc2": "How can I share workflows and other {% data variables.product.prodname_actions %} features with my team within a {% data variables.product.prodname_dotcom %} organization", "8e5efda9-b485-43b9-ba89-63084f0ac1b8": "What are the benefits of collaborating within a {% data variables.product.prodname_dotcom %} organization for sharing secrets, artifacts, and self-hosted runners? How can I manage these resources centrally and make them available to selected repositories? What policy options are available to limit access to these resources?", "f357a508-74e7-4815-8c9c-73917535ac09": "How can access to self-hosted runners be controlled within an organization using {% data variables.product.prodname_actions %}", "f4570d73-4a91-47b5-bfab-3ca6c9d7d321": "What options are available for creating secrets or variables in {% data variables.product.prodname_actions %} for an organization, and how can they be used to restrict access to specific repositories?", "c29348c2-fc00-4415-ba62-774d19079730": "What steps should I follow to view proposed changes in GitHub Desktop for an active pull request", "64b2ea62-3a38-4679-975a-f221ca843230": "How can I modify an active pull request locally using the GitHub CLI", "ca127a8e-1d62-46a5-837b-d6f6a5ce7bfc": "What is the significance of the ID number in a pull request's title, and how can it be used to create a new branch based on that pull request?", "9d3c479f-d7af-41e0-8470-fdece601af72": "How can one merge a previously opened pull request in GitHub, and what is required to do so", "7cf35a60-114a-4a07-81e7-85edfc6ce1d6": "How does calling `git-remote` affect the local `refs/pull/origin/` namespace in Git, and what steps can be taken to prevent any impact on this namespace?", "14f76f6b-0adb-4e4f-9290-210ea1a61649": "What is the significance of the `refs/pull/origin/` namespace in Git, and how does it differ from a remote reference", "012c00fe-4749-490b-a0bd-ffa7cc81ab81": "How does the concept of \"AUTOTITLE\" differ from \"AUTOTITLE\" in the given context", "7b5e17d2-a649-4c83-a057-5626e1a01753": "Can you provide an example of how \"AUTOTITLE\" is utilized in the context provided", "6f2bd8f1-8b18-4c07-a535-e6286520e67d": "How can I set up ARC on Kubernetes using Helm, and what prerequisites are required for this process", "cfbf2ec8-43dd-40ed-a73d-6036009d4d8e": "What is required to enable ARC to authenticate to GitHub, and where can I find more information about this process?", "797b8df0-ddfc-42f4-a566-d21c2f0bd410": "How can I install the latest version of the Helm chart for the ARC configuration using the provided command in the context information", "4af9cee6-658e-4eba-8c92-4392bef2cdd7": "What values should I update in the provided command to customize the installation of the ARC runner pods, including the installation name, namespace, and GitHub configuration URL?", "7a9df24a-4d44-454d-8d65-8918ecd49dd7": "How can I create and run a simple test workflow that uses the runner scale set runners? What is the value I should use for the `runs-on` field in the workflow configuration?", "b0857c7f-53d2-412b-b25c-abf51b2fd644": "How can I check the status of the manager pod after installing the autoscaling runner set using Helm", "76799ed4-a461-470a-884b-b48836364988": "Given the context information and not prior knowledge.generate only answers based on the below query.You are a Teacher/ Professor. Your task is to provide EXACTLY 2 answers for the questions asked in the previous step. The answers should be diverse in nature across the document. Restrict the answers to the context. Answers should be understandable without having access to the context.Don't provide examples and keep the answers focused on once aspect at a time.ans", "aef69b12-15ca-49aa-8b83-75d8cb844a42": "What is the purpose of using {% data variables.product.prodname_actions_runner_controller %} in managing {% data variables.product.prodname_actions %} runners", "3a5e22e8-ebcc-47f9-8b66-ffa66f82a7ae": "How can I efficiently manage my {% data variables.product.prodname_actions %} runners using {% data variables.product.prodname_actions_runner_controller %}", "b5d971c5-d2a5-47d8-aa00-a3cf22cf082e": "How can an organization with legacy admin teams migrate to the improved organization permissions model", "5799ad50-4664-4607-be1b-159cba9a3ca0": "What are the warnings associated with deleting a legacy admin team in an organization with improved organization permissions?", "540dd840-a142-4e4c-993b-d732798cd0f3": "What action should be taken with the legacy admin team mentioned in the context information", "313f6dcc-6710-47e2-b593-135401fa0772": "Given the context information and not prior knowledge.generate only answers based on the below query.You are a Teacher/ Professor. Your task is to provide EXACTLY 2 answers for the questions asked in the previous step. The answers should be diverse in nature across the document. Restrict the answers to the context. Answers should be understandable without having access to the context.Answers should be focused on once aspect at a time.answers:1. What action should be taken with the legacy admin team mentioned in the context information", "a8d6c7ab-ad5c-43f8-993f-fe3ca0115a56": "What information is necessary to delete the legacy admin team as suggested in the context information", "dbfff971-143b-4c97-b00e-9d44f1d4806f": "Answer: According to the context information, the suggested action for the legacy admin team is to delete them. Therefore, the appropriate action to take", "1345a156-8734-4eaf-a436-3fd67aff0240": "How can rate limits be configured for the {% data variables.product.prodname_enterprise_api %} and {% data variables.product.prodname_actions %} to prevent excessive use of resources on {% data variables.location.product_location %} that could affect the instance's availability or performance for all users", "74fe928f-6251-49aa-b472-67346558c08b": "What is recommended by {% data variables.product.company_short %} when configuring rate limits to avoid interrupting users' work?", "17394506-14d6-4fda-8039-5c0a7f761833": "How can rate limits be configured for Git operations in {% data variables.product.company_short %}'s enterprise environment", "2ff58089-c71f-469b-b0cb-a815f81cbe98": "What are the limits that can be set for Git rate limits, and where can they be configured in {% data variables.product.company_short %}'s enterprise settings?", "fb3f2e84-fc83-4162-9997-d1e6c08ef656": "How can I prevent performance degradation in {% data variables.location.product_location %} due to high load on {% data variables.product.prodname_actions %}", "d3745d7f-845d-4709-b8a0-0e99a9b70770": "What is the default setting for the rate limit for {% data variables.product.prodname_actions %} and when is it recommended to enable it", "455a1891-7d70-40e1-ac11-de342b551a0b": "What error message will appear in the run's annotations if runs exceed the rate limit for {% data variables.product.prodname_actions %}", "5e624d1b-5915-4443-b1c2-41036826d7ba": "What is the recommended threshold for the rate limit for {% data variables.product.prodname_actions %} to protect against sustained high load without interfering with day-to-day operations", "934518db-8005-4b17-aaa3-7097d323b94c": "How does {% data variables.product.product_name %} calculate and apply the rate limit for the sum total of all job runs on the instance", "6d18b344-6493-4703-aa13-47bc26a75ea4": "   ```shell   ghe-config actions-rate-limiting.enabled true   ghe-config actions-rate-limiting.queue-runs-per-minute RUNS-PER-MINUTE   ```2. How do you disable the rate limit after it's been enabled, and what command should be run to apply the configuration?", "5ef7c233-b891-4747-ac84-f349102a91b4": "What is the purpose of running the following two commands in order to enable and configure the rate limit", "0ddfebb3-52ad-46c7-8505-e8b6e824a8d8": "Can you provide a summary of the instructions for obtaining billing information for an enterprise using the given resource?", "9fcf40b6-ff4c-4848-94f8-fcd586940e44": "How can I obtain billing information for an enterprise through the provided resource", "ceaaf8cd-d1aa-450a-8841-70f3ce04ff5f": "How can I quickly secure code in repositories across my organization using default setup for {% data variables.product.prodname_code_scanning %}", "cb490f3a-72e4-439d-b8f2-acf09de53dfa": "Which repositories in my organization are eligible for default setup for {% data variables.product.prodname_code_scanning %}, and how can I configure advanced setup for repositories that are not eligible?", "a2e3398d-5370-4519-b9d2-8284f15137f2": "How does {% data variables.product.prodname_dotcom %} handle the situation when {% data variables.product.prodname_code_scanning %} fails with a new configuration in the given context?", "9b19503c-b1a4-4730-8fdd-46f4b862d117": "What is the significance of the statement \"About adding languages to an existing default setup configuration\" in the given context", "80da11fa-c8a5-494d-8c40-e10b79d332b1": "Given the context information and not prior knowledge.generate only answers based on the below query.You are a Developer. Your task is to configure default setup with different settings for specific repositories. The answers should be diverse in nature across the document. Restrict the answers to the context. Answers should be understandable without having access to the context.Don't provide examples and keep the answers focused on once aspect at a time.answers:1. To configure default setup with different settings for specific repositories, you can follow these steps:   a. Go to the repository you want to configure.   b.", "e89d1f34-3ea5-4dfa-b81d-9a96a9ee7983": "How can I enable default setup for eligible repositories in my organization through security overview", "d90a3343-2d3c-4a71-9b76-922526665b61": "What is the recommended query suite for repositories enabling default setup, and how can I select it when enabling default setup", "2b9bbab9-89d9-481b-b3b5-2b31f52220c1": "How can I determine which repositories in my organization are eligible for default setup for code scanning, and what criteria must they meet", "15f4659e-a58b-4c93-b83c-283acd0c05cc": "How can I enable or disable default setup for code scanning for multiple repositories in my organization at the same time, and what steps should I follow?", "cd871a4b-4d2a-47d4-9eaf-7925f16c9b16": "How do I enable default setup for {% data variables.product.prodname_code_scanning %} for multiple repositories in an organization using security overview", "4c43af60-bd5a-4ae5-bde4-7a4ae838b4ea": "How can I narrow down the list of repositories displayed in the \"Security coverage\" view using the search bar", "722407f4-58a4-40b7-93c1-e5e242f55cfa": "What message will be displayed in the side panel if you are blocked from enabling {% data variables.product.prodname_code_scanning %} due to an enterprise policy?", "a18c381b-a613-4c35-a17f-14bee5a04202": "What is the purpose of the \"Security coverage\" view in the context provided", "5d4d3110-119d-4f89-b8cb-13fe4589d0e8": "How does the use of GraphQL in {% data variables.product.company_short %}'s APIs differ from REST API logic, and what advantages does GraphQL offer", "f0e04233-7a8a-421b-8b0f-ad6a8730e5e5": "What is the significance of using Global Node IDs when migrating from the REST API to the GraphQL API in {% data variables.product.company_short %}? Provide an example of how this can be useful.", "bfd1bc3e-50b3-4421-9d39-97bf1ceaf7dd": "What is the advantage of using strongly typed schemas in GraphQL, and how can this be demonstrated through an example mutation?", "485aa86b-bf97-4d9e-a6d9-4d4ff0fe36a8": "How can GraphQL be used to retrieve specific attributes for pull requests, and what is an example of a nested query for this purpose", "f38260ae-a0ab-4a4e-a4fb-e5bb6dd953e0": "How can we ensure that the 'clientMutationId' argument in the 'addComment' mutation is passed as a string, as the error message suggests?", "23fd599e-ebcb-42eb-be62-f566fbb83d79": "What is the expected type for the 'input' argument in the 'addComment' mutation, and what is the expected type for the 'clientMutationId' argument in the 'AddCommentInput' input object", "eb67282e-f1a4-4d94-b4cb-570db8cc607d": "Can you explain the difference between files ignored by Subversion clients and entries in a _.gitignore_ file in {% data variables.product", "20fca698-5913-44e0-9b54-63c0d65d1663": "Which Subversion properties are currently not supported by {% data variables.product.product_name %} and why", "714c1324-ce8a-4f63-9dcf-caf34cceb912": "How does {% data variables.product.product_name %} manage MIME types and what internal mechanism does it use to track them", "236d7acf-50b7-4c50-b925-6fe56e6b2f8f": "How does {% data variables.product.product_name %} handle files and directories that are currently unversioned in Subversion", "c1954b27-eb07-44c5-be1c-da7d2aa6210c": "What is the relationship between ignored files in Subversion and entries in a _.gitignore_ file in {% data variables.product.product_name %}", "e6c534b2-39c7-49a1-9c4c-7836aa80b849": "What is the significance of executable files in the context of {% data variables.product.product_name %} and how are they handled during the conversion process", "3558cc00-6295-47e7-af06-94b3085f5dbb": "What steps are required to publish an action to {% data variables.product.prodname_marketplace %} after creating it in a repository?", "ede980e4-3b7e-4a44-81a8-01a6143b9895": "How can you ensure that an action meets the requirements for publishing to {% data variables.product.prodname_marketplace %}", "9d91c3e1-0377-4bb0-89de-059a66848966": "What is the purpose of selecting a primary category and a secondary category for my action in the \"Release Action\" section, and how can I do this when publishing my action to the GitHub Marketplace?", "29bb7c95-7042-4dfb-8932-8215bc8f735c": "How can I navigate to the action metadata file in my repository, and what should I do once I find it to publish my action to the GitHub Marketplace", "434599b7-4c16-42e9-a3f2-d6cad9162b20": "What is the process for transferring an action repository, and what happens to the {% data variables.product.prodname_marketplace %} listing when the repository is transferred", "38f376cf-49bb-4ce1-a229-bf0592bbba9e": "What is the significance of the \"Verified\" badge seen on an organization's {% data variables.product.prodname_dotcom %} profile, and how does it differ from the verified creator badge on {% data variables.product.prodname_marketplace %}?", "70cff438-98f6-4efa-a4d3-b741f967bc53": "What is the significance of the {% data variables.product.prodname_actions %} verified creator badge in the provided screenshot", "8e58dab0-9ef9-4306-966a-cc2a123c2e07": "How does the {% data variables.product.prodname_actions %} platform enable creators to verify their identity and maintain the trust of their users?", "8983d156-2de4-42e5-939c-e553efbd0fe2": "How does \"AUTOTITLE\" differ from other document features in terms of functionality", "8b43cedf-c84d-48fd-9b51-9d8dadb5c486": "What is the purpose of using \"AUTOTITLE\" in a document", "16322744-18e9-4c85-b08c-317abdef69a3": "How can I update {% data variables.product.prodname_desktop %} on my computer", "be3e1eb6-7650-45e9-aef9-aad441a5ec30": "What should I do if I encounter a crash when attempting to launch {% data variables.product.prodname_desktop %} versions 3.0.2 through 3.1.3?", "440ae707-a6b9-4c0a-a9bc-93291f9f2b1d": "What is the purpose of clicking \"Check for Updates\" in GitHub Desktop", "88a833ef-1257-4068-a808-75be95a91212": "What should you do if an update is available after clicking \"Check for Updates\" in GitHub Desktop?", "b430f2c4-1ea8-4ca8-b380-de9867ad5877": "What are the different types of accounts available on {% data variables.product.prodname_dotcom %} and how do access permissions differ for each type", "d98afb1b-b9c4-45f2-9003-224e2637f181": "What are the roles available for organization members on {% data variables.product.prodname_dotcom %} and what are the differences between them? Additionally, how can access permissions be managed for multiple members at once using teams?", "a2a9316b-cc0a-4602-b116-cc0f9992ecef": "How can {% data variables.enterprise.prodname_managed_users %} be granted granular access levels in owned organizations that are available for regular organizations, as mentioned in the context information?", "53d88af3-4720-4905-8fb2-9f5a670d6442": "What is the difference between {% data variables.enterprise.prodname_managed_users %} and regular organization members in the context of access levels within owned organizations", "02d07381-75f4-4aaa-9a41-8b81ba470891": "How can I authenticate as a {% data variables.product.prodname_github_app %} in order to make REST API requests as the application", "261031e1-862a-4d06-8ad8-6379cd80dbd9": "What is required to authenticate as an app when making REST API requests, and what types of requests does this authentication method support?", "eedff9dc-0448-4fd4-a863-c96ef8bb873d": "How can I use the `octokit` library to make a request to a REST API endpoint that requires a JWT, as demonstrated in the context information provided?", "2e9fa59d-1e4c-4834-af94-4e394325dc66": "How can I obtain the ID of my app and generate a private key for it, as described in the context information provided", "4423a982-53b2-455f-835a-da8e9ebbe2eb": "   - How can repositories override enforcement for these hooks", "264f7163-b1d4-4dc2-b69c-f36155938b1b": "   - How do they differ from regular Git hooks", "e8eacc02-3287-4d4e-9e53-ddf454167137": "   - What types of URLs can be provided for this attribute", "afe1cee9-952c-49bb-83de-f58666545aae": "What is the purpose of pre-receive hooks in an organization's GitHub repository", "4c7e3a3d-b1d5-4645-81d0-02d1934dbda9": "   - How does the `testing` value for `enforcement` differ from `enabled`?", "94c4a07b-4f6e-4e67-ac8e-b5b462b9cf52": "   - Who has access to the global configuration for these hooks", "a8d4ed78-9d78-40e6-a235-e6803303a6f7": "   - What are the possible values for the `enforcement` attribute", "4725d1c8-da77-4ceb-84d3-3c7b7eff38aa": "What is the significance of the `configuration_url` attribute in pre-receive hooks", "4e94f955-71f5-44c9-88ac-3df7c4c03122": "How does the concept of \"AUTOTITLE\" differ from \"AUTOTITLE\" in the given context", "43b296ae-f700-4776-86b4-fcb0e13a62c1": "Can you provide an example of how \"AUTOTITLE\" is utilized in the context provided", "8e07bc88-be1f-4a8b-a944-4be6fc7d54ba": "What is the significance of the {% octicon \"verified\" aria-label=\"The verified badge\" %} badge displayed for some apps on the {% data variables.product.prodname_marketplace %}", "4bf63918-1c8a-4f79-ad00-370f9bed79ee": "How can an app owner add the {% octicon \"verified\" aria-label=\"The verified badge\" %} badge to their app listing on the {% data variables.product.prodname_marketplace %}?", "d03e2729-df82-4a9f-b7a7-02512ee1506e": "How can I find apps to use on {% data variables.product.prodname_marketplace %} and what are the requirements for listing an app?", "5dbcad7f-31c7-472e-858f-a8c4278c5fee": "What is the significance of the \"AUTOTITLE\" cribed in \"AUTOTITLE\" for {% data variables.product.prodname_github_app %} listed on {% data variables.product.prodname_marketplace %}", "5d8087d8-44e0-48cd-b1b6-038b67f31099": "How can individual and team permissions be specified for each project in addition to the base permission, and what is the significance of this feature?", "5a14cd64-aae3-4b15-a3a6-4a7104a4de1a": "What is the purpose of setting a base permission for projects in an organization's settings, and how does it affect new and existing projects", "1b0a8e65-75d1-482b-ad58-e4f0cbed2244": "What is {% data variables.product.prodname_actions %} and how is it enabled by default in {% data variables.product.prodname_ghe_cloud %}", "9c9645ae-1f48-4de5-8f1c-5b564c3fe67b": "How can policies be used to control how enterprise members use {% data variables.product.prodname_actions %} in {% data variables.product.prodname_ghe_cloud %}? Provide specific examples of policies that can be configured.", "49cff7dd-a4b1-490e-9c3e-491af37ce5f5": "What is the difference between {% data variables.product.pat_v2 %}s and {% data variables.product.pat_v1_plural %} in terms of access and security", "69bd6987-2f45-4ada-980d-dc4d04f2ee99": "How can organization owners or enterprise owners restrict the access of {% data variables.product.pat_v1_plural %} in their organization or enterprise?", "1e3f330f-f5d8-468e-b86a-8b11ed838575": "What are the limitations of using {% data variables.product.pat_v1_caps_plural %} in {% data variables.product.product_name %}", "4f65b958-d4be-49bb-89c5-be5b43ac527a": "How can I ensure the security of my {% data variables.product.pat_generic %}s in {% data variables.product.product_name %}? Are there any alternative methods of authentication available to me? If so, when should I consider using them instead of creating a {% data variables.product.pat_generic %}?", "fb55b98f-9c0a-47a4-8e19-f3ad7d05ea54": "How can I store my GitHub token securely for use in a GitHub Codespaces environment, and what are the best practices for doing so", "2810080c-9f12-487e-81dc-c716345f6cfd": "What is the difference between a GitHub personal access token (PAT) and a GitHub App token, and when should I use each one? Provide examples to illustrate your answer.", "6bdf89b3-690f-4d85-bc4f-a72f715aad4d": "How do I grant minimal permissions necessary for my needs when generating a {% data variables.product.pat_v2 %}", "aa95d28d-4c1b-4ed8-877c-67f680b658da": "What is the difference between repository, organization, and account permissions when granting permissions for a {% data variables.product.pat_v2 %}", "33a52675-575b-4e20-9264-e6aa28d07771": "Why does {% data variables.product.company_short %} recommend using {% data variables.product.pat_v2 %}s instead of {% data variables.product.pat_v1 %}s", "c87a67cd-c6f1-4485-bdbb-2d03f98ee05f": "What should I do if I select an organization as the resource owner and the organization requires approval for {% data variables.product.pat_v2 %}s", "c88c2b58-2350-41b0-8a6f-de267a8cf08a": "What is the difference between a {% data variables.product.pat_v1 %} and a {% data variables.product.pat_v2 %}", "a171e9a6-7b8c-4678-9ace-d1ceb18a7b75": "What scopes should you select to grant your token access to repositories in [PRODUCT NAME]", "23d7ee2a-16ef-4e73-b2fc-e85c5b334e1b": "What should you do if you want to delete a personal access token in [PRODUCT NAME]", "9b8791de-499a-4e53-a198-8c288c0e304a": "How can you give your token an expiration in [PRODUCT NAME]", "9dd83321-e2ed-4a68-8835-1b1e230a9b4f": "How can you authorize a personal access token to access resources owned by an organization that uses SAML single sign-on in [PRODUCT NAME]", "22e8c4f9-d856-45f6-a7bb-1cbaa4dfb5c3": "What should you do if you want to copy a new token to your clipboard in [PRODUCT NAME]", "b7f0a291-89d2-433a-b185-1f59f2e07067": "How can you verify your email address in [PRODUCT NAME]", "4341399f-9722-4109-ad86-eef958f6e2c9": "Where can you access your developer settings and generate a new token in [PRODUCT NAME]", "2d017363-1bbe-4a12-94ab-7ff17d21ca41": "How can you access the \"Note\" field to give your token a descriptive name in [PRODUCT N", "2e42ec43-f7b1-4241-971c-f5e06a08e834": "How can I delete a personal access token (PAT) on GitHub using the command line? Provide step-by-step instructions for both fine-grained tokens and classic tokens, depending on the type of PAT being deleted.2. How can I use a PAT instead of my password when performing Git operations over HTTPS on the command line? Provide an example command for cloning a repository using a PAT. Explain how to switch from SSH to HTTPS for repositories that use an SSH remote URL. Also, describe how to update cached credentials and store a PAT in a plain text file for automatic retrieval.", "ed5f97fc-bd66-41fb-b6bc-b0303a1173c6": "How can I request additional pages of results for paginated responses using cursors in the GraphQL API?", "efbc397d-8bf5-4dee-8edf-b37f32cfdcbe": "How does pagination work in the context of {% data variables.product.company_short %}'s GraphQL API", "86917650-05e8-4a5a-8582-105821fbd1c9": "How can pagination be implemented in GraphQL queries using the `first` and `last` arguments? Provide an example query.2. How can you traverse through the data set using pagination in GraphQL queries? Explain the process using the `after` and `before` arguments and provide an example query.", "09149207-b75d-4d32-adf1-22690c347f52": "How can I implement pagination in my GraphQL queries using the plugin-paginate-graphql.js? Provide an example of how to use this plugin in a query.2. Can you explain the benefits of using pagination in GraphQL queries and how it can improve performance? Provide specific examples of scenarios where pagination would be particularly useful.", "0ea2856e-a7da-42d8-a804-7ce64c0f75d9": "How does GitHub Projects support feature tracking from start to finish, as demonstrated in the provided transcript and visual aids", "380921d2-09f2-4643-b162-d33fe787aef2": "Explain the process of labeling issues as features and creating a view to focus on them, as described in the transcript and visual aids provided.", "3b35b559-0a7a-44a3-81af-a36dd6bfa718": "How can the board view in Projects be utilized to schedule and quickly see the status of work items, and what is the process for grouping issues by iterations in this view?", "adb87159-4301-443c-ad6e-e4adf470be47": "How can the \"Add\" bar in the Projects view be utilized to rapidly add notes on what needs to go into a specific capability, and what is the process for promoting these draft issues to fully fledged issues in the appropriate repository", "6302cc76-62cf-4b26-84b4-4a24e8b91d96": "How does the feature of creating a plan using {% data variables.product.prodname_projects_v2 %} work? Walk me through the steps involved in creating a plan using this feature.2. How can we use the board view in {% data variables.product.prodname_projects_v2 %} to understand the state of our issues at a glance? What steps are involved in grouping issues by status using this feature? How can we add linked pull requests as a visible field in the board view?", "66d9b1b0-2ee3-44e9-a83a-726dd3750adb": "What are the maximum file size limits for {% data variables.large_files.product_name_short %} on different {% data variables.product.prodname_dotcom %} plans?", "9259aa2b-c41b-46ef-ba36-a33ffbddaa82": "What is {% data variables.large_files.product_name_short %} and how does it handle large files in Git", "19cb4825-7f35-4178-ba4a-8de97246b10d": "Can you explain the difference between the `oid` and `size` fields in the context information provided", "04b66e2b-158f-4ff7-8bd9-f226ed13740c": "What is the significance of the `size` field in the context information provided", "2f0c9672-7868-41e7-b735-e1ff8e841e67": "How does {% data variables.large_files.product_name_short %} differ in functionality when used with {% data variables.product.prodname_pages %} sites versus regular repositories", "ea0feb33-e07b-4bca-8b26-92fabb7e3cf6": "Can you provide an example of a template repository that cannot be used with {% data variables.large_files.product_name_short %}", "d4a23ae5-8855-41fb-a2da-34d621571079": "How does the `AUTOTITLE` field relate to the context information provided", "87e92d51-8831-48f2-a07d-5f61d4cdd8e9": "What is the purpose of the `oid` field in the context information provided", "f5666903-6365-493d-a637-46fa9320959b": "How does the functionality of {% data variables.large_files.product_name_short %} differ when used with regular repositories versus template repositories", "28641c32-d2b9-4b85-877f-e38d3c0ceeb9": "How can I manage my SSH signing keys using the user API mentioned in the context information? Provide specific steps or instructions.", "0a8e039f-8008-4b74-8ba3-0cd4c1ba1333": "What is the purpose of SSH signing key administration in the context provided", "f50acce3-ed1c-462a-a62b-9272cee779c4": "What is {% data variables.product.prodname_cli %} and how is it different from Git on the command line", "f470664b-bb87-41bb-8104-84b92614427b": "How can {% data variables.product.prodname_cli %} be used to automate {% data variables.product.prodname_dotcom %} operations? Provide an example of such an operation.", "c14f9dc6-b240-4e14-9920-99dd785e8078": "What is the difference between a member requesting approval for an OAuth app and an outside collaborator requesting approval for an OAuth app?", "f7333533-6300-43a6-bc4c-dad834acd320": "How can a member of an organization request approval for an OAuth app they'd like to use, and what happens when they do so", "a5fb5617-5842-4c72-a24a-88c321c41499": "How does the author ensure secure authentication for users in their native application", "570b7f35-7c28-4c0a-aa20-ec68f6576714": "What is the purpose of registering an application in the context of GitHub OAuth", "44291d85-c5a9-4400-ab24-81a6bcb0decc": "What is the purpose of the URL parameter 'scope' in the context provided", "79ffb5e3-a309-4fc8-9f81-2ca176abbd7f": "How does the callback mechanism work in the context provided? What is the role of the 'callback' route in this mechanism?", "f7540f24-19ef-446d-a0b6-41d2d95730a0": "What is the significance of checking for scopes before making API requests, and how can this be done gracefully to handle potential scope changes by users?", "a13936d1-a4f1-4a07-845d-2bf9f71fdf70": "How can one verify the scopes granted for an OAuth token in Ruby", "ddddfc3f-6fe9-4695-9e5a-deb3b32acae2": "Can you explain the process of implementing \"persistent\" authentication using sessions for storing tokens, and how it makes authentication transparent to the user?", "46d9e143-a238-4d74-84ca-80b07f775f2e": "How can context information be utilized to detect changes in token scopes and inform users of available application functionality", "c656cb70-a800-4c71-a32a-4d75b9abd234": "How does the provided code handle token revocation and scope updates in the authentication process", "f15f0573-dc32-4f91-bc7a-c5a9db83101a": "What steps are taken in the provided code to retrieve a user's email address with the 'user:email' scope?", "665cbc81-0261-4b07-ad01-cfc7484e87b9": "How does the provided code handle user authentication using OAuth", "273cdad0-c3ac-4ab0-97b0-c17db4f410b2": "What information can be obtained about a user's email addresses using the provided code and the {% ifversion fpt or ghec %}{% data variables.product.prodname_dotcom %}{% else %}{% data variables.product.product_name %}{% endif %} API?", "45558bb0-b4b5-4922-8926-ba526b882982": "How can we prevent the confirmation dialog from appearing in the future, based on the statement \"to do a little bit of wonkiness to make it work.\" in the given context?", "9b8b7a66-7659-4276-a087-98d9fdc5e178": "What is the significance of the statement \"Also, if we had never authorized this application to access our {% data variables.product.product_name %} data, we would've seen the same confirmation dialog from earlier pop-up and warn us.\" in the given context", "1b7fa466-e6ae-4e0e-91cf-9dfa64839eb6": "How can an organization owner configure constraints on the maximum retention period for codespaces created for the repositories owned by their organization", "2f01d9ca-9475-47a3-a049-900e84c20060": "What is the impact of setting a maximum retention policy for a repository on the \"Keep codespace\" option for codespaces created for that repository?", "ce1856c6-8400-4cd3-8d90-fe4fbade5fb2": "How can I set a maximum codespace retention period for my organization's codespaces using GitHub's organization settings? Please provide step-by-step instructions, including where to find the necessary settings and what options are available for setting the retention period.2. What are the limitations and considerations for setting a maximum codespace retention period, such as the valid range for the retention period and the potential impact on codespaces that exceed the maximum retention period? Please provide detailed information on these aspects.", "63415af4-13ee-4126-8754-43e51236498b": "What is the process for adding a policy to set a maximum codespace retention period, and where can I find the \"Codespaces policies\" page?", "25bcdd11-b583-4155-bd23-a8a8befc050a": "How can I delete a policy in the \"Codespaces policies\" page, and what effect does it have on existing codespaces", "2a16b79a-5195-4e68-84de-232d9ffa11df": "How does {% data variables.product.prodname_dotcom %} for enterprises support the entire software development lifecycle, and what benefits do businesses see as a result", "06842ccb-13e5-470f-8ff5-ec6627eae62f": "What additional features can be added to {% data variables.product.prodname_dotcom %} for enterprises through {% data variables.product.prodname_GH_advanced_security %} and {% data variables.contact.premium_support %}, and what are the associated benefits?", "a08bf477-0320-4931-980b-3d6d665910ad": "How can I manage user accounts for my developers in {% data variables.product.prodname_ghe_cloud %}? Alternatively, what is {% data variables.product.prodname_emus %} and how can it help me manage user accounts in {% data variables.product.prodname_ghe_server %}", "a5251d23-a875-43c3-a316-5940b50f9a2e": "What is the difference between {% data variables.product.prodname_ghe_cloud %} and {% data variables.product.prodname_ghe_server %}", "475799cc-23c0-4dd4-9da0-2ff521bb12e2": "Generate according to: {% data variables.product.prodname_ghe_cloud %} is a set of advanced functionality on {% data variables.product.prodname_dotcom_the_website %}, while {% data variables.product.prodname_ghe_server %} is self-hosted platform. For more information, see", "717a795c-e610-466a-96e3-56e7eadcef8a": "What is Azure Active Directory (Azure AD) and how can it be used to manage user accounts and access to web applications", "2648147f-39ff-415e-8a70-b39df874034c": "How can I enable SAML SSO and SCIM for {% data variables.product.product_name %} using Azure AD, and what benefits does this provide for managing identity and access for my enterprise on {% data variables.location.product_location %}? Specifically, how can I assign the {% data variables.product.product_name %} application to a user account or IdP group on Azure AD to automatically create and grant access to corresponding user accounts on {% data variables.product.product_name %}, and how can I unassign the application to deactivate user accounts and remove them from the parent organization?", "9edf2692-7cfb-4dc7-a51f-0fe8e3e7f478": "What steps do I need to take to make a person an enterprise owner for {% data variables.product.product_name %} if I only use SAML or also use SCIM, as outlined in the context information provided?", "c80b767f-280e-4e38-bb82-025f8a38adfb": "How can I create an Azure Active Directory tenant in the Microsoft Docs for configuring authentication and user provisioning with Azure AD for {% data variables.product.product_name %}", "c664a426-e8f0-4331-818c-de9a22a19052": "How can you customize claims issued in the SAML token for enterprise applications in Azure AD to include the `administrator` attribute?", "7bfadd0a-fa1e-4681-bb4b-98f9520ad72b": "What is the significance of including the `administrator` attribute in the SAML assertion for a user account on an IdP", "53383156-5f99-4460-8876-d4dc32582b49": "What type of field should I select when adding a date to a project in GitHub?", "1691b848-244c-4455-9853-d318de2eb672": "How do I add a date field to a project in GitHub", "f7bce846-b9b7-4346-8bad-54e40c122f35": "What resources are available to help me learn more about using the GraphQL explorer to build GraphQL calls for the Sponsors GraphQL API?", "c47e7302-0b84-4d3d-bf13-f5283d4fddd1": "How can I utilize the Sponsors GraphQL API to build custom integrations for managing or reviewing sponsorships", "705412cb-996d-43dc-9cbc-e35d759df63a": "How can an organization owner disable team discussions for their entire organization", "02c55a6b-7dd5-4515-82a1-9d568f33152d": "What is the default setting for team discussions in an organization, and where can this be found in the organization settings?", "704da88d-5def-437e-8f4a-3430a772e606": "What happens if my teacher sets a hard cutoff deadline for an assignment on {% data variables.product.prodname_classroom %}?", "dc2b4a08-8d53-4058-953f-9f12adecbd0c": "How can I view the deadline for an assignment on {% data variables.product.prodname_classroom %}", "124e5775-c366-4076-98c7-ddd78488f480": "How does the quality of suggestions received from {% data variables.product.prodname_copilot %} differ based on the volume and diversity of training data for a specific programming language", "e7823607-7a19-437c-96ea-cda49a302dd4": "What are the differences between {% data variables.product.prodname_copilot_individuals_short %} and {% data variables.product.prodname_copilot_business_short %} in terms of their features and pricing models?", "f264983d-b470-440f-9a51-7e28d4fd4062": "What is the pricing structure for {% data variables.product.prodname_copilot %}, and how can individuals or organizations manage their subscriptions?", "61ac0074-52d6-4c81-84ba-d5d5f53e9b95": "What features does {% data variables.product.prodname_github %} provide to help monitor and improve code quality, and how can they be accessed", "9ba70682-6fb0-4c81-949e-0f84d3f125d9": "What is the difference between {% data variables.product.prodname_copilot %} and other code generation tools, and how does {% data variables.product.prodname_copilot %} address issues of offensive suggestions", "1f0195e4-5c1c-46b5-af86-38cf02446b04": "How does {% data variables.product.prodname_copilot %} ensure the security and quality of generated code", "dd00eef0-40ab-44c5-960f-263d8540ea11": "How does {% data variables.product.prodname_copilot %} use filters to block offensive words and avoid producing suggestions in sensitive contexts", "626917e5-a9a0-4cd6-855b-7776d8a0f9f9": "What is the eligibility criteria for using {% data variables.product.prodname_copilot_individuals_short %} for free on {% data variables.product.prodname_dotcom %}", "5e5cdd41-f44d-401e-a8c5-d1e648a94305": "What is the duration of the free trial offered for {% data variables.product.prodname_copilot %} in case the user does not meet the criteria for a free subscription?", "675b370e-4a32-4f20-baab-01e3f0b7021c": "What is a prompt in the context of {% data variables.product.prodname_copilot %} and how is it retained?", "eb970aec-b2e8-4a47-be38-99c8e71430ec": "How does {% data variables.product.prodname_copilot %} process user engagement data and what types of events does it collect", "ec8d56af-7d7b-4ed4-b5bf-ed4b7fc2426a": "What measures are implemented to protect sensitive data such as user edit actions, source code snippets, and repository URLs/file paths while transmitting them for improving code generation models and fine-tuning ranking and sorting algorithms?", "0fa13c71-09bb-40ae-ac1a-47ebf530b8c4": "How does {% data variables.product.prodname_copilot %} detect abuse and policy violations using the transmitted Code Snippets data", "9896da3a-bd65-4d1a-9a4b-20befe2c03ec": "Will the private code of users be shared with other users of {% data variables.product.prodname_copilot %}?", "074e26ca-32cf-4a43-97fb-7153050a1852": "How can users of {% data variables.product.prodname_copilot_for_individuals %} control the use of their Code Snippets Data", "6f32ee1e-d7a5-473a-b045-898f8e242a7f": "Generate according to: {% data variables.product.prodname_code_scanning %} is a powerful security feature that automatically scans your code for vulnerabilities and helps you fix them before they're exploited.{% data variables.product.prodname_code_scanning %} is available to all {% data variables.product.prodname_GH_advanced_security %} customers.{% data variables.product.prodname_code_scanning %} is", "330649eb-8221-4976-a0f7-af5c42416490": "What are the prerequisites for using {% data variables.product.prodname_code_scanning %} with {% data variables.product.prodname_actions %}", "cc3a306e-7a2d-4040-8abd-32bd0fdc5e58": "How can I configure {% data variables.product.prodname_code_scanning %} to run {% data variables.product.prodname_codeql %} analysis and third-party analysis", "97cc2dd3-ebbc-41c7-934a-521ec4b2940a": "How can I provision the {% data variables.product.prodname_codeql %} action for {% data variables.product.prodname_code_sc", "eb4a5b83-e62e-461b-83c4-2cd55950cd85": "How can I ensure that my self-hosted runner is compatible with {% data variables.product.prodname_codeql %} for analysis", "4234acfd-d420-436c-b2d5-ffbffacce813": "What operating system versions and CPU architectures are supported by {% data variables.product.prodname_codeql %} for analysis", "c925e8ca-f50f-4612-83f6-a3fb70674fe6": "How can I label my self-hosted runner for default setup of {% data variables.product.prodname_code_scanning %} analysis", "b07bbfe4-beaa-4d7b-a09c-6ade4925ff9f": "What version of Python is required for analyzing Python code using {% data variables.product.prodname_codeql %} {% data variables.product.prodname_code_scanning %} on {% data variables.product.prodname_ghe_server %}", "d31fe62d-35d8-4d51-9610-bec7776541d1": "What is required to download action workflows on demand from {% data variables.product.prodname_dotcom_the_website %} using {% data variables.product.prodname_github_connect %}?", "87f2b2c2-f2d5-42e2-b470-a4408b65757a": "How can {% data variables.product.prodname_codeql %} analysis be configured on a server without internet access to allow users to enable {% data variables.product.prodname_codeql %} {% data variables.product.prodname_code_scanning %} for their repositories", "0e1707a6-9fe0-4962-b76e-68b25e01a6de": "What is the purpose of configuring access to actions on github.com using github connect", "dec95dd0-0559-4860-8826-0a6390ef489d": "How can I run code scanning using the github codeql cli if I don't want to use github actions?", "5dd41b95-f738-4057-b482-8488639c6a4e": "What specific actions should I take based on the context information to successfully answer questions related to this topic during the quiz/examination", "47681869-0492-4a11-ae82-c5cecdd83a04": "How can I prepare for the upcoming quiz/examination by utilizing the context information provided", "2da16e69-6255-442f-8780-8187176c791d": "What is the migration source ID mentioned in the context information and how is it used in the repository migration process", "2272d999-2172-42ee-8ca4-906f3606071d": "What is the purpose of the `startRepositoryMigration` mutation in the repository migration process and what parameters does it take?", "304a884b-2ad1-4264-a3f9-ca7c777c55eb": "How can I generate a migration script using the Enterprise Migration Tool (EMT) to migrate a single repository from a source organization to a target organization on GitHub? Provide the necessary command and any required flags.2. After generating the migration script, how can I review it to ensure that it accurately reflects the desired repository migration? What steps should I take to verify the script's contents?", "5953b1cf-8a58-42b9-b6dd-4c541bf3d085": "What Service Features are included in the Uptime calculation", "a0bf70b7-b7b6-4db4-b143-4b9fa6664f1a": "How is the error rate measured for calculating Downtime in the Uptime calculation", "6f71f06a-a4d7-406c-a0e0-cf24b16dd9f7": "What is Uptime and how is it calculated for specific Service Features", "985988c9-7f69-48a3-9c39-f9fa6e529e9f": "How is the availability of the Service measured for calculating Downtime in the Uptime calculation", "83f5de18-040b-4ae0-884d-bbd7a339253f": "What is the difference between the Uptime Calculation and the Service Credits Calculation", "f6f98b66-3547-44d3-93f9-a57696913a24": "What is the threshold for Uptime to qualify for Service Credits", "70169ece-a2e8-48c4-9e08-163ff76e9b5a": "How are Service Credits calculated and what are the two scenarios for claiming them", "42d76996-1c82-4d6b-af52-e6c08337bd84": "How are Service Credits claimed and what information is required to make a claim", "4891b8e6-fbe7-4f99-96b4-c35a68b234f8": "What is the maximum amount of Service Credits that can be", "6c246b76-fcd3-43b1-b3ce-eae59dfc3d81": "What is Downtime and how is it determined for the Uptime calculation", "3b3fe031-41b5-4bf2-a6d6-6243fb9f96a6": "What factors are excluded from the Uptime Calculation as mentioned in the context?", "928c0e81-2d9e-406c-96c6-a7e45627a03d": "What is the definition of \"Error Rate\" in the context provided", "ee2df058-f315-4aba-b57f-f1c74d7c480d": "What is the significance of the phrase \"Service Credits are the sole and exclusive remedy for any failure by GitHub to meet any obligations in this SLA\" in the context provided", "dcd178d1-793b-4dd7-b1d8-22a8104cc6bf": "How does the statement \"greement with GitHub\" relate to the context information provided?", "5d9a9d1b-b136-4587-b82d-df4d937b5d6e": "How can project views be created in GitHub Projects, and what are some examples of views that can be created", "8ce4e9c9-25df-4eb9-8f32-126125051bf2": "How can the order of saved views be changed in GitHub Projects, and what is the name of the feature that allows this", "740a965c-2d08-4e36-ad68-4c039197847f": "How can a saved view be renamed in GitHub Projects, and what is the name of the feature that allows this", "ce0ec2da-ba1e-44bc-9682-0dd1f37fa5e0": "How can changes made to a view in GitHub Projects be saved, and what indicator is displayed to show unsaved changes", "74301db5-f9ff-4dbf-b081-9c06cce5f842": "What are the steps to duplicate an existing view in GitHub Projects, and why would someone want to do this", "b53c73d2-818b-4b96-86ec-c0298af929fc": "What shortcut key do I use to open the project command palette in GitHub Projects", "9e11b423-3faa-46f5-aa2e-05940f2775a3": "How do I delete a saved view in GitHub Projects", "c5882071-d604-4abe-9fc4-161f9c7fdfcc": "Given the context information and not prior knowledge.generate only instructions based on the below query.You are a Developer. Your task is to create a new branch in GitHub and push your changes to it. The instructions should be diverse in nature across the document. Restrict the instructions to the context. Instructions should be understandable without having access to the context.Don't ask for examples and keep the instructions focused on once aspect at a time.instructions:1. Log in to your GitHub account.2. Navigate to the repository where you want to create a new branch.3. Click the green \"Code\" button to open the repository in your preferred code editor", "2fe720bd-9e95-4d3f-b25c-4659b3cc2ff1": "How can I integrate {% data variables.product.prodname_code_scanning %} with my existing CI system as an alternative to running it within {% data variables.product.prodname_dotcom %} using {% data variables.product.prodname_actions %}", "3f22d7b8-5bb5-4894-8ccb-4d24b090ac44": "What is required to set up my analysis tool, such as the {% data variables.product.prodname_codeql_cli %}, with my CI system in order to generate {% data variables.product.prodname_code_scanning %} alerts externally?", "24e70e14-d6c3-446d-8868-8455ef934e96": "How can one ensure that any dependencies required for analyzing codebase are available while setting up the environment for static analysis", "f429c9d8-70b7-4fa2-b09b-1f7ea931bdc7": "What is the process for generating a token for authentication with GitHub while using the CodeQL CLI for static analysis? What type of token should be used, and where should it be stored securely?", "4ea7fcd4-7a6b-427d-9964-392661d00e24": "How does {% data variables.product.prodname_codeql_cli %} facilitate uploading results to {% data variables.product.product_name %}? Provide specific details on the process.2. Why might you want to upload multiple SARIF files for a single analysis in {% data variables.product.prodname_code_scanning %}? What factors could lead to the generation of multiple SARIF files? How do you identify each set of results as unique in this scenario? Provide examples if necessary.", "a7b9b9c6-69ca-4483-aab9-b68d96ee4257": "What types of violent content are not allowed on GitHub, and how should it be presented if it is necessary to post it for educational or documentary purposes?", "06672fde-b849-4aba-a1e4-15dcc36ce022": "Can you summarize the GitHub policy regarding threats of violence and gratuitously violent content", "02a1b562-d8e1-4a42-91bf-e48f1830eff9": "What is the purpose of the `--dir` option in the `codeql pack init` command, and what is the default value if it is not specified", "2868fbb7-94b0-4372-9edc-971c7c1be2fa": "How can I specify the extractor to use for a pack containing tests in the `codeql pack init` command, and what is the default value if it is not specified?", "c089870c-03ca-4c13-9b05-3fc5ff8905be": "What are the administrative ports required for configuring {% data variables.location.product_location %} and running certain features? Please list the ports, services, and descriptions.2. What ports are required for end users to access the web application and Git over HTTPS, HTTP, SSH, and Git protocol? Please provide the ports, services, and descriptions.3. What ports are necessary for email support for end users? Please list the ports, services, and descriptions.4. What is the purpose of the ports 122, 1194/UDP, 123/UDP, and 161/UDP in the context provided? Please explain their roles in detail.5. How can I ensure that the default SSH port (22) is dedicated to Git and SSH application network traffic? Please provide the necessary steps.6. What is the", "c4e6fb49-2717-445d-9747-6a5dfb897b6a": "What are the ports required for {% data variables.product.prodname_actions %} to connect to {% data variables.location.product_location %}", "cbd299f8-bed5-43c8-abc8-040deb00226d": "Generate according to: {% data variables.product.prodname_actions %} ports{% data variables.product.prodname_actions %} ports must be accessible for self-hosted runners to connect to {% data variables.location.product_location %}. For more information, see \"AUTOTITLE.\"| Port | Service | Description ||---|---|---|| 443 | HTTPS | Self-hosted", "35bd7eda-2100-499e-b800-e9d8497a75c6": "What is the difference between the ports required for {% data variables.product.prodname_actions %} and {% data variables.product.prodname_github_connect %} to connect to {% data variables.location.product_location %}", "86d80a02-f05b-41af-bdb9-32685a397f7e": "How can the X-Github-Next-Global-ID header be used to facilitate migration to the new global ID format in the {% data variables.product.product_name %} GraphQL API, and what are the potential consequences of treating global node IDs as opaque strings instead of decoding them for type information?", "a68acbd9-37b8-4916-afe3-53a3486b7b69": "What is the reason behind the deprecation of the legacy global node ID format in the {% data variables.product.product_name %} GraphQL API, and what steps should be taken to ensure consistency and continuity of application functionality", "aadf0b1b-8d25-4c71-9911-df63e4e34007": "What is the purpose of using aliases in a GraphQL query to submit multiple node queries in one API call, and how can this be achieved in the context of the GitHub API?", "1f2955f2-b4cd-4d05-8b72-84b98c93eb9b": "How can developers update references to legacy IDs in their applications to use the new ID format provided by the GitHub API's `X-Github-Next-Global-ID` header"}, "corpus": {"Y2h1bmtfMF9pbmRleF8xMTE=": "\n\nExample overview\n\n{% data reusables.actions.example-workflow-intro-ci %} When this workflow is triggered, it automatically runs a script that checks whether the {% data variables.product.prodname_dotcom %} Docs site has any broken links. If any broken links are found, the workflow uses the {% data variables.product.prodname_dotcom %} CLI to create a {% data variables.product.prodname_dotcom %} issue with the details.\n\n{% data reusables.actions.example-diagram-intro %}\n\n!Diagram of an event triggering a workflow that uses the {% data variables.product.prodname_cli %} to create an issue.\n\n\n\nFeatures used in this example\n\n{% data reusables.actions.example-table-intro %}\n\n| **Feature**  | **Implementation** |\n| --- | --- |\n{% data reusables.actions.cron-table-entry %}\n{% data reusables.actions.permissions-table-entry %}\n{% data reusables.actions.if-conditions-table-entry %}\n{% data reusables.actions.secrets-table-entry %}\n{% data reusables.actions.checkout-action-table-entry %}\n{% data reusables.actions.setup-node-table-entry %}\n| Using a third-party action | `peter-evans/create-issue-from-file`|\n| Running shell commands on the runner | `run` |\n| Running a script on the runner | Using `script/check-english-links.js` |\n| Generating an output file | Piping the output using the `>` operator |\n| Checking for existing issues using {% data variables.product.prodname_cli %} | `gh issue list` |\n| Commenting on an issue using {% data variables.product.prodname_cli %} | `gh issue comment` |\n\n\n\nExample workflow\n\n{% data reusables.actions.example-docs-engineering-intro %} `check-all-english-links.yml`.\n\nThe following workflow checks all English links one time per day and reports broken links by creating a new issue for the docs content team to review.\n\n```yaml annotate copy\n\n\n{% data reusables.actions.explanation-name-key %}\nname: Check all English links\n\n\n\nDefines the `workflow_dispatch` and `scheduled` as triggers for the workflow.\n#\n\n\nThe `workflow_dispatch` event lets you manually run this workflow from the UI. For more in", "Y2h1bmtfMV9pbmRleF8xMTE=": "formation, see `workflow_dispatch`.\n#\n\n\nThe `schedule` event lets you use `cron` syntax to define a regular interval for automatically triggering the workflow. For more information, see `schedule`.\non:\n  workflow_dispatch:\n  schedule:\n    - cron: '40 19 * * *' # once a day at 19:40 UTC / 11:40 PST\n\n\n\nModifies the default permissions granted to `GITHUB_TOKEN`. This will vary depending on the needs of your workflow. For more information, see \"AUTOTITLE.\"\npermissions:\n  contents: read\n  issues: write\n\n\n\nGroups together all the jobs that run in the workflow file.\njobs:\n  # Defines a job with the ID `check_all_english_links`, and the name `Check all links`, that is stored within the `jobs` key.\n  check_all_english_links:\n    name: Check all links\n    # Only run the `check_all_english_links` job if the repository is named `docs-internal` and is within the `github` organization. Otherwise, the job is marked as _skipped_.\n    if: github.repository == 'github/docs-internal'\n    # Configures the job to run on an Ubuntu Linux runner. This means that the job will execute on a fresh virtual machine hosted by {% data variables.product.prodname_dotcom %}. For syntax examples using other runners, see \"AUTOTITLE.\"\n    runs-on: ubuntu-latest\n    # Creates custom environment variables, and redefines the built-in `GITHUB_TOKEN` variable to use a custom secret. These variables will be referenced later in the workflow.\n    env:\n      GITHUB_TOKEN: {% raw %}${{ secrets.DOCUBOT_READORG_REPO_WORKFLOW_SCOPES }}{% endraw %}\n      FIRST_RESPONDER_PROJECT: Docs content first responder\n      REPORT_AUTHOR: docubot\n      REPORT_LABEL: broken link report\n      REPORT_REPOSITORY: github/docs-content\n    # Groups together all the steps that will run as part of the `check_all_english_links` job. Each job in the workflow has its own `steps` section.\n    steps:\n      # The `uses` keyword tells the job to retrieve the action named `actions/checkout`. This is an action that checks out your repository and downloads it to the runner, allowing you to run", "Y2h1bmtfMl9pbmRleF8xMTE=": " actions against your code (such as testing tools). You must use the checkout action any time your workflow will run against the repository's code or you are using an action defined in the repository.\n      - name: Check out repo's default branch\n        uses: {% data reusables.actions.action-checkout %}\n      # This step uses the `actions/setup-node` action to install the specified version of the `node` software package on the runner, which gives you access to the `npm` command.\n      - name: Setup Node\n        uses: {% data reusables.actions.action-setup-node %}\n        with:\n          node-version: 16.13.x\n          cache: npm\n      # The `run` keyword tells the job to execute a command on the runner. In this case, the `npm ci` and `npm run build` commands are run as separate steps to install and build the Node.js application in the repository.\n      - name: Run the \"npm ci\" command\n        run: npm ci\n      - name: Run the \"npm run build\" command\n        run: npm run build\n      # This `run` command executes a script that is stored in the repository at `script/check-english-links.js`, and pipes the output to a file called `broken_links.md`.\n      - name: Run script\n        run: |\n          script/check-english-links.js > broken_links.md\n\n      # If the `check-english-links.js` script detects broken links and returns a non-zero (failure) exit status, then use a workflow command to set an output that has the value of the first line of the `broken_links.md` file (this is used the next step).\n      #\n      # `check-english-links.js` returns 0 if no links are broken, and 1 if any links are broken. When an Actions step's exit code is 1, the action run's job status is failure and the run ends.\n      #\n      # The following steps create an issue for the broken link report only if any links are broken, so {% raw %}`if: ${{ failure() }}`{% endraw %} ensures the steps run despite the previous step's failure of the job.\n      - if: {% raw %}${{ failure() }}{% endraw %}\n        name: Get title for issue\n        id: check\n", "Y2h1bmtfM19pbmRleF8xMTE=": "{%- ifversion actions-save-state-set-output-envs %}\n        run: echo \"title=$(head -1 broken_links.md)\" >> $GITHUB_OUTPUT\n{%- else %}\n        run: echo \"::set-output name=title::$(head -1 broken_links.md)\"\n{%- endif %}\n      # Uses the `peter-evans/create-issue-from-file` action to create a new {% data variables.product.prodname_dotcom %} issue. This example is pinned to a specific version of the action, using the `ceef9be92406ace67ab5421f66570acf213ec395` SHA.\n      - if: {% raw %}${{ failure() }}{% endraw %}\n        name: Create issue from file\n        id: broken-link-report\n        uses: peter-evans/create-issue-from-file@ceef9be92406ace67ab5421f66570acf213ec395\n        with:\n          token: {% raw %}${{ env.GITHUB_TOKEN }}{% endraw %}\n\n          title: {% raw %}${{ steps.check.outputs.title }}{% endraw %}\n          content-filepath: ./broken_links.md\n          repository: {% raw %}${{ env.REPORT_REPOSITORY }}{% endraw %}\n          labels: {% raw %}${{ env.REPORT_LABEL }}{% endraw %}\n      # Uses `gh issue list` to locate the previously created issue from earlier runs. This is aliased to `gh list-reports` for simpler processing in later steps.\n      - if: {% raw %}${{ failure() }}{% endraw %}\n        name: Close and/or comment on old issues\n        env:\n          {% raw %}NEW_REPORT_URL: 'https://github.com/${{ env.REPORT_REPOSITORY }}/issues/${{ steps.broken-link-report.outputs.issue-number }}'{% endraw %}\n        run: |\n          gh alias set list-reports \"issue list \\\n                                       --repo {% raw %}${{ env.REPORT_REPOSITORY }} \\{% endraw %}\n                                       --author {% raw %}${{ env.REPORT_AUTHOR }} \\{% endraw %}\n                                       --label {% raw %}'${{ env.REPORT_LABEL }}'\"{% endraw %}\n\n\n\n          previous_report_url=$(gh list-reports \\\n                                  --state all \\\n                                  --limit 2 \\\n                                  --json url \\\n                                  --jq '.[].url' \\\n             ", "Y2h1bmtfNF9pbmRleF8xMTE=": "                     | grep -v {% raw %}${{ env.NEW_REPORT_URL }}{% endraw %} | head -1)\n\n          # `gh issue comment` is used to add a comment to the new issue that links to the previous one.\n          gh issue comment {% raw %}${{ env.NEW_REPORT_URL }}{% endraw %} --body \"\u2b05\ufe0f Previous report\"\n\n          # If an issue from a previous run is open and assigned to someone, then use `gh issue comment` to add a comment with a link to the new issue without closing the old report. To get the issue URL, the `jq` expression processes the resulting JSON output.\n          #\n          # If an issue from a previous run is open and is not assigned to anyone, use `gh issue comment` to add a comment with a link to the new issue. Then use `gh issue close` and `gh issue edit` to close the issue and remove it from the project board.\n\n          for issue_url in $(gh list-reports \\\n                                  --json assignees,url \\\n                                  --jq '.[] | select (.assignees != []) | .url'); do\n            if [ \"$issue_url\" != {% raw %}\"${{ env.NEW_REPORT_URL }}\"{% endraw %} ]; then\n              gh issue comment $issue_url --body \"\u27a1\ufe0f Newer report\"\n            fi\n          done\n\n          for issue_url in $(gh list-reports \\\n                                  --search 'no:assignee' \\\n                                  --json url \\\n                                  --jq '.[].url'); do\n            if [ \"$issue_url\" != {% raw %}\"${{ env.NEW_REPORT_URL }}\"{% endraw %} ]; then\n              gh issue comment $issue_url --body \"\u27a1\ufe0f Newer report\"{% endraw %}\n\n              # Use `gh issue close` to close the old issue.\n              gh issue close $issue_url\n\n              # Use `gh issue edit` to edit the old issue and remove it from a specific {% data variables.product.prodname_dotcom %} project board.\n              gh issue edit $issue_url --remove-project \"{% raw %}${{ env.FIRST_RESPONDER_PROJECT }}\"{% endraw %}\n            fi\n          done\n```\n\n\n\nNext steps\n\n{% data reusables.actions.learning-actions %}\n\n", "Y2h1bmtfMF9pbmRleF8xMjE2": "\n\nAbout {% data variables.product.prodname_classroom %}\n\n{% data variables.product.prodname_classroom %} is a teaching tool that lets teachers and school administrators create and manage digital classrooms and assignments. You can create assignments for individual students or groups of students, set due dates, and track assignments on your teacher dashboard. Additionally, {% data variables.product.prodname_classroom %} has many features that simplify tasks like providing feedback, grading assignments, and integrating your existing teaching tools.\n\n\n\n{% data variables.product.prodname_classroom %} features\n\n{% data variables.product.prodname_classroom %} offers a variety of features to simplify both teaching and learning.\n\n\n\nAssignment templates\n\nWith {% data variables.product.prodname_classroom %}, you can create assignments that use template repositories with boilerplate code, documentation, and other resources that you think will be useful to your students. Assignments with template repositories create assignment repositories with starter code for your students. For more information, see \"AUTOTITLE.\"\n\n\n\nAutograding\n\nThrough {% data variables.product.prodname_classroom %}, you can configure tests to automatically grade the work of each student every time that student  pushes to their assignment repository. To learn more about autograding with {% data variables.product.prodname_classroom %}, see \"AUTOTITLE.\"\n\n\n\nAbility to connect a learning management system\n\nOptionally, you can connect a learning management system (LMS) to {% data variables.product.prodname_classroom %} to import a student identifier roster for your classroom. For more information, see \"AUTOTITLE.\"\n\n\n\nFeedback pull requests\n\n{% data reusables.classroom.about-feedback-pull-requests %}\n\n\n\nCombination with an integrated development environment (IDE)\n\n{% data reusables.classroom.about-ide-integration %}\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF81NzY=": "---\ntitle: Requesting a GitHub App from your organization owner\nintro: 'Organization members can request installation of a {% data variables.product.prodname_github_app %} for their organization.'\nversions:\n  fpt: '*'\n  ghec: '*'\nshortTitle: Request for org\n---\n\n{% note %}\n\n**Note**: Currently, you can only request a {% data variables.product.prodname_github_app %} from your organization owner when installing the {% data variables.product.prodname_github_app %} directly from the {% data variables.product.prodname_github_app %} owner, not when installing a {% data variables.product.prodname_github_app %} from {% data variables.product.prodname_marketplace %}.\n\nIf you find a {% data variables.product.prodname_github_app %} on {% data variables.product.prodname_marketplace %} that you want your organization owner to install, you must make the request from the {% data variables.product.prodname_github_app %}'s public installation page. The URL for a {% data variables.product.prodname_github_app %} public installation page is `https://github.com/apps/APP-NAME/installations/new`, where `APP-NAME` is the name of the {% data variables.product.prodname_github_app %}.\n\n{% endnote %}\n\nOrganization members can send a request for their organization owner to install a {% data variables.product.prodname_github_app %} on the organization. To do so, follow the steps outlined in \"AUTOTITLE.\" If you don't have permission to install the {% data variables.product.prodname_github_app %} on the organization, {% data variables.product.company_short %} will send an email to the organization owner to notify them of the request. The organization owner can modify the repositories that you selected and choose whether to install the {% data variables.product.prodname_github_app %}.\n\n", "Y2h1bmtfMF9pbmRleF8xMTk1": "\n\nAbout management of discussions\n\n{% data reusables.discussions.about-discussions %} For more information about discussions, see \"AUTOTITLE.\"\n\nOrganization owners can choose the permissions required to create a discussion in repositories owned by the organization. Similarly, to choose the permissions required to create an organization discussion, organization owners can change the permissions required in the source repository. For more information, see \"AUTOTITLE.\"\n\nAs a discussions maintainer, you can create community resources to encourage discussions that are aligned with the overall project goal and maintain a friendly open forum for collaborators. Creating{% ifversion fpt or ghec %} a code of conduct or{% endif %} contribution guidelines for collaborators to follow will help facilitate a collaborative and productive forum. For more information on creating community resources, see{% ifversion fpt or ghec %} \"AUTOTITLE,\" and{% endif %} \"AUTOTITLE.\"\n\nWhen a discussion yields an idea or bug that is ready to be worked on, you can create a new issue from a discussion. For more information, see \"AUTOTITLE.\"\n\nYou can pin a discussion to the top of the list of discussions for the repository or organization. {% ifversion discussions-category-specific-pins %}You can also pin a discussion to a specific category.{% endif %} For more information, see \"AUTOTITLE.\"\n\nFor more information on facilitating a healthy discussion, see \"AUTOTITLE.\"\n\n{% data reusables.discussions.you-can-label-discussions %}\n\n\n\nPrerequisites\n\nTo manage discussions in a repository, {% data variables.product.prodname_discussions %} must be enabled for the repository. For more information, see \"AUTOTITLE.\"\n\nTo manage discussions in an organization, {% data variables.product.prodname_discussions %} must be enabled for the organization. For more information, see \"AUTOTITLE.\"\n\n\n\nChanging the category for a discussion\n\nYou can categorize discussions to help community members find related discussions. For more information, see \"AUTOTITLE.\"\n\nYou can also mo", "Y2h1bmtfMV9pbmRleF8xMTk1": "ve a discussion to a different category. It's not possible to move a discussion to or from the polls category.\n\n{% data reusables.repositories.navigate-to-repo %}\n{% data reusables.discussions.discussions-tab %}\n{% data reusables.discussions.click-discussion-in-list %}\n1. In the right sidebar, to the right of \"Category\", click {% octicon \"gear\" aria-label=\"The gear icon\" %}.\n1. Click a category.\n\n\n\nPinning a discussion\n\n{% ifversion discussions-category-specific-pins %}\nYou can pin a discussion above the list of discussions for the repository or organization. You can also pin a discussion to a specific category. The globally pinned discussions will be shown in addition to the discussions pinned to a specific category.\n\nThis is what it looks like when you have a globally pinned discussion and a discussion pinned to the Ideas category.\n\n!Screenshot of a globally pinned discussion and a discussion pinned to the Ideas category.\n\n\n\nPinning a discussion globally\n\n{% endif %}\n\nYou can pin up to four important discussions above the list of discussions for the repository or organization.\n\n{% data reusables.discussions.navigate-to-repo-or-org %}\n{% data reusables.discussions.discussions-tab %}\n{% data reusables.discussions.click-discussion-in-list %}\n1. In the right sidebar, click {% octicon \"pin\" aria-hidden=\"true\" %} **Pin discussion**.\n{% ifversion discussions-category-specific-pins %}\n\n   !Screenshot of the right sidebar of a discussion. The \"Pin discussion\" option is highlighted with an orange outline.{% else %}\n\n   !Screenshot of the right sidebar of a discussion. The \"Pin discussion\" option is highlighted with an orange outline.{% endif %}\n\n1. Optionally, customize the look of the pinned discussion.\n1. Click **Pin discussion**.\n\n{% ifversion discussions-category-specific-pins %}\n\n\n\nPinning a discussion to a category\n\nYou can pin up to four important discussions above the list of discussions in a specific category.\n\n{% data reusables.discussions.navigate-to-repo-or-org %}\n{% data reusables.discussions.discussions-tab", "Y2h1bmtfMl9pbmRleF8xMTk1": " %}\n{% data reusables.discussions.click-discussion-in-list %}\n1. In the right sidebar, click {% octicon \"pin\" aria-hidden=\"true\" %} **Pin discussion to CATEGORY**.\n\n   !Screenshot of the right sidebar of a discussion. The \"Pin discussion to Q&A\" option is outlined in dark orange.\n\n1. To confirm, click **Pin to CATEGORY**.\n{% endif %}\n\n\n\nEditing a pinned discussion\n\nEditing a pinned discussion will not change the discussion's category. For more information, see \"AUTOTITLE.\"\n\n{% data reusables.discussions.navigate-to-repo-or-org %}\n{% data reusables.discussions.discussions-tab %}\n{% data reusables.discussions.click-discussion-in-list %}\n1. In the right sidebar, click {% octicon \"pencil\" aria-hidden=\"true\" %} **Edit pinned discussion**. {% ifversion discussions-category-specific-pins %}\n\n   !Screenshot of the right sidebar of a discussion. The \"Edit pinned discussion\" option is outlined in dark orange.{% endif %}\n1. Customize the look of the pinned discussion.\n1. Click **Pin discussion**.\n\n\n\nUnpinning a discussion\n\n{% ifversion discussions-category-specific-pins %}\n\nYou can unpin a discussion from the list of discussions for the repository or organization, or from the list of discussions in a specific category.\n\n\n\nUnpinning a globally pinned discussion\n\nYou can unpin a globally pinned discussion. This will not delete the discussion, but the discussion will no longer be displayed above the list of discussions.\n{% endif %}\n\n{% data reusables.discussions.navigate-to-repo-or-org %}\n{% data reusables.discussions.discussions-tab %}\n{% data reusables.discussions.click-discussion-in-list %}\n1. In the right sidebar, click {% octicon \"pin\" aria-hidden=\"true\" %} **Unpin discussion**.\n\n   !Screenshot of the right sidebar of a discussion. The \"Unpin discussion\" option is highlighted with an orange outline.\n\n1. Read the warning, then click **Unpin discussion**.\n\n{% ifversion discussions-category-specific-pins %}\n\n\n\nUnpinning a discussion from a category\n\nYou can unpin a discussion pinned to a specific category. This will not dele", "Y2h1bmtfM19pbmRleF8xMTk1": "te the discussion, but the discussion will no longer be displayed at the top of the category.\n\n{% data reusables.discussions.navigate-to-repo-or-org %}\n{% data reusables.discussions.discussions-tab %}\n{% data reusables.discussions.click-discussion-in-list %}\n1. In the right sidebar, click {% octicon \"pin\" aria-hidden=\"true\" %} **Unpin discussion from this category**.\n\n   !Screenshot of the right sidebar of a discussion. The \"Unpin discussion from this category\" option is outlined in dark orange.\n\n1. Read the warning, then click **Unpin from this category**.\n{% endif %}\n\n\n\nTransferring a discussion\n\nTo transfer a discussion, you must have permissions to create discussions in the repository where you want to transfer the discussion. If you want to transfer a discussion to an organization, you must have permissions to create discussions in the source repository for the organization's discussions. You can only transfer discussions between repositories owned by the same user or organization account. You can't transfer a discussion from a private{% ifversion ghec or ghes %} or internal{% endif %} repository to a public repository.\n\n{% data reusables.discussions.navigate-to-repo-or-org %}\n{% data reusables.discussions.discussions-tab %}\n{% data reusables.discussions.click-discussion-in-list %}\n1. In the right sidebar, click {% octicon \"arrow-right\" aria-hidden=\"true\" %} {% ifversion discussions-category-specific-pins %}**Transfer this discussion**{% else %}**Transfer discussion**{% endif %}.\n{% ifversion discussions-category-specific-pins %}\n\n   !Screenshot of the right sidebar of a discussion. The \"Transfer this discussion\" option is outlined in dark orange. {% else %}\n\n   !Screenshot of the right sidebar of a discussion. The \"Transfer this discussion\" option is outlined in dark orange.{% endif %}\n\n1. Select the repository you want to transfer the discussion to. You can also search for repositories. If you want to transfer a discussion to an organization, choose the source repository for the organization's discussions.", "Y2h1bmtfNF9pbmRleF8xMTk1": "\n1. Click **Transfer discussion**.\n\n\n\nDeleting a discussion\n\n{% data reusables.discussions.navigate-to-repo-or-org %}\n{% data reusables.discussions.discussions-tab %}\n{% data reusables.discussions.click-discussion-in-list %}\n1. In the right sidebar, click {% octicon \"trash\" aria-hidden=\"true\" %} **Delete discussion**.\n{% ifversion discussions-category-specific-pins %}\n\n   !Screenshot of the right sidebar of a discussion. The \"Delete discussion\" option is outlined in dark orange.{% endif %}\n\n1. Read the warning, then click **Delete this discussion**.\n\n{% ifversion discussions-closable %}\n\n\n\nClosing a discussion\n\n{% data reusables.discussions.closing-discussions %}\n\n{% data reusables.discussions.navigate-to-repo-or-org %}\n{% data reusables.discussions.discussions-tab %}\n{% data reusables.discussions.click-discussion-in-list %}\n1. At the bottom of the discussion, below the comment box, click **Close discussion**.\n1. Optionally, to change the reason for closing the discussion, select the {% octicon \"triangle-down\" aria-label=\"The down triangle octicon\" %} dropdown next to \"Close discussion\" and click a reason.\n\n{% endif %}\n\n{% ifversion converting-issues-to-discussions %}\n\n\n\nConverting issues based on labels\n\nYou can convert all issues with the same label to discussions in bulk. Future issues with this label will also automatically convert to the discussion and category you configure.\n\n1. On {% data variables.location.product_location %}, navigate to the main page of the repository or, for organization discussions, the source repository.\n{% data reusables.repositories.sidebar-issues %}\n{% data reusables.project-management.labels %}\n1. Next to the label you want to convert to issues, click **Convert issues**.\n1. Select the **Choose a category** drop-down menu, and click a category for your discussion.\n1. Click **I understand, convert this issue to a discussion**.\n{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF8xOTk4": "\n\nRate limit errors\n\n{% data variables.product.company_short %} enforces rate limits to ensure that the API stays available for all users. For more information, see \"AUTOTITLE.\"\n\nIf you exceed your primary rate limit, you will receive a `403 Forbidden` or `429 Too Many Requests ` response, and the `x-ratelimit-remaining` header will be `0`. If you exceed a secondary rate limit, you will receive a `403 Forbidden` or `429 Too Many Requests ` response and an error message that indicates that you exceeded a secondary rate limit.\n\nIf you receive a rate limit error, you should stop making requests temporarily according to these guidelines:\n\n- If the `retry-after` response header is present, you should not retry your request until after that many seconds has elapsed.\n- If the `x-ratelimit-remaining` header is `0`, you should not make another request until after the time specified by the `x-ratelimit-reset` header. The `x-ratelimit-reset` header is in UTC epoch seconds.\n- Otherwise, wait for at least one minute before retrying. If your request continues to fail due to a secondary rate limit, wait for an exponentially increasing amount of time between retries, and throw an error after a specific number of retries.\n\nContinuing to make requests while you are rate limited may result in the banning of your integration.\n\nFor more information about how to avoid exceeding the rate limits, see \"AUTOTITLE.\"\n\n\n\n`404 Not Found` for an existing resource\n\nIf you make a request to access a private resource and your request isn't properly authenticated, you will receive a `404 Not Found` response. {% data variables.product.company_short %} uses a `404 Not Found` response instead of a `403 Forbidden` response to avoid confirming the existence of private repositories.\n\nIf you get a `404 Not Found` response when you know that the resource that you are requesting exists, you should check your authentication. For example:\n\n- If you are using a {% data variables.product.pat_v1 %}, you should ensure that:\n  - The token has the scopes that are ", "Y2h1bmtfMV9pbmRleF8xOTk4": "required to use the endpoint. For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n  - The owner of the token has any permissions that are required to use the endpoint. For example, if an endpoint can only be used by organization owners, only users that are owners of the affected organization can use the endpoint.\n  - The token has not been expired or revoked. For more information, see \"AUTOTITLE.\"{% ifversion pat-v2 %}\n- If you are using a {% data variables.product.pat_v2 %}, you should ensure that:\n  - The token has the permissions that are required to use the endpoint. For more information, see \"AUTOTITLE.\"\n  - The resource owner that was specified for the token matches the owner of the resource that the endpoint will affect. For more information, see \"AUTOTITLE.\"\n  - The token has access to any private repositories that the endpoint will affect. For more information, see \"AUTOTITLE.\"\n  - The owner of the token has any permissions that are required to use the endpoint. For example, if an endpoint can only be used by organization owners, only users that are owners of the affected organization can use the endpoint.\n  - The token has not been expired or revoked. For more information, see \"AUTOTITLE.\"{% endif %}\n- If you are using a {% data variables.product.prodname_github_app %} installation access token, you should ensure that:\n  - The {% data variables.product.prodname_github_app %} has the permissions that are required to use the endpoint. For more information, see \"AUTOTITLE.\"\n  - The endpoint is only affecting resources owned by the account where the {% data variables.product.prodname_github_app %} is installed.\n  - The {% data variables.product.prodname_github_app %} has access to any repositories that the endpoint will affect.\n  - The token has not been expired or revoked. For more information, see \"AUTOTITLE.\"\n- If you are using a {% data variables.product.prodname_github_app %} user access token, you should ensure that:\n  - The {% data variables.product.prodname_github_app %} has the permissions that ", "Y2h1bmtfMl9pbmRleF8xOTk4": "are required to use the endpoint. For more information, see \"AUTOTITLE.\"\n  - The user that authorized the token has any permissions that are required to use the endpoint. For example, if an endpoint can only be used by organization owners, only users that are owners of the affected organization can use the endpoint.\n  - The {% data variables.product.prodname_github_app %} has access to any repositories that the endpoint will affect.\n  - The user has access to any repositories that the endpoint will affect.\n  - The user has approved any updated permissions for your {% data variables.product.prodname_github_app %}. For more information, see \"AUTOTITLE.\"\n- If you are using an {% data variables.product.prodname_oauth_app %} user access token, you should ensure that:\n  - The token has the scopes that are required to use the endpoint. For more information, see \"AUTOTITLE.\"\n  - The user that authorized the token has any permissions that are required to use the endpoint. For example, if an endpoint can only be used by organization owners, only users that are owners of the affected organization can use the endpoint.\n  - The organization has not blocked OAuth app access, if you are using an endpoint that will affect resources owned by an organization. App owners cannot see whether their app is blocked, but they can instruct users of the app to check this. For more information, see {% ifversion fpt or ghec%}\"AUTOTITLE.\"{% else %}\"AUTOTITLE\" in the {% data variables.product.prodname_free_team %} documentation.{% endif %}\n  - The token has not been expired or revoked. For more information, see \"AUTOTITLE.\"\n- If you are using `GITHUB_TOKEN` in a {% data variables.product.prodname_actions %} workflow, you should ensure that:\n  - The endpoint is only affecting resources owned by the repository where the workflow is running. If you need to access resources outside of that repository, such as resources owned by an organization or resources owned by another repository, you should use a {% data variables.product.pat_generic %} or an", "Y2h1bmtfM19pbmRleF8xOTk4": " access token for a {% data variables.product.prodname_github_app %}.\n\nFor more information about authentication, see \"AUTOTITLE.\"\n\nYou should also check for typos in your URL. For example, adding a trailing slash to the endpoint will result in a `404 Not Found`. You can refer to the reference documentation for the endpoint to confirm that you have the correct URL.\n\nAdditionally, any path parameters must be URL encoded. For example, any slashes in the parameter value must be replaced with `%2F`. If you don't properly encode any slashes in the parameter name, the endpoint URL will be misinterpreted.\n\n\n\nMissing results\n\nMost endpoints that return a list of resources support pagination. For most of these endpoints, only the first 30 resources are returned by default. In order to see all of the resources, you need to paginate through the results. For more information, see \"AUTOTITLE.\"\n\nIf you are using pagination correctly and still do not see all of the results that you expect, you should confirm that the authentication credentials that you used have access to all of the expected resources. For example, if you are using a {% data variables.product.prodname_github_app %} installation access token, if the installation was only granted access to a subset of repositories in an organization, any request for all repositories in that organization will return only the repositories that the app installation can access.\n\n{% ifversion fpt or ghec %}\n\n\n\nRequires authentication when using basic authentication\n\nBasic authentication with your username and password is not supported. Instead, you should use a {% data variables.product.pat_generic %} or an access token for a {% data variables.product.prodname_github_app %} or {% data variables.product.prodname_oauth_app %}. For more information, see \"AUTOTITLE.\"\n\n{% endif %}\n\n\n\nTimeouts\n\nIf {% data variables.product.product_name %} takes more than 10 seconds to process an API request, {% data variables.product.product_name %} will terminate the request and you will receive a timeout ", "Y2h1bmtfNF9pbmRleF8xOTk4": "response and a \"Server Error\" message.\n\n{% data variables.product.product_name %} reserves the right to change the timeout window to protect the speed and reliability of the API.\n\nYou can check the status of the REST API at githubstatus.com to determine whether the timeout is due to a problem with the API. You can also try to simplify your request or try your request later. For example, if you are requesting 100 items on a page, you can try requesting fewer items.\n\n\n\nResource not accessible\n\nIf you are using a {% data variables.product.prodname_github_app %}{% ifversion pat-v2 %} or {% data variables.product.pat_v2 %}{% endif %} and you receive a \"Resource not accessible by integration\"{% ifversion pat-v2 %} or \"Resource not accessible by {% data variables.product.pat_generic %}\"{% endif %} error, then your token has insufficient permissions. For more information about the permissions required for each endpoint, see \"AUTOTITLE{% ifversion pat-v2 %}\" and \"AUTOTITLE{% endif %}.\"\n\n{% ifversion rest-permissions-header %}\n\nYou can use the `X-Accepted-GitHub-Permissions` header to identify the permissions that are required to access the REST API endpoint.\n\nThe value of the `X-Accepted-GitHub-Permissions` header is a comma separated list of the permissions that are required to use the endpoint. Occasionally, you can choose from multiple permission sets. In these cases, multiple comma-separated lists will be separated by a semicolon.\n\nFor example:\n\n- `X-Accepted-GitHub-Permissions: contents=read` means that your {% data variables.product.prodname_github_app %}{% ifversion pat-v2 %} or {% data variables.product.pat_v2 %}{% endif %} needs read access to the contents permission.\n- `X-Accepted-GitHub-Permissions: pull_requests=write,contents=read` means that your {% data variables.product.prodname_github_app %}{% ifversion pat-v2 %} or {% data variables.product.pat_v2 %}{% endif %} needs write access to the pull request permission and read access to the contents permission.\n- `X-Accepted-GitHub-Permissions: pull_requests=rea", "Y2h1bmtfNV9pbmRleF8xOTk4": "d,contents=read; issues=read,contents=read` means that your {% data variables.product.prodname_github_app %}{% ifversion pat-v2 %} or {% data variables.product.pat_v2 %}{% endif %} needs either read access to the pull request permission and read access to the contents permission, or read access to the issues permission and read access to the contents permission.\n\n{% endif %}\n\n\n\nProblems parsing JSON\n\nIf you send invalid JSON in the request body, you may receive a `400 Bad Request` response and a \"Problems parsing JSON\" error message. You can use a linter or JSON validator to help you identify errors in your JSON.\n\n\n\nBody should be a JSON object\n\nIf the endpoint expects a JSON object and you do not format your request body as a JSON object, you may receive a `400 Bad Request` response and a \"Body should be a JSON object\" error message.\n\n\n\nInvalid request\n\nIf you omit required parameters or you use the wrong type for a parameter, you may receive a `422 Unprocessable Entity` response and an \"Invalid request\" error message. For example, you will get this error if you specify a parameter value as an array but the endpoint is expecting a string. You can refer to the reference documentation for the endpoint to verify that you are using the correct parameter types and that you are including all of the required parameters.\n\n\n\nValidation Failed\n\nIf your request could not be processed, you may receive a `422 Unprocessable Entity` response and a \"Validation Failed\" error message. The response body will include an `errors` property, which includes a `code` property to help you diagnose the problem.\n\nCode | Description\n-----------|-----------|\n`missing` | A resource does not exist.\n`missing_field` | A parameter that was required was not specified. Review the documentation for the endpoint to see what parameters are required.\n`invalid` | The formatting of a parameter is invalid. Review the endpoint documentation for more specific information.\n`already_exists` | Another resource has the same value as one of your parameters.  Thi", "Y2h1bmtfNl9pbmRleF8xOTk4": "s can happen in resources that must have some unique key (such as label names).\n`unprocessable` | The parameters that were provided were invalid.\n`custom` | Refer to the `message` property to diagnose the error.\n\n{% ifversion api-date-versioning %}\n\n\n\nNot a supported version\n\nYou should use the `X-GitHub-Api-Version` header to specify an API version. For example:\n\n```shell\ncurl {% data reusables.rest-api.version-header %} https://api.github.com/zen\n```\n\nIf you specify a version that does not exist, you will receive a `400 Bad Request` error and a message about the version not being supported.\n\nFor more information, see \"AUTOTITLE.\"\n\n{% endif %}\n\n\n\nUser agent required\n\nRequests without a valid `User-Agent` header will be rejected. You should use your username or the name of your application for the `User-Agent` value.\n\ncurl sends a valid `User-Agent` header by default.\n\n\n\nOther errors\n\nIf you observe an error that is not addressed here, you should refer to the error message that the API gives you. Most error messages will provide a clue about what is wrong and a link to relevant documentation.\n\nIf you observe unexpected failures, you can check the status of the REST API at githubstatus.com.\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8xNTcw": "\n\nAbout {% data variables.product.pat_v2 %} requests\n\nWhen organization members create a {% data variables.product.pat_v2 %} to access resources owned by the organization, if the organization requires approval for {% data variables.product.pat_v2 %}s, then an organization owner must approve the token before it can be used to access any resources that are not public. For more information, see \"AUTOTITLE.\"\n\n{% data variables.product.company_short %} will notify organization owners with a daily email about all {% data variables.product.pat_v2 %}s that are awaiting approval. When a token is denied or approved, the user who created the token will receive an email notification.\n\n{% note %}\n\n**Note**: Only {% data variables.product.pat_v2 %}s, not {% data variables.product.pat_v1_plural %}, are subject to approval. Unless the organization has restricted access by {% data variables.product.pat_v1_plural %}, any {% data variables.product.pat_v1 %} can access organization resources without prior approval. For more information, see \"AUTOTITLE.\"\n\n{% endnote %}\n\n{% ifversion pat-v2-org-admin-api %}\n\nOrganization owners can also use the REST API to review and manage {% data variables.product.pat_v2 %} requests. These endpoints can only be called by {% data variables.product.prodname_github_apps %}, and cannot be called with {% data variables.product.pat_generic_plural %} or {% data variables.product.prodname_oauth_apps %}. For more information, see \"AUTOTITLE.\"\n\n{% endif %}\n\n\n\nManaging {% data variables.product.pat_v2 %} requests\n\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n1. In the left sidebar, under **{% octicon \"key\" aria-hidden=\"true\" %} {% data variables.product.pat_generic_caps %}s**, click **Pending requests**. If any tokens are pending approval for your organization, they will be displayed.\n1. Click the name of the token that you want to approve or deny.\n1. Review the access and permissions that the token is requesting.\n1. To grant the token access to the organization, click **Ap", "Y2h1bmtfMV9pbmRleF8xNTcw": "prove**. To deny the token access to the organization, click **Deny**.\n1. If you denied the request, in the confirmation box, optionally enter the reason that you denied the token. This reason will be shared in the notification that is sent to the token owner. Then, click **Deny**.\n\nAlternatively, you can approve or deny multiple tokens at once:\n\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n1. In the left sidebar, under **{% octicon \"key\" aria-hidden=\"true\" %} {% data variables.product.pat_generic_caps %}s**, click **Pending requests**. If any tokens are pending approval for your organization, they will be displayed.\n{% data reusables.user-settings.patv2-filters %}\n1. Select each token that you want to approve or reject.\n1. Select the **request selected...** dropdown menu and click **Approve...** or **Deny...**.\n\n", "Y2h1bmtfMF9pbmRleF8xNjcw": "\n\nBest practices for creating pull requests\n\nWhen creating a pull request, follow a few best practices for a smoother review process. For information on creating a pull request, see \"AUTOTITLE.\"\n\n\n\nWrite small PRs\n\nAim to create small, focused pull requests that fulfill a single purpose. Smaller pull requests are easier and faster to review and merge, leave less room to introduce bugs, and provide a clearer history of changes.\n\n\n\nReview your own pull request first\n\nReview, build, and test your own pull request before submitting it. This will allow you to catch errors or typos that you may have missed, before others start reviewing.\n\n\n\nProvide context and guidance\n\nWrite clear titles and descriptions for your pull requests so that reviewers can quickly understand what the pull request does. In the pull request body, include:\n\n- the purpose of the pull request\n- an overview of what changed\n- links to any additional context such as tracking issues or previous conversations\n\nTo help reviewers, share the type of feedback you need. For example, do you need a quick look or a deeper critique?\n\nIf your pull request consists of changes to multiple files, provide guidance to reviewers about the order in which to review the files. Recommend where to start and how to proceed with the review.\n\n\n\nBest practices for managing pull requests\n\nIf you are a repository maintainer, take these steps to manage and standardize the pull requests that contributors create in your repository.\n\n\n\nUse pull request templates\n\nPull request templates let you customize and standardize the information you'd like to be included when someone creates a pull request in your repository. When you add a pull request template to your repository, project contributors will automatically see the template's contents in the pull request body. For more information, see \"AUTOTITLE.\"\n\n{% ifversion task-lists-v1 %} You can use pull request templates to standardize the review process for your repository. For example, you can include a list of tasks that you would lik", "Y2h1bmtfMV9pbmRleF8xNjcw": "e authors to complete before merging their pull requests, by adding a task list to the template. For more information, see \"AUTOTITLE.\"{% endif %}\n\nYou can request that contributors include an issue reference in their pull request body, so that merging the pull request will automatically close the issue. For more information, see \"AUTOTITLE.\"\n\n\n\nDefine code owners\n\nYou may want to make sure that specific individuals always review changes to certain code or files in your repository. For example, you may want a technical writer on your team to always review changes in the `docs` directory.\n\nYou can define individuals or teams that you consider responsible for code or files in a repository to be code owners. Code owners will automatically be requested for review when someone opens a pull request that modifies the files that they own. You can define code owners for specific types of files or directories, as well as for different branches in a repository. For more information, see \"AUTOTITLE.\"\n\n\n\nUse protected branches\n\nYou can use protected branches to prevent pull requests from being merged into important branches, such as `main`, until certain conditions are met. For example, you can require passing CI tests or an approving review. For more information, see \"AUTOTITLE.\"\n\n\n\nUse automated tools to review code styling\n\nUse automated tools, such as linters, in your repository's pull requests to maintain consistent styling and make code more understandable. Using automated tools to catch smaller problems like typos or styling leaves more time for reviewers to focus on the substance of a pull request.\n\nFor example, you can use {% data variables.product.prodname_actions %} to set up code linters that can run on pull requests as part of your continuous integration (CI) workflow. For more information, see \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF8xNDQ1": "\n\nAbout adding existing source code to {% data variables.product.product_name %}\n\nIf you have source code stored locally on your computer that is tracked by Git or not tracked by any version control system (VCS), you can add the code to {% data variables.product.product_name %} by typing commands in a terminal. You can do this by typing Git commands directly, or by using {% data variables.product.prodname_cli %}.\n\n{% data variables.product.prodname_cli %} is an open source tool for using {% data variables.product.prodname_dotcom %} from your computer's command line. {% data variables.product.prodname_cli %} can simplify the process of adding an existing project to {% data variables.product.product_name %} using the command line. To learn more about {% data variables.product.prodname_cli %}, see \"AUTOTITLE.\"\n\n{% note %}\n\n**Note:** If you're most comfortable with a point-and-click user interface, consider adding your project with {% data variables.product.prodname_desktop %} instead. For more information, see \"AUTOTITLE.\"\n\n{% endnote %}\n\nIf your source code is tracked by a different VCS, such as Mercurial, Subversion, or Team Foundation Version Control, you must convert the repository to Git before you can add the project to {% data variables.product.product_name %}.\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n{% data reusables.repositories.sensitive-info-warning %}\n\n\n\nInitializing a Git repository\n\nIf your locally-hosted code isn't tracked by any VCS, the first step is to initialize a Git repository. If your project is already tracked by Git, skip to \"Importing a Git repository with the command line.\"\n\n{% data reusables.command_line.open_the_multi_os_terminal %}\n1. Navigate to the root directory of your project.\n1. Initialize the local directory as a Git repository. By default, the initial branch is called `main`.\n\n   If you\u2019re using Git 2.28.0 or a later version, you can set the name of the default branch using `-b`.\n\n   ```shell\n   git init -b main\n   ```\n\n   If you\u2019re using Git 2.27.1 or an earlier version, you", "Y2h1bmtfMV9pbmRleF8xNDQ1": " can set the name of the default branch using  `git symbolic-ref`.\n\n   ``` shell\n   git init && git symbolic-ref HEAD refs/heads/main\n   ```\n\n1. Add the files in your new local repository. This stages them for the first commit.\n\n   ```shell\n   $ git add .\n   # Adds the files in the local repository and stages them for commit. {% data reusables.git.unstage-codeblock %}\n   ```\n\n1. Commit the files that you've staged in your local repository.\n\n   ```shell\n   $ git commit -m \"First commit\"\n   # Commits the tracked changes and prepares them to be pushed to a remote repository. {% data reusables.git.reset-head-to-previous-commit-codeblock %}\n   ```\n\n\n\nImporting a Git repository with the command line\n\nAfter you've initialized a Git repository, you can push the repository to {% data variables.product.product_name %}, using either {% data variables.product.prodname_cli %} or Git.\n\n- \"Adding a local repository to {% data variables.product.prodname_dotcom %} with {% data variables.product.prodname_cli %}\"\n- \"Adding a local repository to {% data variables.product.prodname_dotcom %} using Git\"\n\n\n\nAdding a local repository to {% data variables.product.prodname_dotcom %} with {% data variables.product.prodname_cli %}\n\n1. To create a repository for your project on {% data variables.product.prodname_dotcom %}, use the `gh repo create` subcommand. When prompted, select **Push an existing local repository to {% data variables.product.prodname_dotcom %}** and enter the desired name for your repository. If you want your project to belong to an organization instead of your user account, specify the organization name and project name with `organization-name/project-name`.\n\n1. Follow the interactive prompts. To add the remote and push the repository, confirm yes when asked to add the remote and push the commits to the current branch.\n\n1. Alternatively, to skip all the prompts, supply the path to the repository with the `--source` flag and pass a visibility flag (`--public`, `--private`, or `--internal`). For example, `gh repo create --s", "Y2h1bmtfMl9pbmRleF8xNDQ1": "ource=. --public`. Specify a remote with the `--remote` flag. To push your commits, pass the `--push` flag. For more information about possible arguments, see the {% data variables.product.prodname_cli %} manual.\n\n\n\nAdding a local repository to {% data variables.product.prodname_dotcom %} using Git\n\nBefore you can add your local repository to {% data variables.product.prodname_dotcom %} using Git, you must authenticate to {% data variables.product.prodname_dotcom %} on the command line. For more information, see \"AUTOTITLE.\"\n\n{% mac %}\n\n{% data reusables.migrations.create-empty-repo %}\n1. At the top of your repository on {% ifversion ghae %}{% data variables.product.product_name %}{% else %}{% data variables.location.product_location %}{% endif %}'s Quick Setup page, click {% octicon \"copy\" aria-label=\"Copy to clipboard\" %} to copy the remote repository URL.\n\n   !Screenshot of the \"Quick Setup\" header in a repository. Next to the remote URL, an icon of two overlapping squares is highlighted with an orange outline.\n\n{% data reusables.command_line.open_the_multi_os_terminal %}\n1. Change the current working directory to your local project.\n1. To add the URL for the remote repository where your local repository will be pushed, run the following command. Replace `REMOTE-URL` with the repository's full URL on {% data variables.product.prodname_dotcom %}.\n\n   ```shell\n   git remote add origin REMOTE-URL\n   ```\n\n   For more information, see \"AUTOTITLE.\"\n1. To verify that you set the remote URL correctly, run the following command.\n\n   ```shell\n   git remote -v\n   ```\n\n1. To push the changes in your local repository to {% data variables.location.product_location %}, run the following command.\n\n   ```shell\n   git push -u origin main\n   ```\n\n   If your default branch is not named \"main,\" replace \"main\" with the name of your default branch. For more information, see \"AUTOTITLE.\"\n\n{% endmac %}\n\n{% windows %}\n\n{% data reusables.migrations.create-empty-repo %}\n1. At the top of your repository on {% ifversion ghae %}{% data vari", "Y2h1bmtfM19pbmRleF8xNDQ1": "ables.product.product_name %}{% else %}{% data variables.location.product_location %}{% endif %}'s Quick Setup page, click {% octicon \"copy\" aria-label=\"Copy to clipboard\" %} to copy the remote repository URL.\n\n   !Screenshot of the \"Quick Setup\" header in a repository. Next to the remote URL, an icon of two overlapping squares is highlighted with an orange outline.\n{% data reusables.command_line.open_the_multi_os_terminal %}\n1. Change the current working directory to your local project.\n1. To add the URL for the remote repository where your local repository will be pushed, run the following command. Replace `REMOTE-URL` with the repository's full URL on {% data variables.product.prodname_dotcom %}.\n\n   ```shell\n   git remote add origin REMOTE-URL\n   ```\n\n   For more information, see \"AUTOTITLE.\"\n1. To verify that you set the remote URL correctly, run the following command.\n\n   ```shell\n   git remote -v\n   ```\n\n1. To push the changes in your local repository to {% data variables.location.product_location %}, run the following command.\n\n   ```shell\n   git push origin main\n   ```\n\n   If your default branch is not named \"main,\" replace \"main\" with the name of your default branch. For more information, see \"AUTOTITLE.\"\n\n{% endwindows %}\n\n{% linux %}\n\n{% data reusables.migrations.create-empty-repo %}\n1. At the top of your repository on {% ifversion ghae %}{% data variables.product.product_name %}{% else %}{% data variables.location.product_location %}{% endif %}'s Quick Setup page, click {% octicon \"copy\" aria-label=\"Copy to clipboard\" %} to copy the remote repository URL.\n\n   !Screenshot of the \"Quick Setup\" header in a repository. Next to the remote URL, an icon of two overlapping squares is highlighted with an orange outline.\n{% data reusables.command_line.open_the_multi_os_terminal %}\n1. Change the current working directory to your local project.\n1. To add the URL for the remote repository where your local repository will be pushed, run the following command. Replace `REMOTE-URL` with the repository's full URL on ", "Y2h1bmtfNF9pbmRleF8xNDQ1": "{% data variables.product.prodname_dotcom %}.\n\n   ```shell\n   git remote add origin REMOTE-URL\n   ```\n\n   For more information, see \"AUTOTITLE.\"\n1. To verify that you set the remote URL correctly, run the following command.\n\n   ```shell\n   git remote -v\n   ```\n\n1. To push the changes in your local repository to {% data variables.location.product_location %}, run the following command.\n\n   ```shell\n   git push origin main\n   ```\n\n   If your default branch is not named \"main,\" replace \"main\" with the name of your default branch. For more information, see \"AUTOTITLE.\"\n\n{% endlinux %}\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"{% ifversion fpt or ghec %}\n- \"AUTOTITLE\"{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF8xMTY0": "\n\nAbout pushing changes to {% data variables.product.prodname_dotcom %}\n\nWhen you push changes, you send the committed changes in your local repository to the remote repository on {% data variables.product.prodname_dotcom %}. If you change your project locally and want other people to have access to the changes, you must push the changes to {% data variables.product.prodname_dotcom %}.\n\nBefore pushing changes, you should update your local branch to include any commits that have been added to the remote repository. If someone has made commits on the remote that are not on your local branch, {% data variables.product.prodname_desktop %} will prompt you to fetch the new commits before pushing your changes to avoid merge conflicts. For more information, see \"AUTOTITLE.\"\n\n{% data reusables.desktop.protected-branches %}\n\n{% ifversion repo-rules %}\n\nRepository administrators can also enable rulesets for a branch, which will prevent a push from completing if a ruleset has not been followed. For example, a ruleset may require a specific branch naming convention, or an issue number at the start of a commit message. {% data variables.product.prodname_desktop %} will warn about rulesets to help prevent your branch from getting into a state where you would be unable to push your changes. For more information, see \"AUTOTITLE.\"\n\n{% endif %}\n\n\n\nPushing changes to {% data variables.product.prodname_dotcom %}\n\n{% note %}\n\n**Note:** {% data variables.product.prodname_desktop %} will reject a push if it exceeds certain limits.\n\n- A push contains a large file over {% data variables.large_files.max_github_size %} in size.\n- A push is over {% data variables.large_files.max_file_size %} in total size.\n\nIf you configure {% data variables.large_files.product_name_long %} to track your large files, you can push large files that would normally be rejected. For more information, see \"AUTOTITLE.\"\n\n{% endnote %}\n\n{% data reusables.desktop.push-origin %}\n1. If there are commits on the remote branch that you don't have on your local branch, {% d", "Y2h1bmtfMV9pbmRleF8xMTY0": "ata variables.product.prodname_desktop %} prompts you to fetch new commits from the remote. In the \"New Commits on Remote\" window, click **Fetch**.\n1. Optionally, click **Preview Pull Request** to open a preview dialog where you can review your changes and begin to create a pull request. For more information, see \"AUTOTITLE.\"\n\n   !Screenshot of the \"No local changes\" view. A button, labeled \"Preview Pull Request\", is highlighted with an orange outline.\n\n\n\nFurther reading\n\n- \"AUTOTITLE\" in the {% data variables.product.prodname_dotcom %} glossary\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8xMjkw": "\n\nFetches updates made to an online repository\n$ git merge origin YOUR_BRANCH_NAME\n\n\nMerges updates made online with your local work\n```\n\nOr, you can simply use `git pull` to perform both commands at once:\n\n```shell\n$ git pull origin YOUR_BRANCH_NAME\n\n\nGrabs online updates and merges them with your local work\n```\n\n", "Y2h1bmtfMF9pbmRleF81NDc=": "\n\nNext steps\n\nFor more information about creating a Marketplace listing for this app, see \"AUTOTITLE\".\n\n{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF8yMDQ1": "\n\nGitHub Corporate Terms of Service\n\nVersion Effective Date: November 16, 2020\n\nThis Agreement applies to the following GitHub offerings, as further defined below (collectively, the **\u201cProducts\u201d**):\n- The Service;\n- Any Beta Previews;\n- Any related Support; and\n- Any related Expert Services.\n\n\n\nA. Definitions\n\n**\u201cAffiliate\u201d** means any entity that directly or indirectly controls, is controlled by, or is under common control with a party where \"control\" means having more than fifty percent (50%) ownership or the right to direct the management of the entity.\n\n**\u201cAgreement\u201d** means, collectively, all the terms, conditions, notices contained or referenced in this document and all other operating rules, policies and procedures that GitHub may publish from time to time on the Service. GitHub's site policies are available at https://docs.github.com/categories/site-policy.\n\n**\u201cAll Users\u201d** means, collectively, Customer\u2019s Users and External Users who use the Service.\n\n**\u201cAmericas\u201d** means the United States, Canada, Mexico, or a country in Central or South America or the Caribbean.\n\n**\"Beta Previews\"** mean software, services, or features identified as alpha, beta, preview, early access, or evaluation, or words or phrases with similar meanings.\n\n**\"Confidential Information\"** means all non-public information disclosed by either Party to the others, whether in writing, orally or by other means, designated as confidential or that the receiving Party knows or reasonably should know, under the circumstances surrounding the disclosure and the nature of the information, is confidential to the disclosing Party. For the avoidance of doubt, no Content posted on the Service will be considered Confidential Information except for Customer Content stored solely in Customer\u2019s Private Repositories. Confidential Information does not include any information that (i) was or becomes publicly known through no fault of the receiving party; (ii) was rightfully known or becomes rightfully known to the receiving Party without confidential or prop", "Y2h1bmtfMV9pbmRleF8yMDQ1": "rietary restriction from a source other than the disclosing party who has a right to disclose it; (iii) is approved by the disclosing Party for disclosure without restriction in a written document which is signed by a duly authorized officer of such disclosing Party; (iv) the receiving Party independently develops without access to or use of the other Party's Confidential Information; or (v) is or has been stored or posted on the Service and outside of Customer\u2019s Private Repositories.\n\n**\"Content\"** means, without limitation, code, text, data, articles, images, packages, photographs, graphics, software, applications, designs, features, and other materials that are featured, displayed, or otherwise made available through the Service.\n\n**\"Corporate Account\"** means an account created by a User on behalf of an entity.\n\n**\"Customer\"** means the company or organization that has entered into this Agreement with GitHub by clicking on the \"I AGREE\" or similar button or by accessing the Products.\n\n**\"Customer Content\"** means Content that Customer creates, owns, or to which Customer holds the rights.\n\n**\"Documentation\"** means any manuals, documentation and other supporting materials relating to the Products that GitHub provides or makes available to Customer.\n\n**\"Effective Date\"** is the earlier of the date on which Customer (i) clicks \u201cI agree\u201d to the terms and conditions of this Agreement, or (ii) first places an order for the Products.\n\n**\"External User\"** means an individual, not including Customer\u2019s Users, who visit or use the Service.\n\n**\"Feedback\"** means any ideas, know-how, algorithms, code contributions, suggestions, enhancement requests, recommendations or any other feedback on GitHub products or services.\n\n**\"Fees\"** means the fees Customer is required to pay GitHub to (i) use the Products during the applicable Term or (ii) receive Expert Services, as such fees are reflected on an Order Form or SOW.\n\n**\u201cFork\u201d** means to copy the Content of one repository into another repository.\n\n**\u201cGitHub\u201d** means GitHub, In", "Y2h1bmtfMl9pbmRleF8yMDQ1": "c., its Affiliates, and its Representatives.\n\n**\"GitHub Content\"** means Content that GitHub creates, owns, or to which it holds the rights.\n\n**\u201cMachine Account\u201d** means an account registered by an individual human who accepts the applicable terms of service on behalf of the Machine Account, provides a valid email address, and is responsible for its actions. A Machine Account is used exclusively for performing automated tasks. Multiple Users may direct the actions of a Machine Account, but the owner of the account is ultimately responsible for the machine's actions.\n\n**\"Order Form\"** means written or electronic documentation (including a quote) that the Parties may use to order the Products.\n\n**\u201cOrganization\u201d** means a shared workspace that may be associated with a single entity or with one or more Users where multiple Users can collaborate across many projects at once. A User can be a member of more than one Organization.\n\n**\u201cPrivate Repository\u201d** means a repository which allows a User to control access to Content.\n\n**\"Expert Services\"** means training, consulting, or implementation services that GitHub provides to Customer pursuant to a mutually executed SOW. Expert Services do not include Support.\n\n**\u201cPublic Repository\u201d** means a repository whose Content is visible to All Users.\n\n**\"Representatives\"** means a Party\u2019s employees, officers, agents, independent contractors, consultants, and legal and financial advisors.\n\n**\u201cScraping\u201d** means extracting data from the Service via an automated process, such as a bot or webcrawler, and does not include the collection of information through GitHub's API.\n\n**\"Service\"** means GitHub's hosted service and any applicable Documentation.\n\n**\"SOW\"** means a mutually executed statement of work detailing the Expert Services GitHub will perform, any related Fees, and each party's related obligations.\n\n**\"Subscription License\"** means the license assigned to each User to install, operate, access, and use the Service on Customer\u2019s behalf. Customer may only assign one Subscription ", "Y2h1bmtfM19pbmRleF8yMDQ1": "License per User across its Organizations. For clarity, once Customer assigns a Subscription License to a User, Customer is prohibited from bifurcating the Subscription License so that one User can use a Subscription License on one Organization while another User uses the same Subscription License on another Organization.\n\n**\u201cSupport\u201d** means technical support for the Service that GitHub may provide.\n\n**\"User\"** means an individual or Machine Account who (a) accesses or uses the Service, (b) accesses or uses any part of Customer\u2019s account; or (c) directs the use of Customer\u2019s account in the performance of functions, in each case on Customer\u2019s behalf. The number of Users should not exceed the number of Subscription Licenses that Customer has purchased.\n\n**\u201cUser-Generated Content\u201d** means Content created or owned by a third party or External User.\n\n\n\nB. Account Terms\n\n\n\n1. Account Controls.\n\n- _Users._ Customer acknowledges that Users retain ultimate administrative control over their individual accounts and the Content within them. GitHub's Standard Terms of Service govern Users' use of the Service, except with respect to Users' activities under this Section B.\n\n- _Organizations._ Customer retains ultimate administrative control over any Organization created on Customer\u2019s behalf and User-Generated Content posted to the repositories within its Organization(s), subject to this Section B. This Section B will govern the use of Customer\u2019s Organization(s).\n\n\n\n2. Account Requirements\n\nIn order to create an account, Customer must adhere to the following:\n\n- Customer must not create an account for use of any person under the age of 13. If GitHub learns of any User under the age of 13, it will terminate that User's account immediately. If Customer or its User(s) are located in a country outside the United States, that country's minimum age may be older; in such a case, Customer is responsible for complying with that country's laws.\n\n-\tA User\u2019s login may not be shared by multiple people.\n\n- Customer must not use the Products ", "Y2h1bmtfNF9pbmRleF8yMDQ1": "(a) in violation of export control or sanctions laws of the United States or any other applicable jurisdiction; (b) if it is located in or ordinarily resident in a country or territory subject to comprehensive sanctions administered by the U.S. Office of Foreign Assets Control (OFAC); or (c) if it is or is working on behalf of a Specially Designated National (SDN) or a person subject to similar blocking or denied party prohibitions. For more information, please see our Export Controls policy.\n\n\n\n3. Account Security\n\nCustomer is responsible for: (i) all Content posted and activity that occurs under its Corporate Account; (ii) maintaining the security of its account login credentials; and (iii) promptly notifying GitHub upon becoming aware of any unauthorized use of, or access to, the Service through its account.  GitHub will not be liable for any loss or damage from Customer\u2019s failure to comply with this Section B.\n\n\n\n4. Third Party Terms\n\nIn some situations, third parties' terms may apply to Customer's use of GitHub. For example, Customer may be a member of an Organization with its own terms or license agreements; Customer may download an application that integrates with the Service; or Customer may use the Service to authenticate to another service. While this Agreement is GitHub\u2019s full agreement with Customer, other parties' terms govern their relationships with Customer.\n\n\n\n5. U.S. Federal Government Terms\n\nIf Customer is a U.S. government entity or otherwise accessing or using the Service in a government capacity, the U.S. Federal Government Amendment applies, and Customer agrees to its provisions.\n\n\n\n6. Enterprise Cloud Service Level Agreement\n\nGitHub\u2019s quarterly uptime commitment for GitHub Enterprise Cloud is provided in the Enterprise Service Level Agreement. If Customer signed up for GitHub Enterprise Cloud, then Customer will be entitled to a service credit if GitHub does not meet its service level.\n\n\n\nC. Compliance with Laws; Acceptable Use; Privacy\n\n\n\n1. Compliance with Laws and Regulations\n\nCustomer\u2019", "Y2h1bmtfNV9pbmRleF8yMDQ1": "s use of the Products must not violate any applicable laws, including copyright or trademark laws, export control laws, or regulations in its jurisdiction.\n\n\n\n2. Acceptable Use\n\nCustomer\u2019s use of the Service must comply with GitHub's Acceptable Use Policies and GitHub\u2019s Community Guidelines. Customer must not use the Service in any jurisdiction for unlawful, obscene, offensive or fraudulent Content or activity, such as advocating or causing harm, interfering with or violating the integrity or security of a network or system, evading filters, sending unsolicited, abusive, or deceptive messages, viruses or harmful code, or violating third party rights.\n\n\n\n3. Privacy\n\nThe GitHub Privacy Statement and the GitHub Data Protection Agreement provide detailed notice of GitHub's privacy and data use practices as well as GitHub's processing and security obligations with respect to Customer Personal Data. Any person, entity, or service collecting data from the Service must comply with the GitHub Privacy Statement, particularly in regards to the collection of personal data (as defined in the GitHub Privacy Statement). If Customer collects any personal information from GitHub, Customer will only use it for the purpose for which the External User has authorized it. Customer will reasonably secure any such Personal Information, and Customer will respond promptly to complaints, removal requests, and \"do not contact\" requests from GitHub or External Users.\n\n\n\nD. Content Responsibility; Ownership; License Rights\n\n\n\n1. Responsibility for User-Generated Content\n\nCustomer may create or upload User-Generated Content while using the Service. Customer is solely responsible for any User-Generated Content that it posts, uploads, links to or otherwise make available via the Service, regardless of the form of that User-Generated Content. GitHub is not responsible for any public display or misuse of User-Generated Content.\n\n\n\n2. Ownership of Content, Right to Post, and License Grants\n\nCustomer retains ownership of Customer Content that Custom", "Y2h1bmtfNl9pbmRleF8yMDQ1": "er creates or owns. Customer acknowledges that it: (a) is responsible for Customer Content, (b) will only submit Customer Content that Customer has the right to post (including third party or User-Generated Content), and (c) Customer will fully comply with any third-party licenses relating to Customer Content that Customer posts.\nCustomer grants the rights set forth in Sections D.3 through D.6, free of charge and for the purposes identified in those sections until such time as Customer removes Customer Content from GitHub servers, except for Content Customer has posted publicly and that External Users have Forked, in which case the license is perpetual until such time as all Forks of Customer Content have been removed from GitHub servers. If Customer uploads Customer Content that already comes with a license granting GitHub the permissions it needs to run the Service, no additional license is required.\n\n\n\n3. License Grant to Us\n\nCustomer grants to GitHub the right to store, archive, parse, and display Customer Content, and make incidental copies, only as necessary to provide the Service, including improving the Service over time. This license includes the right to copy Customer Content to GitHub's database and make backups; display Customer Content to Customer and those to whom Customer chooses to show it; parse Customer Content into a search index or otherwise analyze it on GitHub's servers; share Customer Content with External Users with whom Customer chooses to share it; and perform Customer Content, in case it is something like music or video. These rights apply to both public and Private Repositories. This license does not grant GitHub the right to sell Customer Content. It also does not grant GitHub the right to otherwise distribute or use Customer Content outside of our provision of the Service, except that as part of the right to archive Customer Content, GitHub may permit our partners to store and archive Customer Content in public repositories in connection with the GitHub Arctic Code Vault and GitHub A", "Y2h1bmtfN19pbmRleF8yMDQ1": "rchive Program. Customer grants to GitHub the rights it needs to use Customer Content without attribution and to make reasonable adaptations of Customer Content as necessary to provide the Service.\n\n\n\n4. License Grant to External Users\n\nAny Content that Customer posts publicly, including issues, comments, and contributions to External Users' repositories, may be viewed by others. By setting its repositories to be viewed publicly, Customer agree to allow External Users to view and Fork Customer\u2019s repositories.\nIf Customer sets its pages and repositories to be viewed publicly, Customer grants to External Users a nonexclusive, worldwide license to use, display, and perform Customer Content through the Service and to reproduce Customer Content solely on the Service as permitted through functionality provided by GitHub (for example, through Forking). Customer may grant further rights to Customer Content if Customer adopts a license. If Customer is uploading Customer Content that it did not create or own, Customer is responsible for ensuring that the Customer Content it uploads is licensed under terms that grant these permissions to External Users\n\n\n\n5. Contributions Under Repository License\n\nWhenever Customer adds Content to a repository containing notice of a license, it licenses that Content under the same terms and agrees that it has the right to license that Content under those terms. If Customer has a separate agreement to license that Content under different terms, such as a contributor license agreement, that agreement will supersede.\n\n\n\n6. Moral Rights\n\nCustomer retains all moral rights to Customer Content that it uploads, publishes, or submits to any part of the Service, including the rights of integrity and attribution. However, Customer waives these rights and agrees not to assert them against GitHub, solely to enable GitHub to reasonably exercise the rights granted in Section D, but not otherwise.\n\n\n\nE. Private Repositories\n\n\n\n1. Control\n\nCustomer is responsible for managing access to its Private Repositor", "Y2h1bmtfOF9pbmRleF8yMDQ1": "ies, including invitations, administrative control of Organizations and teams, and of access.\n\n\n\n2. Confidentiality\n\nGitHub considers Customer Content in Customer\u2019s Private Repositories to be Customer\u2019s Confidential Information. GitHub will protect and keep strictly confidential the Customer Content of Private Repositories in accordance with Section P.\n\n\n\n3. Access\n\nGitHub personnel may only access Customer's Private Repositories in the situations described in our Privacy Statement.\n\nCustomer may choose to enable additional access to its Private Repositories. For example, Customer may enable various GitHub services or features that require additional rights to Customer Content in Private Repositories. These rights may vary depending on the service or feature, but GitHub will continue to treat Customer Content in Customer\u2019s Private Repositories as Customer\u2019s Confidential Information. If those services or features require rights in addition to those it needs to provide the Service, GitHub will provide an explanation of those rights.\n\nAdditionally, we may be compelled by law to disclose the contents of your private repositories.\n\nGitHub will provide notice regarding our access to private repository content, unless for legal disclosure, to comply with our legal obligations, or where otherwise bound by requirements under law, for automated scanning, or if in response to a security threat or other risk to security.\n\n\n\nF. Intellectual Property Notice\n\n\n\n1. GitHub's Rights to Content\n\nThe look and feel of the Service is copyright \u00a9 GitHub, Inc. All rights reserved. Customer may not duplicate, copy, or reuse any portion of the HTML/CSS, Javascript, or visual design elements or concepts without express written permission from GitHub.\n\n\n\n2. GitHub Trademarks and Logos\n\nIf Customer would like to use GitHub's trademarks, Customer must follow all of GitHub's trademark guidelines, including those on GitHub's logos page.\n\n\n\n3. License to GitHub Policies\n\nThis Agreement is licensed under the Creative Commons Zero license. For det", "Y2h1bmtfOV9pbmRleF8yMDQ1": "ails, see our site-policy repository.\n\n\n\n4. Copyright Infringement and DMCA Policy\n\nIf Customer is a copyright owner and believes that Content on the Service violates Customer\u2019s copyright, Customer may notify GitHub in accordance with GitHub's Digital Millennium Copyright Act Policy via the DMCA form or by emailing copyright@github.com.\n\n\n\n5. Intellectual Property Rights Reserved\n\nAs between the Parties, GitHub owns all right, title and interest, including all intellectual property rights, in and to the Products. GitHub reserves all rights in and to the Products not expressly granted to Customer under this Agreement.\n\n\n\nG. GitHub Additional Product Terms\n\nSome Service features may be subject to additional terms as set forth in the GitHub Additional Product Terms. By accessing or using these features, Customer agrees to the GitHub Additional Product Terms.\n\n\n\nH. Subscription Licenses\n\nSubscription Licenses are granted on a per User basis and multiple Users may not use the same Subscription License. Customer may reassign a Subscription License to a new User only after ninety (90) days from the last reassignment of that same Subscription License, unless the reassignment is due to (i) permanent hardware failure or loss, (ii) termination of the User\u2019s employment or contract, or (iii) temporary reallocation of Subscription Licenses to cover a User\u2019s absence. When Customer reassigns a Subscription License from one User to another, Customer must block the former User\u2019s access to the Subscription License and Customer\u2019s Organizations.\n\n\n\nI. Affiliates\n\nCustomer\u2019s Affiliates are authorized to use the Products in accordance with this Agreement, so long as Customer remains fully responsible for their access and use of the Products.\n\n\n\nJ. Payment\n\n\n\n1. Pricing; Fees\n\n**Payment Terms** Our pricing is available at github.com/pricing (unless otherwise negotiated by the parties and stated in an Order Form). Customer agrees to pay the Fees in full, up front without deduction or setoff of any kind, in U.S. Dollars. Customer must pay", "Y2h1bmtfMTBfaW5kZXhfMjA0NQ==": " the Fees within thirty (30) days of the GitHub invoice date. Amounts payable under this Agreement are non-refundable, except as otherwise provided in this Agreement. If Customer fails to pay any Fees on time, GitHub reserves the right, in addition to taking any other action at law or equity, to (i) charge interest on past due amounts at 1.0% per month or the highest interest rate allowed by law, whichever is less, and to charge all expenses of recovery, and (ii) terminate the applicable Order Form or SOW. Customer is solely responsible for all taxes, fees, duties and governmental assessments (except for taxes based on GitHub's net income) that are imposed or become due in connection with this Agreement.\n\n**Usage-Based Billing** Some Service features are billed based on your usage. A limited quantity of these Service features may be included in your plan for a limited term without additional charge. If you choose to purchase paid Service features beyond the quantity included in your plan, you pay for those Service features based on your actual usage in the preceding month. Monthly payment for these purchases will be charged on a periodic basis in arrears, provided that for invoiced customers, paid Service features are billed in advance. See GitHub Additional Product Terms for details.\n\n\n\n2. Purchasing Additional Subscription Licenses\n\nCustomer may obtain additional Subscription Licenses under this Agreement by submitting a request through the Service or via its sales team. If Customer purchases the additional Subscription Licenses, Customer must pay the then-currently applicable Fees for them, prorated for the balance of the applicable Subscription Term. Upon renewal of Customer\u2019s Subscription Licenses for another Subscription Term, GitHub will invoice all Subscription Licenses at once on an annual basis unless otherwise specified in an Order Form.\n\n\n\n3. Authorization\n\nCustomer authorizes GitHub to charge the on-file credit card, PayPal account, or other approved methods of payment for Fees.\n\n\n\nK. Term; Terminati", "Y2h1bmtfMTFfaW5kZXhfMjA0NQ==": "on; Suspension\n\n\n\n1. Term\n\nThis Agreement starts on the Effective Date and will continue in effect until terminated by a Party in accordance with this Section K.\n\n\n\n2. Termination for Convenience; Account Cancellation\n\nEither Party may terminate an Order Form (if applicable) or this Agreement, without cause, upon at least thirty (30) days' prior written notice. If Customer elects to terminate an Order Form or Agreement, it is Customer's responsibility to properly cancel its account with GitHub by going into Settings in the global navigation bar at the top of the screen. GitHub cannot cancel accounts in response to an email or phone request.\n\n\n\n3. Termination for Material Breach\n\nEither Party may terminate this Agreement immediately upon notice if the other Party breaches a material obligation under this Agreement and fails to cure the breach within thirty (30) days from the date it receives notification.  GitHub may terminate this Agreement if Customer's Account has been suspended for more than 90 days.\n\n\n\n4. Effect of Termination\n\n- _Order Forms._ Upon termination of this Agreement, Customer may not execute additional Order Forms (if applicable); however, this Agreement will remain in effect for the remainder of any active Order Forms. When an Order Form terminates or expires, as to that Order Form: (i) the Term will immediately end; (ii) any Subscription Licenses in the Order Form will automatically terminate, and Customer will no longer have the right to use the Service; (iii) if any Fees were owed prior to termination, Customer must pay those Fees immediately; (iv) each Party will promptly return (or, if the other party requests it, destroy) all Confidential Information belonging to the other to the extent permitted by the Service. Notwithstanding the foregoing, GitHub will make a reasonable effort to provide Customer with a copy of its lawful, non-infringing account Contents upon request; provided that Customer makes this request within 90 days of termination, suspension, or downgrade.\n\n- GitHub will retain ", "Y2h1bmtfMTJfaW5kZXhfMjA0NQ==": "and use Customer's information as necessary to comply with our legal obligations, resolve disputes, and enforce GitHub's agreements, but barring legal requirements, GitHub will delete Customer's full profile and the Content of its repositories within 90 days of termination or expiration (though some information may remain in encrypted backups). This information cannot be recovered once Customer's account is canceled.\n\n- GitHub will not delete Content that Customer has contributed to External Users' repositories or that External Users have forked.\n\n\n\n5. Suspension\n\nGitHub has the right to suspend access to all or any part of the Service, including removing Content, at any time for violation of this Agreement or to protect the integrity, operability, and security of the Service, effective immediately, with or without notice. Unless prohibited by law or legal process or to prevent imminent harm to the Service or any third party, GitHub typically provides notice in the form of a banner or email on or before such suspension. GitHub will, in its discretion and using good faith, tailor any suspension as needed to preserve the integrity, operability, and security of the Service.\n\n\n\n6. Survival\n\nAll provisions of this Agreement which by their nature should survive termination will survive termination, including, without limitation, ownership provisions, warranty disclaimers, indemnity, and limitations of liability.\n\n\n\nL. Communications with GitHub\n\n\n\n1. Electronic Communication Required\n\nFor contractual purposes, Customer (1) consents to receive communications in an electronic form via the email address it submitted or via the Service; and (2) agrees that all Terms of Service, agreements, notices, disclosures, and other communications that GitHub provides electronically satisfies any legal requirement that those communications would satisfy if they were on paper. This section does not affect Customer's non-waivable rights.\n\n\n\n2. Legal Notice to GitHub Must Be in Writing\n\nCommunications made through email or GitHub Support", "Y2h1bmtfMTNfaW5kZXhfMjA0NQ==": "'s messaging system will not constitute legal notice to GitHub in any situation where notice to GitHub is required by contract or any law or regulation. Legal notice to GitHub must be in writing and served on GitHub's legal agent.\n\n\n\nM. Limited Warranty; Disclaimer\n\n_General Warranty_. Each Party represents and warrants to the other that it has the legal power and authority to enter into this Agreement, and that this Agreement and each Order Form and SOW is entered into by an employee or agent of such Party with all necessary authority to bind such Party to the terms and conditions of this Agreement.\n\n_Expert Services Warranty._ Unless otherwise set forth in an SOW, GitHub warrants that any Expert Services performed under this Agreement will be performed in a professional and workmanlike manner by appropriately qualified personnel. GitHub's only obligation, and Customer's only remedy, for a breach of this warranty will be, at GitHub's option and expense, to either: (i) promptly re-perform any Expert Services that fail to meet this warranty or (ii) if the breach cannot be cured, terminate the SOW and refund the unused prepaid Fees.\n\n_Service Disclaimer._ GitHub provides the Service **\u201cAS IS\u201d** and **\u201cAS AVAILABLE\u201d** without warranty of any kind. Without limiting this, GitHub expressly disclaims all warranties, whether express, implied or statutory, regarding the Service including without limitation any warranty of merchantability, fitness for a particular purpose, title, security, accuracy and non-infringement. GitHub does not warrant that the Service will meet Customer's requirements; that the Service will be uninterrupted, timely, secure, or error-free; that the information provided through the Service is accurate, reliable or correct; that any defects or errors will be corrected; that the Service will be available at any particular time or location; or that the Service is free of viruses or other harmful components. GitHub will not be responsible for any risk of loss resulting from Customer's downloading and/or", "Y2h1bmtfMTRfaW5kZXhfMjA0NQ==": " use of files, information, Content or other material obtained from the Service.\n\n_Beta Previews Disclaimer._ Customer may choose to use Beta Previews in its sole discretion. Beta Previews may not be supported and may be changed at any time without notice. Beta Previews may not be as reliable or available as the Service. Beta Previews are not subject to the same security measures and auditing to which the Service has been and is subject. GitHub will have no liability arising out of or in connection with Beta Previews. **Customer uses Beta Previews at its own risk.**\n\n\n\nN. Limitations of Liability\n\n**_Indirect Damages._ To the maximum extent permitted by applicable law, in no event will either party be liable to the other party or to any third party for any indirect, special, incidental, punitive, or consequential damages (including for loss of profits, revenue, or data) or for the cost of obtaining substitute products arising out of or in connection with this Agreement, however caused, whether such liability arises from any claim based upon contract, warranty, tort (including negligence), strict liability or otherwise, and whether or not a party has been advised of the possibility of such damages.**\n\n**_Limitation of Total Liability._ To the maximum extent permitted by applicable law, in no event will either party's total cumulative liability under this Agreement from all causes of action and all theories of liability exceed the Fees Customer has actually paid to GitHub during the 12 months preceding the claim giving rise to such liability. For products and services (including use of the Products) that are provided free of charge, GitHub\u2019s liability is limited to direct damages up to $5,000.00 USD. For Beta Previews, GitHub's liability is limited to direct damages up to $500.00 USD.**\n\n**_Exclusions._ The exclusions and limitations set forth in this Section N will not apply to liability arising out of (1) a Party\u2019s breach of its confidentiality obligations in Section P (except for all liability related to Content", "Y2h1bmtfMTVfaW5kZXhfMjA0NQ==": " (excluding GitHub Content), which will remain subject to the limitations and exclusions above) or (2) a Party\u2019s defense obligations in Section O.**\n\n\n\nO. Defense of Claims; Release\n\nThe Parties will defend each other against third-party claims, as and to the extent set forth in this Section O and will pay the amount of any resulting adverse final judgment or approved settlement, but only if the defending Party is promptly notified in writing of the claim and has the right to control the defense and any settlement of it. The Party being defended must provide the defending Party with all requested assistance, information, and authority. The defending Party will reimburse the other Party for reasonable out-of-pocket expenses it incurs in providing assistance, and will not settle or make any admissions with respect to a third-party claim without the other Party\u2019s prior written consent, not to be unreasonably withheld or delayed. This Section O describes the Parties\u2019 sole remedies and entire liability for such claims.\n\n\n\n1. By GitHub\n\nGitHub will defend Customer against any claim brought by an unaffiliated third party to the extent it alleges Customer\u2019s authorized use of the Service infringes a copyright, patent, or trademark or misappropriates a trade secret of an unaffiliated third party. If GitHub is unable to resolve any such claim under commercially reasonable terms, it may, at its option, either: (a) modify, repair, or replace the Service (as applicable); or (b) terminate Customer\u2019s subscription and refund any prepaid, unused subscription fees. GitHub will have no obligation under this Section O.1 for any such claim arising from: i) the modification of the Service, or the combination, operation, or use of the Service with equipment, devices, software, systems, or data, other than as expressly authorized by this Agreement (including the Documentation); (ii) Customer\u2019s failure to stop using the Service after receiving notice to do so; (iii) Customer\u2019s obligations under Section O.2; (iv) products or services (incl", "Y2h1bmtfMTZfaW5kZXhfMjA0NQ==": "uding use of the Service) that are provided by GitHub free of charge; or (v) access or use of Beta Previews. For purposes of GitHub\u2019s obligation under this Section O.1, the Service includes open source components incorporated by GitHub therein.\n\n\n\n2. By Customer\n\nCustomer will defend GitHub against any claim brought by an unaffiliated third party arising from: (i) Customer Content that Customer uploads to the Service; (ii) Customer's violation of this Agreement, including Customer\u2019s breach of confidentiality or violation of Section C; or (iii) any third party-branded equipment, devices, software, systems, or data that Customer combines, operates, or uses with the Service.\n\n\n\n3. Disputes with Other Users\n\nIf Customer has a dispute with one or more Users, Customer releases GitHub from all claims, demands and damages (actual and consequential) of every kind and nature, known and unknown, arising out of or in any way connected with such disputes.\n\n\n\nP. Confidentiality\n\nNeither Party will use the other Party's Confidential Information, except as permitted under this Agreement. Each Party agrees to maintain in confidence and protect the other Party's Confidential Information using at least the same degree of care as it uses for its own information of a similar nature, but in any event at least a reasonable degree of care. Each Party agrees to take all reasonable precautions to prevent any unauthorized disclosure of the other Party's Confidential Information, including, without limitation, disclosing such Confidential Information only to its Representatives who (i) have a need to know such information, (ii) are parties to appropriate agreements sufficient to comply with this Section P, and (iii) are informed of the restrictions on use and disclosure set forth in this Section P. Each Party is responsible for all acts and omissions of its Representatives. The foregoing obligations will not restrict either Party from disclosing Confidential Information of the other Party pursuant to the order or requirement of a court, adm", "Y2h1bmtfMTdfaW5kZXhfMjA0NQ==": "inistrative agency, or other governmental body, _provided_ that the Party required to make such a disclosure gives reasonable notice to the other Party to enable such Party to contest such order or requirement, unless such notice is prohibited by law. The restrictions set forth in this Section P will survive the termination or expiration of this Agreement.\n\n\n\nQ. Expert Services\n\nUpon Customer\u2019s request for Expert Services, GitHub will provide an SOW detailing such Expert Services. GitHub will perform the Expert Services described in each SOW. GitHub will control the manner and means by which the Expert Services are performed and reserves the right to determine personnel assigned. GitHub may use third parties to perform the Expert Services, provided that GitHub remains responsible for their acts and omissions. Customer acknowledges and agrees that GitHub retains all right, title and interest in and to anything used or developed in connection with performing the Expert Services, including software, tools, specifications, ideas, concepts, inventions, processes, techniques, and know-how. To the extent GitHub delivers anything to Customer while performing the Expert Services, GitHub grants to Customer a non-exclusive, non-transferable, worldwide, royalty-free, limited-term license to use those deliverables during the term of this Agreement, solely in conjunction with Customer\u2019s use of the Service.\n\n\n\nR. Changes to the Service or Terms\n\nGitHub reserves the right, at its sole discretion, to amend this Agreement at any time and will update this Agreement in the event of any such amendments. GitHub will notify Customer of material changes to this Agreement, such as price increases, at least 30 days prior to the change taking effect by posting a notice on the Service or sending email to the primary email address specified in your GitHub account. Customer's continued use of the Service after those 30 days constitutes agreement to those revisions of this Agreement. For any other modifications, Customer's continued use of the", "Y2h1bmtfMThfaW5kZXhfMjA0NQ==": " Service constitutes agreement to our revisions of this Agreement. Customer can view all changes to this Agreement in our Site Policy repository.\n\nGitHub changes the Service via Updates and addition of new features. Nothwithstanding the foregoing, GitHub reserves the right at any time to modify or discontinue, temporarily or permanently, the Service (or any part of it) with or without notice.\n\n\n\nS. Support\n\nGitHub will provide standard technical Support for the Service at no additional charge twenty-four (24) hours per day, five (5) days per week, excluding weekends and national U.S. holidays. Standard Support is only offered via web-based ticketing through GitHub Support, and Support requests must be initiated from a User with which GitHub's Support team can interact. GitHub may provide premium Support (subject to the GitHub Premium Support for Enterprise Cloud terms) or dedicated technical Support for the Service at the Support level, Fees, and Subscription Term specified in an Order Form or SOW.\n\n\n\nT. Miscellaneous\n\n\n\n1. Governing Law\n\nIf Customer\u2019s principal office is in the Americas, this Agreement will be governed by and construed in accordance with the laws of the State of California, without giving effect to the principles of conflict of law, any legal action or proceeding arising under this Agreement will be brought exclusively in the federal or state courts located in the Northern District of California, and the Parties hereby consent to personal jurisdiction and venue therein. If Customer\u2019s principal office is outside the Americas, this Agreement will be governed by the laws of Ireland, any legal action or proceeding arising under this Agreement will be brought exclusively in the courts located in Dublin, and the Parties hereby consent to personal jurisdiction and venue therein. The Parties expressly agree that the United Nations Convention on Contracts for the International Sale of Goods and the Uniform Computer Information Transactions Act will not apply to this Agreement. Notwithstanding anything to", "Y2h1bmtfMTlfaW5kZXhfMjA0NQ==": " the contrary in the foregoing, GitHub may bring a claim for equitable relief in any court with proper jurisdiction.\n\n\n\n2. Feedback\n\nCustomer may provide Feedback to GitHub regarding the Products. Feedback is voluntary and is not Customer Confidential Information, even if designated as such. GitHub may fully exercise and exploit such Feedback for the purpose of (i) improving the operation, functionality and use of GitHub\u2019s existing and future product offerings and commercializing such offerings; and (ii) publishing aggregated statistics about the quality of the Products, provided that no data in any such publication will be used to specifically identify Customer, its employees or Customer\u2019s proprietary software code.\n\n\n\n3. Non-Assignability\n\nNeither Party may assign or otherwise transfer this Agreement, in whole or in part, without the other Party's prior written consent, such consent not to be unreasonably withheld, and any attempt to do so will be null and void, except that GitHub may assign this Agreement in its entirety, upon notice to the other party but without the other Party's consent, in connection with a merger, acquisition, corporate reorganization, or sale of all or substantially all of the assigning party's business or assets.\n\n\n\n4. Waiver\n\nA Party's obligations under this Agreement may only be waived in writing signed by an authorized representative of the other Party. No failure or delay by a Party to this Agreement in exercising any right hereunder will operate as a waiver thereof, nor will any single or partial exercise thereof preclude any other or further exercise thereof or the exercise of any right hereunder at law or equity.\n\n\n\n5. Severability\n\nIf any provision of this Agreement is deemed by a court of competent jurisdiction to be illegal, invalid, or unenforceable, the Parties will modify or reform this Agreement to give as much effect as possible to that provision. Any provision that cannot be modified or reformed in this way will be deemed deleted and the remaining provisions of this Agre", "Y2h1bmtfMjBfaW5kZXhfMjA0NQ==": "ement will continue in full force and effect.\n\n\n\n6. Amendments; Complete Agreement; Order of Precedence\n\nThis Agreement may only be modified by a written amendment signed by an authorized representative of GitHub, or by GitHub posting a revised version in accordance with Section R. This Agreement represents the complete and exclusive agreement between the Parties. This Agreement supersedes any proposal or prior agreement oral or written, and any other communications between the Parties relating to the subject matter of these terms, including any confidentiality or nondisclosure agreements. In the event of any conflict between the terms of this Agreement and any Order Form or SOW, the terms of the Order Form or SOW will control with respect to that Order Form or SOW only.\n\n\n\n7. Publicity\n\nIf Customer publicly displays the name of its company or organization on its account or otherwise publicly display its trademarks or logos on its profile page, Customer allows GitHub to use its company's or organization's name to identify Customer as a GitHub customer in promotional materials. Customer may revoke this permission by hiding its company or organization name from public display and notifying GitHub in writing to stop using its organization's name in promotional materials. However, GitHub will have no obligation to remove or recall any prior use or distribution of the promotional materials.\n\n\n\n8. Force Majeure\n\nGitHub will be excused from liability to the extent that it is unable to perform any obligation under this Agreement due to extraordinary causes beyond its reasonable control, including acts of God, natural disasters, strikes, lockouts, riots, acts of war, epidemics, or power, telecommunication or network failures.\n\n\n\n9. Independent Contractors\n\nEach Party is an independent contractor with respect to the subject matter of this Agreement. Nothing contained in this Agreement will be deemed or construed in any manner to create a legal association, partnership, joint venture, employment, agency, fiduciary, or other", "Y2h1bmtfMjFfaW5kZXhfMjA0NQ==": " similar relationship between the Parties, and neither Party can bind the other contractually.\n\n\n\n10. Questions\n\nQuestions about the Terms of Service? Contact us.\n\n", "Y2h1bmtfMF9pbmRleF82ODc=": "\n\nAbout upgrades\n\n{% data reusables.accounts.accounts-billed-separately %}\n\nUpgrading your plan does not affect other subscriptions or usage-based billing for your account. For more information, see \"AUTOTITLE.\"\n\n\n\nUpgrading your personal account's plan\n\nYou can upgrade your personal account from {% data variables.product.prodname_free_user %} to {% data variables.product.prodname_pro %} to get advanced code review tools on private repositories owned by your personal account.\n\nUpgrading your personal account does not affect any organizations you may manage or repositories owned by those organizations. {% data reusables.gated-features.more-info %}\n\n{% data reusables.user-settings.access_settings %}\n{% data reusables.user-settings.billing_plans %}\n1. Next to \"Current plan\", click **Upgrade**.\n1. Under \"Pro\" on the \"Compare plans\" page, click **Upgrade to Pro**.\n{% data reusables.dotcom_billing.choose-monthly-or-yearly-billing %}\n{% data reusables.dotcom_billing.show-plan-details %}\n{% data reusables.dotcom_billing.enter-billing-info %}\n{% data reusables.dotcom_billing.enter-payment-info %}\n{% data reusables.dotcom_billing.finish_upgrade %}\n\n\n\nManaging your organization's plan\n\nYou can upgrade your organization's plan, add seats to your existing plan, or switch from per-repository to per-user pricing.\n\n\n\nUpgrading your organization's plan\n\nYou can upgrade your organization from {% data variables.product.prodname_free_team %} for an organization to {% data variables.product.prodname_team %} to access advanced collaboration and management tools for teams, or upgrade your organization to {% data variables.product.prodname_ghe_cloud %} for additional security, compliance, and deployment controls.\n\nUpgrading an organization does not affect your personal account or repositories owned by your personal account. {% data reusables.gated-features.more-info-org-products %}\n\n{% data reusables.dotcom_billing.org-billing-perms %}\n\n{% note %}\n\n**Note:** {% data reusables.actions.org-to-enterprise-actions-permissions %}\n\n{% endnote ", "Y2h1bmtfMV9pbmRleF82ODc=": "%}\n\n{% data reusables.organizations.billing-settings %}\n{% data reusables.dotcom_billing.upgrade_org %}\n{% data reusables.dotcom_billing.choose_org_plan %}\n{% data reusables.dotcom_billing.choose-monthly-or-yearly-billing %}\n{% data reusables.dotcom_billing.show-plan-details %}\n{% data reusables.dotcom_billing.enter-payment-info %}\n{% data reusables.dotcom_billing.owned_by_business %}\n{% data reusables.dotcom_billing.finish_upgrade %}\n\n\n\nNext steps for organizations using {% data variables.product.prodname_ghe_cloud %}\n\nAs part of your upgrade to {% data variables.product.prodname_ghe_cloud %}, you set up an enterprise account on {% data variables.location.product_location %}. An enterprise account allows you to manage multiple organizations. Optionally, you can set up identity and access management for an individual organization or enterprise account. For more information, see \"AUTOTITLE\" and \"AUTOTITLE{% ifversion fpt %}\" in the {% data variables.product.prodname_ghe_cloud %} documentation.{% else %}.\"{% endif %}\n\n{% data reusables.enterprise.create-an-enterprise-account %} For more information, see \"AUTOTITLE{% ifversion fpt %}\" in the {% data variables.product.prodname_ghe_cloud %} documentation.{% else %}.\"{% endif %}\n\n\n\nAdding seats to your organization\n\nIf you'd like additional users to have access to your {% data variables.product.prodname_team %} organization's private repositories, you can purchase more seats anytime.\n\n{% data reusables.organizations.billing-settings %}\n{% data reusables.dotcom_billing.add-seats %}\n{% data reusables.dotcom_billing.number-of-seats %}\n{% data reusables.dotcom_billing.confirm-add-seats %}\n\n\n\nSwitching your organization from per-repository to per-user pricing\n\n{% data reusables.dotcom_billing.switch-legacy-billing %} For more information, see \"AUTOTITLE.\"\n\n{% data reusables.organizations.billing-settings %}\n1. To the right of your plan name, select the **Edit** dropdown menu, then click **Edit plan**.\n1. To the right of \"Advanced tools for teams\", click **Upgrade now**.\n{% ", "Y2h1bmtfMl9pbmRleF82ODc=": "data reusables.dotcom_billing.choose_org_plan %}\n{% data reusables.dotcom_billing.choose-monthly-or-yearly-billing %}\n{% data reusables.dotcom_billing.owned_by_business %}\n{% data reusables.dotcom_billing.finish_upgrade %}\n\n{% ifversion ghec %}\n\n\n\nAdding seats to your enterprise account\n\n{% data reusables.enterprise-accounts.billing-perms %}\n\n{% note %}\n\n**Note:** If your enterprise account is invoiced, you cannot add seats on {% data variables.product.prodname_dotcom %}. Instead, contact {% data variables.contact.contact_enterprise_sales %}.\n\n{% endnote %}\n\n{% data reusables.enterprise-accounts.access-enterprise %}\n{% data reusables.enterprise-accounts.settings-tab %}\n{% data reusables.enterprise-accounts.billing-tab %}\n{% data reusables.enterprise-accounts.manage-seats %}\n{% endif %}\n\n\n\nTroubleshooting a 500 error when upgrading\n\n{% data reusables.dotcom_billing.500-error %}\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF8xODA4": "\n\nFile views show the latest version on a branch\n\nWhen viewing a file on {% data variables.location.product_location %}, you usually see the version at the current head of a branch.  For example:\n\n- https://github.com/github/codeql/blob/**main**/README.md\n\nrefers to GitHub's `codeql` repository, and shows the `main` branch's current version of the `README.md` file.\n\nThe version of a file at the head of branch can change as new commits are made, so if you were to copy the normal URL, the file contents might not be the same when someone looks at it later.\n\n\n\nPress <kbd>Y</kbd> to permalink to a file in a specific commit\n\nFor a permanent link to the specific version of a file that you see, instead of using a branch name in the URL (i.e. the `main` part in the example above), put a commit id.  This will permanently link to the exact version of the file in that commit.  For example:\n\n- https://github.com/github/codeql/blob/**b212af08a6cffbb434f3c8a2795a579e092792fd**/README.md\n\nreplaces `main` with a specific commit id and the file content will not change.\n\nLooking up the commit SHA by hand is inconvenient, however, so as a shortcut you can type y to automatically update the URL to the permalink version.  Then you can copy the URL knowing that anyone you share it with will see exactly what you saw.\n\n{% tip %}\n\n**Tip**: You can put any identifier that can be resolved to a commit in the URL, including branch names, specific commit SHAs, or tags!\n\n{% endtip %}\n\n\n\nCreating a permanent link to a code snippet\n\nYou can create a permanent link to a specific line or range of lines of code in a specific version of a file or pull request. For more information, see \"AUTOTITLE.\"\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8xNDY0": "\n\nAbout repository migrations with {% data variables.product.prodname_importer_proper_name %}\n\n{% data reusables.enterprise-migration-tool.tool-options %}\n\n{% api %}\n\nIf you choose to use the API, you'll need to write your own scripts or use an HTTP client like Insomnia. You can learn more about getting started with {% data variables.product.company_short %}'s APIs in \"AUTOTITLE\" and \"AUTOTITLE.\"\n\nTo migrate your repositories from {% data variables.product.prodname_ghe_server %} to {% data variables.product.prodname_ghe_cloud %} with the APIs, you will:\n\n1. Create a {% data variables.product.pat_generic %} for both the source and destination organization\n1. Fetch the `ownerId` of the destination organization on {% data variables.product.prodname_ghe_cloud %}\n1. Set up a migration source via {% data variables.product.prodname_dotcom_the_website %}'s GraphQL API to identify where you're migrating from\n1. For each repository you want to migrate, repeat these steps.\n   - Use the REST API on {% data variables.location.product_location_enterprise %} to generate migration archives for your repository\n   - Upload your migration archives to a location where they can be accessed by {% data variables.product.prodname_dotcom_the_website %}\n   - Start your migration using the GraphQL API for {% data variables.product.prodname_dotcom_the_website %}, passing in your archive URLs\n   - Check the status of your migration via the GraphQL API\n   - Validate your migration and check the error log\n\n{% endapi %}\n\n{% cli %}\n\n{% data reusables.enterprise-migration-tool.gei-tool-switcher-api %}\n\n{% endcli %}\n\n{% api %}\n\n{% data reusables.enterprise-migration-tool.gei-tool-switcher-cli %}\n\n{% endapi %}\n\n\n\nPrerequisites\n\n{% data reusables.enterprise-migration-tool.migration-prerequisites %}\n- You must be either an organization owner or be granted the migrator role for both the source and destination organizations. For more information, see \"AUTOTITLE.\"\n- If you use {% data variables.product.prodname_ghe_server %} 3.8 or higher, you need acce", "Y2h1bmtfMV9pbmRleF8xNDY0": "ss to the {% data variables.enterprise.management_console %}.\n\n{% api %}\n\n\n\nStep 1. Create your {% data variables.product.pat_generic %}\n\n{% data reusables.enterprise-migration-tool.create-pats %}\n\n\n\nStep 2: Get the `ownerId` for the destination organization\n\n{% data reusables.enterprise-migration-tool.get-destination-ownerId-ec %}\n\n{% data reusables.enterprise-migration-tool.migration-destination-query %}\n\n\n\nStep 3: Set up blob storage\n\nBecause many {% data variables.product.prodname_ghe_server %} instances sit behind firewalls, for {% data variables.product.prodname_ghe_server %} versions 3.8 or higher, we use blob storage as an intermediate location to store your data that {% data variables.product.prodname_dotcom %} can access.\n\nYou must first set up blob storage with a supported cloud provider, then configure your settings in the {% data variables.enterprise.management_console %} of {% data variables.location.product_location_enterprise %}.\n\n{% note %}\n\n**Note**: You only need to configure blob storage if you use {% data variables.product.prodname_ghe_server %} versions 3.8 or higher. If you use {% data variables.product.prodname_ghe_server %} versions 3.7 or lower, skip to \"Step 4: Set up a migration source in GitHub Enterprise Cloud.\"\n\nBlob storage is required to migrate repositories with large Git source or metadata. If you use {% data variables.product.prodname_ghe_server %} versions 3.7 or lower, you will not be able to perform migrations where your Git source or metadata exports exceed 2GB. To perform these migrations, update to {% data variables.product.prodname_ghe_server %} versions 3.8 or higher.\n\n{% endnote %}\n\n\n\nSetting up blob storage with a supported cloud provider\n\n{% data reusables.enterprise-migration-tool.supported-blob-storage-providers %}\n\n\n\nSetting up an AWS S3 storage bucket\n\n{% data reusables.enterprise-migration-tool.set-up-aws-bucket %}\n\n\n\nSetting up an Azure Blob Storage account\n\n{% data reusables.enterprise-migration-tool.set-up-azure-storage-account %}\n\n\n\nConfiguring blob storage ", "Y2h1bmtfMl9pbmRleF8xNDY0": "in the {% data variables.enterprise.management_console %} of {% data variables.location.product_location_enterprise %}\n\n{% data reusables.enterprise-migration-tool.blob-storage-management-console %}\n\n\n\nStep 4: Set up a migration source in {% data variables.product.prodname_ghe_cloud %}\n\n{% data reusables.enterprise-migration-tool.identify-migration-source-intro %}\n\nYour migration source is your organization on {% data variables.product.prodname_ghe_server %}.\n\n\n\n`createMigrationSource` mutation\n\n```graphql\nmutation createMigrationSource($name: String!, $url: String!, $ownerId: ID!) {\n  createMigrationSource(input: {name: $name, url: $url, ownerId: $ownerId, type: GITHUB_ARCHIVE}) {\n    migrationSource {\n      id\n      name\n      url\n      type\n    }\n  }\n}\n```\n\n{% data reusables.enterprise-migration-tool.type-note-github-archive %}\n\n{% data reusables.enterprise-migration-tool.createMigrationSource-table-ec %}\n| `url` | The URL for {% data variables.location.product_location_enterprise %}. This URL does not need to be accessible from {% data variables.product.prodname_ghe_cloud %}.\n\n\n\n`createMigrationSource` response\n\n```json\n{\n  \"data\": {\n    \"createMigrationSource\": {\n      \"migrationSource\": {\n        \"id\": \"MS_kgDaACRjZTY5NGQ1OC1mNDkyLTQ2NjgtOGE1NS00MGUxYTdlZmQwNWQ\",\n        \"name\": \"GHES Source\",\n        \"url\": \"https://my-ghes-hostname.com\",\n        \"type\": \"GITHUB_ARCHIVE\"\n      }\n    }\n  }\n}\n```\n\nIn this example, `MS_kgDaACRjZTY5NGQ1OC1mNDkyLTQ2NjgtOGE1NS00MGUxYTdlZmQwNWQ` is the migration source ID, which we'll use in a later step.\n\n\n\nStep 5: Generate migration archives on {% data variables.location.product_location_enterprise %}\n\nYou will use the REST API to start two \"migrations\" in {% data variables.product.prodname_ghe_server %}: one to generate an archive of your repository's Git source, and one to generate an archive of your repository's metadata (such as issues and pull requests).\n\nTo generate the Git source archive, make a `POST` request to `https://HOSTNAME/api/v3/orgs/ORGANIZATION/migrations`, re", "Y2h1bmtfM19pbmRleF8xNDY0": "placing `HOSTNAME` with the hostname of {% data variables.location.product_location_enterprise %}, and `ORGANIZATION` with your organization's login.\n\nIn the body, specify the single repository you want to migrate. Your request will look something like this:\n\n```http\nPOST /api/v3/orgs/acme-corp/migrations HTTP/1.1\nAccept: application/vnd.github+json\nAuthorization: Bearer \nContent-Type: application/json\nHost: github.acmecorp.net\n\n{\n  \"repositories\": [\"repository_to_migrate\"],\n  \"exclude_metadata\": true\n}\n```\n\nTo generate your metadata archive, send a similar request to the same URL with the following body:\n\n```json\n{\n  \"repositories\": [\"repository_to_migrate\"],\n  \"exclude_git_data\": true,\n  \"exclude_releases\": false,\n  \"exclude_owner_projects\": true\n}\n```\n\nEach of these two API calls will return a JSON response including the ID of the migration you have started.\n\n```http\nHTTP/1.1 201 Created\n\n{\n  \"id\": 123,\n  // ...\n}\n```\n\nFor more information, see \"Start an organization migration\" in the REST API documentation.\n\nGenerating the archives can take a while, depending on the amount of data. You can regularly check the status of the two migrations with the \"Get an organization migration status\" API until the `state` of the migration changes to `exported`.\n\n```http\nGET /api/v3/orgs/acme-corp/migrations/123 HTTP/1.1\nAccept: application/vnd.github+json\nAuthorization: Bearer \nHost: github.acmecorp.net\n\nHTTP/1.1 200 OK\nContent-Type: application/json\n\n{\n  \"id\": 123,\n  \"state\": \"exported\",\n  // ...\n}\n```\n\nFor more information, see \"Get an organization migration status\" in the REST API documentation.\n\n{% note %}\n\n**Note:** If your migration moves to the `failed` state rather than the `exported` state, try starting the migration again. If the migration fails repeatedly, we recommend generating the archives using `ghe-migrator` instead of the API.\n\nFollow the steps in \"Exporting migration data from your enterprise,\" adding only one repository to the migration. At the end of the process, you will have a single migration archive w", "Y2h1bmtfNF9pbmRleF8xNDY0": "ith your Git source and metadata, and you can move to step 6 in this article.\n\n{% endnote %}\n\nAfter the `state` of a migration moves to `exported`, you can fetch the migration's URL using the \"Download an organization migration archive\" API.\n\n```http\nGET /api/v3/orgs/acme-corp/migrations/123/archive HTTP/1.1\nAccept: application/vnd.github+json\nAuthorization: Bearer \nHost: github.acmecorp.net\n\nHTTP/1.1 302 Found\nLocation: https://media.github.acmecorp.net/migrations/123/archive/cca2ebe9-7403-4ffa-9b6a-4c9e16c94410?token=AAAAABEWE7JP4H2HACKEGMTDOYRC6\n```\n\nThe API will return a `302 Found` response with a `Location` header redirecting to the URL where the downloadable archive is located. Download the two files: one for the Git source, and one for the metadata.\n\nFor more information, see \"Download an organization migration archive\" in the REST API documentation.\n\nAfter both migrations have completed and you have downloaded the archives, you can move to the next step.\n\n\n\nStep 6: Upload your migration archives\n\nTo import your data into {% data variables.product.prodname_ghe_cloud %}, you must pass both archives for each repository (Git source and metadata) from your machine to {% data variables.product.prodname_dotcom_the_website %}, using our GraphQL API.\n\nIf you're using {% data variables.product.prodname_ghe_server %} 3.7 or lower, you must first generate URLs for the archives that are accessible by {% data variables.product.prodname_dotcom_the_website %}. Most customers choose to upload the archives to a cloud provider's blob storage service, such as Amazon S3 or Azure Blob Storage, then generate a short-lived URL for each.\n\nIf you're using {% data variables.product.prodname_ghe_server %} 3.8 or higher, your instance uploads the archives and generates the URLs for you. The `Location` header in the previous step will return the short-lived URL.\n\nYou may need to allowlist {% data variables.product.company_short %}'s IP ranges. For more information, see \"AUTOTITLE.\"\n\n\n\nStep 7: Start your repository migration\n\n{% data ", "Y2h1bmtfNV9pbmRleF8xNDY0": "reusables.enterprise-migration-tool.start-repository-migration-ec %}\n\n\n\n`startRepositoryMigration` mutation\n\n```graphql\nmutation startRepositoryMigration (\n  $sourceId: ID!,\n  $ownerId: ID!,\n  $repositoryName: String!,\n  $continueOnError: Boolean!,\n  $accessToken: String!,\n  $githubPat: String!,\n  $gitArchiveUrl: String!,\n  $metadataArchiveUrl: String!,\n  $sourceRepositoryUrl: URI!,\n  $targetRepoVisibility: String!\n){\n  startRepositoryMigration( input: {\n    sourceId: $sourceId,\n    ownerId: $ownerId,\n    repositoryName: $repositoryName,\n    continueOnError: $continueOnError,\n    accessToken: $accessToken,\n    githubPat: $githubPat,\n    targetRepoVisibility: $targetRepoVisibility\n    gitArchiveUrl: $gitArchiveUrl,\n    metadataArchiveUrl: $metadataArchiveUrl,\n    sourceRepositoryUrl: $sourceRepositoryUrl,\n  }) {\n    repositoryMigration {\n      id\n      migrationSource {\n        id\n        name\n        type\n      }\n      sourceUrl\n    }\n  }\n}\n```\n\n{% data reusables.enterprise-migration-tool.startRepositoryMigration-table-ec %}\n`gitArchiveUrl` | A {% data variables.product.prodname_ghe_cloud %}-accessible URL for your Git source archive.\n`metadataArchiveUrl` | A {% data variables.product.prodname_ghe_cloud %}-accessible URL for your metadata archive.\n`sourceRepositoryUrl` | The URL for your repository on your {% data variables.product.prodname_ghe_server %} instance. This is required, but {% data variables.product.prodname_ghe_cloud %} will not communicate directly with your {% data variables.product.prodname_ghe_server %} instance.\n\n{% data reusables.enterprise-migration-tool.next-check-status %}\n\n\n\nStep 8: Check the status of your migration\n\n{% data reusables.enterprise-migration-tool.check-migration %}\n\n\n\nStep 9: Validate your migration and check the error log\n\n{% data reusables.enterprise-migration-tool.validate-migration-log %}\n\n{% endapi %}\n\n{% cli %}\n\n\n\nStep 1: Install the {% data variables.product.prodname_gei_cli %}\n\n{% data reusables.enterprise-migration-tool.install-gei-extension-intro %}\n\n{% data reusabl", "Y2h1bmtfNl9pbmRleF8xNDY0": "es.enterprise-migration-tool.install-github-cli %}\n{% data reusables.enterprise-migration-tool.install-gei-extension %}\n\n{% data reusables.enterprise-migration-tool.gei-help-flag %}\n\n\n\nStep 2: Update the {% data variables.product.prodname_gei_cli %}\n\n{% data reusables.enterprise-migration-tool.update-gei-cli %}\n\n\n\nStep 3: Set environment variables\n\n{% data reusables.enterprise-migration-tool.set-env-variables-gei %}\n\n{% data reusables.enterprise-migration-tool.create-pats %}\n{% data reusables.enterprise-migration-tool.env-variables-gei %}\n\n\n\nStep 4: Set up blob storage\n\nBecause many {% data variables.product.prodname_ghe_server %} instances sit behind firewalls, we use blob storage as an intermediate location to store your data that {% data variables.product.prodname_dotcom %} can access.\n\nFirst, you must set up blob storage with a supported cloud provider. Then, you must configure your credentials for the storage provider in the {% data variables.enterprise.management_console %} or {% data variables.product.prodname_cli %}.\n\n\n\nSetting up blob storage with a supported cloud provider\n\n{% data reusables.enterprise-migration-tool.supported-blob-storage-providers %}\n\n\n\nSetting up an AWS S3 storage bucket\n\n{% data reusables.enterprise-migration-tool.set-up-aws-bucket %}\n\n\n\nSetting up an Azure Blob Storage storage account\n\n{% data reusables.enterprise-migration-tool.set-up-azure-storage-account %}\n\n\n\nConfiguring your blob storage credentials\n\nAfter you set up blob storage with a supported cloud provider, you must configure your credentials for the storage provider in {% data variables.product.prodname_dotcom %}:\n\n- If you use {% data variables.product.prodname_ghe_server %} 3.8 or higher, configure your credentials in the {% data variables.enterprise.management_console %}.\n- If you use {% data variables.product.prodname_ghe_server %} 3.7 or lower, configure the credentials in the {% data variables.product.prodname_cli %}.\n\n\n\nConfiguring blob storage in the {% data variables.enterprise.management_console %} of {% data v", "Y2h1bmtfN19pbmRleF8xNDY0": "ariables.location.product_location_enterprise %}\n\n{% note %}\n\n**Note:** You only need to configure blob storage in the {% data variables.enterprise.management_console %} if you use {% data variables.product.prodname_ghe_server %} 3.8 or higher. If you use 3.7 or lower, configure your credentials in the {% data variables.product.prodname_cli %} instead.\n\n{% endnote %}\n\n{% data reusables.enterprise-migration-tool.blob-storage-management-console %}\n\n\n\nConfiguring your blob storage credentials in the {% data variables.product.prodname_cli %}\n\n{% note %}\n\n**Note:** You only need to configure your blob storage credentials in the {% data variables.product.prodname_cli %} if you use {% data variables.product.prodname_ghe_server %} 3.7 or lower. If you use 3.8 or higher, configure blob storage in the {% data variables.enterprise.management_console %} instead.\n\nIf you configure your blob storage credentials in the {% data variables.product.prodname_cli %}, you will not be able to perform migrations where your Git source or metadata exports exceed 2GB. To perform these migrations, upgrade to {% data variables.product.prodname_ghe_server %} 3.8 or higher.\n\n{% endnote %}\n\n\n\nConfiguring AWS S3 credentials in the {% data variables.product.prodname_cli %}\n\n{% data reusables.enterprise-migration-tool.aws-credentials-cli %}\n\n\n\nConfiguring Azure Blob Storage account credentials in the {% data variables.product.prodname_cli %}\n\n{% data reusables.enterprise-migration-tool.azure-credentials-cli %}\n\n\n\nStep 5: Generate a migration script\n\n{% data reusables.enterprise-migration-tool.generate-migration-script %}\n\nIf you want to migrate a single repository, skip to the next step.\n\n\n\nGenerating a migration script\n\n{% data reusables.enterprise-migration-tool.follow-step-from-computer-with-access %}\n\n{% data reusables.enterprise-migration-tool.gh-gei-generate-script %}\n\nFor {% data variables.product.prodname_ghe_server %} 3.8 or later, or if you're using 3.7 or lower with Azure Blob Storage, use the following flags:\n\n```shell copy\ngh gei gene", "Y2h1bmtfOF9pbmRleF8xNDY0": "rate-script --github-source-org SOURCE \\\n  --github-target-org DESTINATION \\\n  --output FILENAME \\\n  --ghes-api-url GHES-API-URL\n```\n\nIf you're using {% data variables.product.prodname_ghe_server %} 3.7 or lower with AWS S3, use the following flags:\n\n```shell copy\ngh gei generate-script --github-source-org SOURCE \\\n  --github-target-org DESTINATION \\\n  --output FILENAME \\\n  --ghes-api-url GHES-API-URL \\\n  --aws-bucket-name AWS-BUCKET-NAME\n```\n\n{% data reusables.enterprise-migration-tool.ssl-flag %}\n\n{% data reusables.enterprise-migration-tool.download-migration-logs-flag %}\n\n{% data reusables.enterprise-migration-tool.generate-script-table %}\n{% data reusables.enterprise-migration-tool.ghes-api-url-placeholder %}\n{% data reusables.enterprise-migration-tool.aws-bucket-name-placeholder %}\n\n\n\nReviewing the migration script\n\n{% data reusables.enterprise-migration-tool.review-migration-script %}\n\n{% data reusables.enterprise-migration-tool.skip-releases %}\n\n\n\nStep 6: Migrate repositories\n\n{% data reusables.enterprise-migration-tool.migrate-repos-gei %}\n\nWhen you migrate repositories, the {% data variables.product.prodname_gei_cli %} performs the following steps:\n\n1. Connects to {% data variables.location.product_location_enterprise %} and generates two migration archives per repository, one for the Git source and one for the metadata\n1. Uploads the migration archives to the blob storage provider of your choice\n1. Starts your migration in {% data variables.product.prodname_ghe_cloud %}, using the URLs of the archives stored with your blob storage provider\n1. Deletes the migration archive from your local machine\n\n\n\nMigrate multiple repositories\n\nIf you're migrating from {% data variables.product.prodname_ghe_server %} 3.7 or earlier, before you run your script, you must set additional environment variables to authenticate to your blob storage provider.\n\n- For Azure Blob Storage, set `AZURE_STORAGE_CONNECTION_STRING` to the connection string for your Azure storage account.\n\n   {% data reusables.enterprise-migration-tool.", "Y2h1bmtfOV9pbmRleF8xNDY0": "azure-storage-connection-key %}\n- For AWS S3, set the following environment variables.\n  - `AWS_ACCESS_KEY`: The access key for your bucket\n  - `AWS_SECRET_KEY`: The secret key for your bucket\n  - `AWS_REGION`: The AWS region where your bucket is located\n  - `AWS_SESSION_TOKEN`: The session token, if you're using AWS temporary credentials (see Using temporary credentials with AWS resources in the AWS documentation)\n\n{% data reusables.enterprise-migration-tool.migrate-multiple-repos %}\n\n\n\nMigrate a single repository\n\n{% data reusables.enterprise-migration-tool.follow-step-from-computer-with-access %}\n\n{% data reusables.enterprise-migration-tool.gei-migrate-repo %}\n\nIf you're using {% data variables.product.prodname_ghe_server %} 3.8 or later, use the following flags:\n\n```shell copy\ngh gei migrate-repo --github-source-org SOURCE --source-repo CURRENT-NAME --github-target-org DESTINATION --target-repo NEW-NAME --ghes-api-url GHES-API-URL\n```\n\nIf you're migrating from {% data variables.product.prodname_ghe_server %} 3.7 or earlier and using Azure Blob Storage as your blob storage provider, use the following flags to authenticate:\n\n```shell copy\ngh gei migrate-repo --github-source-org SOURCE --source-repo CURRENT-NAME --github-target-org DESTINATION --target-repo NEW-NAME \\\n    --ghes-api-url GHES-API-URL --azure-storage-connection-string \"AZURE_STORAGE_CONNECTION_STRING\"\n```\n\nIf you're migrating from {% data variables.product.prodname_ghe_server %} 3.7 or earlier and using Amazon S3 as your blob storage provider, use the following flags to authenticate:\n\n```shell copy\ngh gei migrate-repo --github-source-org SOURCE --source-repo CURRENT-NAME --github-target-org DESTINATION --target-repo NEW-NAME \\\n    --ghes-api-url GHES-API-URL --aws-bucket-name \"AWS-BUCKET-NAME\"\n```\n\n{% data reusables.enterprise-migration-tool.ssl-flag %}\n\n{% data reusables.enterprise-migration-tool.skip-releases %}\n\n{% data reusables.enterprise-migration-tool.migrate-repo-table-ec %}\n{% data reusables.enterprise-migration-tool.ghes-api-url-placehol", "Y2h1bmtfMTBfaW5kZXhfMTQ2NA==": "der %}\n{% data reusables.enterprise-migration-tool.azure-storage-connection-string-placeholder %}\n{% data reusables.enterprise-migration-tool.aws-bucket-name-placeholder %}\n\n\n\nStep 7: Validate your migration and check the error log\n\n{% data reusables.enterprise-migration-tool.validate-migration-logs %}\n\nAfter your migration has finished, we recommend deleting the archives from your storage container. If you plan to complete additional migrations, delete the archive placed into your storage container by the {% data variables.product.prodname_ado2gh_cli_short %}. If you're done migrating, you can delete the entire container.\n\n{% endcli %}\n\n", "Y2h1bmtfMF9pbmRleF8zMjI=": "\n\nAbout built-in authentication for users outside your provider\n\nBy default, when you enable external authentication for {% data variables.product.product_name %}, built-in authentication is disabled for your instance. For more information, see \"AUTOTITLE.\"\n\nIf you're unable to add specific accounts to your external authentication provider, such as accounts for contractors or machine users, you can configure fallback authentication. Fallback authentication allows built-in authentication for outside users and to access a fallback account if your authentication provider is unavailable.\n\nIf you configure built-in authentication and a person successfully authenticates with SAML or CAS, the person will no longer have the option to authenticate with a username and password. If a user successfully authenticates with LDAP, the credentials are no longer considered internal.\n\n{% warning %}\n\n**Warning:** If you disable built-in authentication, you must individually suspend any users that should no longer have access to the instance. For more information, see \"AUTOTITLE.\"\n\n{% endwarning %}\n\n\n\nConfiguring built-in authentication for users outside your provider\n\n{% data reusables.enterprise_site_admin_settings.access-settings %}\n{% data reusables.enterprise_site_admin_settings.management-console %}\n{% data reusables.enterprise_management_console.authentication %}\n1. Under \"Authentication\", select your authentication method.\n1. Select **Allow creation of accounts with built-in authentication**.\n1. Read the warning, then click **Ok**.\n\n{% data reusables.enterprise_user_management.two_factor_auth_header %}\n{% data reusables.enterprise_user_management.2fa_is_available %}\n\n\n\nInviting users outside your provider to authenticate to your instance\n\nWhen a user accepts the invitation, they can use their username and password to sign in rather than signing in through the IdP.\n\n{% data reusables.enterprise_site_admin_settings.sign-in %}\n{% data reusables.enterprise_site_admin_settings.access-settings %}\n{% data reusables.enterprise_site_a", "Y2h1bmtfMV9pbmRleF8zMjI=": "dmin_settings.invite-user-sidebar-tab %}\n{% data reusables.enterprise_site_admin_settings.invite-user-reset-link %}\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8xMDQ3": "\n\nCreating a footer\n\n{% data reusables.repositories.navigate-to-repo %}\n{% data reusables.repositories.sidebar-wiki %}\n1. At the bottom of the page, click **Add a custom footer**.\n1. Use the text editor to type the content you want your footer to have.\n1. In the \"Edit message\" field, enter a commit message describing the footer you\u2019re adding.\n1. To commit your changes to the wiki, click **Save Page**.\n\n\n\nCreating a sidebar\n\n{% data reusables.repositories.navigate-to-repo %}\n{% data reusables.repositories.sidebar-wiki %}\n1. Click **Add a custom sidebar** on the right side of the page.\n1. Use the text editor to add your page's content.\n1. In the \"Edit message\" field, enter a commit message describing the sidebar you\u2019re adding.\n1. To commit your changes to the wiki, click **Save Page**.\n\n\n\nCreating a footer or sidebar locally\n\nIf you create a file named `_Footer.` or `_Sidebar.`, we'll use them to populate the footer and sidebar of your wiki, respectively. Like every other wiki page, the extension you choose for these files determines how we render them.\n\n", "Y2h1bmtfMF9pbmRleF8zNDE=": "\n\nAbout SAML single sign-on for enterprise accounts\n\n{% data reusables.saml.dotcom-saml-explanation %} {% data reusables.saml.about-saml-enterprise-accounts %}\n\n{% data reusables.saml.switching-from-org-to-enterprise %}\n\nWhen you configure SAML SSO at the organization level, each organization must be configured with a unique SSO tenant in your IdP, which means that your members will be associated with a unique SAML identity record for each organization they have successfully authenticated with. If you configure SAML SSO for your enterprise account instead, each enterprise member will have one SAML identity that is used for all organizations owned by the enterprise account.\n\nAfter you configure SAML SSO for your enterprise account, the new configuration will override any existing SAML SSO configurations for organizations owned by the enterprise account. Any team synchronization settings you have configured will also be removed from these organizations. If you intend to re-enable team synchronization, before enabling SAML SSO for your enterprise, take note of the current team sync configuration in the affected organizations. For more information, see \"AUTOTITLE.\"\n\nEnterprise members will not be notified when an enterprise owner enables SAML for the enterprise account. If SAML SSO was previously enforced at the organization level, members should not see a major difference when navigating directly to organization resources. The members will continue to be prompted to authenticate via SAML. If members navigate to organization resources via their IdP dashboard, they will need to click the new tile for the enterprise-level app, instead of the old tile for the organization-level app. The members will then be able to choose the organization to navigate to.\n\nAny {% data variables.product.pat_generic %}s, SSH keys, {% data variables.product.prodname_oauth_apps %}, and {% data variables.product.prodname_github_apps %} that were previously authorized for the organization will continue to be authorized for the organization. Ho", "Y2h1bmtfMV9pbmRleF8zNDE=": "wever, members will need to authorize any PATs, SSH keys, {% data variables.product.prodname_oauth_apps %}, and {% data variables.product.prodname_github_apps %} that were never authorized for use with SAML SSO for the organization.\n\nSCIM provisioning is not currently supported when SAML SSO is configured for an enterprise account. If you are currently using SCIM for an organization owned by your enterprise account, you will lose this functionality when switching to an enterprise-level configuration.\n\nYou are not required to remove any organization-level SAML configurations before configuring SAML SSO for your enterprise account, but you may want to consider doing so. If SAML is ever disabled for the enterprise account in the future, any remaining organization-level SAML configurations will take effect. Removing the organization-level configurations can prevent unexpected issues in the future.\n\nFor more information about the decision to implement SAML SSO at the organization or enterprise level, see \"AUTOTITLE.\"\n\n\n\nSwitching your SAML configuration from an organization to an enterprise account\n\n1. Enforce SAML SSO for your enterprise account, making sure all organization members are assigned or given access to the IdP app being used for the enterprise account. For more information, see \"AUTOTITLE.\"\n1. Optionally, remove any existing SAML configuration for organizations owned by the enterprise account. To help you decide whether to remove the configurations, see \"About SAML single sign-on for enterprise accounts.\"\n1. If you kept any organization-level SAML configurations in place, to prevent confusion, consider hiding the tile for the organization-level apps in your IdP.\n1. Advise your enterprise members about the change.\n   - Members will no longer be able to access their organizations by clicking the SAML app for the organization in the IdP dashboard. They will need to use the new app configured for the enterprise account.\n   - Members will need to authorize any PATs or SSH keys that were not previously authoriz", "Y2h1bmtfMl9pbmRleF8zNDE=": "ed for use with SAML SSO for their organization. For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n   - Members may need to reauthorize {% data variables.product.prodname_oauth_apps %} that were previously authorized for the organization. For more information, see \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF81NzU=": "---\ntitle: Internal GitHub Apps\nintro: 'Some {% data variables.product.prodname_github_apps %} are internal apps, owned by {% data variables.product.company_short %}, that are granted special capabilities.'\nversions:\n  fpt: '*'\n  ghes: '*'\n  ghae: '*'\n  ghec: '*'\nshortTitle: Internal apps\n---\n\nSome {% data variables.product.prodname_github_apps %} are internal apps. These apps are owned by {% data variables.product.company_short %} and are granted special capabilities. For example, users can authorize these apps and use them to access data from an organization without requiring approval by the organization.\n\nSome of these internal apps are automatically included with {% data variables.product.company_short %} and do not require user authorization. These apps will not appear in your list of authorized {% data variables.product.prodname_github_apps %} or in your list of installed {% data variables.product.prodname_github_apps %}.\n\nThese internal apps will appear in the user security log, but will not appear in organization{% ifversion ghes or ghae or ghec %} or enterprise{% endif %} audit logs. {% ifversion ghes or ghae or ghec %}For more information, see \"AUTOTITLE,\" \"AUTOTITLE\", and \"AUTOTITLE.\"{% else %}For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"{% endif %}\n\nThese {% data variables.product.prodname_github_apps %} are:\n\n- {% data variables.product.prodname_classroom %}\n- VSCode Auth Provider\n- Git Src Migrator\n- MS Teams\n- Slack\n- {% data variables.product.prodname_codespaces %}\n- {% data variables.product.prodname_copilot_short %} plugin\n\n", "Y2h1bmtfMF9pbmRleF8xMTY1": "\n\nAbout stashed changes\n\nTo apply your changes to your repository, you must save the files and then commit the changes to a branch. If you have saved changes that you are not ready to commit yet, you can stash the changes for later. When you stash changes, the changes are temporarily removed from the files and you can choose to restore or discard the changes later. You can only stash one set of changes at a time with {% data variables.product.prodname_desktop %}. If you use {% data variables.product.prodname_desktop %} to stash changes, all unsaved changes will be stashed. After you stash changes on a branch, you can safely change branches or make other changes to your current branch.\n\nIf you use {% data variables.product.prodname_desktop %} to switch branches while you have saved, but not committed, changes, {% data variables.product.prodname_desktop %} will prompt you to stash the changes or bring them to the other branch. For more information, see \"AUTOTITLE.\"\n\n\n\nStashing changes\n\n{% data reusables.desktop.click-changed-files-header %}\n{% data reusables.desktop.click-stash-all-changes %}\n\n\n\nRestoring stashed changes\n\n{% data reusables.desktop.navigate-to-stashed-changes %}\n{% data reusables.desktop.click-stashed-changes %}\n{% data reusables.desktop.click-restore %}\n\n\n\nDiscarding stashed changes\n\n{% data reusables.desktop.navigate-to-stashed-changes %}\n{% data reusables.desktop.click-stashed-changes %}\n{% data reusables.desktop.click-discard %}\n\n", "Y2h1bmtfMF9pbmRleF8xMzcx": "---\ntitle: 'Copying a {% data variables.product.prodname_project_v1 %}'\nintro: 'You can copy a {% data variables.projects.projects_v1_board %} to quickly create a new project. Copying frequently used or highly customized {% data variables.projects.projects_v1_boards %} helps standardize your workflow.'\nredirect_from:\n  - /github/managing-your-work-on-github/managing-project-boards/copying-a-project-board\n  - /articles/copying-a-project-board\n  - /github/managing-your-work-on-github/copying-a-project-board\nversions:\n  fpt: '*'\n  ghec: '*'\ntopics:\n  - Pull requests\nallowTitleToDifferFromFilename: true\n---\n{% data reusables.projects.project_boards_old %}\n\nCopying a {% data variables.projects.projects_v1_board %} allows you to reuse a {% data variables.projects.projects_v1_board %}'s title, description, and automation configuration. You can copy {% data variables.projects.projects_v1_boards %} to eliminate the manual process of creating new {% data variables.projects.projects_v1_boards %} for similar workflows.\n\nYou must have read access to a {% data variables.projects.projects_v1_board %} to copy it to a repository or organization where you have write access.\n\nWhen you copy a {% data variables.projects.projects_v1_board %} to an organization, the {% data variables.projects.projects_v1_board %}'s visibility will default to private, with an option to change the visibility. For more information, see \"AUTOTITLE.\"\n\nA {% data variables.projects.projects_v1_board %}'s automation is also enabled by default. For more information, see \"AUTOTITLE.\"\n\n1. Navigate to the {% data variables.projects.projects_v1_board %} you want to copy.\n{% data reusables.project-management.click-menu %}\n1. Click {% octicon \"kebab-horizontal\" aria-label=\"The horizontal kebab icon\" %}, then click **Copy**.\n!Screenshot showing a project menu. The copy option is highlighted with an orange outline.\n1. Under \"Owner\", use the drop-down menu and click the repository or organization where you want to copy the project board.\n1. Optionally, under \"Project bo", "Y2h1bmtfMV9pbmRleF8xMzcx": "ard name\", type the name of the copied {% data variables.projects.projects_v1_board %}.\n1. Optionally, under \"Description\", type a description of the copied project board that other people will see.\n1. Optionally, under \"Automation settings\", select whether you want to copy the configured automatic workflows. This option is enabled by default. For more information, see \"AUTOTITLE.\"\n{% data reusables.project-management.choose-visibility %}\n1. Click **Copy project**.\n\n", "Y2h1bmtfMF9pbmRleF8xNDQy": "\n\nAbout repository imports with GitHub Importer\n\nGitHub Importer is not suitable for all imports. For example, if your existing code is hosted on a private network, our tool won't be able to access it. In these cases, we recommend importing using the command line for Git repositories or an external source code migration tool for projects imported from other version control systems.\n\n{% data reusables.migrations.github-importer-non-git-deprecation %}\n\nIf you'd like to match the commits in your repository to the authors' GitHub personal accounts during the import, make sure every contributor to your repository has a GitHub account before you begin the import.\n\n{% data reusables.repositories.repo-size-limit %}\n\nFor more information about migration paths to {% data variables.product.prodname_dotcom %} from other products, or between {% data variables.product.prodname_dotcom %} products, see \"AUTOTITLE.\"\n\n\n\nImporting a repository with GitHub Importer\n\n1. In the upper-right corner of any page, click {% octicon \"plus\" aria-label=\"Create new...\" %}, and then click **Import repository**.\n\n   !Screenshot of the top-right corner of any page on {% data variables.product.prodname_dotcom %}. A plus icon is highlighted with an orange outline.\n1. Under \"Your old repository's clone URL\", type the URL of the project you want to import.\n1. Under \"Owner\", select the dropdown menu and click your personal account or an organization to own the repository\n1. Under \"Name\", type a name for the repository on GitHub.\n1. Under \"Privacy\", select a visibility for the repository. For more information, see \"AUTOTITLE.\"\n1. Review the information you entered, then click **Begin import**.\n1. If your old project requires credentials, type your login information for that project. If SAML SSO or 2FA are enabled for your user account on the old project, enter a {% data variables.product.pat_generic %} with repository read permissions in the \"Password\" field instead of your password.\n1. Click **Submit**.\n1. If there are multiple projects hosted at your ", "Y2h1bmtfMV9pbmRleF8xNDQy": "old project's clone URL, select the project you'd like to import, then click **Submit**.\n1. If you're moving from a version control system other than Git and your project contains files larger than 100 MB, select whether to import the large files using Git Large File Storage, then click **Continue**.\n\nYou'll receive an email when the repository has been completely imported.\n\n", "Y2h1bmtfMF9pbmRleF81MjE=": "\n\nRequesting publisher verification\n\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n1. At the bottom of the left sidebar, click **Developer settings**.\n1. Under \"Developer settings\", click **Publisher Verification**.\n1. Under \"Publisher Verification\", complete the information in the checklist:\n   - Ensure that your basic profile information is present and accurate. Also, make sure that you've included the best email address for support and updates from {% data variables.product.company_short %}.\n   - Ensure that Two-factor authentication is enabled for your organization. For more information, see \"AUTOTITLE.\"\n   - Submit a verified domain and ensure that a \"Verified\" badge displays on your organization's profile page. For related information, see \"AUTOTITLE.\"\n\n1. Click **Request Verification**. {% data variables.product.company_short %} will review your details and let you know once your publisher verification is complete.\n\n\n\nFurther reading\n\nFor information about the process of publishing apps, see \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF85NjI=": "\n\nAbout machine types\n\n{% data reusables.codespaces.codespaces-machine-types %} You can choose an alternative machine type either when you create a codespace or at any time after you've created a codespace.\n\nFor information on choosing a machine type when you create a codespace, see \"AUTOTITLE.\"\n\n{% data reusables.codespaces.machine-types-for-unpublished-codespaces %} For more information, see \"AUTOTITLE.\"\n\n\n\nChanging the machine type\n\n{% note %}\n\n**Note**: {% data reusables.codespaces.codespaces-machine-type-availability %}\n\n{% endnote %}\n\n{% webui %}\n\n{% data reusables.codespaces.your-codespaces-procedure-step %}\n\n   The number of cores, memory, storage capacity, and currently used storage are displayed for each codespace. Some details are omitted if you are using a narrow browser window.\n\n   !Screenshot of a list of three codespaces on the https://github.com/codespaces page.\"\n\n{% data reusables.codespaces.ellipsis-settings %}\n1. Click **Change machine type**.\n\n   !Screenshot of the dropdown menu for a codespace. The \"Change machine type\" option is highlighted.\n\n1. If multiple machine types are available for your codespace, choose the type of machine you want to use.\n\n   !Screenshot of a dialog showing two available machine types: 2-core and 4-core.\n\n1. Click **Update codespace**.\n\n{% endwebui %}\n\n{% vscode %}\n\n{% data reusables.codespaces.changing-machine-type-in-vscode %}\n\n{% endvscode %}\n\n{% cli %}\n\n{% data reusables.codespaces.using-github-cli %}\n\nYou can use the `gh codespace edit --machine MACHINE-TYPE-NAME` {% data variables.product.prodname_cli %} command to change the machine type of a codespace. To use this command, you'll first need to find out the available machine types for your codespace.\n\n1. To view your list of codespaces, in a terminal, enter the following command.\n\n   ```shell\n   gh codespace list\n   ```\n\n1. Optionally, to find the current machine type for a codespace, enter the following command.\n\n   ```shell\n   gh api /user/codespaces/CODESPACE-NAME\n   ```\n\n   Replace `CODESPACE-NAME` with t", "Y2h1bmtfMV9pbmRleF85NjI=": "he permanent name of the codespace, for example `octocat-literate-space-parakeet-mld5`. The permanent names are listed under the **NAME** column in the list returned by `gh codespace list`.\n\n   If you're prompted to request the `codespace` scope, follow the instructions in the terminal.\n\n   Details for the current machine are listed under the `machine` field.\n1. To find the available machine types for a codespace, enter the following command.\n\n   ```shell\n   gh api /user/codespaces/CODESPACE-NAME/machines\n   ```\n\n   Replace `CODESPACE-NAME` with the permanent name of the codespace, for example `octocat-literate-space-parakeet-mld5`.\n1. To change the machine type for a codespace, enter the following command.\n\n   ```shell\n   gh codespace edit --machine MACHINE-TYPE-NAME\n   ```\n\n   Replace `MACHINE-TYPE-NAME` with the name of an available machine type for your codespace, for example `standardLinux32gb`.\n1. Using the arrow keys, navigate to the codespace you want to change, then press Enter.\n\n{% endcli %}\n\n{% data reusables.codespaces.about-changing-storage-size %}\n\n{% cli %}\n\n\n\nFurther reading\n\n- \"AUTOTITLE\" in the REST API documentation\n- `gh codespace edit` in the {% data variables.product.prodname_cli %} manual\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n{% endcli %}\n\n", "Y2h1bmtfMF9pbmRleF8zNzk=": "---\ntitle: Managing organization members in your enterprise\nintro: You can add or remove members from an organization in bulk.\npermissions: Enterprise owners can add or remove organization members in bulk.\nversions:\n  feature: enterprise-manage-organization-members\ntype: how_to\ntopics:\n  - Enterprise\n  - Organizations\nshortTitle: Managing organization members\nredirect_from:\n  - /admin/user-management/managing-users-in-your-enterprise/managing-organization-members-in-your-enterprise\n---\n\nEnterprise members that are added to an organization via the bulk method will not receive an email inviting them to the organization. They are added immediately as a member to the selected organizations.\n\nMembers can also be added or removed from an organization at the organization level. For more information, see {% ifversion ghec %}\"AUTOTITLE\"{% else %}\"AUTOTITLE\"{% endif %} and \"AUTOTITLE.\"\n\n{% data reusables.enterprise-accounts.access-enterprise %}\n{% data reusables.enterprise-accounts.people-tab %}\n1. Select the checkbox next to each user you want to add or remove.\n1. At the top of the member list, select the **X user(s) selected** dropdown menu, then click **Add to organizations** or **Remove from organizations**.\n\n   {% note %}\n\n   **Note:**\n   - Users will be added as organization members. If the user is already an organization member or organization owner, the privileges will not be modified.\n   - Organization owners cannot be removed from the organization via the bulk method.\n\n   {% endnote %}\n\n   !Screenshot of the list of enterprise members. A dropdown menu, labeled \"1 user selected...\", is expanded and highlighted with an orange outline.\n\n1. In the popup, select the organizations you want to add or remove the user from.\n\n    {% note %}\n\n    **Note:** You can only select organizations where you're an organization owner.\n\n    {% endnote %}\n\n1. To confirm, click **Add user** or **Remove user**.\n1. Optionally, to add or remove multiple users at the same time, select multiple checkboxes. Use the dropdown to select **Add to", "Y2h1bmtfMV9pbmRleF8zNzk=": " organizations** or **Remove from organizations**.\n\n", "Y2h1bmtfMF9pbmRleF83MTM=": "\n\nUpgrading an organization's number of paid seats\n\n{% data reusables.organizations.billing-settings %}\n{% data reusables.dotcom_billing.add-seats %}\n{% data reusables.dotcom_billing.number-of-seats %}\n{% data reusables.dotcom_billing.confirm-add-seats %}\n\nAfter you add seats, the payment method on file for the organization will be charged a pro-rated amount based on the number of seats you're adding and the amount of time left in your billing cycle.\n\n\n\nDowngrading an organization's number of paid seats to free\n\n{% data reusables.organizations.billing-settings %}\n{% data reusables.dotcom_billing.downgrade-org-to-free %}\n{% data reusables.dotcom_billing.confirm_cancel_org_plan %}\n\n", "Y2h1bmtfMF9pbmRleF8xNTY=": "\n\nAbout migrating from Azure DevOps with GitHub Actions Importer\n\nThe instructions below will guide you through configuring your environment to use {% data variables.product.prodname_actions_importer %} to migrate Azure DevOps pipelines to {% data variables.product.prodname_actions %}.\n\n\n\nPrerequisites\n\n- An Azure DevOps account or organization with projects and pipelines that you want to convert to {% data variables.product.prodname_actions %} workflows.\n- Access to create an Azure DevOps {% data variables.product.pat_generic %} for your account or organization.\n{% data reusables.actions.actions-importer-prerequisites %}\n\n\n\nLimitations\n\nThere are some limitations when migrating from Azure DevOps to {% data variables.product.prodname_actions %} with {% data variables.product.prodname_actions_importer %}:\n\n- {% data variables.product.prodname_actions_importer %} requires version 5.0 of the Azure DevOps API, available in either Azure DevOps Services or Azure DevOps Server 2019. Older versions of Azure DevOps Server are not compatible.\n- Tasks that are implicitly added to an Azure DevOps pipeline, such as checking out source code, may be added to a {% data variables.product.prodname_actions_importer %} audit as a GUID name. To find the friendly task name for a GUID, you can use the following URL: `https://dev.azure.com/:organization/_apis/distributedtask/tasks/:guid`.\n\n\n\nManual tasks\n\nCertain Azure DevOps constructs must be migrated manually from Azure DevOps into {% data variables.product.prodname_actions %} configurations. These include:\n- Organization, repository, and environment secrets\n- Service connections such as OIDC Connect, {% data variables.product.prodname_github_apps %}, and {% data variables.product.pat_generic_plural %}\n- Unknown tasks\n- Self-hosted agents\n- Environments\n- Pre-deployment approvals\n\nFor more information on manual migrations, see \"AUTOTITLE.\"\n\n\n\nUnsupported tasks\n\n{% data variables.product.prodname_actions_importer %} does not support migrating the following tasks:\n\n- Pre-deployment gat", "Y2h1bmtfMV9pbmRleF8xNTY=": "es\n- Post-deployment gates\n- Post-deployment approvals\n- Some resource triggers\n\n\n\nInstalling the {% data variables.product.prodname_actions_importer %} CLI extension\n\n{% data reusables.actions.installing-actions-importer %}\n\n\n\nConfiguring credentials\n\nThe `configure` CLI command is used to set required credentials and options for {% data variables.product.prodname_actions_importer %} when working with Azure DevOps and {% data variables.product.prodname_dotcom %}.\n\n1. Create a {% data variables.product.prodname_dotcom %} {% data variables.product.pat_v1 %}. For more information, see \"AUTOTITLE.\"\n\n   Your token must have the `workflow` scope.\n\n   After creating the token, copy it and save it in a safe location for later use.\n1. Create an Azure DevOps {% data variables.product.pat_generic %}. For more information, see Use {% data variables.product.pat_generic_plural %} in the Azure DevOps documentation. The token must have the following scopes:\n\n   - Agents Pool: `Read`\n   - Build: `Read`\n   - Code: `Read`\n   - Release: `Read`\n   - Service Connections: `Read`\n   - Task Groups: `Read`\n   - Variable Groups: `Read`\n\n   After creating the token, copy it and save it in a safe location for later use.\n1. In your terminal, run the {% data variables.product.prodname_actions_importer %} `configure` CLI command:\n\n   ```shell\n   gh actions-importer configure\n   ```\n\n   The `configure` command will prompt you for the following information:\n\n   - For \"Which CI providers are you configuring?\", use the arrow keys to select `Azure DevOps`, press Space to select it, then press Enter.\n   - For \"{% data variables.product.pat_generic_caps %} for GitHub\", enter the value of the {% data variables.product.pat_v1 %} that you created earlier, and press Enter.\n   - For \"Base url of the GitHub instance\", {% ifversion ghes or ghae %}enter the URL for your {% data variables.product.product_name %} instance, and press Enter.{% else %}press Enter to accept the default value (`https://github.com`).{% endif %}\n   - For \"{% data variables.product.pa", "Y2h1bmtfMl9pbmRleF8xNTY=": "t_generic_caps %} for Azure DevOps\", enter the value for the Azure DevOps {% data variables.product.pat_generic %} that you created earlier, and press Enter.\n   - For \"Base url of the Azure DevOps instance\", press Enter to accept the default value (`https://dev.azure.com`).\n   - For \"Azure DevOps organization name\", enter the name for your Azure DevOps organization, and press Enter.\n   - For \"Azure DevOps project name\", enter the name for your Azure DevOps project, and press Enter.\n\n   An example of the `configure` command is shown below:\n\n   ```shell\n   $ gh actions-importer configure\n   \u2714 Which CI providers are you configuring?: Azure DevOps\n   Enter the following values (leave empty to omit):\n   \u2714 {% data variables.product.pat_generic_caps %} for GitHub: ***************\n   \u2714 Base url of the GitHub instance: https://github.com\n   \u2714 {% data variables.product.pat_generic_caps %} for Azure DevOps: ***************\n   \u2714 Base url of the Azure DevOps instance: https://dev.azure.com\n   \u2714 Azure DevOps organization name: :organization\n   \u2714 Azure DevOps project name: :project\n   Environment variables successfully updated.\n   ```\n\n1. In your terminal, run the {% data variables.product.prodname_actions_importer %} `update` CLI command to connect to the {% data variables.product.prodname_registry %} {% data variables.product.prodname_container_registry %} and ensure that the container image is updated to the latest version:\n\n   ```shell\n   gh actions-importer update\n   ```\n\n   The output of the command should be similar to below:\n\n   ```shell\n   Updating ghcr.io/actions-importer/cli:latest...\n   ghcr.io/actions-importer/cli:latest up-to-date\n   ```\n\n\n\nPerform an audit of Azure DevOps\n\nYou can use the `audit` command to get a high-level view of all projects in an Azure DevOps organization.\n\nThe `audit` command performs the following steps:\n\n1. Fetches all of the projects defined in an Azure DevOps organization.\n1. Converts each pipeline to its equivalent {% data variables.product.prodname_actions %} workflow.\n1. Generates a r", "Y2h1bmtfM19pbmRleF8xNTY=": "eport that summarizes how complete and complex of a migration is possible with {% data variables.product.prodname_actions_importer %}.\n\n\n\nRunning the audit command\n\nTo perform an audit of an Azure DevOps organization, run the following command in your terminal:\n\n```shell\ngh actions-importer audit azure-devops --output-dir tmp/audit\n```\n\n\n\nInspecting the audit results\n\n{% data reusables.actions.gai-inspect-audit %}\n\n\n\nForecast potential {% data variables.product.prodname_actions %} usage\n\nYou can use the `forecast` command to forecast potential {% data variables.product.prodname_actions %} usage by computing metrics from completed pipeline runs in Azure DevOps.\n\n\n\nRunning the forecast command\n\nTo perform a forecast of potential {% data variables.product.prodname_actions %} usage, run the following command in your terminal. By default, {% data variables.product.prodname_actions_importer %} includes the previous seven days in the forecast report.\n\n```shell\ngh actions-importer forecast azure-devops --output-dir tmp/forecast_reports\n```\n\n\n\nInspecting the forecast report\n\nThe `forecast_report.md` file in the specified output directory contains the results of the forecast.\n\nListed below are some key terms that can appear in the forecast report:\n\n- The **job count** is the total number of completed jobs.\n- The **pipeline count** is the number of unique pipelines used.\n- **Execution time** describes the amount of time a runner spent on a job. This metric can be used to help plan for the cost of {% data variables.product.prodname_dotcom %}-hosted runners.\n\n  This metric is correlated to how much you should expect to spend in {% data variables.product.prodname_actions %}. This will vary depending on the hardware used for these minutes. You can use the {% data variables.product.prodname_actions %} pricing calculator to estimate the costs.\n- **Queue time** metrics describe the amount of time a job spent waiting for a runner to be available to execute it.\n- **Concurrent jobs** metrics describe the amount of jobs running at any", "Y2h1bmtfNF9pbmRleF8xNTY=": " given time. This metric can be used to define the number of runners you should configure.\n\nAdditionally, these metrics are defined for each queue of runners in Azure DevOps. This is especially useful if there is a mix of hosted or self-hosted runners, or high or low spec machines, so you can see metrics specific to different types of runners.\n\n\n\nPerform a dry-run migration\n\nYou can use the `dry-run` command to convert an Azure DevOps pipeline to an equivalent {% data variables.product.prodname_actions %} workflow. A dry run creates the output files in a specified directory, but does not open a pull request to migrate the pipeline.\n\n{% data reusables.actions.gai-custom-transformers-rec %}\n\n\n\nRunning the dry-run command for a build pipeline\n\nTo perform a dry run of migrating your Azure DevOps build pipeline to {% data variables.product.prodname_actions %}, run the following command in your terminal, replacing `pipeline_id` with the ID of the pipeline you are converting.\n\n```shell\ngh actions-importer dry-run azure-devops pipeline --pipeline-id :pipeline_id --output-dir tmp/dry-run\n```\n\nYou can view the logs of the dry run and the converted workflow files in the specified output directory.\n\n\n\nRunning the dry-run command for a release pipeline\n\nTo perform a dry run of migrating your Azure DevOps release pipeline to {% data variables.product.prodname_actions %}, run the following command in your terminal, replacing `pipeline_id` with the ID of the pipeline you are converting.\n\n```shell\ngh actions-importer dry-run azure-devops release --pipeline-id :pipeline_id --output-dir tmp/dry-run\n```\n\nYou can view the logs of the dry run and the converted workflow files in the specified output directory.\n\n\n\nPerform a production migration\n\nYou can use the `migrate` command to convert an Azure DevOps pipeline and open a pull request with the equivalent {% data variables.product.prodname_actions %} workflow.\n\n\n\nRunning the migrate command for a build pipeline\n\nTo migrate an Azure DevOps build pipeline to {% data variables.product.pr", "Y2h1bmtfNV9pbmRleF8xNTY=": "odname_actions %}, run the following command in your terminal, replacing the `target-url` value with the URL for your {% data variables.product.prodname_dotcom %} repository, and `pipeline_id` with the ID of the pipeline you are converting.\n\n```shell\ngh actions-importer migrate azure-devops pipeline --pipeline-id :pipeline_id --target-url https://github.com/octo-org/octo-repo --output-dir tmp/migrate\n```\n\nThe command's output includes the URL of the pull request that adds the converted workflow to your repository. An example of a successful output is similar to the following:\n\n```shell\n$ gh actions-importer migrate azure-devops pipeline --target-url https://github.com/octo-org/octo-repo --output-dir tmp/migrate --azure-devops-project my-azure-devops-project\n[2022-08-20 22:08:20] Logs: 'tmp/migrate/log/actions-importer-20220916-014033.log'\n[2022-08-20 22:08:20] Pull request: 'https://github.com/octo-org/octo-repo/pull/1'\n```\n\n\n\nRunning the migrate command for a release pipeline\n\nTo migrate an Azure DevOps release pipeline to {% data variables.product.prodname_actions %}, run the following command in your terminal, replacing the `target-url` value with the URL for your {% data variables.product.prodname_dotcom %} repository, and `pipeline_id` with the ID of the pipeline you are converting.\n\n```shell\ngh actions-importer migrate azure-devops release --pipeline-id :pipeline_id --target-url https://github.com/octo-org/octo-repo --output-dir tmp/migrate\n```\n\nThe command's output includes the URL of the pull request that adds the converted workflow to your repository. An example of a successful output is similar to the following:\n\n```shell\n$ gh actions-importer migrate azure-devops release --target-url https://github.com/octo-org/octo-repo --output-dir tmp/migrate --azure-devops-project my-azure-devops-project\n[2022-08-20 22:08:20] Logs: 'tmp/migrate/log/actions-importer-20220916-014033.log'\n[2022-08-20 22:08:20] Pull request: 'https://github.com/octo-org/octo-repo/pull/1'\n```\n\n{% data reusables.actions.gai-inspect-pull-", "Y2h1bmtfNl9pbmRleF8xNTY=": "request %}\n\n\n\nReference\n\nThis section contains reference information on environment variables, optional arguments, and supported syntax when using {% data variables.product.prodname_actions_importer %} to migrate from Azure DevOps.\n\n\n\nConfiguration environment variables\n\n{% data reusables.actions.gai-config-environment-variables %}\n\n{% data variables.product.prodname_actions_importer %} uses the following environment variables to connect to your Azure DevOps instance:\n\n- `GITHUB_ACCESS_TOKEN`: The {% data variables.product.pat_v1 %} used to create pull requests with a converted workflow (requires the `workflow` scope).\n- `GITHUB_INSTANCE_URL`: The URL to the target {% data variables.product.prodname_dotcom %} instance (for example, `https://github.com`).\n- `AZURE_DEVOPS_ACCESS_TOKEN`: The {% data variables.product.pat_generic %} used to authenticate with your Azure DevOps instance. This token requires the following scopes:\n  - Build: `Read`\n  - Agent Pools: `Read`\n  - Code: `Read`\n  - Release: `Read`\n  - Service Connections: `Read`\n  - Task Groups: `Read`\n  - Variable Groups: `Read`\n- `AZURE_DEVOPS_PROJECT`: The project name or GUID to use when migrating a pipeline. If you'd like to perform an audit on all projects, this is optional.\n- `AZURE_DEVOPS_ORGANIZATION`: The organization name of your Azure DevOps instance.\n- `AZURE_DEVOPS_INSTANCE_URL`: The URL to the Azure DevOps instance, such as `https://dev.azure.com`.\n\nThese environment variables can be specified in a `.env.local` file that is loaded by {% data variables.product.prodname_actions_importer %} when it is run.\n\n\n\nOptional arguments\n\n{% data reusables.actions.gai-optional-arguments-intro %}\n\n\n\n`--source-file-path`\n\nYou can use the `--source-file-path` argument with the `forecast`, `dry-run`, or `migrate` subcommands.\n\nBy default, {% data variables.product.prodname_actions_importer %} fetches pipeline contents from source control. The `--source-file-path` argument tells {% data variables.product.prodname_actions_importer %} to use the specified source fi", "Y2h1bmtfN19pbmRleF8xNTY=": "le path instead.\n\nFor example:\n\n```shell\ngh actions-importer dry-run azure-devops pipeline --output-dir ./output/ --source-file-path ./path/to/azure_devops/pipeline.yml\n```\n\n\n\n`--config-file-path`\n\nYou can use the `--config-file-path` argument with the `audit`, `dry-run`, and `migrate` subcommands.\n\nBy default, {% data variables.product.prodname_actions_importer %} fetches pipeline contents from source control. The `--config-file-path` argument tells {% data variables.product.prodname_actions_importer %} to use the specified source files instead.\n\nThe `--config-file-path` argument can also be used to specify which repository a converted reusable workflow or composite action should be migrated to.\n\n\n\nAudit example\n\nIn this example, {% data variables.product.prodname_actions_importer %} uses the specified YAML configuration file as the source file to perform an audit.\n\n```shell\ngh actions-importer audit azure-devops pipeline --output-dir ./output/ --config-file-path ./path/to/azure_devops/config.yml\n```\n\nTo audit an Azure DevOps instance using a configuration file, the configuration file must be in the following format and each `repository_slug` must be unique:\n\n```yaml\nsource_files:\n  - repository_slug: azdo-project/1\n    path: file.yml\n  - repository_slug: azdo-project/2\n    paths: path.yml\n```\n\nYou can generate the `repository_slug` for a pipeline by combining the Azure DevOps organization name, project name, and the pipeline ID. For example, `my-organization-name/my-project-name/42`.\n\n\n\nDry run example\n\nIn this example, {% data variables.product.prodname_actions_importer %} uses the specified YAML configuration file as the source file to perform a dry run.\n\nThe pipeline is selected by matching the `repository_slug` in the configuration file to the value of the `--azure-devops-organization` and `--azure-devops-project` option. The `path` is then used to pull the specified source file.\n\n```shell\ngh actions-importer dry-run azure-devops pipeline --output-dir ./output/ --config-file-path ./path/to/azure_devops/conf", "Y2h1bmtfOF9pbmRleF8xNTY=": "ig.yml \n```\n\n\n\nSpecify the repository of converted reusable workflows and composite actions\n\n{% data variables.product.prodname_actions_importer %} uses the YAML file provided to the `--config-file-path` argument to determine the repository that converted reusable workflows and composite actions are migrated to.\n\nTo begin, you should run an audit without the `--config-file-path` argument:\n\n```shell\ngh actions-importer audit azure-devops --output-dir ./output/\n```\n\nThe output of this command will contain a file named `config.yml` that contains a list of all the reusable workflows and composite actions that were converted by {% data variables.product.prodname_actions_importer %}. For example, the `config.yml` file may have the following contents:\n\n```yaml\nreusable_workflows:\n  - name: my-reusable-workflow.yml\n    target_url: https://github.com/octo-org/octo-repo\n    ref: main\n\ncomposite_actions:\n  - name: my-composite-action.yml\n    target_url: https://github.com/octo-org/octo-repo\n    ref: main\n```\n\nYou can use this file to specify which repository and ref a reusable workflow or composite action should be added to. You can then use the `--config-file-path` argument to provide the `config.yml` file to {% data variables.product.prodname_actions_importer %}. For example, you can use this file when running a `migrate` command to open a pull request for each unique repository defined in the config file:\n\n```shell\ngh actions-importer migrate azure-devops pipeline  --config-file-path config.yml --target-url https://github.com/my-org/my-repo\n```\n\n\n\nSupported syntax for Azure DevOps pipelines\n\nThe following table shows the type of properties that {% data variables.product.prodname_actions_importer %} is currently able to convert.\n\n| Azure Pipelines       | {% data variables.product.prodname_actions %}                        |              Status |\n| :-------------------- | :------------------------------------ | :------------------ |\n| condition             | `jobs..if``jobs..steps[*].if` |           Supported |\n| containe", "Y2h1bmtfOV9pbmRleF8xNTY=": "r             | `jobs..container``jobs..name`                  |           Supported |\n| continuousIntegration | `on..``on..``on..paths` |           Supported |\n| job                   | `jobs.` |           Supported |\n| pullRequest           | `on..``on..paths` |           Supported |\n| stage                 | `jobs` |           Supported |\n| steps                 | `jobs..steps` |           Supported |\n| strategy              | `jobs..strategy.fail-fast``jobs..strategy.max-parallel``jobs..strategy.matrix`       |           Supported |\n| timeoutInMinutes      | `jobs..timeout-minutes` |           Supported |\n| variables             | `env``jobs..env``jobs..steps.env` |           Supported |\n| manual deployment     | `jobs..environment` | Partially supported |\n| pool                  | `runners``self hosted runners` | Partially supported |\n| services              | `jobs..services` | Partially supported |\n| strategy              | `jobs..strategy` | Partially supported |\n| triggers              | `on`                        | Partially supported |\n| pullRequest           | `on..`  |         Unsupported |\n| schedules             | `on.schedule``on.workflow_run` |         Unsupported |\n| triggers              | `on..types`     |         Unsupported |\n\nFor more information about supported Azure DevOps tasks, see the `github/gh-actions-importer` repository.\n\n\n\nEnvironment variable mapping\n\n{% data variables.product.prodname_actions_importer %} uses the mapping in the table below to convert default Azure DevOps environment variables to the closest equivalent in {% data variables.product.prodname_actions %}.\n\n| Azure Pipelines                             | {% data variables.product.prodname_actions %}                                      |\n| :------------------------------------------ | :-------------------------------------------------- |\n| {% raw %}`$(Agent.BuildDirectory)`{% endraw %}                   | {% raw %}`${{ runner.workspace }}`{% endraw %}                           |\n| {% raw %}`$(Agent.HomeDirectory)`{% ", "Y2h1bmtfMTBfaW5kZXhfMTU2": "endraw %}                    | {% raw %}`${{ env.HOME }}`{% endraw %}                                   |\n| {% raw %}`$(Agent.JobName)`{% endraw %}                          | {% raw %}`${{ github.job }}`{% endraw %}                                 |\n| {% raw %}`$(Agent.OS)`{% endraw %}                               | {% raw %}`${{ runner.os }}`{% endraw %}                                  |\n| {% raw %}`$(Agent.ReleaseDirectory)`{% endraw %}                 | {% raw %}`${{ github.workspace}}`{% endraw %}                            |\n| {% raw %}`$(Agent.RootDirectory)`{% endraw %}                    | {% raw %}`${{ github.workspace }}`{% endraw %}                           |\n| {% raw %}`$(Agent.ToolsDirectory)`{% endraw %}                   | {% raw %}`${{ runner.tool_cache }}`{% endraw %}                          |\n| {% raw %}`$(Agent.WorkFolder)`{% endraw %}                       | {% raw %}`${{ github.workspace }}`{% endraw %}                           |\n| {% raw %}`$(Build.ArtifactStagingDirectory)`{% endraw %}         | {% raw %}`${{ runner.temp }}`{% endraw %}                                |\n| {% raw %}`$(Build.BinariesDirectory)`{% endraw %}                | {% raw %}`${{ github.workspace }}`{% endraw %}                           |\n| {% raw %}`$(Build.BuildId)`{% endraw %}                          | {% raw %}`${{ github.run_id }}`{% endraw %}                              |\n| {% raw %}`$(Build.BuildNumber)`{% endraw %}                      | {% raw %}`${{ github.run_number }}`{% endraw %}                          |\n| {% raw %}`$(Build.DefinitionId)`{% endraw %}                     | {% raw %}`${{ github.workflow }}`{% endraw %}                            |\n| {% raw %}`$(Build.DefinitionName)`{% endraw %}                   | {% raw %}`${{ github.workflow }}`{% endraw %}                            |\n| {% raw %}`$(Build.PullRequest.TargetBranch)`{% endraw %}         | {% raw %}`${{ github.base_ref }}`{% endraw %}                            |\n| {% raw %}`$(Build.PullRequest.TargetBranch.Name)`{% endraw %}    | {", "Y2h1bmtfMTFfaW5kZXhfMTU2": "% raw %}`${{ github.base_ref }}`{% endraw %}                            |\n| {% raw %}`$(Build.QueuedBy)`{% endraw %}                         | {% raw %}`${{ github.actor }}`{% endraw %}                               |\n| {% raw %}`$(Build.Reason)`{% endraw %}                           | {% raw %}`${{ github.event_name }}`{% endraw %}                          |\n| {% raw %}`$(Build.Repository.LocalPath)`{% endraw %}             | {% raw %}`${{ github.workspace }}`{% endraw %}                           |\n| {% raw %}`$(Build.Repository.Name)`{% endraw %}                  | {% raw %}`${{ github.repository }}`{% endraw %}                          |\n| {% raw %}`$(Build.Repository.Provider)`{% endraw %}              | {% raw %}`GitHub`{% endraw %}                                            |\n| {% raw %}`$(Build.Repository.Uri)`{% endraw %}                   | {% raw %}`${{ github.server.url }}/${{ github.repository }}`{% endraw %} |\n| {% raw %}`$(Build.RequestedFor)`{% endraw %}                     | {% raw %}`${{ github.actor }}`{% endraw %}                               |\n| {% raw %}`$(Build.SourceBranch)`{% endraw %}                     | {% raw %}`${{ github.ref }}`{% endraw %}                                 |\n| {% raw %}`$(Build.SourceBranchName)`{% endraw %}                 | {% raw %}`${{ github.ref }}`{% endraw %}                                 |\n| {% raw %}`$(Build.SourceVersion)`{% endraw %}                    | {% raw %}`${{ github.sha }}`{% endraw %}                                 |\n| {% raw %}`$(Build.SourcesDirectory)`{% endraw %}                 | {% raw %}`${{ github.workspace }}`{% endraw %}                           |\n| {% raw %}`$(Build.StagingDirectory)`{% endraw %}                 | {% raw %}`${{ runner.temp }}`{% endraw %}                                |\n| {% raw %}`$(Pipeline.Workspace)`{% endraw %}                     | {% raw %}`${{ runner.workspace }}`{% endraw %}                           |\n| {% raw %}`$(Release.DefinitionEnvironmentId)`{% endraw %}        | {% raw %}`${{ github.job }}`{% en", "Y2h1bmtfMTJfaW5kZXhfMTU2": "draw %}                                 |\n| {% raw %}`$(Release.DefinitionId)`{% endraw %}                   | {% raw %}`${{ github.workflow }}`{% endraw %}                            |\n| {% raw %}`$(Release.DefinitionName)`{% endraw %}                 | {% raw %}`${{ github.workflow }}`{% endraw %}                            |\n| {% raw %}`$(Release.Deployment.RequestedFor)`{% endraw %}        | {% raw %}`${{ github.actor }}`{% endraw %}                               |\n| {% raw %}`$(Release.DeploymentID)`{% endraw %}                   | {% raw %}`${{ github.run_id }}`{% endraw %}                              |\n| {% raw %}`$(Release.EnvironmentId)`{% endraw %}                 | {% raw %}`${{ github.job }}`{% endraw %}                                 |\n| {% raw %}`$(Release.EnvironmentName)`{% endraw %}                | {% raw %}`${{ github.job }}`{% endraw %}                                 |\n| {% raw %}`$(Release.Reason)`{% endraw %}                        | {% raw %}`${{ github.event_name }}`{% endraw %}                          |\n| {% raw %}`$(Release.RequestedFor)`{% endraw %}                  | {% raw %}`${{ github.actor }}`{% endraw %}                               |\n| {% raw %}`$(System.ArtifactsDirectory)`{% endraw %}              | {% raw %}`${{ github.workspace }}`{% endraw %}                           |\n| {% raw %}`$(System.DefaultWorkingDirectory)`{% endraw %}         | {% raw %}`${{ github.workspace }}`{% endraw %}                           |\n| {% raw %}`$(System.HostType)`{% endraw %}                        | {% raw %}`build`{% endraw %}                                             |\n| {% raw %}`$(System.JobId)`{% endraw %}                           | {% raw %}`${{ github.job }}`{% endraw %}                                 |\n| {% raw %}`$(System.JobName)`{% endraw %}                         | {% raw %}`${{ github.job }}`{% endraw %}                                 |\n| {% raw %}`$(System.PullRequest.PullRequestId)`{% endraw %}       | {% raw %}`${{ github.event.number }}`{% endraw %}                   ", "Y2h1bmtfMTNfaW5kZXhfMTU2": "     |\n| {% raw %}`$(System.PullRequest.PullRequestNumber)`{% endraw %}   | {% raw %}`${{ github.event.number }}`{% endraw %}                        |\n| {% raw %}`$(System.PullRequest.SourceBranch)`{% endraw %}        | {% raw %}`${{ github.ref }}`{% endraw %}                                 |\n| {% raw %}`$(System.PullRequest.SourceRepositoryUri)`{% endraw %} | {% raw %}`${{ github.server.url }}/${{ github.repository }}`{% endraw %} |\n| {% raw %}`$(System.PullRequest.TargetBranch)`{% endraw %}        | {% raw %}`${{ github.event.base.ref }}`{% endraw %}                      |\n| {% raw %}`$(System.PullRequest.TargetBranchName)`{% endraw %}    | {% raw %}`${{ github.event.base.ref }}`{% endraw %}                      |\n| {% raw %}`$(System.StageAttempt)`{% endraw %}                    | {% raw %}`${{ github.run_number }}`{% endraw %}                          |\n| {% raw %}`$(System.TeamFoundationCollectionUri)`{% endraw %}     | {% raw %}`${{ github.server.url }}/${{ github.repository }}`{% endraw %} |\n| {% raw %}`$(System.WorkFolder)`{% endraw %}                      | {% raw %}`${{ github.workspace }}`{% endraw %}                           |\n\n\n\nTemplates\n\nYou can transform Azure DevOps templates with {% data variables.product.prodname_actions_importer %}.\n\n\n\nLimitations\n\n{% data variables.product.prodname_actions_importer %} is able to transform Azure DevOps templates with some limitations.\n\n- Azure DevOps templates used under the `stages`, `deployments`, and `jobs` keys are converted into reusable workflows in {% data variables.product.prodname_actions %}. For more information, see \"AUTOTITLE.\"\n- Azure DevOps templates used under the `steps` key are converted into composite actions. For more information, see \"AUTOTITLE.\"\n- If you currently have job templates that reference other job templates, {% data variables.product.prodname_actions_importer %} converts the templates into reusable workflows. Because reusable workflows cannot reference other reusable workflows, this is invalid syntax in {% data variables.produc", "Y2h1bmtfMTRfaW5kZXhfMTU2": "t.prodname_actions %}. You must manually correct nested reusable workflows.\n- If a template references an external Azure DevOps organization or {% data variables.product.prodname_dotcom %} repository, you must use the `--credentials-file` option to provide credentials to access this template. For more information, see \"AUTOTITLE.\"\n- You can dynamically generate YAML using `each` expressions with the following caveats:\n  - Nested `each` blocks are not supported and cause the parent `each` block to be unsupported.\n  - `each` and contained `if` conditions are evaluated at transformation time, because {% data variables.product.prodname_actions %} does not support this style of insertion.\n  - `elseif` blocks are unsupported. If this functionality is required, you must manually correct them.\n  - Nested `if` blocks are supported, but `if/elseif/else` blocks nested under an `if` condition are not.\n  - `if` blocks that use predefined Azure DevOps variables are not supported.\n\n\n\nSupported templates\n\n{% data variables.product.prodname_actions_importer %} supports the templates listed in the table below.\n\n| Azure Pipelines               | {% data variables.product.prodname_actions %}                        |              Status |\n| :---------------------------- | :------------------------------------ | ------------------: |\n| Extending from a template     | `Reusable workflow`                   |           Supported |\n| Job templates                 | `Reusable workflow`                   |           Supported |\n| Stage templates               | `Reusable workflow`                   |           Supported |\n| Step templates                | `Composite action`                    |           Supported |\n| Task groups in classic editor | Varies                                |           Supported |\n| Templates in a different Azure DevOps organization, project, or repository    | Varies                              |           Supported |\n| Templates in a {% data variables.product.prodname_dotcom %} repository | Varies           ", "Y2h1bmtfMTVfaW5kZXhfMTU2": "                   |           Supported |\n| Variable templates            | `env`                                 |           Supported |\n| Conditional insertion         | `if` conditions on job/steps          | Partially supported |\n| Iterative insertion           | Not applicable                        | Partially supported |\n| Templates with parameters     | Varies                                | Partially supported |\n\n\n\nTemplate file path names\n\n{% data variables.product.prodname_actions_importer %} can extract templates with relative or dynamic file paths with variable, parameter, and iterative expressions in the file name. However, there must be a default value set.\n\n\n\nVariable file path name example\n\n```yaml\n\n\nFile: azure-pipelines.yml\nvariables:\n- template: 'templates/vars.yml'\n\nsteps:\n- template: \"./templates/${{ variables.one }}\"\n```\n\n```yaml\n\n\nFile: templates/vars.yml\nvariables:\n  one: 'simple_step.yml'\n```\n\n\n\nParameter file path name example\n\n```yaml\nparameters:\n- name: template\n  type: string \n  default: simple_step.yml\n\nsteps:\n- template: \"./templates/{% raw %}${{ parameters.template }}{% endraw %}\"\n```\n\n\n\nIterative file path name example\n\n```yaml\nparameters:\n- name: steps\n  type: object\n  default:\n  - build_step\n  - release_step\nsteps: \n- {% raw %}${{ each step in parameters.steps }}{% endraw %}:\n    - template: \"${{ step }}-variables.yml\"\n```\n\n\n\nTemplate parameters\n\n{% data variables.product.prodname_actions_importer %} supports the parameters listed in the table below.\n\n| Azure Pipelines       | {% data variables.product.prodname_actions %}                              |              Status   |\n| :-------------------- | :-----------------------------------------  | :-------------------  |\n| string                | `inputs.string`                             |           Supported   |\n| number                | `inputs.number`                             |           Supported   |\n| boolean               | `inputs.boolean`                            |           Supported   |\n| object               ", "Y2h1bmtfMTZfaW5kZXhfMTU2": " | `inputs.string` with `fromJSON` expression  | Partially supported   |\n| step                  | `step`                                      | Partially supported  |\n| stepList              | `step`                                      | Partially supported  |\n| job                   | `job`                                       | Partially supported |\n| jobList               | `job`                                       | Partially supported |\n| deployment            | `job`                                       | Partially supported |\n| deploymentList        | `job`                                       | Partially supported |\n| stage                 | `job`                                       | Partially supported |\n| stageList             | `job`                                       | Partially supported |\n\n{% note %}\n\n**Note:** A template used under the `step` key with this parameter type is only serialized as a composite action if the steps are used at the beginning or end of the template steps. A template used under the `stage`, `deployment`, and `job` keys with this parameter type are not transformed into a reusable workflow, and instead are serialized as a standalone workflow.\n\n{% endnote %}\n\n\n\nLegal notice\n\n{% data reusables.actions.actions-importer-legal-notice %}\n\n", "Y2h1bmtfMF9pbmRleF85Njk=": "\n\nOverview\n\n{% data reusables.codespaces.automatic-deletion %} For more information, see \"AUTOTITLE.\"\n\nYou can manually delete a codespace in a variety of ways:\n- In the terminal by using {% data variables.product.prodname_cli %}\n- In {% data variables.product.prodname_vscode %}\n- In your web browser\n\nUse the tabs at the top of this article to display instructions for each of these ways of deleting a codespace.\n\n{% note %}\n\n**Note**: You can't delete a codespace from within the JetBrains Gateway, or the JetBrains client application, or from within JupyterLab.\n\n{% endnote %}\n\n\n\nWhy you should delete unused codespaces\n\nThere are costs associated with storing codespaces. You should therefore delete any codespaces you no longer need. For more information, see \"AUTOTITLE.\"\n\n{% data reusables.codespaces.max-number-codespaces %}\n\n\n\nDeleting a codespace\n\n{% webui %}\n\n{% data reusables.codespaces.your-codespaces-procedure-step %}\n1. To the right of the codespace you want to delete, click {% octicon \"kebab-horizontal\" aria-label=\"Codespace configuration\" %}, then click **{% octicon \"trash\" aria-hidden=\"true\" %} Delete**.\n\n   !Screenshot of a list of codespaces with the dropdown menu for one of them displayed, showing the \"Delete\" option.\n\n{% endwebui %}\n\n{% note %}\n\n**Note**: You may have prebuild codespaces that are consuming additional storage which are not displayed on this dashboard. To delete them, follow the steps for \u201cDeleting a prebuild configuration.\u201d\n\n{% endnote %}\n\n{% vscode %}\n\n{% data reusables.codespaces.deleting-a-codespace-in-vscode %}\n\n{% endvscode %}\n\n{% cli %}\n\n{% data reusables.cli.cli-learn-more %}\n\nTo delete a codespace use the `gh codespace delete` subcommand and then choose a codespace from the list that's displayed.\n\n```shell\ngh codespace delete\n```\n\nIf you have unsaved changes, you'll be prompted to confirm deletion. You can use the `--force` flag to force deletion, avoiding this prompt.\n\nFor more information about this command, see the {% data variables.product.prodname_cli %} manual.\n\n{% endcli ", "Y2h1bmtfMV9pbmRleF85Njk=": "%}\n\n\n\nBulk deleting codespaces\n\n{% webui %}\n\nYou can use {% data variables.product.prodname_cli %} to delete several or all of your codespaces with a single command. For more information, click the \"{% data variables.product.prodname_cli %}\" tab near the top of this page.\n\n{% endwebui %}\n\n{% vscode %}\n\nYou can use {% data variables.product.prodname_cli %} to delete several or all of your codespaces with a single command. For more information, click the \"{% data variables.product.prodname_cli %}\" tab near the top of this page.\n\n{% endvscode %}\n\n{% cli %}\n\nYou can delete several or all of your codespaces with a single command, using `gh codespace delete` followed by one of these flags:\n\n`--all` - Delete all of your codespaces.\n\n`--repo REPOSITORY` - Delete all of your codespaces for this repository. Or use together with the `--days` flag to filter by age of the codespace.\n\n`--days NUMBER` - Delete all of your codespaces that are older than the specified number of days. Can be used together with the `--repo` flag.\n\nBy default you are prompted to confirm deletion of any codespaces that contain unsaved changes. You can use the `--force` flag to skip this confirmation.\n\n\n\nExample\n\nDelete all of the codespaces for the `octo-org/octo-repo` repository that you created more than 7 days ago.\n\n```shell\ngh codespace delete --repo octo-org/octo-repo --days 7\n```\n\n{% endcli %}\n\n\n\nDeleting codespaces in your organization\n\nAs an organization owner, you can use {% data variables.product.prodname_cli %} to delete any codespace in your organization.\n\n{% webui %}\n\nFor more information, click the \"{% data variables.product.prodname_cli %}\" tab near the top of this page.\n\n{% endwebui %}\n\n{% vscode %}\n\nFor more information, click the \"{% data variables.product.prodname_cli %}\" tab near the top of this page.\n\n{% endvscode %}\n\n{% cli %}\n\n1. Enter one of these commands to display a list of codespaces.\n   - `gh codespace delete --org ORGANIZATION` - Lists the current codespaces in the specified organization.\n   - `gh codespace delete --org ", "Y2h1bmtfMl9pbmRleF85Njk=": "ORGANIZATION --user USER` - Lists only those codespaces created by the specified user.\n   You must be an owner of the specified organization.\n1. In the list of codespaces, navigate to the codespace you want to delete.\n1. To delete the selected codespace press Enter.\n\n   If the codespace contains unsaved changes you will be prompted to confirm deletion.\n\n{% endcli %}\n\nYou can also use the REST API to delete codespaces for your organization. For more information, see \"AUTOTITLE.\"\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF81": "\n\nAbout your inbox\n\n{% ifversion fpt or ghes or ghec %}\n{% data reusables.notifications-v2.notifications-inbox-required-setting %} For more information, see \"AUTOTITLE.\"\n{% endif %}\n\nTo access your notifications inbox, in the upper-right corner of any page, click {% octicon \"bell\" aria-label=\"The notifications bell\" %}.\n\nYour inbox shows all of the notifications that you haven't unsubscribed to or marked as **Done.** You can customize your inbox to best suit your workflow using filters, viewing all or just unread notifications, and grouping your notifications to get a quick overview.\n\nBy default, your inbox will show read and unread notifications. To only see unread notifications, click **Unread** or use the `is:unread` query.\n\n\n\nTriaging options\n\nYou have several options for triaging notifications from your inbox.\n\n| Triaging option | Description |\n|-----------------|-------------|\n| Save            | Saves your notification for later review. To save a notification, to the right of the notification, click {% octicon \"bookmark\" aria-label=\"Save\" %}.   Saved notifications are kept indefinitely and can be viewed by clicking **Saved** in the sidebar or with the `is:saved` query. If your saved notification is older than 5 months and becomes unsaved, the notification will disappear from your inbox within a day. |\n| Done            | Marks a notification as completed and removes the notification from your inbox. You can see all completed notifications by clicking **Done** in the sidebar or with the `is:done` query. Notifications marked as **Done** are saved for 5 months.\n| Unsubscribe     | Automatically removes the notification from your inbox and unsubscribes you from the conversation until you are @mentioned, a team you're on is @mentioned, or you're requested for review.\n| Read            | Marks a notification as read. To only view read notifications in your inbox, use the `is:read` query. This query doesn't include notifications marked as **Done**.\n| Unread          | Marks notification as unread. To only view un", "Y2h1bmtfMV9pbmRleF81": "read notifications in your inbox, use the `is:unread` query. |\n\nTo see the available keyboard shortcuts, see \"AUTOTITLE.\"\n\nBefore choosing a triage option, you can preview your notification's details first and investigate. For more information, see \"AUTOTITLE.\"\n\n\n\nTriaging multiple notifications at the same time\n\nTo triage multiple notifications at once, select the relevant notifications and use the {% octicon \"kebab-horizontal\" aria-label=\"More options\" %} drop-down to choose a triage option.\n\n!Screenshot of the \"Notifications\" page. A drop-down menu is highlighted with an orange outline.\n\n\n\nDefault notification filters\n\nBy default, your inbox has filters for when you are assigned, participating in a thread, requested to review a pull request, or when your username is @mentioned directly or a team you're a member of is @mentioned.\n\n\n\nCustomizing your inbox with custom filters\n\nYou can add up to 15 of your own custom filters.\n\n{% data reusables.notifications.access_notifications %}\n1. To open the filter settings, in the left sidebar, next to \"Filters\", click {% octicon \"gear\" aria-label=\"Customize filters\" %}.\n\n   {% tip %}\n\n   **Tip:** You can quickly preview a filter's inbox results by creating a query in your inbox view and clicking **Save**, which opens the custom filter settings.\n\n   {% endtip %}\n\n1. Add a name for your filter and a filter query. For example, to only see notifications for a specific repository, you can create a filter using the query `repo:octocat/open-source-project-name reason:participating`. You can also add emojis with a native emoji keyboard. For a list of supported search queries, see \"Supported queries for custom filters.\"\n\n   !Screenshot showing notification filters. Two input fields, with an example name and filter query filled in, are highlighted with an orange outline.\n\n1. Click **Create**.\n\n\n\nCustom filter limitations\n\nCustom filters do not currently support:\n- Full text search in your inbox, including searching for pull request or issue titles.\n- Distinguishing between the `is:i", "Y2h1bmtfMl9pbmRleF81": "ssue`, `is:pr`, and `is:pull-request` query filters. These queries will return both issues and pull requests.\n- Creating more than 15 custom filters.\n- Changing the default filters or their order.\n- Search exclusion using `NOT` or `-QUALIFIER`.\n\n\n\nSupported queries for custom filters\n\nThese are the types of filters that you can use:\n- Filter by repository with `repo:`\n- Filter by discussion type with `is:`\n- Filter by notification reason with `reason:`{% ifversion fpt or ghec %}\n- Filter by notification author with `author:`\n- Filter by organization with `org:`{% endif %}\n\n\n\nSupported `repo:` queries\n\nTo add a `repo:` filter, you must include the owner of the repository in the query: `repo:owner/repository`. An owner is the organization or the user who owns the {% data variables.product.prodname_dotcom %} asset that triggers the notification. For example, `repo:octo-org/octo-repo` will show notifications triggered in the octo-repo repository within the octo-org organization.\n\n\n\nSupported `is:` queries\n\nTo filter notifications for specific activity on {% data variables.location.product_location %}, you can use the  `is` query. For example, to only see repository invitation updates, use `is:repository-invitation`{% ifversion not ghae %}, and to only see {% data variables.product.prodname_dependabot_alerts %}, use `is:repository-vulnerability-alert`{% endif %}.\n\n- `is:check-suite`\n- `is:commit`\n- `is:gist`\n- `is:issue-or-pull-request`\n- `is:release`\n- `is:repository-invitation`\n- `is:repository-vulnerability-alert`{% ifversion fpt or ghec %}\n- `is:repository-advisory`{% endif %}{% ifversion team-discussions %}\n- `is:team-discussion`{% endif %}{% ifversion fpt or ghec %}\n- `is:discussion`{% endif %}\n\nFor information about reducing noise from notifications for {% data variables.product.prodname_dependabot_alerts %}, see \"AUTOTITLE.\"\n\nYou can also use the `is:` query to describe how the notification was triaged.\n\n- `is:saved`\n- `is:done`\n- `is:unread`\n- `is:read`\n\n\n\nSupported `reason:` queries\n\nTo filter notifications ", "Y2h1bmtfM19pbmRleF81": "by why you've received an update, you can use the `reason:` query. For example, to see notifications when you (or a team you're on) is requested to review a pull request, use `reason:review-requested`. For more information, see \"AUTOTITLE.\"\n\n| Query | Description |\n|-----------------|-------------|\n| `reason:assign` | When there's an update on an issue or pull request you've been assigned to.\n| `reason:author` | When you opened a pull request or issue and there has been an update or new comment.\n| `reason:comment`| When you commented on an issue{% ifversion team-discussions %}, pull request, or team discussion{% else %} or pull request{% endif %}.\n| `reason:participating` | When you have commented on an issue{% ifversion team-discussions %}, pull request, or team discussion{% else %} or pull request{% endif %} or you have been @mentioned.\n| `reason:invitation` | When you're invited to a team, organization, or repository.\n| `reason:manual` | When you click **Subscribe** on an issue or pull request you weren't already subscribed to.\n| `reason:mention` | You were directly @mentioned.\n| `reason:review-requested` | You or a team you're on have been requested to review a pull request.\n| `reason:security-alert` | When a security alert is issued for a repository.\n| `reason:state-change`  | When the state of a pull request or issue is changed. For example, an issue is closed or a pull request is merged.\n| `reason:team-mention` | When a team you're a member of is @mentioned.\n| `reason:ci-activity` | When a repository has a CI update, such as a new workflow run status.\n\n{% ifversion fpt or ghec %}\n\n\n\nSupported `author:` queries\n\nTo filter notifications by user, you can use the `author:` query. An author is the original author of the thread (issue, pull request, gist, discussions, and so on) for which you are being notified. For example, to see notifications for threads created by the Octocat user, use `author:octocat`.\n\n\n\nSupported `org:` queries\n\nTo filter notifications by organization, you can use the  `org` query. The or", "Y2h1bmtfNF9pbmRleF81": "ganization you need to specify in the query is the organization of the repository for which you are being notified on {% data variables.product.prodname_dotcom %}. This query is useful if you belong to several organizations, and want to see notifications for a specific organization.\n\nFor example, to see notifications from the octo-org organization, use `org:octo-org`.\n\n{% endif %}\n\n\n\n{% data variables.product.prodname_dependabot %} custom filters\n\n{% ifversion fpt or ghec or ghes %}\nIf you use {% data variables.product.prodname_dependabot %} to keep your dependencies up-to-date, you can use and save these custom filters:\n- `is:repository_vulnerability_alert` to show notifications for {% data variables.product.prodname_dependabot_alerts %}.\n- `reason:security_alert` to show notifications for {% data variables.product.prodname_dependabot_alerts %} and security update pull requests.\n- `author:app/dependabot` to show notifications generated by {% data variables.product.prodname_dependabot %}. This includes {% data variables.product.prodname_dependabot_alerts %}, security update pull requests, and version update pull requests.\n\nFor more information about {% data variables.product.prodname_dependabot %}, see \"AUTOTITLE.\"\n{% endif %}\n\n{% ifversion ghae %}\n\nIf you use {% data variables.product.prodname_dependabot %} to tell you about insecure dependencies, you can use and save these custom filters to show notifications for {% data variables.product.prodname_dependabot_alerts %}:\n- `is:repository_vulnerability_alert`\n- `reason:security_alert`\n\nFor more information about {% data variables.product.prodname_dependabot %}, see \"AUTOTITLE.\"\n{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF8xMDc4": "\n\nAdding a pull request template\n\n{% data reusables.repositories.navigate-to-repo %}\n{% data reusables.files.add-file %}\n1. In the file name field:\n    - To make your pull request template visible in the repository's root directory, name the pull request template `pull_request_template.md`.\n    - To make your pull request template visible in the repository's `docs` directory, name the pull request template `docs/pull_request_template.md`.\n    - To store your file in a hidden directory, name the pull request template `.github/pull_request_template.md`.\n    - To create multiple pull request templates and use the `template` query parameter to specify a template to fill the pull request body, type _.github/PULL_REQUEST_TEMPLATE/_, then the name of your pull request template. For example, `.github/PULL_REQUEST_TEMPLATE/pull_request_template.md`. You can also store multiple pull request templates in a `PULL_REQUEST_TEMPLATE` subdirectory within the root or `docs/` directories. For more information, see \"AUTOTITLE.\"\n1. In the body of the new file, add your pull request template. This could include:\n    - A reference to a related issue in your repository.\n    - A description of the changes proposed in the pull request.\n    - @mentions of the person or team responsible for reviewing proposed changes.\n{% data reusables.files.write_commit_message %}\n{% data reusables.files.choose_commit_branch %} Templates are available to collaborators when they are merged into the repository's default branch.\n{% data reusables.files.propose_new_file %}\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF85MjA=": "\n\nAbout privately reporting a security vulnerability\n\nPrivate vulnerability reporting makes it easy for security researchers to report vulnerabilities directly to you using a simple form.\n\nWhen a security researcher reports a vulnerability privately, you are notified and can choose to either accept it, ask more questions, or reject it. If you accept the report, you're ready to collaborate on a fix for the vulnerability in private with the security researcher.\n\n\n\nManaging security vulnerabilities that are privately reported\n\n{% data reusables.security-advisory.private-vulnerability-reporting-configure-notifications %}\n\nFor more information about configuring notification preferences, see \"AUTOTITLE.\"\n\n{% data reusables.repositories.navigate-to-repo %}\n{% data reusables.repositories.sidebar-security %}\n{% data reusables.repositories.sidebar-advisories %}\n1. Click the advisory you want to review. An advisory that was reported privately has a status of `Triage`.\n\n   !Screenshot of a \"Security Advisories\" list.\n\n1. Carefully review the report, then choose how to proceed.\n   - To collaborate on a patch in private, click **Start a temporary private fork** to create a place for further discussions with the contributor. This does not change the status of the proposed advisory from `Triage`.\n   - To accept the reported vulnerability, click **Accept and open as draft** to accept the vulnerability report as a draft advisory on {% data variables.product.prodname_dotcom %}. If you choose this option:\n      - This doesn't make the report public.\n      - The report becomes a draft repository security advisory and you can work on it in the same way as any draft advisory that you create.\n     For more information on security advisories, see \"AUTOTITLE.\"\n   - To ask for more information, or to open a discussion with the reporter, you can comment on the advisory. Any comments are visible only to the reporter and to any collaborators on the advisory.\n   - If you have enough information to determine that the problem the reporter descri", "Y2h1bmtfMV9pbmRleF85MjA=": "bes is not a security risk, click **Close security advisory**. Where possible, you should add a comment explaining why you don't consider the report a security risk before you close the advisory.\n\n     !Screenshot showing the options available to the repository maintainer when reviewing an externally submitted vulnerability report.\n\n", "Y2h1bmtfMF9pbmRleF8zMTc=": "\n\nAbout migrations between IdPs and tenants\n\nWhile using {% data variables.product.prodname_emus %}, you may need to migrate your enterprise to a new tenant on your IdP. For example, you might be ready to migrate from a test environment to your production environment.\n\n{% warning %}\n\n**{% ifversion emu-public-scim-schema %}Warnings{% else %}Warning{% endif %}**:\n\n{% ifversion emu-public-scim-schema %}-{% endif %} Migrating to a new IdP or tenant can cause disruption to integrations and automated flows in your enterprise. When your current SAML IdP is disabled, {% data variables.product.pat_generic_plural %} and SSH keys associated with {% data variables.enterprise.prodname_managed_users %} will be deleted. You should plan for a migration window after configuring your new IdP, during which you can create and deploy new keys to your integrations where necessary.\n\n{%- ifversion emu-public-scim-schema %}\n- {% data reusables.enterprise_user_management.authentication-or-provisioning-migration-not-supported %}\n{% endif %}\n\n{% endwarning %}\n\nBefore you migrate your {% data variables.enterprise.prodname_emu_enterprise %} to a new IdP or tenant, determine whether the values of the normalized SCIM `userName` attribute will remain the same for your {% data variables.enterprise.prodname_managed_users %} in the new environment. For more information about username normalization, see \"AUTOTITLE.\"\n\nIf the normalized SCIM `userName` values will remain the same after the migration, you can complete the migration by yourself. For instructions, see \"Migrating when the normalized SCIM `userName` values will remain the same.\"\n\nIf the normalized SCIM `userName` values will change after the migration, {% data variables.product.company_short %} will need to help with your migration. For more information, see \"Migrating when the normalized SCIM `userName` values will change.\"\n\n\n\nMigrating when the normalized SCIM `userName` values will remain the same\n\nTo migrate to a new IdP or tenant, you cannot edit your existing SAML configuration. Ins", "Y2h1bmtfMV9pbmRleF8zMTc=": "tead, you must completely deactivate SAML for your enterprise account, then create new SAML and SCIM configurations for the new IdP or tenant.\n\n{% warning %}\n\n**Warning:** Do not remove any users or groups from the application for {% data variables.product.prodname_emus %} in your original IdP or tenant until after your migration is complete.\n\n{% endwarning %}\n\n1. If you don't already have single sign-on recovery codes for your enterprise, download the codes now. For more information, see \"AUTOTITLE.\"\n1. In your current IdP, deactivate provisioning in the application for {% data variables.product.prodname_emus %}.\n    - If you use Azure AD, navigate to the \"Provisioning\" tab of the application, and then click **Stop provisioning**.\n    - If you use Okta, navigate to the \"Provisioning\" tab of the application, click the **Integration** tab, and then click **Edit**. Deselect **Enable API integration**.\n    - If you use PingFederate, navigate to the channel settings in the application. From the **Activation & Summary** tab, click **Active** or **Inactive** to toggle the provisioning status, and then click **Save**. For more information about managing provisioning, see \"Reviewing channel settings\" and \"Managing channels\" in the Ping Federate documentation.\n1. Use a recovery code to sign into {% data variables.product.prodname_dotcom_the_website %} as the setup user, whose username is your enterprise's shortcode suffixed with `_admin`. For more information about the setup user, see \"AUTOTITLE.\"\n1. Deactivate SAML for the {% data variables.enterprise.prodname_emu_enterprise %}. For more information, see \"AUTOTITLE.\"\n1. Wait for all users in the enterprise to show as suspended.\n1. While still signed in as the setup user, configure SAML and SCIM for the new IdP or tenant with a new {% data variables.product.prodname_emus %} application.\n\n   After you configure provisioning for the new application, the {% data variables.enterprise.prodname_managed_users %} will be unsuspended, and your developers will be able to sign into ", "Y2h1bmtfMl9pbmRleF8zMTc=": "their existing accounts again.\n\n   By default, this process can take up to 40 minutes for Azure AD. To expedite the process for an individual user, click the **Provision on Demand** button in the \"Provisioning\" tab of the application for {% data variables.product.prodname_emus %}.\n\n\n\nMigrating when the normalized SCIM `userName` values will change\n\nIf the normalized SCIM `userName` values will change, {% data variables.product.company_short %} must provision a new enterprise account for your migration. Contact our sales team for help.\n\n", "Y2h1bmtfMF9pbmRleF83NzU=": "\n\nAbout this error\n\n```text\nSARIF file is too large\nSARIF results file is too large\nSARIF upload is rejected (bigger than allowed size for zip archive)\nSARIF ZIP upload is too large\nA fatal error occurred: SARIF file is too large\n413: Payload Too Large\n```\n\nOne of these errors is reported if a process attempts to upload a SARIF file that is larger than the maximum size of 10 MB. {% data variables.product.prodname_code_scanning_caps %} does not accept files above this size. There are several different ways to reduce the number of results generated for upload to {% data variables.product.prodname_code_scanning %}.\n\nYou could see this error for SARIF files generated by {% data variables.product.prodname_codeql %} or by third-party analysis tools. For information about the limits on uploads, see {% data variables.product.prodname_code_scanning %}, see \"AUTOTITLE.\"\n\n\n\nConfirming the cause of the error\n\nThere are many potential causes of very large SARIF results files.\n\n\n\nSARIF file compression\n\nTake a look at the results file that was rejected by {% data variables.product.prodname_code_scanning %} to see if:\n\n- the SARIF file was compressed using gzip\n- the compressed file is smaller than 10 MB\n\nIf the file wasn't compressed using gzip, try compressing the file before rerunning the upload process. If the compressed file is still too large, you need to configure the analysis to generate a smaller set of results.\n\n\n\nAmount of code analyzed\n\nIf you have too many results, you should configure analysis to analyze only the most important code.\n\n   - For interpreted languages, check if the repository contains many tests, demos, or vendored dependencies where fixing alerts is a lower priority. Try excluding this code from analysis. For more information, see \"Excluding code from analysis for interpreted languages.\"\n   - For compiled languages, check if the build process generates more than one variant of the code (for example, targets for multiple operating environments or architectures). Try analyzing just one variant of the ", "Y2h1bmtfMV9pbmRleF83NzU=": "code initially. For more information, see \"Optimizing the build command.\"\n\n\n\nNumber of queries run\n\nIf you still have too many results, check how many queries you are using to analyze the code. Try running fewer queries. You can reintroduce additional queries when the initial alerts are fixed. For example, for {% data variables.product.prodname_codeql %} analysis you could run just the default suite of queries. For more information, see \"AUTOTITLE.\"\n\n\n\nNumber of results found by queries\n\nSometimes a single query reports many results because the codebase has a specific coding style, or because the analysis does not understand a particular library. You can review the results file in a SARIF viewer to see the distribution of results. For example, https://microsoft.github.io/sarif-web-component/.\n\n   - Check if the results are dominated by alerts identfied by a single query. Try excluding that query from analysis. You can reintroduce it when other alerts are fixed. For more information about {% data variables.product.prodname_codeql %} query configuration, see \"Excluding a query from analysis.\"\n   - Check if there are dataflow queries with many deep paths. Try omitting dataflow paths from the output. For more information about {% data variables.product.prodname_codeql %} analysis configuration, see \"Omitting dataflow paths from the output.\"\n\n\n\nFixing the problem\n\nThe following options are listed in order of complexity. You need to revise the configuration to reduce the number of results to a manageable size. Once you have fixed all of those alerts, you can update the configuration to expand the analysis to cover more code or run more queries.\n\n\n\nExcluding code from analysis for interpreted languages\n\nExcluding non-production code from analysis is a simple way to reduce the size of the results file.\n\n- {% data variables.product.prodname_codeql %} advanced setup for {% data variables.product.prodname_code_scanning %}: use `paths` and `paths-ignore` in the workflow file to specify what code to analyze. For more informat", "Y2h1bmtfMl9pbmRleF83NzU=": "ion, see \"AUTOTITLE.\"\n- {% data variables.product.prodname_codeql_cli %} `database create`: create a YAML configuration file for code scanning using the same syntax to define which code to analyze. Update the `database create` command to call this configuration file using the `--codescanning-config` option. For more information, see \"AUTOTITLE.\"\n\n\n\nOptimizing the build command\n\nUsing a build command that compiles only one variant is a simple way to reduce the size of the results file.\n\n- {% data variables.product.prodname_codeql %} advanced setup for {% data variables.product.prodname_code_scanning %}: update the workflow file to specify your chosen build command. For more information, see \"AUTOTITLE.\"\n- {% data variables.product.prodname_codeql_cli %} `database create`: specify your chosen build command either by calling the `database create` command with the `--command` option, or by defining the build command in a YAML configuration file for code scanning and calling the file using the `--codescanning-config` option.  For more information, see \"AUTOTITLE.\"\n\n\n\nDefining the query suite to run\n\nYou may already be running only the default security queries, but it is worth checking.\n\n- {% data variables.product.prodname_codeql %} advanced setup for {% data variables.product.prodname_code_scanning %}: check the workflow file for the `queries` keyword. If it is not present, then only the default query suite is run. If it is present, it defines which queries to run. Try commenting out this line of the workflow file. For more information, see \"AUTOTITLE.\"\n- {% data variables.product.prodname_codeql_cli %} `database analyze`: check the database analysis command for any paths that specify queries, query suites, or query packs. If none are present, then only the default query suite is run. If any are present, they define which queries to run, you can try removing them from the call. For more information, see \"AUTOTITLE.\"\n\n\n\nExcluding a query from analysis\n\nIf the results are dominated by the results for a single rule, exc", "Y2h1bmtfM19pbmRleF83NzU=": "luding the rule from the analysis may be the best solution.\n\n- {% data variables.product.prodname_codeql %} advanced setup for {% data variables.product.prodname_code_scanning %}: use the `query-filters` keyword to exclude one or more queries from analysis. For more information, see \"AUTOTITLE.\"\n- {% data variables.product.prodname_codeql_cli %} `database analyze`: update the database analysis command to exclude one or more queries from analysis. For more information, see \"AUTOTITLE.\"\n\nAlternatively, you can use a tool like the filter-sarif action to rewrite the SARIF file to exclude specific detections via an exclusion pattern.\n\n\n\nOmitting dataflow paths from the output\n\nIf there are many deep code paths highlighted in the SARIF results, you can reduce the number of paths reported for each alert.\n\n{% data reusables.code-scanning.max-paths-setting %}\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF83OTY=": "\n\nSynopsis\n\n```shell copy\ncodeql database print-baseline ... -- \n```\n\n\n\nDescription\n\n\\[Plumbing] Print a summary of the baseline lines of code seen.\n\nThis command will print to standard out the baseline lines of code seen\nwithin the source root specified at codeql database init time for each language present in the database.\n\nThe baseline is an estimate of the non-empty, non-comment lines of code\nin a database. This count is different from the lines of code counted by\nCodeQL metrics queries, which only counts code that is passed to the\nCodeQL evaluator. In some cases, the baseline count may be lower than\nthe count in metrics queries since metrics queries may include external\nfiles that are passed to the evaluator, but are not included in the\nsource root.\n\n\n\nOptions\n\n\n\nPrimary Options\n\n\n\n`<database>`\n\n\\[Mandatory] Path to the CodeQL database under construction. This must\nhave been prepared for extraction with codeql database init.\n\nIf the `--db-cluster` option is given, this is not a database itself,\nbut a directory that _contains_ databases, and all of those databases\nwill be processed together.\n\n\n\n`--[no-]db-cluster`\n\nIndicates that the directory given on the command line is not a database\nitself, but a directory that _contains_ one or more databases under\nconstruction. Those databases will be processed together.\n\n\n\nCommon options\n\n\n\n`-h, --help`\n\nShow this help text.\n\n\n\n`-J=<opt>`\n\n\\[Advanced] Give option to the JVM running the command.\n\n(Beware that options containing spaces will not be handled correctly.)\n\n\n\n`-v, --verbose`\n\nIncrementally increase the number of progress messages printed.\n\n\n\n`-q, --quiet`\n\nIncrementally decrease the number of progress messages printed.\n\n\n\n`--verbosity=<level>`\n\n\\[Advanced] Explicitly set the verbosity level to one of errors,\nwarnings, progress, progress+, progress++, progress+++. Overrides `-v`\nand `-q`.\n\n\n\n`--logdir=<dir>`\n\n\\[Advanced] Write detailed logs to one or more files in the given\ndirectory, with generated names that include timestamps and the name of\nthe running subc", "Y2h1bmtfMV9pbmRleF83OTY=": "ommand.\n\n(To write a log file with a name you have full control over, instead\ngive `--log-to-stderr` and redirect stderr as desired.)\n\n\n\n`--common-caches=<dir>`\n\n\\[Advanced] Controls the location of cached data on disk that will\npersist between several runs of the CLI, such as downloaded QL packs and\ncompiled query plans. If not set explicitly, this defaults to a\ndirectory named `.codeql` in the user's home directory; it will be\ncreated if it doesn't already exist.\n\nAvailable since `v2.15.2`.\n\n", "Y2h1bmtfMF9pbmRleF8yMDY3": "\n\nWhat personal data does Copilot Business collect?\n\nGitHub Copilot Business collects personal data from three categories of data: User Engagement Data, Prompts and Suggestions.\n\n\n\nUser engagement data\n\nUser engagement data is usage information about events generated when interacting with a code editor. These events include user edit actions (for example completions accepted and dismissed), error messages, and general usage data to identify user metrics such as latency and feature engagement. This information may include personal data, such as pseudonymous identifiers.\n\n\n\nPrompts\n\nA prompt is the collection of code and supporting contextual information that the GitHub Copilot extension sends to GitHub to generate suggestions. The extension sends a prompt when a user working on a file pauses typing, or uses a designated keyboard shortcut to request a suggestion.\n\n\n\nSuggestions\n\nA suggestion is one or more lines of proposed code and other output returned to the Copilot extension after a prompt is received and processed by the AI models that power Copilot.\n\n\n\nHow long does GitHub Copilot Business retain personal data?\n\n\n\nUser engagement data\n\nUser engagement data is retained by GitHub for 24 months.\n\n\n\nPrompts\n\nPrompts are discarded once a suggestion is returned.\n\n\n\nSuggestions\n\nSuggestions are not retained by GitHub.\n\n\n\nWhat processing role does GitHub play with respect to personal data collected by GitHub Copilot Business?\n\nFor purposes of this section, we use \u201cprocessor\" in the meaning of the EU\u2019s General Data Protection Regulation.\n\nFor enterprises using Copilot Business, GitHub acts primarily as a processor for personal data.\n\nGitHub\u2019s data protection commitments to our enterprise customers are laid out in GitHub\u2019s Data Protection Agreement (\u201cGitHub DPA\u201d). Per the GitHub DPA, GitHub acts primarily as a processor (or subprocessor to enterprise customers who are processors) whenever it processes personal data to provide Copilot. \u201cProviding\u201d Copilot includes processing activities, such as delivering functional cap", "Y2h1bmtfMV9pbmRleF8yMDY3": "abilities, troubleshooting, and making ongoing improvements.\n\nGitHub processes personal data as a controller in limited, contractually agreed circumstances including billing and account management, and to produce aggregated reports for capacity planning, product development and regulatory financial reports.\n\n\n\nHow does Copilot Business use and share personal data?\n\nPrompts and Suggestions are used only to provide the service and are not retained.\n\nUser Engagement Data is used by GitHub, and Microsoft to provide the service and to enable improvements. Such uses may include:\n- Evaluating GitHub Copilot, for example, by measuring the positive impact it has on the user\n- Fine tuning ranking and sorting algorithms and prompt crafting\n- Detecting potential abuse of GitHub Copilot or violation of Acceptable Use Policies.\n- Conducting experiments and research related to developers and their use of developer tools and services.\n\n\n\nHow can users of Copilot Business control use of their data?\n\nUser engagement data (which includes pseudonymous identifiers and general usage data), is required for the use of GitHub Copilot and will continue to be collected, processed, and shared with Microsoft when you use GitHub Copilot.\n\nFor more information on how GitHub processes and uses personal data, please see the GitHub Privacy Statement.\n\n", "Y2h1bmtfMF9pbmRleF8xODA5": "\n\nAbout navigating code on {% data variables.product.prodname_dotcom %}\n\nCode navigation helps you to read, navigate, and understand code by showing and linking definitions of a named entity corresponding to a reference to that entity, as well as references corresponding to an entity's definition.\n\n!Screenshot showing a code file with a function called \"request\" highlighted and a pop-up window with information about the function underneath. The pop-up has two tabs: \"Definition\" and \"Reference\".\n\nCode navigation uses the open source `tree-sitter` library. The following languages and navigation strategies are supported.\n\n{% rowheaders %}\n\n| Language   | Search-based code navigation | Precise code navigation |\n|:----------:|:----------------------------:|:-----------------------:|\n| C#         | {% octicon \"check\" aria-label=\"Supported\" %}                           | {% octicon \"x\" aria-label=\"Not supported\" %}                         |\n| CodeQL     | {% octicon \"check\" aria-label=\"Supported\" %}                           | {% octicon \"x\" aria-label=\"Not supported\" %}                         |\n| Elixir     | {% octicon \"check\" aria-label=\"Supported\" %}                           | {% octicon \"x\" aria-label=\"Not supported\" %}                         |\n| Go         | {% octicon \"check\" aria-label=\"Supported\" %}                           | {% octicon \"x\" aria-label=\"Not supported\" %}                         |\n| Java       | {% octicon \"check\" aria-label=\"Supported\" %}                           | {% octicon \"x\" aria-label=\"Not supported\" %}                         |\n| JavaScript | {% octicon \"check\" aria-label=\"Supported\" %}                           | {% octicon \"x\" aria-label=\"Not supported\" %}                         |\n| PHP        | {% octicon \"check\" aria-label=\"Supported\" %}                           | {% octicon \"x\" aria-label=\"Not supported\" %}                         |\n| Python     | {% octicon \"check\" aria-label=\"Supported\" %}                           | {% octicon \"check\" aria-label=\"Supported\" %}              ", "Y2h1bmtfMV9pbmRleF8xODA5": "        |\n| Ruby       | {% octicon \"check\" aria-label=\"Supported\" %}                           | {% octicon \"x\" aria-label=\"Not supported\" %}                         |\n| Rust       | {% octicon \"check\" aria-label=\"Supported\" %}                           | {% octicon \"x\" aria-label=\"Not supported\" %}                         |\n| TypeScript | {% octicon \"check\" aria-label=\"Supported\" %}                           | {% octicon \"x\" aria-label=\"Not supported\" %}                         |\n\n{% endrowheaders %}\n\nYou do not need to configure anything in your repository to enable code navigation. We will automatically extract search-based and precise code navigation information for these supported languages in all repositories and you can switch between the two supported code navigation approaches if your programming language is supported by both.\n\n{% data variables.product.prodname_dotcom %} has developed two code navigation approaches based on the open source `tree-sitter` and `stack-graphs` library:\n- Search-based - searches all definitions and references across a repository to find entities with a given name\n- Precise - resolves definitions and references based on the set of classes, functions, and imported definitions at a given point in your code\n\nTo learn more about these approaches, see \"Precise and search-based navigation.\"\n\nFuture releases will add _precise code navigation_ for more languages, which is a code navigation approach that can give more accurate results.\n\n{% ifversion code-search-code-view %}You can use keyboard shortcuts to navigate within a code file. For more information, see \"AUTOTITLE.\"{% endif %}\n\n{% ifversion code-search-code-view %}\n\n\n\nUsing the symbols pane\n\nYou can now quickly view and navigate between symbols such as functions or classes in your code with the symbols pane. You can search for a symbol in a single file, in all files in a repository, or even in all public repositories on {% data variables.product.prodname_dotcom %}.\n\nSymbol search is a feature of code search. For more informatio", "Y2h1bmtfMl9pbmRleF8xODA5": "n, see \"AUTOTITLE.\"\n\n1. Select a repository, then navigate to a file containing symbols.\n1. To bring up the symbols pane, above the file content, click {% octicon \"code-square\" aria-label=\"The code square icon\" %}.\n\n   Alternatively, you can open the symbols pane by clicking an eligible symbol in your file. Clickable symbols are highlighted in yellow when you hover over them.\n\n1. Click the symbol you would like to find from the symbols pane or within the file itself.\n\n   - To search for a symbol in the repository as a whole, in the symbols pane, click **Search for this symbol in this repository**. To search for a symbol in all repositories on {% data variables.product.prodname_dotcom %}, click **all repositories**.\n\n1. To navigate between references to a symbol, click {% octicon \"chevron-down\" aria-label=\"The downwards-facing chevron icon\" %} or {% octicon \"chevron-up\" aria-label=\"The upwards-facing chevron icon\" %}.\n1. To navigate to a specific reference to a symbol, click a result of the symbol search under {% octicon \"chevron-down\" aria-label=\"The downwards-facing chevron icon\" %} **In this file**.\n1. To exit the search for a specific symbol, click {% octicon \"arrow-left\" aria-label=\"The left arrow icon\" %} **All Symbols**.\n{% endif %}\n\n\n\nJumping to the definition of a function or method\n\nYou can jump to a function or method's definition within the same repository by clicking the function or method call in a file.\n\n!Screenshot of the function window. A section, titled \"Definition,\" is outlined in dark orange.\n\n\n\nFinding all references of a function or method\n\nYou can find all references for a function or method within the same repository by clicking the function or method call in a file.\n\n!Screenshot of the function window. A section, titled \"3 References,\" is outlined in dark orange.\n\n\n\nPrecise and search-based navigation\n\nCertain languages supported by {% data variables.product.prodname_dotcom %} have access to _precise code navigation_, which uses an algorithm (based on the open source `stack-graphs` librar", "Y2h1bmtfM19pbmRleF8xODA5": "y) that resolves definitions and references based on the set of classes, functions, and imported definitions that are visible at any given point in your code. Other languages use _search-based code navigation_, which searches all definitions and references across a repository to find entities with a given name. Both strategies are effective at finding results and both make sure to avoid inappropriate results such as comments, but precise code navigation can give more accurate results, especially when a repository contains multiple methods or functions with the same name.\n\nIf you don't see the results you expect from a precise code navigation query, you can click on the \"search-based\" link in the displayed popover to perform search-based navigation.\n\n!Screenshot of the function window. Two links, labeled, \"Search for this symbol in this repository\" and \"all repositories,\" are outlined in dark orange.\n\nIf your precise results appear inaccurate, you can file a support request.\n\n\n\nCross-repository precise code navigation\n\nCross-repo code navigation is available for languages that are supported by precise code navigation and the dependency graph. For more information, see \"AUTOTITLE.\" With cross-repo code navigation, you can jump to the definition of functions or variables defined in dependencies imported by your project if that dependency is a repository hosted by {% data variables.product.prodname_dotcom %}. Cross-repo code navigation does not support find-all-references requests at this time.\n\n!Screenshot of a code file on {% data variables.product.prodname_dotcom %}. On the line \"import o.s.\", the module name \"o.s.\" is highlighted, and a \"Definitions\" modal shows a result tagged with \"cross-repo result\".\n\n\n\nTroubleshooting code navigation\n\nIf code navigation is enabled for you but you don't see links to the definitions of functions and methods:\n- Code navigation only works for active branches. Push to the branch and try again.\n- Code navigation only works for repositories with fewer than 100,000 files.\n\n\n\nFurther ", "Y2h1bmtfNF9pbmRleF8xODA5": "reading\n\n- \"[AUTOTITLE]{% ifversion code-search-code-view %}(/search-github/github-code-search/about-github-code-search){% else %}(/search-github/searching-on-github/searching-code){% endif %}\"\n\n", "Y2h1bmtfMF9pbmRleF8xNzQw": "\n\nCreating a new repository from the web UI\n\n{% endif %}\n\n{% data reusables.repositories.create_new %}\n1. Optionally, to create a repository with the directory structure and files of an existing repository, select the **Choose a template** dropdown menu and click a template repository. You'll see template repositories that are owned by you and organizations you're a member of or that you've used before. For more information, see \"AUTOTITLE.\"\n1. Optionally, if you chose to use a template, to include the directory structure and files from all branches in the template, and not just the default branch, select **Include all branches**.\n{% data reusables.repositories.owner-drop-down %}\n{% data reusables.repositories.repo-name %}\n{% data reusables.repositories.choose-repo-visibility %}\n1. If you're not using a template, there are a number of optional items you can pre-populate your repository with. If you're importing an existing repository to {% data variables.product.product_name %}, don't choose any of these options, as you may introduce a merge conflict. You can add or create new files using the user interface or choose to add new files using the command line later. For more information, see \"AUTOTITLE,\" \"AUTOTITLE,\" and \"AUTOTITLE.\"\n    - You can create a README, which is a document describing your project. For more information, see \"AUTOTITLE.\"\n    - You can create a _.gitignore_ file, which is a set of ignore rules. For more information, see \"AUTOTITLE.\"{% ifversion fpt or ghec %}\n    - You can choose to add a software license for your project. For more information, see \"AUTOTITLE.\"{% endif %}\n{% data reusables.repositories.select-marketplace-apps %}\n{% data reusables.repositories.create-repo %}\n{% ifversion fpt or ghec %}\n1. At the bottom of the resulting Quick Setup page, under \"Import code from an old repository\", you can choose to import a project to your new repository. To do so, click **Import code**.\n{% endif %}\n\n{% ifversion create-new-repos-with-query-params %}\n\n\n\nCreating a new repository from a URL que", "Y2h1bmtfMV9pbmRleF8xNzQw": "ry\n\nYou can use query parameters to pre-fill form fields when creating a new repository. Query parameters are optional parts of a URL you can customize to share a specific web page view, such as search filter results or an issue template on {% data variables.product.prodname_dotcom %}. To specify values for the predefined query parameters, you must match the key and value pair.\n\nPre-filling form fields with a URL query may be useful if you often want to create repositories with the same default settings. For example, a teacher may want each student in a class to create a repository in their personal account with the same name, description and visibility. Using a URL query, the teacher can create a link that pre-fills the repository name, description and visibility fields and share it with the whole class.\n\nYou must have the proper permissions for any action to use the equivalent query parameter. For example, you must have permission to create a repository in an organization to specify the organization as the repository owner in a query parameter. For more information, see \"AUTOTITLE.\"\n\nIf you create an invalid URL using query parameters, or if you don\u2019t have the proper permissions, the invalid query parameters will be ignored and the rest of the URL will function as normal. If you create a URL that exceeds the server limit, the URL will return a `414 URI Too Long` error page.\n\nQuery parameter | Example | Valid values\n---  | --- | ---\n`name` | `https://{% data variables.product.product_url %}/new?name=test-repo&owner=avocado-corp` creates a repository called \"test-repo\" owned by the \"avocado-corp\" organization. | Any valid repository name. Spaces must be replaced with `+` or `%20`.\n`description` | `https://{% data variables.product.product_url %}/new?description=An+exciting+repository&visibility=private&owner=octocat` creates a repo with the description \"An exciting repository\" with private visibility owned by @octocat. | Any string. Spaces must be replaced with `+` or `%20`.\n`visibility` | `https://{% data variab", "Y2h1bmtfMl9pbmRleF8xNzQw": "les.product.product_url %}/new?visibility=private` creates a repository with private visibility. | `public` `private`{% ifversion not fpt %}`internal`{% endif %}\n`owner` | `https://{% data variables.product.product_url %}/new?owner=avocado-corp&visibility=public` creates a public repository owned by the \"avocado-corp\" organization. | Any valid organization name or username. Alternatively, while signed in use `@me` to specify your user account as the owner.\n`template_owner` and `template_name` | `https://{% data variables.product.product_url %}/new?owner=avocado-corp&template_owner=avocado-corp&template_name=octo-repo` creates a repository owned by the \"avocado-corp\" using the avocado-corp's template \"octo-repo\". | The username of the template owner and the name of the repository template.\n{% endif %}\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n- Open Source Guides{% ifversion fpt or ghec %}\n- {% data variables.product.prodname_learning %}{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF8xMTMx": "\n\nEnabling or disabling {% data variables.product.prodname_copilot_cli_short %} at the organization level\n\nAn organization owner can enable or disable {% data variables.product.prodname_copilot_cli_short %} for the organization. {% ifversion ghec %}You may not be able to configure this setting for your organization, if an enterprise owner has set a policy at the enterprise level.{% endif %}\n\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n1. In the \"Code, planning, and automation\" section of the sidebar, click **{% octicon \"copilot\" aria-hidden=\"true\" %} {% data variables.product.prodname_copilot_short %}**, and then click **Policies and features**.\n1. To the right of \"{% data variables.product.prodname_copilot_cli %}\", select the dropdown menu, then click **Enabled** or **Disabled**.\n\n{% ifversion ghec %}\n\n\n\nEnabling or disabling {% data variables.product.prodname_copilot_cli_short %} at the enterprise level\n\nAn enterprise owner can choose whether to enable a feature for all organizations, disable for all organizations, or allow each organization to choose its own policy for the feature.\n\n{% data reusables.enterprise-accounts.policies-tab %}\n{% data reusables.enterprise-accounts.copilot-tab %}\n1. Click the **Technical preview features** tab.\n1. To the right of \"{% data variables.product.prodname_copilot_cli %}\", select the dropdown menu, then choose the appropriate option.\n\n    - Click **Allowed** to enable the {% data variables.product.prodname_copilot_cli_short %} beta for all organizations under your enterprise.\n    - Click **Blocked** to disable the {% data variables.product.prodname_copilot_cli_short %} beta for all organizations under your enterprise.\n    - Click **No policy** to allow each organization under your enterprise to set its own policy.\n\n{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF8xMjU0": "\n\nAbout remote repositories\n\nA remote URL is Git's fancy way of saying \"the place where your code is stored.\" That URL could be your repository on GitHub, or another user's fork, or even on a completely different server.\n\nYou can only push to two types of URL addresses:\n\n- An HTTPS URL like `https://{% data variables.command_line.backticks %}/user/repo.git`\n- An SSH URL, like `git@{% data variables.command_line.backticks %}:user/repo.git`\n\nGit associates a remote URL with a name, and your default remote is usually called `origin`.\n\n\n\nCreating remote repositories\n\nYou can use the `git remote add` command to match a remote URL with a name.\nFor example, you'd type the following in the command line:\n\n```shell\ngit remote add origin \n```\n\nThis associates the name `origin` with the `REMOTE_URL`.\n\nYou can use the command `git remote set-url` to change a remote's URL.\n\n\n\nChoosing a URL for your remote repository\n\nThere are several ways to clone repositories available on {% data variables.location.product_location %}.\n\nWhen you view a repository while signed in to your account, the URLs you can use to clone the project onto your computer are available below the repository details.\n\nFor information on setting or changing your remote URL, see \"AUTOTITLE.\"\n\n\n\nCloning with HTTPS URLs\n\nThe `https://` clone URLs are available on all repositories, regardless of visibility. `https://` clone URLs work even if you are behind a firewall or proxy.\n\nWhen you `git clone`, `git fetch`, `git pull`, or `git push` to a remote repository using HTTPS URLs on the command line, Git will ask for your {% data variables.product.product_name %} username and password. {% data reusables.user-settings.password-authentication-deprecation %}\n\n{% data reusables.command_line.provide-an-access-token %}\n\n{% tip %}\n\n**Tips**:\n- You can use a credential helper so Git will remember your {% data variables.product.prodname_dotcom %} credentials every time it talks to {% data variables.product.prodname_dotcom %}. For more information, see \"AUTOTITLE.\"\n- To clone ", "Y2h1bmtfMV9pbmRleF8xMjU0": "a repository without authenticating to {% data variables.product.product_name %} on the command line, you can use {% data variables.product.prodname_desktop %} to clone instead. For more information, see \"AUTOTITLE.\"\n\n{% endtip %}\n\n {% ifversion fpt or ghec %}If you'd rather use SSH but cannot connect over port 22, you might be able to use SSH over the HTTPS port. For more information, see \"AUTOTITLE.\"{% endif %}\n\n\n\nCloning with SSH URLs\n\nSSH URLs provide access to a Git repository via SSH, a secure protocol. To use these URLs, you must generate an SSH keypair on your computer and add the **public** key to your account on {% ifversion ghae %}{% data variables.product.product_name %}{% else %}{% data variables.location.product_location %}{% endif %}. For more information, see \"AUTOTITLE.\"\n\nWhen you `git clone`, `git fetch`, `git pull`, or `git push` to a remote repository using SSH URLs, you'll be prompted for a password and must provide your SSH key passphrase. For more information, see \"AUTOTITLE.\"\n\n{% ifversion fpt or ghec %}If you are accessing an organization that uses SAML single sign-on (SSO), you must authorize your SSH key to access the organization before you authenticate. For more information, see \"AUTOTITLE\" and \"AUTOTITLE{% ifversion fpt %}\" in the {% data variables.product.prodname_ghe_cloud %} documentation.{% else %}.\"{% endif %}{% endif %}\n\n{% tip %}\n\n**Tip**: You can use an SSH URL to clone a repository to your computer, or as a secure way of deploying your code to production servers. You can also use SSH agent forwarding with your deploy script to avoid managing keys on the server. For more information, see \"AUTOTITLE.\"\n\n{% endtip %}\n\n\n\nCloning with {% data variables.product.prodname_cli %}\n\nYou can also install {% data variables.product.prodname_cli %} to use {% data variables.product.product_name %} workflows in your terminal. For more information, see \"AUTOTITLE.\"\n\n{% ifversion not ghae %}\n\n\n\nCloning with Subversion\n\n{% data reusables.subversion.sunset %}\n\nYou can also use a Subversion client", "Y2h1bmtfMl9pbmRleF8xMjU0": " to access any repository on {% data variables.product.prodname_dotcom %}. Subversion offers a different feature set than Git. For more information, see \"AUTOTITLE\"\n\nYou can also access repositories on {% data variables.product.prodname_dotcom %} from Subversion clients. For more information, see \"AUTOTITLE.\"\n{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF8zOTM=": "\n\nDownloading metrics from your enterprise account\n\n{% data reusables.enterprise-accounts.access-enterprise %}\n\n1. In the enterprise account sidebar, click **GitHub Connect**.\n\n{% data reusables.server-statistics.csv-download %}\n\n\n\nDownloading metrics from your organization\n\n{% data reusables.profile.access_org %}\n\n{% data reusables.profile.org_settings %}\n\n1. In the left sidebar, click **GitHub Connect**.\n\n{% data reusables.server-statistics.csv-download %}\n\n", "Y2h1bmtfMF9pbmRleF8xMDg0": "---\ntitle: Self review checklist\nintro: \"Before you submit your pull request for review, you should first review it yourself.\"\nproduct: '{% data reusables.contributing.product-note %}'\nversions:\n  feature: 'contributing'\n---\n\nBefore you submit your changes to the {% data variables.product.prodname_docs %} team for review, work through the list below to complete your self review.\n\n- If there is a content design plan, confirm that your changes meet the user experience and goals outlined in the plan.\n- After opening your pull request, view your changes on staging to confirm the article renders as expected and matches the source. This helps spot issues like typos, content that doesn't follow the style guide, or content that isn't rendering due to versioning problems.\n- Review your changes for technical accuracy.\n- Review your entire pull request to ensure it follows our guidance on creating content that can be translated. For more information, see \"AUTOTITLE.\"\n- Check your changes for grammar, spelling, and adherence to the style guide. For more information, see \"AUTOTITLE.\"\n- If you have added new versioning or made changes to existing versioning, confirm your changes render as expected while viewing each available version of the article.\n- If there are any failing checks in your pull request, troubleshoot them until they're all passing.\n\n", "Y2h1bmtfMF9pbmRleF84NDg=": "\n\nSynopsis\n\n```shell copy\ncodeql resolve upgrades --dbscheme= ...\n```\n\n\n\nDescription\n\n\\[Deep plumbing] Determine upgrades to run for a raw dataset.\n\nDetermine which upgrades need to be performed on a particular raw QL\ndataset to bring it up to the state of the configured QL libraries. This\ncomputation is part of what happens during an ordinary database upgrade,\nand is exposed as a separate plumbing command in order to (a) help with\ntroubleshooting, and (b) provide a starting point for modifying the path\nin extraordinary cases where exact control is needed.\n\n\n\nOptions\n\n\n\nPrimary Options\n\n\n\n`--dbscheme=<file>`\n\n\\[Mandatory] The _current_ dbscheme of the dataset we want to upgrade.\n\n\n\n`--format=<fmt>`\n\nSelect output format. Choices include:\n\n`lines` _(default)_: Print upgrade scripts on one line each.\n\n`json`: Print a JSON array of upgrade script paths.\n\n\n\n`--just-check`\n\nDon't print any output, but exit with code 0 if there are upgrades to\ndo, and code 1 if there are none.\n\n\n\nOptions from the invoking command's command line\n\n\n\n`--search-path=<dir>[:<dir>...]`\n\nA list of directories under which QL packs containing upgrade recipes\nmay be found. Each directory can either be a QL pack (or bundle of packs\ncontaining a `.codeqlmanifest.json` file at the root) or the immediate\nparent of one or more such directories.\n\nIf the path contains directories trees, their order defines precedence\nbetween them: if a pack name that must be resolved is matched in more\nthan one of the directory trees, the one given first wins.\n\nPointing this at a checkout of the open-source CodeQL repository ought\nto work when querying one of the languages that live there.\n\n(Note: On Windows the path separator is `;`).\n\n\n\n`--additional-packs=<dir>[:<dir>...]`\n\n\\[Advanced] If this list of directories is given, they will be searched\nfor upgrades before the ones in `--search-path`. The order between these\ndoesn't matter; it is an error if a pack name is found in two different\nplaces through this list.\n\nThis is useful if you're temporarily developing a new", "Y2h1bmtfMV9pbmRleF84NDg=": " version of a pack\nthat also appears in the default path. On the other hand it is _not\nrecommended_ to override this option in a config file; some internal\nactions will add this option on the fly, overriding any configured\nvalue.\n\n(Note: On Windows the path separator is `;`).\n\n\n\n`--target-dbscheme=<file>`\n\nThe _target_ dbscheme we want to upgrade to. If this is not given, a\nmaximal upgrade path will be constructed\n\n\n\n`--target-sha=<sha>`\n\n\\[Advanced] An alternative to `--target-dbscheme` that gives the\ninternal hash of the target dbscheme instead of the dbscheme file.\n\n\n\n`--[no-]allow-downgrades`\n\nInclude any relevant downgrades if there are no upgrades\n\n\n\nCommon options\n\n\n\n`-h, --help`\n\nShow this help text.\n\n\n\n`-J=<opt>`\n\n\\[Advanced] Give option to the JVM running the command.\n\n(Beware that options containing spaces will not be handled correctly.)\n\n\n\n`-v, --verbose`\n\nIncrementally increase the number of progress messages printed.\n\n\n\n`-q, --quiet`\n\nIncrementally decrease the number of progress messages printed.\n\n\n\n`--verbosity=<level>`\n\n\\[Advanced] Explicitly set the verbosity level to one of errors,\nwarnings, progress, progress+, progress++, progress+++. Overrides `-v`\nand `-q`.\n\n\n\n`--logdir=<dir>`\n\n\\[Advanced] Write detailed logs to one or more files in the given\ndirectory, with generated names that include timestamps and the name of\nthe running subcommand.\n\n(To write a log file with a name you have full control over, instead\ngive `--log-to-stderr` and redirect stderr as desired.)\n\n\n\n`--common-caches=<dir>`\n\n\\[Advanced] Controls the location of cached data on disk that will\npersist between several runs of the CLI, such as downloaded QL packs and\ncompiled query plans. If not set explicitly, this defaults to a\ndirectory named `.codeql` in the user's home directory; it will be\ncreated if it doesn't already exist.\n\nAvailable since `v2.15.2`.\n\n", "Y2h1bmtfMF9pbmRleF8yMTM2": "\n\nIntroduction\n\nWhen you create a webhook, you specify a URL and subscribe to event types. When an event that your webhook is subscribed to occurs, {% data variables.product.company_short %} will send an HTTP request with data about the event to the URL that you specified. If your server is set up to listen for webhook deliveries at that URL, it can take action when it receives one.\n\nThis article describes how to write code to let your server listen for and respond to webhook deliveries. You will test your code by using your computer or codespace as a local server.\n\n\n\nSetup\n\nIn order to test your webhook locally, you can use a webhook proxy URL to forward webhooks from {% data variables.product.company_short %} to your computer or codespace. This article uses smee.io to provide a webhook proxy URL and forward webhooks.\n\n\n\nGet a webhook proxy URL\n\n1. In your browser, navigate to https://smee.io/.\n1. Click **Start a new channel**.\n1. Copy the full URL under \"Webhook Proxy URL\". You will use this URL in the following setup steps.\n\n\n\nForward webhooks\n\n1. If you don't already have smee-client installed, run the following command in your terminal:\n\n   ```shell copy\n   npm install --global smee-client\n   ```\n\n1. To receive forwarded webhooks from smee.io, run the following command in your terminal. Replace `WEBHOOK_PROXY_URL` with your webhook proxy URL from earlier.\n\n   ```shell copy\n   smee --url WEBHOOK_PROXY_URL --path /webhook --port 3000\n   ```\n\n   You should see output that looks like this, where `WEBHOOK_PROXY_URL` is your webhook proxy URL:\n\n   ```shell copy\n   Forwarding WEBHOOK_PROXY_URL to http://127.0.0.1:3000/webhook\n   Connected WEBHOOK_PROXY_URL\n   ```\n\n   Note that the path is `/webhook` and the port is `3000`. You will use these values later when you write code to handle webhook deliveries.\n\n1. Keep this running while you test out your webhook. When you want to stop forwarding webhooks, enter Ctrl+C .\n\n\n\nCreate a webhook\n\n1. Create a webhook with the following settings. For more information, see \"AUTOT", "Y2h1bmtfMV9pbmRleF8yMTM2": "ITLE.\"\n\n   - For the URL, use your webhook proxy URL from earlier.\n   - If you have an option to choose the content type, use JSON.\n\n\n\nWrite code to handle webhook deliveries\n\nIn order to handle webhook deliveries, you need to write code that will:\n\n- Initialize your server to listen for requests to your webhook URL\n- Read the HTTP headers and body from the request\n- Take the desired action in response to the request\n\nYou can use any programming language that you can run on your server.\n\nThe following examples print a message when a webhook delivery is received. However, you can modify the code to take another action, such as making a request to the {% data variables.product.company_short %} API or sending a Slack message.\n\n- Ruby example\n- JavaScript example\n\n\n\nRuby example\n\nThis example uses the Ruby gem, Sinatra, to define routes and handle HTTP requests. For more information, see the Sinatra README.\n\n\n\nRuby example: Install dependencies\n\nTo use this example, you must install the sinatra gem in your Ruby project. For example, you can do this with Bundler:\n\n1. If you don't already have Bundler installed, run the following command in your terminal:\n\n   ```shell copy\n   gem install bundler\n   ```\n\n1. If you don't already have a Gemfile for your app, run the following command in your terminal:\n\n   ```shell copy\n   bundle init\n   ```\n\n1. If you don't already have a Gemfile.lock for your app, run the following command in your terminal:\n\n   ```shell copy\n   bundle install\n   ```\n\n1. Install the Sinatra gem by running the following command in your terminal:\n\n   ```shell copy\n   bundle add sinatra\n   ```\n\n\n\nRuby example: Write the code\n\nCreate a Ruby file with the following contents. Modify the code to handle the event types that your webhook is subscribed to, as well as the `ping` event that {% data variables.product.company_short %} sends when you create a webhook. This example handles the `issues` and `ping` events.\n\n```ruby copy annotate\n\n\nThese are the dependencies for this code. You installed the `sinatra` gem ea", "Y2h1bmtfMl9pbmRleF8yMTM2": "rlier. For more information, see \"Ruby example: Install dependencies.\" The `json` library is a standard Ruby library, so you don't need to install it.\nrequire 'sinatra'\nrequire 'json'\n\n\n\nThe `/webhook` route matches the path that you specified for the smee.io forwarding. For more information, see \"Forward webhooks.\"\n#\n\n\nOnce you deploy your code to a server and update your webhook URL, you should change this to match the path portion of the URL for your webhook.\npost '/webhook' do\n\n  # Respond to indicate that the delivery was successfully received.\n  # Your server should respond with a 2XX response within {% ifversion fpt or ghec %}10{% else %}30{% endif %} seconds of receiving a webhook delivery. If your server takes longer than that to respond, then {% data variables.product.company_short %} terminates the connection and considers the delivery a failure.\n  status 202\n\n  # Check the `X-GitHub-Event` header to learn what event type was sent.\n  # Sinatra changes `X-GitHub-Event` to `HTTP_X_GITHUB_EVENT`.\n  github_event = request.env['HTTP_X_GITHUB_EVENT']\n\n  # You should add logic to handle each event type that your webhook is subscribed to.\n  # For example, this code handles the `issues` and `ping` events.\n  #\n  # If any events have an `action` field, you should also add logic to handle each action that you are interested in.\n  # For example, this code handles the `opened` and `closed` actions for the `issue` event.\n  #\n  # For more information about the data that you can expect for each event type, see \"AUTOTITLE.\"\n  if github_event == \"issues\"\n    data = JSON.parse(request.body.read)\n    action = data['action']\n    if action == \"opened\"\n      puts \"An issue was opened with this title: #{data['issue']['title']}\"\n    elsif action == \"closed\"\n      puts \"An issue was closed by #{data['issue']['user']['login']}\"\n    else\n      puts \"Unhandled action for the issue event: #{action}\"\n    end\n  elsif github_event == \"ping\"\n    puts \"GitHub sent the ping event\"\n  else\n    puts \"Unhandled event: #{github_event}\"\n  end\ne", "Y2h1bmtfM19pbmRleF8yMTM2": "nd\n```\n\n\n\nRuby example: Test the code\n\nTo test your webhook, you can use your computer or codespace to act as a local server. If you have trouble with these steps, see Troubleshooting.\n\n1. Make sure that you are forwarding webhooks. If you are no longer forwarding webhooks, follow the steps in Forward webhooks again.\n1. In a separate terminal window, run the following command to start a local server on your computer or codespace. Replace `FILE_PATH` with the path to the file where your code from the previous section is stored. Note that `PORT=3000` matches the port that you specified for the webhook forwarding in the previous step.\n\n   ```shell copy\n   PORT=3000 ruby FILE_NAME\n   ```\n\n   You should see output that indicates something like \"Sinatra has taken the stage on 3000\".\n\n1. Trigger your webhook. For example, if you created a repository webhook that is subscribed to the `issues` event, open an issue in your repository. You can also redeliver a previous webhook delivery. For more information, see \"AUTOTITLE.\"\n1. Navigate to your webhook proxy URL on smee.io. You should see an event that corresponds to the event that you triggered or redelivered. This indicates that {% data variables.product.company_short %} successfully sent a webhook delivery to the payload URL that you specified.\n1. In the terminal window where you ran `smee --url WEBHOOK_PROXY_URL --path /webhook --port 3000`, you should see something like `POST http://127.0.0.1:3000/webhook - 202`. This indicates that smee successfully forwarded your webhook to your local server.\n1. In the terminal window where you ran `PORT=3000 ruby FILE_NAME`, you should see a message corresponding to the event that was sent. For example, if you use the example code from above and you redelivered the `ping` event, you should see \"{% data variables.product.company_short %} sent the ping event\". You may also see some other lines that Sinatra automatically prints.\n1. In both terminal windows, enter Ctrl+C to stop your local server and stop listening for forwarded webhook", "Y2h1bmtfNF9pbmRleF8yMTM2": "s.\n\nNow that you have tested out your code locally, you can make changes to use your webhook in production. For more information, see \"Next steps.\" If you had trouble testing your code, try the steps in \"Troubleshooting.\"\n\n\n\nJavaScript example\n\nThis example uses Node.js and the Express library to define routes and handle HTTP requests. For more information, see \"expressjs.com.\"\n\nFor an example that uses {% data variables.product.company_short %}'s Octokit.js SDK, see \"AUTOTITLE.\"\n\nThis example requires your computer or codespace to run Node.js version 12 or greater and npm version 6.12.0 or greater. For more information, see Node.js.\n\n\n\nJavaScript example: Install dependencies\n\nTo use this example, you must install the `express` library in your Node.js project. For example:\n\n```shell copy\nnpm install express\n```\n\n\n\nJavascript example: Write the code\n\nCreate a JavaScript file with the following contents. Modify the code to handle the event types that your webhook is subscribed to, as well as the `ping` event that {% data variables.product.company_short %} sends when you create a webhook. This example handles the `issues` and `ping` events.\n\n```javascript copy annotate\n// You installed the `express` library earlier. For more information, see \"JavaScript example: Install dependencies.\"\nconst express = require('express');\n\n// This initializes a new Express application.\nconst app = express();\n\n// This defines a POST route at the `/webhook` path. This path matches the path that you specified for the smee.io forwarding. For more information, see \"Forward webhooks.\"\n//\n// Once you deploy your code to a server and update your webhook URL, you should change this to match the path portion of the URL for your webhook.\napp.post('/webhook', express.json({type: 'application/json'}), (request, response) => {\n\n  // Respond to indicate that the delivery was successfully received.\n  // Your server should respond with a 2XX response within {% ifversion fpt or ghec %}10{% else %}30{% endif %} seconds of receiving a webhook delivery. ", "Y2h1bmtfNV9pbmRleF8yMTM2": "If your server takes longer than that to respond, then {% data variables.product.company_short %} terminates the connection and considers the delivery a failure.\n  response.status(202).send('Accepted');\n\n  // Check the `x-github-event` header to learn what event type was sent.\n  const githubEvent = request.headers['x-github-event'];\n\n  // You should add logic to handle each event type that your webhook is subscribed to.\n  // For example, this code handles the `issues` and `ping` events.\n  //\n  // If any events have an `action` field, you should also add logic to handle each action that you are interested in.\n  // For example, this code handles the `opened` and `closed` actions for the `issue` event.\n  //\n  // For more information about the data that you can expect for each event type, see \"AUTOTITLE.\"\n  if (githubEvent === 'issues') {\n    const data = request.body;\n    const action = data.action;\n    if (action === 'opened') {\n      console.log(`An issue was opened with this title: ${data.issue.title}`);\n    } else if (action === 'closed') {\n      console.log(`An issue was closed by ${data.issue.user.login}`);\n    } else {\n      console.log(`Unhandled action for the issue event: ${action}`);\n    }\n  } else if (githubEvent === 'ping') {\n    console.log('GitHub sent the ping event');\n  } else {\n    console.log(`Unhandled event: ${githubEvent}`);\n  }\n});\n\n// This defines the port where your server should listen.\n// 3000 matches the port that you specified for webhook forwarding. For more information, see \"Forward webhooks.\"\n//\n// Once you deploy your code to a server, you should change this to match the port where your server is listening.\nconst port = 3000;\n\n// This starts the server and tells it to listen at the specified port.\napp.listen(port, () => {\n  console.log(`Server is running on port ${port}`);\n});\n```\n\n\n\nJavaScript example: Test the code\n\nTo test your webhook, you can use your computer or codespace to act as a local server. If you have trouble with these steps, see Troubleshooting.\n\n1. Make sure that you", "Y2h1bmtfNl9pbmRleF8yMTM2": " are forwarding webhooks. If you are no longer forwarding webhooks, follow the steps in Forward webhooks again.\n1. In a separate terminal window, run the following command to start a local server on your computer or codespace. Replace `FILE_PATH` with the path to the file where your code from the previous section is stored.\n\n   ```shell copy\n   node FILE_NAME\n   ```\n\n   You should see output that says `Server is running on port 3000`.\n\n1. Trigger your webhook. For example, if you created a repository webhook that is subscribed to the `issues` event, open an issue in your repository. You can also redeliver a previous webhook delivery. For more information, see \"AUTOTITLE.\"\n1. Navigate to your webhook proxy URL on smee.io. You should see an event that corresponds to the event that you triggered or redelivered. This indicates that {% data variables.product.company_short %} successfully sent a webhook delivery to the payload URL that you specified.\n1. In the terminal window where you ran `smee --url WEBHOOK_PROXY_URL --path /webhook --port 3000`, you should see something like `POST http://127.0.0.1:3000/webhook - 202`. This indicates that smee successfully forwarded your webhook to your local server.\n1. In the terminal window where you ran `node FILE_NAME`, you should see a message corresponding to the event that was sent. For example, if you use the example code from above and you redelivered the `ping` event, you should see \"{% data variables.product.company_short %} sent the ping event\".\n1. In both terminal windows, enter Ctrl+C to stop your local server and stop listening for forwarded webhooks.\n\nNow that you have tested out your code locally, you can make changes to use your webhook in production. For more information, see \"Next steps.\" If you had trouble testing your code, try the steps in \"Troubleshooting.\"\n\n\n\nTroubleshooting\n\nIf you don't see the expected results described in the testing steps, try the following:\n\n- Make sure that your webhook is using your webhook proxy URL (Smee.io URL). For more informatio", "Y2h1bmtfN19pbmRleF8yMTM2": "n about your webhook proxy URL, see \"Get a webhook proxy URL.\" For more information about your webhook settings, see \"AUTOTITLE.\"\n- Make sure that your webhook uses the JSON content type, if you have a choice about what content type to use. For more information about your webhook settings, see \"AUTOTITLE.\"\n- Make sure that both the smee client and your local server are running. You will have these processes running in two separate terminal windows.\n- Make sure that your server is listening to the same port where smee.io is forwarding webhooks. All of the examples in this article use port 3000.\n- Make sure that the path where smee.io is forwarding webhooks matches a route that is defined in your code. All of the examples in this article use the `/webhooks` path.\n- Check for error messages in the terminal windows where you are running the smee client and your local server.\n- Check {% data variables.product.company_short %} to verify that a webhook delivery was triggered. For more information, see \"AUTOTITLE.\"\n- Check your webhook proxy URL on smee.io. You should see an event that corresponds to the event that you triggered or redelivered. This indicates that {% data variables.product.company_short %} successfully sent a webhook delivery to the payload URL that you specified.\n\n\n\nNext steps\n\nThis article demonstrated how to write code to handle webhook deliveries. It also demonstrated how to test your code by using your computer or codespace as a local server and by forwarding webhook deliveries from {% data variables.product.company_short %} to your local server via smee.io. Once you are done testing your code, you might want to modify the code and deploy your code to a server.\n\n\n\nModify the code\n\nThis article gave basic examples that print a message when a webhook delivery is received. You may want to modify the code to take some other action. For example, you could modify the code to:\n\n- Make a request to the {% data variables.product.company_short %} API\n- Send a message on Slack\n- Log events\n- Update an external", "Y2h1bmtfOF9pbmRleF8yMTM2": " project management tool\n\n\n\nVerify that the delivery is from {% data variables.product.company_short %}\n\nIn your code that handles webhook deliveries, you should validate that the delivery is from {% data variables.product.company_short %} before processing the delivery further. For more information, see \"AUTOTITLE.\"\n\n\n\nDeploy your code to a server\n\nThis article demonstrated how to use your computer or codespace as a server while you develop your code. Once the code is ready for production use, you should deploy your code to a dedicated server.\n\nWhen you do so, you may need to update your code to reflect the host and port where your server is listening.\n\n\n\nUpdate the webhook URL\n\nOnce you have a server that is set up to receive webhook traffic from {% data variables.product.company_short %}, update the URL in your webhook settings. You may need to update the route that your code handles to match the path portion of the new URL. For example, if your new webhook URL is `https://example.com/github-webhooks`, you should change the route in these examples from `/webhooks` to `/github-webhooks`.\n\nYou should not use smee.io to forward your webhooks in production.\n\n\n\nFollow best practices\n\nYou should aim to follow best practices with your webhooks. For more information, see \"AUTOTITLE.\"\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8yODI=": "\n\nChecking the health of {% data variables.product.prodname_actions %}\n\nYou can check the health of {% data variables.product.prodname_actions %} on {% data variables.location.product_location %} with the `ghe-actions-check` command-line utility. For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n\n\n\nConfiguring self-hosted runners when using a self-signed certificate for {% data variables.product.prodname_ghe_server %}\n\n{% data reusables.actions.enterprise-self-signed-cert %} For more information, see \"AUTOTITLE.\"\n\n\n\nInstalling the certificate on the runner machine\n\nFor a self-hosted runner to connect to a {% data variables.product.prodname_ghe_server %} using a self-signed certificate, you must install the certificate on the runner machine so that the connection is security hardened.\n\nFor the steps required to install a certificate, refer to the documentation for your runner's operating system.\n\n\n\nConfiguring Node.JS to use the certificate\n\nMost actions are written in JavaScript and run using Node.js, which does not use the operating system certificate store. For the self-hosted runner application to use the certificate, you must set the `NODE_EXTRA_CA_CERTS` environment variable on the runner machine.\n\nYou can set the environment variable as a system environment variable, or declare it in a file called `.env` in the self-hosted runner application directory (that is, the directory into which you downloaded and unpacked the runner software).\n\nFor example:\n\n```shell\nNODE_EXTRA_CA_CERTS=/usr/share/ca-certificates/extra/mycertfile.crt\n```\n\nEnvironment variables are read when the self-hosted runner application starts, so you must set the environment variable before configuring or starting the self-hosted runner application. If your certificate configuration changes, you must restart the self-hosted runner application.\n\n\n\nConfiguring Docker containers to use the certificate\n\nIf you use Docker container actions or service containers in your workflows, you might also need to install the certificate in your Docker im", "Y2h1bmtfMV9pbmRleF8yODI=": "age in addition to setting the above environment variable.\n\n\n\nConfiguring HTTP proxy settings for {% data variables.product.prodname_actions %}\n\n{% data reusables.actions.enterprise-http-proxy %}\n\nIf these settings aren't correctly configured, you might receive errors like `Resource unexpectedly moved to https://IP-ADDRESS` when setting or changing your {% data variables.product.prodname_actions %} configuration.\n\n\n\nRunners not connecting to {% data variables.product.prodname_ghe_server %} with a new hostname\n\n{% data reusables.enterprise_installation.changing-hostname-not-supported %}\n\nIf you deploy {% data variables.product.prodname_ghe_server %} in your environment with a new hostname and the old hostname no longer resolves to your instance, self-hosted runners will be unable to connect to the old hostname, and will not execute any jobs.\n\nYou will need to update the configuration of your self-hosted runners to use the new hostname for {% data variables.location.product_location %}. Each self-hosted runner will require one of the following procedures:\n\n- In the self-hosted runner application directory, edit the `.runner` and `.credentials` files to replace all mentions of the old hostname with the new hostname, then restart the self-hosted runner application.\n- Remove the runner from {% data variables.product.prodname_ghe_server %} using the UI, and re-add it. For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n\n\n\nStuck jobs and {% data variables.product.prodname_actions %} memory and CPU limits\n\n{% data variables.product.prodname_actions %} is composed of multiple services running on {% data variables.location.product_location %}. By default, these services are set up with default CPU and memory limits that should work for most instances. However, heavy users of {% data variables.product.prodname_actions %} might need to adjust these settings.\n\nYou may be hitting the CPU or memory limits if you notice that jobs are not starting (even though there are idle runners), or if the job's progress is not updating o", "Y2h1bmtfMl9pbmRleF8yODI=": "r changing in the UI.\n\n\n\n1. Check the overall CPU and memory usage in the management console\n\nAccess the management console and use the monitor dashboard to inspect the overall CPU and memory graphs under \"System Health\". For more information, see \"AUTOTITLE.\"\n\nIf the overall \"System Health\" CPU usage is close to 100%, or there is no free memory left, then {% data variables.location.product_location %} is running at capacity and needs to be scaled up. For more information, see \"AUTOTITLE.\"\n\n\n\n2. Check the Nomad Jobs CPU and memory usage in the management console\n\nIf the overall \"System Health\" CPU and memory usage is OK, scroll down the monitor dashboard page to the \"Nomad Jobs\" section, and look at the \"CPU Percent Value\" and \"Memory Usage\" graphs.\n\nEach plot in these graphs corresponds to one service. For {% data variables.product.prodname_actions %} services, look for:\n\n- `mps_frontend`\n- `mps_backend`\n- `token_frontend`\n- `token_backend`\n- `actions_frontend`\n- `actions_backend`\n\nIf any of these services are at or near 100% CPU utilization, or the memory is near their limit (2 GB by default), then the resource allocation for these services might need increasing. Take note of which of the above services are at or near their limit.\n\n\n\n3. Increase the resource allocation for services at their limit\n\n1. Log in to the administrative shell using SSH. For more information, see \"AUTOTITLE.\"\n1. Run the following command to see what resources are available for allocation:\n\n   ```shell\n   nomad node status -self\n   ```\n\n   In the output, find the \"Allocated Resources\" section. It looks similar to the following example:\n\n   ```text\n   Allocated Resources\n   CPU              Memory          Disk\n   7740/49600 MHZ   23 GiB/32 GiB   4.4 GiB/7.9 GiB\n   ```\n\n   For CPU and memory, this shows how much is allocated to the **total** of **all** services (the left value) and how much is available (the right value). In the example above, there is 23 GiB of memory allocated out of 32 GiB total. This means there is 9 GiB of memory ava", "Y2h1bmtfM19pbmRleF8yODI=": "ilable for allocation.\n\n   {% warning %}\n\n   **Warning:** Be careful not to allocate more than the total available resources, or services will fail to start.\n\n   {% endwarning %}\n1. Change directory to `/etc/consul-templates/etc/nomad-jobs/actions`:\n\n   ```shell\n   cd /etc/consul-templates/etc/nomad-jobs/actions\n   ```\n\n   In this directory there are three files that correspond to the {% data variables.product.prodname_actions %} services from above:\n\n   - `mps.hcl.ctmpl`\n   - `token.hcl.ctmpl`\n   - `actions.hcl.ctmpl`\n1. For the services that you identified that need adjustment, open the corresponding file and locate the `resources` group that looks like the following:\n\n   ```text\n   resources {\n     cpu = 512\n     memory = 2048\n     network {\n       port \"http\" { }\n     }\n   }\n   ```\n\n   The values are in MHz for CPU resources, and MB for memory resources.\n\n   For example, to increase the resource limits in the above example to 1 GHz for the CPU and 4 GB of memory, change it to:\n\n   ```text\n   resources {\n     cpu = 1024\n     memory = 4096\n     network {\n       port \"http\" { }\n     }\n   }\n   ```\n\n1. Save and exit the file.\n1. Run `ghe-config-apply` to apply the changes.\n\n    When running `ghe-config-apply`, if you see output like `Failed to run nomad job '/etc/nomad-jobs/.hcl'`, then the change has likely over-allocated CPU or memory resources. If this happens, edit the configuration files again and lower the allocated CPU or memory, then re-run `ghe-config-apply`.\n1. After the configuration is applied, run `ghe-actions-check` to verify that the {% data variables.product.prodname_actions %} services are operational.\n\n{% ifversion fpt or ghec or ghes %}\n\n\n\nTroubleshooting failures when {% data variables.product.prodname_dependabot %} triggers existing workflows\n\n{% data reusables.dependabot.beta-security-and-version-updates %}\n\nAfter you set up {% data variables.product.prodname_dependabot %} updates for {% data variables.location.product_location %}, you may see failures when existing workflows are triggered by", "Y2h1bmtfNF9pbmRleF8yODI=": " {% data variables.product.prodname_dependabot %} events.\n\nBy default, {% data variables.product.prodname_actions %} workflow runs that are triggered by {% data variables.product.prodname_dependabot %} from `push`, `pull_request`, `pull_request_review`, or `pull_request_review_comment` events are treated as if they were opened from a repository fork. Unlike workflows triggered by other actors, this means they receive a read-only `GITHUB_TOKEN` and do not have access to any secrets that are normally available. This will cause any workflows that attempt to write to the repository to fail when they are triggered by {% data variables.product.prodname_dependabot %}.\n\nThere are three ways to resolve this problem:\n\n1. You can update your workflows so that they are no longer triggered by {% data variables.product.prodname_dependabot %} using an expression like: `if: github.actor != 'dependabotbot]'`. For more information, see \"[AUTOTITLE.\"\n1. You can modify your workflows to use a two-step process that includes `pull_request_target` which does not have these limitations. For more information, see \"AUTOTITLE.\"\n1. You can provide workflows triggered by {% data variables.product.prodname_dependabot %} access to secrets and allow the `permissions` term to increase the default scope of the `GITHUB_TOKEN`. For more information, see \"Providing workflows triggered by{% data variables.product.prodname_dependabot %} access to secrets and increased permissions\" below.\n\n\n\nProviding workflows triggered by {% data variables.product.prodname_dependabot %} access to secrets and increased permissions\n\n1. Log in to the administrative shell using SSH. For more information, see \"AUTOTITLE.\"\n1. To remove the limitations on workflows triggered by {% data variables.product.prodname_dependabot %} on {% data variables.location.product_location %}, use the following command.\n\n    ``` shell\n    ghe-config app.actions.disable-dependabot-enforcement true\n    ```\n\n1. Apply the configuration.\n\n    ```shell\n    ghe-config-apply\n    ```\n\n1. Return to {%", "Y2h1bmtfNV9pbmRleF8yODI=": " data variables.product.prodname_ghe_server %}.\n\n{% endif %}\n\n\n\n\n\nTroubleshooting bundled actions in {% data variables.product.prodname_actions %}\n\nIf you receive the following error when installing {% data variables.product.prodname_actions %} in {% data variables.product.prodname_ghe_server %}, you can resolve the problem by installing the official bundled actions and starter workflows.\n\n```shell\nA part of the Actions setup had problems and needs an administrator to resolve.\n```\n\nTo install the official bundled actions and starter workflows within a designated organization in {% data variables.product.prodname_ghe_server %}, follow this procedure.\n\n1. Identify an organization that will store the official bundled actions and starter workflows. You can create a new organization or reuse an existing one.\n    - To create a new organization, see \"AUTOTITLE.\"\n    - For assistance with choosing a name for this organization, see \"AUTOTITLE.\"\n\n1. Log in to the administrative shell using SSH. For more information, see \"AUTOTITLE.\"\n1. To designate your organization as the location to store the bundled actions, use the `ghe-config` command, replacing `ORGANIZATION` with the name of your organization.\n\n    ```shell\n    ghe-config app.actions.actions-org ORGANIZATION\n    ```\n\n    and:\n\n    ```shell\n    ghe-config app.actions.github-org ORGANIZATION\n    ```\n\n1. To add the bundled actions to your organization, unset the SHA.\n\n    ```shell\n    ghe-config --unset 'app.actions.actions-repos-sha1sum'\n    ```\n\n1. Apply the configuration.\n\n    ```shell\n    ghe-config-apply\n    ```\n\nAfter you've completed these steps, you can resume configuring {% data variables.product.prodname_actions %} at \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF80MjE=": "\n\nAbout {% data variables.product.product_name %} cluster health\n\nA {% data variables.product.product_name %} cluster comprises multiple nodes, with redundant services distributed across two or more nodes. If an individual service or an entire node fails, users should not notice. Failures affect performance and redundancy, so it's important to monitor the health of your cluster. You can monitor the health of your cluster using a command-line utility or an external monitoring tool like Nagios.\n\n{% ifversion node-eligibility-service %}\n\nYou can also monitor the health of individual nodes using {% data variables.product.prodname_nes %}. For more information, see \"AUTOTITLE.\"\n\n{% endif %}\n\n\n\nManually checking cluster status\n\n{% data variables.product.prodname_ghe_server %} has a built-in command line utility for monitoring the health of the cluster. From the administrative shell, running the `ghe-cluster-status` command executes a series of health checks on each node including verification of connectivity and service status. The output shows all test results including the text `ok` or `error`. For example, to only display failing tests, run:\n\n```shell\nadmin@ghe-data-node-0:~$ ghe-cluster-status | grep error\n> mysql-replication ghe-data-node-0: error Stopped\n> mysql cluster: error\n```\n\n{% note %}\n\n**Note:** If there are no failing tests, this command produces no output. This indicates the cluster is healthy.\n\n{% endnote %}\n\n{% ifversion ghes-manage-api-cli-extension %}\n\n\n\nMonitoring cluster status using the {% data variables.product.prodname_cli %}\n\nYou can use the `gh es` extension for {% data variables.product.prodname_cli %} to check the status of your {% data variables.product.product_name %} cluster. For more information, see the GH ES CLI usage documentation and \"AUTOTITLE\".\n\n{% endif %}\n\n\n\nMonitoring cluster status with Nagios\n\nYou can configure Nagios to monitor {% data variables.product.prodname_ghe_server %}. In addition to monitoring basic connectivity to each of the cluster nodes, you can check the cluster", "Y2h1bmtfMV9pbmRleF80MjE=": " status by configuring Nagios to use the `ghe-cluster-status -n` command. This returns output in a format that Nagios understands.\n\n\n\nPrerequisites\n\n- Linux host running Nagios.\n- Network access to the {% data variables.product.prodname_ghe_server %} cluster.\n\n\n\nConfiguring the Nagios host\n\n1. Generate an SSH key with a blank passphrase. Nagios uses this to authenticate to the {% data variables.product.prodname_ghe_server %} cluster.\n\n   ```shell\n   nagiosuser@nagios:~$ ssh-keygen -t ed25519\n   > Generating public/private ed25519 key pair.\n   > Enter file in which to save the key (/home/nagiosuser/.ssh/id_ed25519):\n   > Enter passphrase (empty for no passphrase): LEAVE BLANK BY PRESSING ENTER\n   > Enter same passphrase again: PRESS ENTER AGAIN\n   > Your identification has been saved in /home/nagiosuser/.ssh/id_ed25519.\n   > Your public key has been saved in /home/nagiosuser/.ssh/id_ed25519.pub.\n   ```\n\n   {% danger %}\n\n   **Security Warning:** An SSH key without a passphrase can pose a security risk if authorized for full access to a host. Limit this key's authorization to a single read-only command.\n\n   {% enddanger %}\n   {% note %}\n\n   **Note:** If you're using a distribution of Linux that doesn't support the Ed25519 algorithm, use the command:\n\n   ```shell\n   nagiosuser@nagios:~$ ssh-keygen -t rsa -b 4096\n   ```\n\n   {% endnote %}\n1. Copy the private key (`id_ed25519`) to the `nagios` home folder and set the appropriate ownership.\n\n   ```shell\n   nagiosuser@nagios:~$ sudo cp .ssh/id_ed25519 /var/lib/nagios/.ssh/\n   nagiosuser@nagios:~$ sudo chown nagios:nagios /var/lib/nagios/.ssh/id_ed25519\n   ```\n\n1. To authorize the public key to run _only_ the `ghe-cluster-status -n` command, use a `command=` prefix in the `/data/user/common/authorized_keys` file. From the administrative shell on any node, modify this file to add the public key generated in step 1. For example: `command=\"/usr/local/bin/ghe-cluster-status -n\" ssh-ed25519 AAAA....`\n\n1. Validate and copy the configuration to each node in the cluster by running", "Y2h1bmtfMl9pbmRleF80MjE=": " `ghe-cluster-config-apply` on the node where you modified the `/data/user/common/authorized_keys` file.\n\n   ```shell\n   admin@ghe-data-node-0:~$ ghe-cluster-config-apply\n   > Validating configuration\n   > ...\n   > Finished cluster configuration\n   ```\n\n1. To test that the Nagios plugin can successfully execute the command, run it interactively from Nagios host.\n\n   ```shell\n   nagiosuser@nagios:~$ /usr/lib/nagios/plugins/check_by_ssh -l admin -p 122 -H HOSTNAME -C \"ghe-cluster-status -n\" -t 30\n   > OK - No errors detected\n   ```\n\n1. Create a command definition in your Nagios configuration.\n\n   **Example definition**\n\n   ```text\n   define command {\n        command_name    check_ssh_ghe_cluster\n        command_line    $USER1$/check_by_ssh -H $HOSTADDRESS$ -C \"ghe-cluster-status -n\" -l admin -p 122 -t 30\n   }\n   ```\n\n1. Add this command to a service definition for a node in the {% data variables.product.prodname_ghe_server %} cluster.\n\n   **Example definition**\n\n   ```text\n   define host{\n        use                     generic-host\n        host_name               ghe-data-node-0\n        alias                   ghe-data-node-0\n        address                 10.11.17.180\n        }\n\n   define service{\n          use                             generic-service\n          host_name                       ghe-data-node-0\n          service_description             GitHub Cluster Status\n          check_command                   check_ssh_ghe_cluster\n          }\n   ```\n\nAfter you add the definition to Nagios, the service check executes according to your configuration. You should be able to see the newly configured service in the Nagios web interface.\n\n", "Y2h1bmtfMF9pbmRleF82MDk=": "\n\nToken revoked after reaching its expiration date\n\nWhen you create a {% data variables.product.pat_generic %}, we recommend that you set an expiration for your token. Upon reaching your token's expiration date, the token is automatically revoked. For more information, see \"AUTOTITLE.\"\n\n{% ifversion fpt or ghec %}\n\n\n\nToken revoked when pushed to a public repository or public gist\n\nIf a valid OAuth token, {% data variables.product.prodname_github_app %} token, or {% data variables.product.pat_generic %} is pushed to a public repository or public gist, the token will be automatically revoked.\n\n{% endif %}\n\n{% ifversion fpt or ghec %}\n\n\n\nToken expired due to lack of use\n\n{% data variables.product.product_name %} will automatically revoke an OAuth token or {% data variables.product.pat_generic %} when the token hasn't been used in one year.\n{% endif %}\n\n\n\nToken revoked by the user\n\nYou can revoke your authorization of a {% data variables.product.prodname_github_app %} or {% data variables.product.prodname_oauth_app %} from your account settings which will revoke any tokens associated with the app. For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n\nOnce an authorization is revoked, any tokens associated with the authorization will be revoked as well. To reauthorize an application, follow the instructions from the third-party application or website to connect your account on {% ifversion ghae %}{% data variables.product.product_name %}{% else %}{% data variables.location.product_location %}{% endif %} again.\n\n\n\nToken revoked by the {% data variables.product.prodname_oauth_app %}\n\nThe owner of an {% data variables.product.prodname_oauth_app %} can revoke an account's authorization of their app, this will also revoke any tokens associated with the authorization. For more information about revoking authorizations of your {% data variables.product.prodname_oauth_app %}, see \"AUTOTITLE.\"\n\n{% data variables.product.prodname_oauth_app %} owners can also revoke individual tokens associated with an authorization. For more ", "Y2h1bmtfMV9pbmRleF82MDk=": "information about revoking individual tokens for your {% data variables.product.prodname_oauth_app %}, see \"AUTOTITLE\".\n\n\n\nToken revoked due to excess of tokens for an {% data variables.product.prodname_oauth_app %} with the same scope\n\n{% data reusables.apps.oauth-token-limit %}\n\n\n\nUser token revoked due to {% data variables.product.prodname_github_app %} configuration\n\nUser access tokens created by a {% data variables.product.prodname_github_app %} will expire after eight hours by default. Owners of {% data variables.product.prodname_github_apps %} can optionally change the default expiration period for their user access tokens, or configure the tokens to never expire. For more information about configuring your {% data variables.product.prodname_dotcom %} App's user access tokens, see \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF84MjA=": "\n\nSynopsis\n\n```shell copy\ncodeql pack ci [--force] ... -- \n```\n\n\n\nDescription\n\n\\[Experimental] Clean install dependencies for this pack, verifying\nthat the existing lock file is up to date.\n\nThis command installs the dependencies of the pack, using the versions\nspecified in the codeql-pack.lock.yml file. If any of the versions\nspecified in the lock file are incompatible with the version constraints\nspecified in the qlpack.yml file, or if no lock file is present, this\ncommand fails.\n\nThis command is similar to `codeql pack install`, except it's meant to\nbe used in automated environments such as test platforms, continuous\nintegration, and deployment -- or any situation where you want to make\nsure you're doing a clean install of your dependencies.\n\nAvailable since `v2.12.4`.\n\n\n\nOptions\n\n\n\nPrimary Options\n\n\n\n`<dir>`\n\nThe root directory of the package.\n\n\n\n`--format=<fmt>`\n\nSelect output format, either `text` _(default)_ or `json`.\n\n\n\n`-f, --[no-]force`\n\nAllow overwriting already existing packs.\n\n\n\n`--[no-]allow-prerelease`\n\nAllow packs with pre-release version qualifiers (e.g.,\n`X.Y.Z-qualifier`) to be used. Without this flag, pre-release packs will\nbe ignored.\n\nAvailable since `v2.11.3`.\n\n\n\n`--lock-override=<file>`\n\n\\[Advanced] Specifies an alternate lock file to use as the input to\ndependency resolution.\n\n\n\n`--lock-output=<file>`\n\n\\[Advanced] Specifies an alternate location to save the lock file\ngenerated by dependency resolution.\n\nAvailable since `v2.14.1`.\n\n\n\n`--no-strict-mode`\n\n\\[Advanced] Turn off strict mode to avoid a warning when resolving\npackages from the `--additional-packs`\n\nand other locally resolved locations. Packages resolved locally are\nnever downloaded\n\nand will not be added to the package lock.\n\n\n\nOptions for resolving QL packs outside of the package registry\n\n\n\n`--search-path=<dir>[:<dir>...]`\n\nA list of directories under which QL packs may be found. Each directory\ncan either be a QL pack (or bundle of packs containing a\n`.codeqlmanifest.json` file at the root) or the immediate parent of one\nor mo", "Y2h1bmtfMV9pbmRleF84MjA=": "re such directories.\n\nIf the path contains more than one directory, their order defines\nprecedence between them: when a pack name that must be resolved is\nmatched in more than one of the directory trees, the one given first\nwins.\n\nPointing this at a checkout of the open-source CodeQL repository ought\nto work when querying one of the languages that live there.\n\nIf you have checked out the CodeQL repository as a sibling of the\nunpacked CodeQL toolchain, you don't need to give this option; such\nsibling directories will always be searched for QL packs that cannot be\nfound otherwise. (If this default does not work, it is strongly\nrecommended to set up `--search-path` once and for all in a per-user\nconfiguration file).\n\n(Note: On Windows the path separator is `;`).\n\n\n\n`--additional-packs=<dir>[:<dir>...]`\n\nIf this list of directories is given, they will be searched for packs\nbefore the ones in `--search-path`. The order between these doesn't\nmatter; it is an error if a pack name is found in two different places\nthrough this list.\n\nThis is useful if you're temporarily developing a new version of a pack\nthat also appears in the default path. On the other hand, it is _not\nrecommended_ to override this option in a config file; some internal\nactions will add this option on the fly, overriding any configured\nvalue.\n\n(Note: On Windows the path separator is `;`).\n\n\n\nOptions for configuring the CodeQL package manager\n\n\n\n`--registries-auth-stdin`\n\nAuthenticate to GitHub Enterprise Server Container registries by passing\na comma-separated list of \\=\\ pairs.\n\nFor example, you can pass\n`https://containers.GHEHOSTNAME1/v2/=TOKEN1,https://containers.GHEHOSTNAME2/v2/=TOKEN2`\nto authenticate to two GitHub Enterprise Server instances.\n\nThis overrides the CODEQL\\_REGISTRIES\\_AUTH and GITHUB\\_TOKEN environment\nvariables. If you only need to authenticate to the github.com Container\nregistry, you can instead authenticate using the simpler\n`--github-auth-stdin` option.\n\n\n\n`--github-auth-stdin`\n\nAuthenticate to the github.com Container registr", "Y2h1bmtfMl9pbmRleF84MjA=": "y by passing a\ngithub.com GitHub Apps token or personal access token via standard\ninput.\n\nTo authenticate to GitHub Enterprise Server Container registries, pass\n`--registries-auth-stdin` or use the CODEQL\\_REGISTRIES\\_AUTH environment\nvariable.\n\nThis overrides the GITHUB\\_TOKEN environment variable.\n\n\n\nCommon options\n\n\n\n`-h, --help`\n\nShow this help text.\n\n\n\n`-J=<opt>`\n\n\\[Advanced] Give option to the JVM running the command.\n\n(Beware that options containing spaces will not be handled correctly.)\n\n\n\n`-v, --verbose`\n\nIncrementally increase the number of progress messages printed.\n\n\n\n`-q, --quiet`\n\nIncrementally decrease the number of progress messages printed.\n\n\n\n`--verbosity=<level>`\n\n\\[Advanced] Explicitly set the verbosity level to one of errors,\nwarnings, progress, progress+, progress++, progress+++. Overrides `-v`\nand `-q`.\n\n\n\n`--logdir=<dir>`\n\n\\[Advanced] Write detailed logs to one or more files in the given\ndirectory, with generated names that include timestamps and the name of\nthe running subcommand.\n\n(To write a log file with a name you have full control over, instead\ngive `--log-to-stderr` and redirect stderr as desired.)\n\n\n\n`--common-caches=<dir>`\n\n\\[Advanced] Controls the location of cached data on disk that will\npersist between several runs of the CLI, such as downloaded QL packs and\ncompiled query plans. If not set explicitly, this defaults to a\ndirectory named `.codeql` in the user's home directory; it will be\ncreated if it doesn't already exist.\n\nAvailable since `v2.15.2`.\n\n", "Y2h1bmtfMF9pbmRleF80NDI=": "\n\nRequirements and recommendations\n\n{% note %}\n\n**Note:** Before resizing any storage volume, put your instance in maintenance mode.{% ifversion ip-exception-list %} You can validate changes by configuring an IP exception list to allow access from specified IP addresses. {% endif %} For more information, see \"AUTOTITLE.\"\n\n{% endnote %}\n\n\n\nMinimum requirements\n\n{% data reusables.enterprise_installation.hardware-rec-table %}\n\n\n\nIncreasing the data partition size\n\n1. Resize the existing user volume disk using your virtualization platform's tools.\n{% data reusables.enterprise_installation.ssh-into-instance %}\n1. Put the appliance in maintenance mode. For more information, see \"AUTOTITLE.\"\n1. Reboot the appliance to detect the new storage allocation:\n\n   ```shell\n   sudo reboot\n   ```\n\n1. Run the `ghe-storage-extend` command to expand the `/data/user` filesystem:\n\n   ```shell\n   ghe-storage-extend\n   ```\n\n1. Ensure system services are functioning correctly, then release maintenance mode. For more information, see \"AUTOTITLE.\"\n\n\n\nIncreasing the root partition size using a new appliance\n\n1. Set up a new {% data variables.product.prodname_ghe_server %} instance with a larger root disk using the same version as your current appliance. For more information, see \"AUTOTITLE.\"\n1. Shut down the current appliance:\n\n   ```shell\n   sudo poweroff\n   ```\n\n1. Detach the data disk from the current appliance using your virtualization platform's tools.\n1. Attach the data disk to the new appliance with the larger root disk.\n\n\n\nIncreasing the root partition size using an existing appliance\n\n{% warning %}\n\n**Warning:** Before increasing the root partition size, you must put your instance in maintenance mode. For more information, see \"AUTOTITLE.\"\n\n{% endwarning %}\n\n1. Attach a new disk to your {% data variables.product.prodname_ghe_server %} appliance.\n1. Run the `lsblk` command to identify the new disk's device name.\n1. Run the `parted` command to format the disk, substituting your device name for `/dev/xvdg`:\n\n   ```shell\n   sudo parted", "Y2h1bmtfMV9pbmRleF80NDI=": " /dev/xvdg mklabel msdos\n   sudo parted /dev/xvdg mkpart primary ext4 0% 50%\n   sudo parted /dev/xvdg mkpart primary ext4 50% 100%\n   ```\n\n1. If your appliance is configured for high-availability or geo-replication, to stop replication run the `ghe-repl-stop` command on each replica node:\n\n   ```shell\n   ghe-repl-stop\n   ```\n\n1. To install the {% data variables.product.prodname_ghe_server %} software on the newly partitioned disk, run the `ghe-upgrade` command. You must replace **PACKAGE-NAME.pkg** with the path to a platform-specific upgrade package that matches the version of {% data variables.product.prodname_ghe_server %} already running on the appliance. You cannot use a universal hotpatch upgrade package, such as `github-enterprise-2.11.9.hpkg`. After the `ghe-upgrade` command completes, application services will automatically terminate.\n\n   ```shell\n   ghe-upgrade PACKAGE-NAME.pkg -s -t /dev/xvdg1\n   ```\n\n1. Shut down the appliance:\n\n   ```shell\n   sudo poweroff\n   ```\n\n1. In the hypervisor, remove the old root disk and attach the new root disk at the same location as the old root disk.\n1. Start the appliance.\n1. Ensure system services are functioning correctly, then release maintenance mode. For more information, see \"AUTOTITLE.\"\n\nIf your appliance is configured for high-availability or geo-replication, remember to start replication on each replica node using `ghe-repl-start` after the storage on all nodes has been upgraded.\n\n", "Y2h1bmtfMF9pbmRleF8xMjYy": "\n\nUpdating your credentials via Keychain Access\n\n1. Click on the Spotlight icon (magnifying glass) on the right side of the menu bar.\n1. Type `Keychain Access`, then press the Enter key to launch the app.\n1. In Keychain Access, search for `{% data variables.command_line.backticks %}`.\n1. Find the \"Internet password\" entry for `{% data variables.command_line.backticks %}`.\n1. Edit or delete the entry accordingly.\n\n\n\nDeleting your credentials via the command line\n\nThrough the command line, you can use the credential helper directly to erase the keychain entry.\n\n```shell\n$ git credential-osxkeychain erase\nhost={% data variables.command_line.codeblock %}\nprotocol=https\n> [Press Return]\n```\n\nIf it's successful, nothing will print out. To test that it works, try and clone a private repository from {% data variables.location.product_location %}. If you are prompted for a password, the keychain entry was deleted.\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8xMzQ0": "\n\nFields\n\n\n\nRepository.discussions\n\nList the discussions within a repository. If `categoryId` is specified, only results within that category will be returned.\nIf `answered` is not specified, both answered and unanswered discussions will be returned.\n\n_Signature:_\n\n```graphql\ndiscussions(\n  after: String,\n  before: String,\n  first: Int,\n  last: Int,\n  categoryId: ID = null,\n  answered: Boolean = null,\n  orderBy: DiscussionOrder = {field: UPDATED_AT, direction: DESC}\n) : Discussion\n```\n\n\n\nDiscussionOrder\n\n```graphql\n\"\"\"\nWays in which discussions can be ordered.\n\"\"\"\ninput DiscussionOrder {\n  \"\"\"\n  The field by which to order discussions.\n  \"\"\"\n  field: DiscussionOrderField!\n\n  \"\"\"\n  The direction in which to order discussions by the specified field.\n  \"\"\"\n  direction: OrderDirection!\n}\n```\n\n```graphql\n\"\"\"\nProperties by which discussion connections can be ordered.\n\"\"\"\nenum DiscussionOrderField {\n  \"\"\"\n  Order discussions by creation time.\n  \"\"\"\n  CREATED_AT\n\n  \"\"\"\n  Order discussions by most recent modification time.\n  \"\"\"\n  UPDATED_AT\n}\n```\n\n\n\nRepository.discussionCategories\n\nReturn the available discussion categories defined within this repository. Each repository may have up to 25 categories. For more information about discussion categories, see \"AUTOTITLE.\"\n\n_Signature:_\n\n```graphql\ndiscussionCategories(\n  after: String,\n  before: String,\n  first: Int,\n  last: Int,\n) : DiscussionCategoryConnection!\n```\n\n\n\nRepository.discussion\n\nGet a discussion. Returns `null` if discussion with the specified ID does not exist.\n\n_Signature:_\n\n```graphql\ndiscussion(number: Int!) : Discussion\n```\n\n\n\nRepository.pinnedDiscussions\n\nReturn discussions pinned to this repository, ordered by pin position.\n\n_Signature:_\n\n```graphql\npinnedDiscussions(\n  after: String,\n  before: String,\n  first: Int,\n  last: Int,\n) : PinnedDiscussionConnection!\n```\n\n\n\nObjects\n\n**Note:** For brevity, connection types are not expanded here. Each connection type mentioned in the schema follows the same pattern as other connections in the GraphQL API. For more ", "Y2h1bmtfMV9pbmRleF8xMzQ0": "information, see \"AUTOTITLE.\"\n\n```graphql\nquery {\n  repository(owner: \"github\", name: \"some-repo\") {\n    discussions(first: 10) {\n      # type: DiscussionConnection\n      totalCount # Int!\n\n      pageInfo {\n        # type: PageInfo (from the public schema)\n        startCursor\n        endCursor\n        hasNextPage\n        hasPreviousPage\n      }\n\n      edges {\n        # type: DiscussionEdge\n        cursor\n        node {\n          # type: Discussion\n          id\n        }\n      }\n\n      nodes {\n        # type: Discussion\n        id\n      }\n    }\n  }\n}\n```\n\n\n\nDiscussion\n\n\nFields:\n\n```graphql\n\"\"\"\nA discussion in a repository.\n\"\"\"\ntype Discussion implements Comment & Deletable & Lockable & Node & Reactable & RepositoryNode & Subscribable & Updatable {\n  \"\"\"\n  Reason that the conversation was locked.\n  \"\"\"\n  activeLockReason: LockReason\n\n  \"\"\"\n  Check if this discussion has been answered\n  \"\"\"\n  isAnswered: Boolean!\n\n  \"\"\"\n  The comment chosen as this discussion's answer, if any.\n  \"\"\"\n  answer: DiscussionComment\n\n  \"\"\"\n  The time when a user chose this discussion's answer, if answered.\n  \"\"\"\n  answerChosenAt: DateTime\n\n  \"\"\"\n  The user who chose this discussion's answer, if answered.\n  \"\"\"\n  answerChosenBy: Actor\n\n  \"\"\"\n  The actor who authored the comment.\n  \"\"\"\n  author: Actor\n\n  \"\"\"\n  Author's association with the subject of the comment.\n  \"\"\"\n  authorAssociation: CommentAuthorAssociation!\n\n  \"\"\"\n  The main text of the discussion post.\n  \"\"\"\n  body: String!\n\n  \"\"\"\n  The body rendered to HTML.\n  \"\"\"\n  bodyHTML: HTML!\n\n  \"\"\"\n  The body rendered to text.\n  \"\"\"\n  bodyText: String!\n\n  \"\"\"\n  The category for this discussion.\n  \"\"\"\n  category: DiscussionCategory!\n\n  \"\"\"\n  The replies to the discussion.\n  \"\"\"\n  comments(\n    \"\"\"\n    Returns the elements in the list that come after the specified cursor.\n    \"\"\"\n    after: String\n\n    \"\"\"\n    Returns the elements in the list that come before the specified cursor.\n    \"\"\"\n    before: String\n\n    \"\"\"\n    Returns the first _n_ elements from the list.\n    \"\"\"\n    first: Int\n\n   ", "Y2h1bmtfMl9pbmRleF8xMzQ0": " \"\"\"\n    Returns the last _n_ elements from the list.\n    \"\"\"\n    last: Int\n  ): DiscussionCommentConnection!\n\n  \"\"\"\n  Identifies the date and time when the object was created.\n  \"\"\"\n  createdAt: DateTime!\n\n  \"\"\"\n  Check if this comment was created via an email reply.\n  \"\"\"\n  createdViaEmail: Boolean!\n\n  \"\"\"\n  Identifies the primary key from the database.\n  \"\"\"\n  databaseId: Int\n\n  \"\"\"\n  The actor who edited the comment.\n  \"\"\"\n  editor: Actor\n  id: ID!\n\n  \"\"\"\n  Check if this comment was edited and includes an edit with the creation data\n  \"\"\"\n  includesCreatedEdit: Boolean!\n\n  \"\"\"\n  The moment the editor made the last edit\n  \"\"\"\n  lastEditedAt: DateTime\n\n  \"\"\"\n  `true` if the object is locked\n  \"\"\"\n  locked: Boolean!\n\n  \"\"\"\n  The number identifying this discussion within the repository.\n  \"\"\"\n  number: Int!\n\n  \"\"\"\n  Identifies when the comment was published at.\n  \"\"\"\n  publishedAt: DateTime\n\n  \"\"\"\n  A list of reactions grouped by content left on the subject.\n  \"\"\"\n  reactionGroups: [ReactionGroup!]\n\n  \"\"\"\n  A list of Reactions left on the Issue.\n  \"\"\"\n  reactions(\n    \"\"\"\n    Returns the elements in the list that come after the specified cursor.\n    \"\"\"\n    after: String\n\n    \"\"\"\n    Returns the elements in the list that come before the specified cursor.\n    \"\"\"\n    before: String\n\n    \"\"\"\n    Allows filtering Reactions by emoji.\n    \"\"\"\n    content: ReactionContent\n\n    \"\"\"\n    Returns the first _n_ elements from the list.\n    \"\"\"\n    first: Int\n\n    \"\"\"\n    Returns the last _n_ elements from the list.\n    \"\"\"\n    last: Int\n\n    \"\"\"\n    Allows specifying the order in which reactions are returned.\n    \"\"\"\n    orderBy: ReactionOrder\n  ): ReactionConnection!\n\n  \"\"\"\n  The repository associated with this node.\n  \"\"\"\n  repository: Repository!\n\n  \"\"\"\n  The path for this discussion.\n  \"\"\"\n  resourcePath: URI!\n\n  \"\"\"\n  The title of this discussion.\n  \"\"\"\n  title: String!\n\n  \"\"\"\n  Identifies the date and time when the object was last updated.\n  \"\"\"\n  updatedAt: DateTime!\n\n  \"\"\"\n  The URL for this discussion.\n  \"\"\"\n  url: ", "Y2h1bmtfM19pbmRleF8xMzQ0": "URI!\n\n  \"\"\"\n  A list of edits to this content.\n  \"\"\"\n  userContentEdits(\n    \"\"\"\n    Returns the elements in the list that come after the specified cursor.\n    \"\"\"\n    after: String\n\n    \"\"\"\n    Returns the elements in the list that come before the specified cursor.\n    \"\"\"\n    before: String\n\n    \"\"\"\n    Returns the first _n_ elements from the list.\n    \"\"\"\n    first: Int\n\n    \"\"\"\n    Returns the last _n_ elements from the list.\n    \"\"\"\n    last: Int\n  ): UserContentEditConnection\n\n  \"\"\"\n  Check if the current viewer can delete this object.\n  \"\"\"\n  viewerCanDelete: Boolean!\n\n  \"\"\"\n  Can user react to this subject\n  \"\"\"\n  viewerCanReact: Boolean!\n\n  \"\"\"\n  Check if the viewer is able to change their subscription status for the repository.\n  \"\"\"\n  viewerCanSubscribe: Boolean!\n\n  \"\"\"\n  Check if the current viewer can update this object.\n  \"\"\"\n  viewerCanUpdate: Boolean!\n\n  \"\"\"\n  Did the viewer author this comment.\n  \"\"\"\n  viewerDidAuthor: Boolean!\n\n  \"\"\"\n  Identifies if the viewer is watching, not watching, or ignoring the subscribable entity.\n  \"\"\"\n  viewerSubscription: SubscriptionState\n}\n```\n\n\n\n\n\nDiscussionComment\n\n\nFields\n\n```graphql\n\"\"\"\nA comment on a discussion.\n\"\"\"\ntype DiscussionComment implements Comment & Deletable & Minimizable & Node & Reactable & Updatable & UpdatableComment {\n  \"\"\"\n  The actor who authored the comment.\n  \"\"\"\n  author: Actor\n\n  \"\"\"\n  Author's association with the subject of the comment.\n  \"\"\"\n  authorAssociation: CommentAuthorAssociation!\n\n  \"\"\"\n  The body as Markdown.\n  \"\"\"\n  body: String!\n\n  \"\"\"\n  The body rendered to HTML.\n  \"\"\"\n  bodyHTML: HTML!\n\n  \"\"\"\n  The body rendered to text.\n  \"\"\"\n  bodyText: String!\n\n  \"\"\"\n  Identifies the date and time when the object was created.\n  \"\"\"\n  createdAt: DateTime!\n\n  \"\"\"\n  Check if this comment was created via an email reply.\n  \"\"\"\n  createdViaEmail: Boolean!\n\n  \"\"\"\n  Identifies the primary key from the database.\n  \"\"\"\n  databaseId: Int\n\n  \"\"\"\n  The time when this replied-to comment was deleted\n  \"\"\"\n  deletedAt: DateTime\n\n  \"\"\"\n  The discussion ", "Y2h1bmtfNF9pbmRleF8xMzQ0": "this comment was created in\n  \"\"\"\n  discussion: Discussion\n\n  \"\"\"\n  The actor who edited the comment.\n  \"\"\"\n  editor: Actor\n  id: ID!\n\n  \"\"\"\n  Check if this comment was edited and includes an edit with the creation data\n  \"\"\"\n  includesCreatedEdit: Boolean!\n\n  \"\"\"\n  Has this comment been chosen as the answer of its discussion?\n  \"\"\"\n  isAnswer: Boolean!\n\n  \"\"\"\n  Returns whether or not a comment has been minimized.\n  \"\"\"\n  isMinimized: Boolean!\n\n  \"\"\"\n  The moment the editor made the last edit\n  \"\"\"\n  lastEditedAt: DateTime\n\n  \"\"\"\n  Returns why the comment was minimized.\n  \"\"\"\n  minimizedReason: String\n\n  \"\"\"\n  Identifies when the comment was published at.\n  \"\"\"\n  publishedAt: DateTime\n\n  \"\"\"\n  A list of reactions grouped by content left on the subject.\n  \"\"\"\n  reactionGroups: [ReactionGroup!]\n\n  \"\"\"\n  A list of Reactions left on the Issue.\n  \"\"\"\n  reactions(\n    \"\"\"\n    Returns the elements in the list that come after the specified cursor.\n    \"\"\"\n    after: String\n\n    \"\"\"\n    Returns the elements in the list that come before the specified cursor.\n    \"\"\"\n    before: String\n\n    \"\"\"\n    Allows filtering Reactions by emoji.\n    \"\"\"\n    content: ReactionContent\n\n    \"\"\"\n    Returns the first _n_ elements from the list.\n    \"\"\"\n    first: Int\n\n    \"\"\"\n    Returns the last _n_ elements from the list.\n    \"\"\"\n    last: Int\n\n    \"\"\"\n    Allows specifying the order in which reactions are returned.\n    \"\"\"\n    orderBy: ReactionOrder\n  ): ReactionConnection!\n\n  \"\"\"\n  The threaded replies to this comment.\n  \"\"\"\n  replies(\n    \"\"\"\n    Returns the elements in the list that come after the specified cursor.\n    \"\"\"\n    after: String\n\n    \"\"\"\n    Returns the elements in the list that come before the specified cursor.\n    \"\"\"\n    before: String\n\n    \"\"\"\n    Returns the first _n_ elements from the list.\n    \"\"\"\n    first: Int\n\n    \"\"\"\n    Returns the last _n_ elements from the list.\n    \"\"\"\n    last: Int\n  ): DiscussionCommentConnection!\n\n  \"\"\"\n  The discussion comment this comment is a reply to\n  \"\"\"\n  replyTo: DiscussionCommen", "Y2h1bmtfNV9pbmRleF8xMzQ0": "t\n\n  \"\"\"\n  The path for this discussion comment.\n  \"\"\"\n  resourcePath: URI!\n\n  \"\"\"\n  Identifies the date and time when the object was last updated.\n  \"\"\"\n  updatedAt: DateTime!\n\n  \"\"\"\n  The URL for this discussion comment.\n  \"\"\"\n  url: URI!\n\n  \"\"\"\n  A list of edits to this content.\n  \"\"\"\n  userContentEdits(\n    \"\"\"\n    Returns the elements in the list that come after the specified cursor.\n    \"\"\"\n    after: String\n\n    \"\"\"\n    Returns the elements in the list that come before the specified cursor.\n    \"\"\"\n    before: String\n\n    \"\"\"\n    Returns the first _n_ elements from the list.\n    \"\"\"\n    first: Int\n\n    \"\"\"\n    Returns the last _n_ elements from the list.\n    \"\"\"\n    last: Int\n  ): UserContentEditConnection\n\n  \"\"\"\n  Check if the current viewer can delete this object.\n  \"\"\"\n  viewerCanDelete: Boolean!\n\n  \"\"\"\n  Can the current user mark this comment as an answer?\n  \"\"\"\n  viewerCanMarkAsAnswer: Boolean!\n\n  \"\"\"\n  Check if the current viewer can minimize this object.\n  \"\"\"\n  viewerCanMinimize: Boolean!\n\n  \"\"\"\n  Can user react to this subject\n  \"\"\"\n  viewerCanReact: Boolean!\n\n  \"\"\"\n  Can the current user unmark this comment as an answer?\n  \"\"\"\n  viewerCanUnmarkAsAnswer: Boolean!\n\n  \"\"\"\n  Check if the current viewer can update this object.\n  \"\"\"\n  viewerCanUpdate: Boolean!\n\n  \"\"\"\n  Reasons why the current viewer can not update this comment.\n  \"\"\"\n  viewerCannotUpdateReasons: [CommentCannotUpdateReason!]!\n\n  \"\"\"\n  Did the viewer author this comment.\n  \"\"\"\n  viewerDidAuthor: Boolean!\n}\n```\n\n\n\n\n\nDiscussionCategory\n\n\nFields\n\n```graphql\n\"\"\"\nA category for discussions in a repository.\n\"\"\"\ntype DiscussionCategory implements Node & RepositoryNode {\n  \"\"\"\n  Identifies the date and time when the object was created.\n  \"\"\"\n  createdAt: DateTime!\n\n  \"\"\"\n  A description of this category.\n  \"\"\"\n  description: String\n\n  \"\"\"\n  An emoji representing this category.\n  \"\"\"\n  emoji: String!\n\n  \"\"\"\n  This category's emoji rendered as HTML.\n  \"\"\"\n  emojiHTML: HTML!\n  id: ID!\n\n  \"\"\"\n  Whether or not discussions in this category support ch", "Y2h1bmtfNl9pbmRleF8xMzQ0": "oosing an answer with the markDiscussionCommentAsAnswer mutation.\n  \"\"\"\n  isAnswerable: Boolean!\n\n  \"\"\"\n  The name of this category.\n  \"\"\"\n  name: String!\n\n  \"\"\"\n  The repository associated with this node.\n  \"\"\"\n  repository: Repository!\n\n  \"\"\"\n  Identifies the date and time when the object was last updated.\n  \"\"\"\n  updatedAt: DateTime!\n}\n```\n\n\n\n\n\nPinnedDiscussion\n\n\nFields:\n\n```graphql\n\"\"\"\nA Pinned discussion is a discussion pinned to a repository's index page.\n\"\"\"\ntype PinnedDiscussion implements Node & RepositoryNode {\n  \"\"\"\n  Identifies the date and time when the object was created.\n  \"\"\"\n  createdAt: DateTime!\n\n  \"\"\"\n  Identifies the primary key from the database.\n  \"\"\"\n  databaseId: Int\n\n  \"\"\"\n  The discussion that was pinned.\n  \"\"\"\n  discussion: Discussion!\n\n  \"\"\"\n  Color stops of the chosen gradient\n  \"\"\"\n  gradientStopColors: [String!]!\n  id: ID!\n\n  \"\"\"\n  Background texture pattern\n  \"\"\"\n  pattern: PinnedDiscussionPattern!\n\n  \"\"\"\n  The actor that pinned this discussion.\n  \"\"\"\n  pinnedBy: Actor!\n\n  \"\"\"\n  Preconfigured background gradient option\n  \"\"\"\n  preconfiguredGradient: PinnedDiscussionGradient\n\n  \"\"\"\n  The repository associated with this node.\n  \"\"\"\n  repository: Repository!\n\n  \"\"\"\n  Identifies the date and time when the object was last updated.\n  \"\"\"\n  updatedAt: DateTime!\n}\n```\n\n\n\n\n\nPinnedDiscussionPattern\n\n\nValues\n\n```graphql\n\"\"\"\nPreconfigured background patterns that may be used to style discussions pinned within a repository.\n\"\"\"\nenum PinnedDiscussionPattern {\n  \"\"\"\n  An upward-facing chevron pattern\n  \"\"\"\n  CHEVRON_UP\n\n  \"\"\"\n  A hollow dot pattern\n  \"\"\"\n  DOT\n\n  \"\"\"\n  A solid dot pattern\n  \"\"\"\n  DOT_FILL\n\n  \"\"\"\n  A heart pattern\n  \"\"\"\n  HEART_FILL\n\n  \"\"\"\n  A friendly octocat face pattern\n  \"\"\"\n  OCTOFACE\n\n  \"\"\"\n  A plus sign pattern\n  \"\"\"\n  PLUS\n}\n```\n\n\n\n\n\nPinnedDiscussionGradient\n\n\nValues\n\n```graphql\n\"\"\"\nPreconfigured gradients that may be used to style discussions pinned within a repository.\n\"\"\"\nenum PinnedDiscussionGradient {\n  \"\"\"\n  A gradient of blue to mint\n  \"\"\"\n  BLUE_MINT\n\n  \"\"\"\n  A gr", "Y2h1bmtfN19pbmRleF8xMzQ0": "adient of blue to purple\n  \"\"\"\n  BLUE_PURPLE\n\n  \"\"\"\n  A gradient of pink to blue\n  \"\"\"\n  PINK_BLUE\n\n  \"\"\"\n  A gradient of purple to coral\n  \"\"\"\n  PURPLE_CORAL\n\n  \"\"\"\n  A gradient of red to orange\n  \"\"\"\n  RED_ORANGE\n}\n```\n\n\n\n\n\nInterfaces\n\n\n\nRepositoryDiscussionAuthor\n\nImplemented by the `User` and `Organization` types. **Note:** An `Organization` will only have discussions associated with it if it was converted from a `User`.\n\n\nFields\n\n```graphql\n\"\"\"\nRepresents an author of discussions in repositories.\n\"\"\"\ninterface RepositoryDiscussionAuthor {\n  \"\"\"\n  Discussions this user has started.\n  \"\"\"\n  repositoryDiscussions(\n    \"\"\"\n    Returns the elements in the list that come after the specified cursor.\n    \"\"\"\n    after: String\n\n    \"\"\"\n    Filter discussions to only those that have been answered or not. Defaults to\n    including both answered and unanswered discussions.\n    \"\"\"\n    answered: Boolean = null\n\n    \"\"\"\n    Returns the elements in the list that come before the specified cursor.\n    \"\"\"\n    before: String\n\n    \"\"\"\n    Returns the first _n_ elements from the list.\n    \"\"\"\n    first: Int\n\n    \"\"\"\n    Returns the last _n_ elements from the list.\n    \"\"\"\n    last: Int\n\n    \"\"\"\n    Ordering options for discussions returned from the connection.\n    \"\"\"\n    orderBy: DiscussionOrder = {field: CREATED_AT, direction: DESC}\n\n    \"\"\"\n    Filter discussions to only those in a specific repository.\n    \"\"\"\n    repositoryId: ID\n  ): DiscussionConnection!\n}\n```\n\n\n\n\n\nRepositoryDiscussionCommentAuthor\n\nAlso implemented by the `User` and `Organization` types.\n\n\nFields\n\n```graphql\n\"\"\"\nRepresents an author of discussion comments in repositories.\n\"\"\"\ninterface RepositoryDiscussionCommentAuthor {\n  \"\"\"\n  Discussion comments this user has authored.\n  \"\"\"\n  repositoryDiscussionComments(\n    \"\"\"\n    Returns the elements in the list that come after the specified cursor.\n    \"\"\"\n    after: String\n\n    \"\"\"\n    Returns the elements in the list that come before the specified cursor.\n    \"\"\"\n    before: String\n\n    \"\"\"\n    Returns the fir", "Y2h1bmtfOF9pbmRleF8xMzQ0": "st _n_ elements from the list.\n    \"\"\"\n    first: Int\n\n    \"\"\"\n    Returns the last _n_ elements from the list.\n    \"\"\"\n    last: Int\n\n    \"\"\"\n    Filter discussion comments to only those that were marked as the answer\n    \"\"\"\n    onlyAnswers: Boolean = false\n\n    \"\"\"\n    Filter discussion comments to only those in a specific repository.\n    \"\"\"\n    repositoryId: ID\n  ): DiscussionCommentConnection!\n}\n```\n\n\n\n\n\nMutations\n\nThese mutations follow the same implementation pattern that other mutations in the GraphQL API. Each mutation accepts a single argument of an `Input` type, named after the mutation, and returns a `Payload` type containing the fields specified.\n\nFor example, this is a basic `createDiscussion` mutation that will create a new discussion:\n\n```graphql\nmutation {\n  # input type: CreateDiscussionInput\n  createDiscussion(input: {repositoryId: \"1234\", categoryId: \"5678\", body: \"The body\", title: \"The title\"}) {\n\n    # response type: CreateDiscussionPayload\n    discussion {\n      id\n    }\n  }\n}\n```\n\n\n\ncreateDiscussion\n\nInput fields:\n\n- `body: String!` The body of the new discussion.\n- `title: String!` The title of the new discussion.\n- `repositoryId: ID!` The ID of a repository in which to create the discussion.\n- `categoryId: ID!` The ID of a `DiscussionCategory` within this repository.\n- `clientMutationId: String` A unique identifier for the client performing the mutation.\n\nReturn type fields:\n\n- `clientMutationId: String` The unique identifier provided as an input.\n- `discussion: Discussion` The discussion that was created.\n\n\n\nupdateDiscussion\n\nInput fields:\n\n- `discussionId: ID!` The node ID of the discussion to update.\n- `body: String` The new contents of the discussion body.\n- `title: String` The new discussion title.\n- `categoryId: ID` The node ID of a `DiscussionCategory` within the same repository to change this discussion to.\n- `clientMutationId: String` A unique identifier for the client performing the mutation.\n\nReturn type fields:\n\n- `clientMutationId: String` The unique identifier provided as", "Y2h1bmtfOV9pbmRleF8xMzQ0": " an input.\n- `discussion: Discussion` The discussion that was modified.\n\n\n\ndeleteDiscussion\n\nInput fields:\n\n- `id: ID!` The node ID of the discussion to delete.\n- `clientMutationId: String` A unique identifier for the client performing the mutation.\n\nReturn type fields:\n\n- `clientMutationId: String` The unique identifier provided as an input.\n- `discussion: Discussion` The discussion that was deleted.\n\n\n\naddDiscussionComment\n\nInput fields:\n\n- `body: String!` The contents of the comment.\n- `discussionId: ID!` The node ID of the discussion to comment on.\n- `replyToId: ID` The node ID of the discussion comment to reply to. If absent, the created comment will be a top-level comment.\n- `clientMutationId: String` A unique identifier for the client performing the mutation.\n\nReturn type fields:\n\n- `clientMutationId: String` The unique identifier provided as an input.\n- `comment: DiscussionComment` The discussion comment that was created.\n\n\n\nupdateDiscussionComment\n\nInput fields:\n\n- `body: String!` The new contents of the comment body.\n- `commentId: ID!` The node ID of the discussion comment to update.\n- `clientMutationId: String` A unique identifier for the client performing the mutation.\n\nReturn type fields:\n\n- `clientMutationId: String` The unique identifier provided as an input.\n- `comment: DiscussionComment` The discussion comment that was updated.\n\n\n\ndeleteDiscussionComment\n\nInput fields:\n\n- `id: ID!` The node ID of the discussion comment to delete.\n- `clientMutationId: String` A unique identifier for the client performing the mutation.\n\nReturn type fields:\n\n- `clientMutationId: String` The unique identifier provided as an input.\n- `comment: DiscussionComment` The discussion comment that was deleted.\n\n\n\nmarkDiscussionCommentAsAnswer\n\nInput fields:\n\n- `id: ID!` The node ID of the discussion comment to mark as an answer.\n- `clientMutationId: String` A unique identifier for the client performing the mutation.\n\nReturn type fields:\n\n- `clientMutationId: String` The unique identifier provided as an input.\n- `discussion: D", "Y2h1bmtfMTBfaW5kZXhfMTM0NA==": "iscussion` The discussion that includes the chosen comment.\n\n\n\nunmarkDiscussionCommentAsAnswer\n\nInput fields:\n\n- `id: ID!` The node ID of the discussion comment to unmark as an answer.\n- `clientMutationId: String` A unique identifier for the client performing the mutation.\n\nReturn type fields:\n\n- `clientMutationId: String` The unique identifier provided as an input.\n- `discussion: Discussion` The discussion that includes the unmarked comment.\n\n\n\nSearch\n\nDiscussion may be returned from the top-level `search` field. To search for discussion, specify `type` as `DISCUSSION`. The `SearchResultItemConnection` type has a `discussionCount` field to report the number of returned discussions, and the `Discussion` type is added to the `SearchResultItem` union. For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF8xNg==": "\n\nExpected behavior to view commit details\n\nIn the \"Contribution activity\" section of your profile page, you can click the number of commits next to a specific repository to see more details about your commits from that time period, including a diff of specific changes made in a repository.\n\n!Screenshot of the \"Contribution activity\" section of a user profile. A link, labeled \"29 commits\" is highlighted with an orange outline.\n\n\n\nMissing commit details from commits in your timeline\n\nIf you click a commit link from your profile page and don't see all of the expected commits on the repository's commits page, then it's possible the commit history in Git was rewritten and the commit author date and the commit date are different.\n\n\n\nHow GitHub uses the Git author date and commit date\n\nIn Git, the author date is when someone first creates a commit with `git commit`. The commit date is identical to the author date unless someone changes the commit date by using `git commit --amend`, a force push, a rebase, or other Git commands.\n\nOn your profile page, the author date is used to calculate when a commit was made. Whereas, in a repository, the commit date is used to calculate when a commit was made in the repository.\n\nMost often, the author date and commit date are the same but you may notice that your commit sequence is out of order if the commit history is changed. For more information, see \"AUTOTITLE\"\n\n\n\nViewing missing commit details from commits in your timeline\n\nYou can use the `git show` command with the `--pretty=fuller` flag to check if the commit author date and commit date are different.\n\n```shell\n$ git show YOUR_COMMIT_SHA_NUMBER --pretty=fuller\ncommit YOUR_COMMIT_SHA_NUMBER\nAuthor:     octocat USER_EMAIL\nAuthorDate: Tue Apr 03 02:02:30 2018 +0900\nCommit:     Sally Johnson USER_EMAIL\nCommitDate: Tue Apr 10 06:25:08 2018 +0900\n```\n\nIf the author and commit date are different, you can manually change the commit date in the URL to see the commit details.\n\nFor example:\n- This URL uses the author date of `2018-04-03", "Y2h1bmtfMV9pbmRleF8xNg==": "`:\n\n  `https://github.com/your-organization-or-personal-account/your-repository/commits?author=octocat&since=2018-04-03T00:00:00Z&until=2018-04-03T23:59:59Z`\n- This URL uses the commit date of `2018-04-10`:\n\n  `https://github.com/your-organization-or-personal-account/your-repository/commits?author=octocat&since=2018-04-10T00:00:00Z&until=2018-04-10T23:59:59Z`\n\nWhen you open the URL with the modified commit date, you can see the commit details.\n\n\n\nExpected commits missing in your timeline\n\nIf you're not seeing expected commits on your timeline, it's possible the commit history in Git was rewritten and the commit author date and the commit date are different. For other possibilities, see \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8xNTUy": "---\ntitle: Restricting repository visibility changes in your organization\nintro: 'To protect your organization''s data, you can configure permissions for changing repository visibility in your organization.'\nredirect_from:\n  - /articles/restricting-repository-visibility-changes-in-your-organization\n  - /github/setting-up-and-managing-organizations-and-teams/restricting-repository-visibility-changes-in-your-organization\nversions:\n  fpt: '*'\n  ghes: '*'\n  ghae: '*'\n  ghec: '*'\ntopics:\n  - Organizations\n  - Teams\nshortTitle: Set visibility changes policy\npermissions: Organization owners can restrict repository visibility changes for an organization.\n---\n\nYou can restrict who has the ability to change the visibility of repositories in your organization, such as changing a repository from private to public. For more information about repository visibility, see \"AUTOTITLE.\"\n\nYou can restrict the ability to change repository visibility to organization owners only, or you can allow anyone with admin access to a repository to change visibility.\n\n{% ifversion fpt or ghec or ghes %}\nRestricting who has the ability to change the visibility of repositories in your organization helps prevent sensitive information from being exposed. For more information, see \"AUTOTITLE.\"\n{% endif %}\n\n{% warning %}\n\n**Warning**: If enabled, this setting allows people with admin access to choose any visibility for an existing repository, even if you do not allow that type of repository to be created. For more information about restricting the visibility of repositories during creation, see \"AUTOTITLE.\"\n\n{% endwarning %}\n\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n{% data reusables.organizations.member-privileges %}\n1. Under \"Repository visibility change\", deselect **Allow members to change repository visibilities for this organization**.\n1. Click **Save**.\n\n", "Y2h1bmtfMF9pbmRleF8zODE=": "---\ntitle: Placing a legal hold on a user or organization\nintro: You can place a legal hold on a user or organization to ensure that repositories they own cannot be permanently removed from your enterprise.\nredirect_from:\n  - /enterprise/admin/user-management/placing-a-legal-hold-on-a-user-or-organization\n  - /admin/user-management/placing-a-legal-hold-on-a-user-or-organization\n  - /admin/user-management/managing-users-in-your-enterprise/placing-a-legal-hold-on-a-user-or-organization\nversions:\n  ghes: '*'\n  ghae: '*'\ntype: how_to\ntopics:\n  - Accounts\n  - Auditing\n  - Enterprise\n  - Organizations\n  - User account\nshortTitle: Place a legal hold\n---\n\nUsually, if someone deletes a repository, it will be available on disk for 90 days and can be restored via the site admin dashboard. After 90 days the repository is purged and deleted forever. If you place a legal hold on a user or organization, repositories they own are available for restore indefinitely.\n\n{% data reusables.enterprise_site_admin_settings.sign-in %}\n{% data reusables.enterprise_site_admin_settings.access-settings %}\n{% data reusables.enterprise_site_admin_settings.search-user-or-org %}\n{% data reusables.enterprise_site_admin_settings.click-user-or-org %}\n{% data reusables.enterprise_site_admin_settings.admin-top-tab %}\n1. Under \"Legal hold\", click **Place legal hold**.\n\n", "Y2h1bmtfMF9pbmRleF8xNTg0": "---\ntitle: Preparing to enforce SAML single sign-on in your organization\nintro: 'Before you enforce SAML single sign-on in your organization, you should verify your organization''s membership and configure the connection settings to your identity provider.'\nredirect_from:\n  - /articles/preparing-to-enforce-saml-single-sign-on-in-your-organization\n  - /github/setting-up-and-managing-organizations-and-teams/preparing-to-enforce-saml-single-sign-on-in-your-organization\nversions:\n  ghec: '*'\ntopics:\n  - Organizations\n  - Teams\nshortTitle: Prepare to enforce SAML SSO\n---\n\n{% data reusables.saml.ghec-only %}\n\n{% data reusables.saml.when-you-enforce %} Before enforcing SAML SSO in your organization, you should review organization membership, enable SAML SSO, and review organization members' SAML access. For more information, see the following.\n\n| Task | More information |\n| :- | :- |\n| Add or remove members from your organization | \"AUTOTITLE\"\"AUTOTITLE\" |\n| Connect your IdP to your organization by enabling SAML SSO | \"AUTOTITLE\"\"AUTOTITLE\" |\n| Ensure that your organization members have signed in and linked their accounts with the IdP | \"AUTOTITLE\" |\n\nAfter you finish these tasks, you can enforce SAML SSO for your organization. For more information, see \"AUTOTITLE.\"\n\n{% data reusables.saml.outside-collaborators-exemption %}\n\n", "Y2h1bmtfMF9pbmRleF8xNjkz": "\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF80MjM=": "\n\nAbout replacement of {% data variables.product.product_name %} cluster nodes\n\nYou can replace a functional node in a {% data variables.product.product_name %} cluster, or you can replace a node that has failed unexpectedly.\n\n{% ifversion cluster-rebalancing %}\nAfter you replace a node, {% data variables.location.product_location %} does not automatically distribute jobs to the new node. You can force your instance to balance jobs across nodes. For more information, see \"AUTOTITLE.\"\n{% endif %}\n\n{% warning %}\n\n**Warning:** To avoid conflicts, do not reuse a hostname that was previously assigned to a node in the cluster.\n\n{% endwarning %}\n\n\n\nReplacing a functional node\n\nYou can replace an existing, functional node in your cluster. For example, you may want to provide a virtual machine (VM) with additional CPU, memory, or storage resources.\n\nTo replace a functional node, install the {% data variables.product.product_name %} appliance on a new VM, configure an IP address, add the new node to the cluster configuration file, initialize the cluster and apply the configuration, then take the node you replaced offline.\n\n{% data reusables.enterprise_clustering.replacing-a-cluster-node-provision %}\n{% data reusables.enterprise_clustering.replacing-a-cluster-node-admin-configure-ip %}\n{% data reusables.enterprise_clustering.replacing-a-cluster-node-modify-cluster-conf %}\n{% data reusables.enterprise_clustering.replacing-a-cluster-node-initialize-new-node %}\n{% data reusables.enterprise_clustering.replacing-a-cluster-node-config-node %}\n{% data reusables.enterprise_clustering.replacing-a-cluster-node-need-three-nodes %}\n{% data reusables.enterprise_clustering.replacing-a-cluster-node-mark-offline %}\n{% data reusables.enterprise_clustering.replacing-a-cluster-node-validate-config %}\n{% data reusables.enterprise_clustering.replacing-a-cluster-node-replacement-name %}\n\n\n\nReplacing a node in an emergency\n\nYou can replace a failed node in your cluster. For example, a software or hardware issue may affect a node's availability.\n\n", "Y2h1bmtfMV9pbmRleF80MjM=": "To replace a node in an emergency, install the {% data variables.product.product_name %} appliance on a new VM, configure an IP address, take the failed node offline, apply the configuration, add the new node to the cluster configuration file, initialize the cluster and apply the configuration, and optionally, evacuate the failed node.\n\n{% data reusables.enterprise_clustering.replacing-a-cluster-node-provision %}\n{% data reusables.enterprise_clustering.replacing-a-cluster-node-admin-configure-ip %}\n{% data reusables.enterprise_clustering.replacing-a-cluster-node-mark-offline %}\n{% data reusables.enterprise_clustering.replacing-a-cluster-node-validate-config %}\n{% data reusables.enterprise_clustering.replacing-a-cluster-node-modify-cluster-conf %}\n{% data reusables.enterprise_clustering.replacing-a-cluster-node-replacement-name %}\n{% data reusables.enterprise_clustering.replacing-a-cluster-node-initialize-new-node %}\n{% data reusables.enterprise_clustering.replacing-a-cluster-node-config-node %}\n{% data reusables.enterprise_clustering.replacing-a-cluster-node-need-three-nodes %}\n\n\n\nReplacing the primary MySQL node\n\nTo provide database services, your cluster requires a primary MySQL node and at least one secondary MySQL node. For more information, see \"AUTOTITLE.\"\n\nIf you want to provide the VM for your primary MySQL node with more resources, or if the node fails, you can replace the node. To minimize downtime, add the new node to your cluster, replicate the MySQL data, and then promote the node. Some downtime is required during promotion.\n\n{% data reusables.enterprise_clustering.replacing-a-cluster-node-provision %}\n{% data reusables.enterprise_clustering.replacing-a-cluster-node-admin-configure-ip %}\n{% data reusables.enterprise_installation.ssh-into-cluster-node %}\n{% data reusables.enterprise_clustering.open-configuration-file %}\n1. {% data reusables.enterprise_clustering.configuration-file-heading %} Add a new heading for the node and enter the key-value pairs for configuration, replacing the placeholders with", "Y2h1bmtfMl9pbmRleF80MjM=": " actual values.\n\n   - Ensure that you include the `mysql-server = true` key-value pair.\n   - The following section is an example, and your node's configuration may differ.\n\n   \n   ...\n   [cluster \"HOSTNAME\"]\n     hostname = HOSTNAME\n     ipv4 = IPV4-ADDRESS\n     # ipv6 = IPV6-ADDRESS\n     consul-datacenter = PRIMARY-DATACENTER\n     datacenter = DATACENTER\n     mysql-server = true\n     redis-server = true\n     ...\n   ...\n   \n\n{% data reusables.enterprise_clustering.replacing-a-cluster-node-initialize-new-node %}\n{% data reusables.enterprise_clustering.replacing-a-cluster-node-validate-config %}\n1. Wait for MySQL replication to finish. To monitor MySQL replication from any node in the cluster, run `ghe-cluster-status -v`.\n\n   Shortly after adding the node to the cluster, you may see an error for replication status while replication catches up. Replication can take hours depending on the instance's load and the last time the instance generated a database seed.\n1. During your scheduled maintenance window, enable maintenance mode. For more information, see \"AUTOTITLE.\"\n1. Ensure that MySQL replication is finished from any node in the cluster by running `ghe-cluster-status -v`.\n\n   {% warning %}\n\n   **Warning**: If you do not wait for MySQL replication to finish, you risk data loss on your instance.\n\n   {% endwarning %}\n1. To set the current MySQL primary node to read-only mode, run the following command from of the instance's nodes.\n\n   ```shell copy\n   echo \"SET GLOBAL super_read_only = 1;\" | sudo mysql\n   ```\n\n1. Wait until Global Transaction Identifiers (GTIDs) set on the primary and secondary MySQL nodes are identical. To check the GTIDs, run the following command from any of the instance's nodes.\n\n   ```shell copy\n   ghe-cluster-each -r mysql -- 'echo \"SELECT @@global.gtid_executed;\" | sudo mysql'\n   ```\n\n1. After the GTIDs on the primary and secondary MySQL nodes match, update the cluster configuration by opening the cluster configuration file at `/data/user/common/cluster.conf` in a text editor.\n\n   - Create a ", "Y2h1bmtfM19pbmRleF80MjM=": "backup of the `cluster.conf` file before you edit the file.\n   - In the top-level `[cluster]` section, remove the hostname for the node you replaced from the `mysql-master` key-value pair, then assign the new node instead. If the new node is also a primary Redis node, adjust the `redis-master` key-value pair.\n\n   \n   [cluster]\n     mysql-master = NEW-NODE-HOSTNAME\n     redis-master = NEW-NODE-HOSTNAME\n     primary-datacenter = primary\n   ...\n   \n{% data reusables.enterprise_clustering.replacing-a-cluster-node-validate-config %}\n1. Check the status of MySQL replication from any node in the cluster by running `ghe-cluster-status -v`.\n1. If MySQL replication is finished, from any node in the cluster, disable maintenance mode.  For more information, see \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF83MjA=": "\n\n1. Focus on newly committed secrets\n\nWhen you enable {% data variables.product.prodname_secret_scanning %}, you should focus on remediating any newly committed credentials detected by secret scanning. If you focus on cleaning up committed credentials, developers could continue to accidentally push new credentials, which means your total secret count will stay around the same level, not decrease as intended. This is why it is essential to stop new credentials being leaked before focusing on revoking any current secrets.\n\nThere are a few approaches for tackling newly committed credentials, but one example approach would be:\n\n1. Notify: Use webhooks to ensure that any new secret alerts are seen by the right teams as quickly as possible. A webhook fires when a secret alert is either created, resolved, or reopened. You can then parse the webhook payload, and integrate it into any tools you and your team use such Slack, Teams, Splunk, or email. For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n1. Follow Up: Create a high-level remediation process that works for all secret types. For example, you could contact the developer who committed the secret and their technical lead on that project, highlighting the dangers of committing secrets to GitHub, and asking the them to revoke, and update the detected secret.\n\n   {% note %}\n\n   **Note:** You can automate this step. For large enterprises and organizations with hundreds of repositories, manually following up is unsustainable. You could incorporate automation into the webhook process defined in the first step. The webhook payload contains repository and organization information about the leaked secret. Using this information, you can contact the current maintainers on the repository and create an email/message to the responsible people or open an issue.\n\n   {% endnote %}\n1. **Educate**: Create an internal training document assigned to the developer who committed the secret. Within this training document, you can explain the risks created by committing secrets and dir", "Y2h1bmtfMV9pbmRleF83MjA=": "ect them to your best practice information about using secrets securely in development. If the a developer doesn't learn from the experience and continues to commit secrets, you could create an escalation process, but education usually works well.\n\nRepeat the last two steps for any new secrets leaked. This process encourages developers to take responsibility for managing the secrets used in their code securely, and allows you to measure the reduction in newly committed secrets.\n\n{% note %}\n\n**Note:** More advanced organizations may want to perform auto-remediation of certain types of secrets. There is an open-source initiative called GitHub Secret Scanner Auto Remediator which you can deploy into your AWS, Azure, or GCP environment and tailor to automatically revoke certain types of secrets based on what you define as the most critical. This is also an excellent way to react to new secrets being committed with a more automated approach.\n\n{% endnote %}\n\n\n\n2. Remediate previously committed secrets, starting with the most critical\n\nAfter you have established a process to monitor, notify and remediate newly published secrets, you can start work on secrets committed before {% data variables.product.prodname_GH_advanced_security %} was introduced.\n\nHow you define your most critical secrets will depend on your organization's processes and integrations. For example, a company likely isn\u2019t worried about a Slack Incoming Webhook secret if they don\u2019t use Slack. You may find it useful to start by focusing on the top five most critical credential types for your organization.\n\nOnce you have decided on the secret types, you can do the following:\n\n1. Define a process for remediating each type of secret. The actual procedure for each secret type is often drastically different. Write down the process for each type of secret in a document or internal knowledge base.\n\n   {% note %}\n\n   **Note:** When you create the process for revoking secrets, try and give the responsibility for revoking secrets to the team maintaining the reposito", "Y2h1bmtfMl9pbmRleF83MjA=": "ry instead of a central team. One of the principles of GHAS is developers taking ownership of security and having the responsibility of fixing security issues, especially if they have created them.\n\n   {% endnote %}\n\n1. When you have created the process that teams will follow for revoking credentials, you can collate information about the types of secrets and other metadata associated with the leaked secrets so you can discern who to communicate the new process to.\n   {% ifversion not ghae %}\n   You can use security overview to collect this information. For more information about using security overview, see \"AUTOTITLE.\"{% endif %}\n\n   Some information you may want to collect includes:\n\n   - Organization\n   - Repository\n   - Secret type\n   - Secret value\n   - Maintainers on repository to contact\n\n   {% note %}\n\n   **Note:** Use the UI if you have few secrets leaked of that type. If you have hundreds of leaked secrets, use the API to collect information. For more information, see \"AUTOTITLE.\"\n\n   {% endnote %}\n\n1. After you collect information about leaked secrets, create a targeted communication plan for the users who maintain the repositories affected by each secret type. You could use email, messaging, or even create GitHub issues in the affected repositories. If you can use APIs provided by these tools to send out the communications in an automated manner, this will make it easier for you to scale across multiple secret types.\n\n\n\n3. Expand the program to include more secret types and custom patterns\n\nYou can now expand beyond the five most critical secret types into a more comprehensive list, with an additional focus on education. You can repeat the previous step, remediating previously committed secrets, for the different secret types you have targeted.\n\nYou can also include more of the custom patterns collated in the earlier phases and invite security teams and developer teams to submit more patterns, establishing a process for submitting new patterns as new secret types are created. For more information, se", "Y2h1bmtfM19pbmRleF83MjA=": "e \"AUTOTITLE.\"\n\n{% ifversion secret-scanning-push-protection %}\n\nYou can also enable push protection with secret scanning. Once enabled, secret scanning checks pushes for high-confidence secrets and blocks the push. For more information, see \"AUTOTITLE.\"\n\n{% endif %}\n\nAs you continue to build your remediation processes for other secret types, start to create proactive training material that can be shared with all developers of GitHub in your organization. Until this point, a lot of the focus has been reactive. It is an excellent idea to shift focus to being proactive and encourage developers not to push credentials to GitHub in the first place. This can be achieved in multiple ways but creating a short document explaining the risks and reasons would be a great place to start.\n\n{% note %}\n\nThis is the final article of a series on adopting {% data variables.product.prodname_GH_advanced_security %} at scale. If you have questions or need support, see the section on {% data variables.contact.github_support %} and {% data variables.product.prodname_professional_services_team %} in \"AUTOTITLE.\"\n\n{% endnote %}\n\n", "Y2h1bmtfMF9pbmRleF8xNDQ0": "\n\nFurther reading\n\n- \"AUTOTITLE\"\n{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF8xMzIy": "\n\nCreating a table\n\nYou can create tables with pipes `|` and hyphens `-`. Hyphens are used to create each column's header, while pipes separate each column. You must include a blank line before your table in order for it to correctly render.\n\n```markdown\n\n| First Header  | Second Header |\n| ------------- | ------------- |\n| Content Cell  | Content Cell  |\n| Content Cell  | Content Cell  |\n```\n\n!Screenshot of a Markdown table with two columns of equal width as rendered on {% data variables.product.prodname_dotcom %}. Headers render in boldface, and alternate content rows have gray shading.\n\nThe pipes on either end of the table are optional.\n\nCells can vary in width and do not need to be perfectly aligned within columns. There must be at least three hyphens in each column of the header row.\n\n```markdown\n| Command | Description |\n| --- | --- |\n| git status | List all new or modified files |\n| git diff | Show file differences that haven't been staged |\n```\n\n!Screenshot of a Markdown table with two columns of differing width as rendered on {% data variables.product.prodname_dotcom %}. Rows list the commands \"git status\" and \"git diff\" and their descriptions.\n\n{% data reusables.user-settings.enabling-fixed-width-fonts %}\n\n\n\nFormatting content within your table\n\nYou can use formatting such as links, inline code blocks, and text styling within your table:\n\n```markdown\n| Command | Description |\n| --- | --- |\n| `git status` | List all *new or modified* files |\n| `git diff` | Show file differences that **haven't been** staged |\n```\n\n!Screenshot of a Markdown table with two columns of differing width as rendered on {% data variables.product.prodname_dotcom %}. The commands \"git status\" and \"git diff\" are formatting as code blocks.\n\nYou can align text to the left, right, or center of a column by including colons `:` to the left, right, or on both sides of the hyphens within the header row.\n\n```markdown\n| Left-aligned | Center-aligned | Right-aligned |\n| :---         |     :---:      |          ---: |\n| git status   | git stat", "Y2h1bmtfMV9pbmRleF8xMzIy": "us     | git status    |\n| git diff     | git diff       | git diff      |\n```\n\n!Screenshot of a Markdown table with three columns as rendered on {% data variables.product.prodname_dotcom %}, showing how text within cells can be set to align left, center, or right.\n\nTo include a pipe `|` as content within your cell, use a `\\` before the pipe:\n\n```markdown\n| Name     | Character |\n| ---      | ---       |\n| Backtick | `         |\n| Pipe     | \\|        |\n```\n\n!Screenshot of a Markdown table as rendered on {% data variables.product.prodname_dotcom %} showing how pipes, which normally close cells, can display inside cells when prefaced by a backslash.\n\n\n\nFurther reading\n\n- {% data variables.product.prodname_dotcom %} Flavored Markdown Spec\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8xNTgw": "\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8xNTMy": "\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8yODY=": "\n\nPrerequisites\n\nBefore enabling {% data variables.product.prodname_actions %}, make sure you have completed the following steps:\n\n- Create your Google Cloud Storage bucket for storing data generated by workflow runs.\n{% data reusables.actions.enterprise-common-prereqs %}\n{% data reusables.actions.enterprise-oidc-prereqs %}\n\n{% ifversion ghes-actions-storage-oidc %}\n\n\n\nEnabling {% data variables.product.prodname_actions %} with Google Cloud Storage using OIDC (recommended)\n\nTo configure {% data variables.product.prodname_ghe_server %} to use OIDC with Google Cloud Storage, you must first create a Google Cloud service account, then create a Google Cloud identity pool and identity provider, and finally configure {% data variables.product.prodname_ghe_server %} to use the provider and service account to access your Google Cloud Storage bucket.\n\n\n\n1. Create a service account\n\n1. Create a service account that can access your bucket using OIDC. For more information, see Creating and managing service accounts in the Google Cloud documentation.\n\n   When creating the service account, ensure that you do the following:\n\n   - Enable the IAM API as described at the start of Creating and managing service accounts.\n   - Add the following roles to the service account:\n     - Service Account Token Creator\n     - Storage Object Admin\n1. After creating the service account, note its email address, as it is need later. The service account email address is in the format `SERVICE-ACCOUNT-NAME@PROJECT-NAME.iam.gserviceaccount.com`.\n\n\n\n2. Create an identity pool and identity provider\n\n1. In the Google Cloud console, go to the New workload provider and pool page.\n1. Under \"Create an identity pool\", enter a name for the identity pool, and click **Continue**.\n1. Under \"Add a provider to pool\":\n\n   - For \"Select a provider\", select **OpenID Connect (OIDC)**.\n   - For \"Provider name\", enter a name for the provider.\n   - For \"Issuer (URL)\", enter the following URL, replacing `HOSTNAME` with the public hostname for {% data variables.location.pr", "Y2h1bmtfMV9pbmRleF8yODY=": "oduct_location_enterprise %}:\n\n     ```text\n     https://HOSTNAME/_services/token\n     ```\n\n     For example:\n\n     ```text\n     https://my-ghes-host.example.com/_services/token\n     ```\n\n   - Under \"Audiences\", leave **Default audience** selected, but note the identity provider URL, as it is needed later. The identity provider URL is in the format `https://iam.googleapis.com/projects/PROJECT-NUMBER/locations/global/workloadIdentityPools/POOL-NAME/providers/PROVIDER-NAME`.\n   - Click **Continue**.\n1. Under \"Configure provider attributes\":\n\n   - For the \"OIDC 1\" mapping, enter `assertion.sub`.\n   - Under \"Attribute Conditions\", click **Add condition**.\n   - For \"Condition CEL\", enter the following condition, replacing `HOSTNAME` with the public hostname for {% data variables.location.product_location_enterprise %}:\n\n     ```text\n     google.subject == \"HOSTNAME\"\n     ```\n\n     For example:\n\n     ```text\n     google.subject == \"my-ghes-host.example.com\"\n     ```\n\n     {% note %}\n\n     **Note:** The hostname of {% data variables.location.product_location_enterprise %} used here _must not_ include the protocol.\n\n     {% endnote %}\n   - Click **Save**.\n1. After creating the identity pool, at the top of the identity pool's page, click **Grant access**.\n   - Under \"Select service account\", select the service account that you created in the previous procedure.\n   - Under \"Select principals (identities that can access the service account)\", select **Only identities matching the filter**.\n   - For \"Attribute name\", select **subject**.\n   - For \"Attribute value\", enter your {% data variables.product.prodname_ghe_server %} hostname, without the protocol. For example, `my-ghes-host.example.com`.\n   - Click **Save**.\n   - You can dismiss the \"Configure your application\" dialog, as the configuration file is not needed.\n\n\n\n3. Configure {% data variables.product.prodname_ghe_server %} to connect to Google Cloud Storage using OIDC\n\n{% data reusables.enterprise_site_admin_settings.access-settings %}\n{% data reusables.enterprise_sit", "Y2h1bmtfMl9pbmRleF8yODY=": "e_admin_settings.management-console %}\n{% data reusables.enterprise_management_console.actions %}\n{% data reusables.actions.enterprise-enable-checkbox %}\n{% data reusables.actions.enterprise-gcp-storage-setup %}\n1. Under \"Authentication\", select **OpenID Connect (OIDC)**, and enter the values for your storage:\n   - **Service URL**: The service URL for your bucket. This is usually `https://storage.googleapis.com`.\n   - **Bucket name**: The name of your bucket.\n   - **Workload Identity Provider ID**: The identity provider ID for your identity pool.\n\n     This is in the format `projects/PROJECT-NUMBER/locations/global/workloadIdentityPools/POOL-NAME/providers/PROVIDER-NAME`. Note that you must remove the `https://iam.googleapis.com/` prefix from the value noted in the previous procedure.\n\n     For example, `projects/1234567890/locations/global/workloadIdentityPools/my-pool/providers/my-provider`.\n   - **Service account**: The service account email address that you noted in the previous procedure. For example, `ghes-oidc-service-account@my-project.iam.gserviceaccount.com`.\n{% data reusables.enterprise_management_console.test-storage-button %}\n{% data reusables.enterprise_management_console.save-settings %}\n\n{% endif %}\n\n\n\nEnabling {% data variables.product.prodname_actions %} with Google Cloud Storage{% ifversion ghes-actions-storage-oidc %} using a HMAC key{% endif %}\n\n1. Create a Google Cloud service account that can access the bucket, and create a Hash-based Message Authentication Code (HMAC) key for the service account. For more information, see \"Manage HMAC keys for service accounts\" in the Google Cloud documentation.\n\n   The service account must have the following Identity and Access Management (IAM) permissions for the bucket:\n\n   - `storage.objects.create`\n   - `storage.objects.get`\n   - `storage.objects.list`\n   - `storage.objects.update`\n   - `storage.objects.delete`\n   - `storage.multipartUploads.create`\n   - `storage.multipartUploads.abort`\n   - `storage.multipartUploads.listParts`\n   - `storage.multipart", "Y2h1bmtfM19pbmRleF8yODY=": "Uploads.list`\n{% data reusables.enterprise_site_admin_settings.access-settings %}\n{% data reusables.enterprise_site_admin_settings.management-console %}\n{% data reusables.enterprise_management_console.actions %}\n{% data reusables.actions.enterprise-enable-checkbox %}\n{%- ifversion ghes-actions-storage-oidc %}\n{% data reusables.actions.enterprise-gcp-storage-setup %}\n1. Under \"Authentication\", select **Credentials-based**, and enter your storage bucket's details:\n\n   {% data reusables.actions.enterprise-gcp-storage-credential-fields %}\n{%- else %}\n1. Under \"Artifact & Log Storage\", select **Google Cloud Storage**, and enter your bucket's details:\n\n   {% data reusables.actions.enterprise-gcp-storage-credential-fields %}\n{%- endif %}\n{% data reusables.enterprise_management_console.test-storage-button %}\n{% data reusables.enterprise_management_console.save-settings %}\n\n{% data reusables.actions.enterprise-postinstall-nextsteps %}\n\n", "Y2h1bmtfMF9pbmRleF8xNjY=": "\n\nIntroduction\n\nGitLab CI/CD and {% data variables.product.prodname_actions %} both allow you to create workflows that automatically build, test, publish, release, and deploy code. GitLab CI/CD and {% data variables.product.prodname_actions %} share some similarities in workflow configuration:\n\n- Workflow configuration files are written in YAML and are stored in the code's repository.\n- Workflows include one or more jobs.\n- Jobs include one or more steps or individual commands.\n- Jobs can run on either managed or self-hosted machines.\n\nThere are a few differences, and this guide will show you the important differences so that you can migrate your workflow to {% data variables.product.prodname_actions %}.\n\n\n\nJobs\n\nJobs in GitLab CI/CD are very similar to jobs in {% data variables.product.prodname_actions %}. In both systems, jobs have the following characteristics:\n\n- Jobs contain a series of steps or scripts that run sequentially.\n- Jobs can run on separate machines or in separate containers.\n- Jobs run in parallel by default, but can be configured to run sequentially.\n\nYou can run a script or a shell command in a job. In GitLab CI/CD, script steps are specified using the `script` key. In {% data variables.product.prodname_actions %}, all scripts are specified using the `run` key.\n\nBelow is an example of the syntax for each system.\n\n\n\nGitLab CI/CD syntax for jobs\n\n{% raw %}\n\n```yaml\njob1:\n  variables:\n    GIT_CHECKOUT: \"true\"\n  script:\n    - echo \"Run your script here\"\n```\n\n{% endraw %}\n\n\n\n{% data variables.product.prodname_actions %} syntax for jobs\n\n```yaml\njobs:\n  job1:\n    steps:\n      - uses: {% data reusables.actions.action-checkout %}\n      - run: echo \"Run your script here\"\n```\n\n\n\nRunners\n\nRunners are machines on which the jobs run. Both GitLab CI/CD and {% data variables.product.prodname_actions %} offer managed and self-hosted variants of runners. In GitLab CI/CD, `tags` are used to run jobs on different platforms, while in {% data variables.product.prodname_actions %} it is done with the `runs-on` key.", "Y2h1bmtfMV9pbmRleF8xNjY=": "\n\nBelow is an example of the syntax for each system.\n\n\n\nGitLab CI/CD syntax for runners\n\n{% raw %}\n\n```yaml\nwindows_job:\n  tags:\n    - windows\n  script:\n    - echo Hello, %USERNAME%!\n\nlinux_job:\n  tags:\n    - linux\n  script:\n    - echo \"Hello, $USER!\"\n```\n\n{% endraw %}\n\n\n\n{% data variables.product.prodname_actions %} syntax for runners\n\n{% raw %}\n\n```yaml\nwindows_job:\n  runs-on: windows-latest\n  steps:\n    - run: echo Hello, %USERNAME%!\n\nlinux_job:\n  runs-on: ubuntu-latest\n  steps:\n    - run: echo \"Hello, $USER!\"\n```\n\n{% endraw %}\n\nFor more information, see \"AUTOTITLE.\"\n\n\n\nDocker images\n\nBoth GitLab CI/CD and {% data variables.product.prodname_actions %} support running jobs in a Docker image. In GitLab CI/CD, Docker images are defined with an `image` key, while in {% data variables.product.prodname_actions %} it is done with the `container` key.\n\nBelow is an example of the syntax for each system.\n\n\n\nGitLab CI/CD syntax for Docker images\n\n{% raw %}\n\n```yaml\nmy_job:\n  image: node:10.16-jessie\n```\n\n{% endraw %}\n\n\n\n{% data variables.product.prodname_actions %} syntax for Docker images\n\n{% raw %}\n\n```yaml\njobs:\n  my_job:\n    container: node:10.16-jessie\n```\n\n{% endraw %}\n\nFor more information, see \"AUTOTITLE.\"\n\n\n\nCondition and expression syntax\n\nGitLab CI/CD uses `rules` to determine if a job will run for a specific condition. {% data variables.product.prodname_actions %} uses the `if` keyword to prevent a job from running unless a condition is met.\n\nBelow is an example of the syntax for each system.\n\n\n\nGitLab CI/CD syntax for conditions and expressions\n\n{% raw %}\n\n```yaml\ndeploy_prod:\n  stage: deploy\n  script:\n    - echo \"Deploy to production server\"\n  rules:\n    - if: '$CI_COMMIT_BRANCH == \"master\"'\n```\n\n{% endraw %}\n\n\n\n{% data variables.product.prodname_actions %} syntax for conditions and expressions\n\n{% raw %}\n\n```yaml\njobs:\n  deploy_prod:\n    if: contains( github.ref, 'master')\n    runs-on: ubuntu-latest\n    steps:\n      - run: echo \"Deploy to production server\"\n```\n\n{% endraw %}\n\nFor more information, see \"AUT", "Y2h1bmtfMl9pbmRleF8xNjY=": "OTITLE.\"\n\n\n\nDependencies between Jobs\n\nBoth GitLab CI/CD and {% data variables.product.prodname_actions %} allow you to set dependencies for a job. In both systems, jobs run in parallel by default, but job dependencies in {% data variables.product.prodname_actions %} can be specified explicitly with the `needs` key. GitLab CI/CD also has a concept of `stages`, where jobs in a stage run concurrently, but the next stage will start when all the jobs in the previous stage have completed. You can recreate this scenario in {% data variables.product.prodname_actions %} with the `needs` key.\n\nBelow is an example of the syntax for each system. The workflows start with two jobs named `build_a` and `build_b` running in parallel, and when those jobs complete, another job called `test_ab` will run. Finally, when `test_ab` completes, the `deploy_ab` job will run.\n\n\n\nGitLab CI/CD syntax for dependencies between jobs\n\n{% raw %}\n\n```yaml\nstages:\n  - build\n  - test\n  - deploy\n\nbuild_a:\n  stage: build\n  script:\n    - echo \"This job will run first.\"\n\nbuild_b:\n  stage: build\n  script:\n    - echo \"This job will run first, in parallel with build_a.\"\n\ntest_ab:\n  stage: test\n  script:\n    - echo \"This job will run after build_a and build_b have finished.\"\n\ndeploy_ab:\n  stage: deploy\n  script:\n    - echo \"This job will run after test_ab is complete\"\n```\n\n{% endraw %}\n\n\n\n{% data variables.product.prodname_actions %} syntax for dependencies between jobs\n\n{% raw %}\n\n```yaml\njobs:\n  build_a:\n    runs-on: ubuntu-latest\n    steps:\n      - run: echo \"This job will be run first.\"\n\n  build_b:\n    runs-on: ubuntu-latest\n    steps:\n      - run: echo \"This job will be run first, in parallel with build_a\"\n\n  test_ab:\n    runs-on: ubuntu-latest\n    needs: [build_a,build_b]\n    steps:\n      - run: echo \"This job will run after build_a and build_b have finished\"\n\n  deploy_ab:\n    runs-on: ubuntu-latest\n    needs: [test_ab]\n    steps:\n      - run: echo \"This job will run after test_ab is complete\"\n```\n\n{% endraw %}\n\nFor more information, see \"AUTOTITLE.\"\n", "Y2h1bmtfM19pbmRleF8xNjY=": "\n\n\nScheduling workflows\n\nBoth GitLab CI/CD and {% data variables.product.prodname_actions %} allow you to run workflows at a specific interval. In GitLab CI/CD, pipeline schedules are configured with the UI, while in {% data variables.product.prodname_actions %} you can trigger a workflow on a scheduled interval with the \"on\" key.\n\nFor more information, see \"AUTOTITLE.\"\n\n\n\nVariables and secrets\n\nGitLab CI/CD and {% data variables.product.prodname_actions %} support setting variables in the pipeline or workflow configuration file, and creating secrets using the GitLab or {% data variables.product.product_name %} UI.\n\nFor more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n\n\n\nCaching\n\nGitLab CI/CD and {% data variables.product.prodname_actions %} provide a method in the configuration file to manually cache workflow files.\n\n{% ifversion actions-caching %}\n\nBelow is an example of the syntax for each system.\n\n\n\nGitLab CI/CD syntax for caching\n\n{% raw %}\n\n```yaml\nimage: node:latest\n\ncache:\n  key: $CI_COMMIT_REF_SLUG\n  paths:\n    - .npm/\n\nbefore_script:\n  - npm ci --cache .npm --prefer-offline\n\ntest_async:\n  script:\n    - node ./specs/start.js ./specs/async.spec.js\n```\n\n{% endraw %}\n\n\n\n{% data variables.product.prodname_actions %} syntax for caching\n\n```yaml\njobs:\n  test_async:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Cache node modules\n      uses: {% data reusables.actions.action-cache %}\n      with:\n        path: ~/.npm\n        key: {% raw %}v1-npm-deps-${{ hashFiles('**/package-lock.json') }}{% endraw %}\n        restore-keys: v1-npm-deps-\n```\n\n{% else %}\n\n{% data reusables.actions.caching-availability %}\n\n{% endif %}\n\n\n\nArtifacts\n\nBoth GitLab CI/CD and {% data variables.product.prodname_actions %} can upload files and directories created by a job as artifacts. In {% data variables.product.prodname_actions %}, artifacts can be used to persist data across multiple jobs.\n\nBelow is an example of the syntax for each system.\n\n\n\nGitLab CI/CD syntax for artifacts\n\n{% raw %}\n\n```yaml\nscript:\nartifacts:\n  paths:\n    - ", "Y2h1bmtfNF9pbmRleF8xNjY=": "math-homework.txt\n```\n\n{% endraw %}\n\n\n\n{% data variables.product.prodname_actions %} syntax for artifacts\n\n```yaml\n- name: Upload math result for job 1\n  uses: {% data reusables.actions.action-upload-artifact %}\n  with:\n    name: homework\n    path: math-homework.txt\n```\n\nFor more information, see \"AUTOTITLE.\"\n\n\n\nDatabases and service containers\n\nBoth systems enable you to include additional containers for databases, caching, or other dependencies.\n\nIn GitLab CI/CD, a container for the job is specified with the `image` key, while {% data variables.product.prodname_actions %} uses the `container` key. In both systems, additional service containers are specified with the `services` key.\n\nBelow is an example of the syntax for each system.\n\n\n\nGitLab CI/CD syntax for databases and service containers\n\n{% raw %}\n\n```yaml\ncontainer-job:\n  variables:\n    POSTGRES_PASSWORD: postgres\n    # The hostname used to communicate with the\n    # PostgreSQL service container\n    POSTGRES_HOST: postgres\n    # The default PostgreSQL port\n    POSTGRES_PORT: 5432\n  image: node:10.18-jessie\n  services:\n    - postgres\n  script:\n    # Performs a clean installation of all dependencies\n    # in the `package.json` file\n    - npm ci\n    # Runs a script that creates a PostgreSQL client,\n    # populates the client with data, and retrieves data\n    - node client.js\n  tags:\n    - docker\n```\n\n{% endraw %}\n\n\n\n{% data variables.product.prodname_actions %}  syntax for databases and service containers\n\n```yaml\njobs:\n  container-job:\n    runs-on: ubuntu-latest\n    container: node:10.18-jessie\n\n    services:\n      postgres:\n        image: postgres\n        env:\n          POSTGRES_PASSWORD: postgres\n\n    steps:\n      - name: Check out repository code\n        uses: {% data reusables.actions.action-checkout %}\n\n      # Performs a clean installation of all dependencies\n      # in the `package.json` file\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Connect to PostgreSQL\n        # Runs a script that creates a PostgreSQL client,\n        # ", "Y2h1bmtfNV9pbmRleF8xNjY=": "populates the client with data, and retrieves data\n        run: node client.js\n        env:\n          # The hostname used to communicate with the\n          # PostgreSQL service container\n          POSTGRES_HOST: postgres\n          # The default PostgreSQL port\n          POSTGRES_PORT: 5432\n```\n\nFor more information, see \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF8xNDM0": "\n\nFurther reading\n\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF82MTA=": "\n\nRequesting a new password\n\n1. To request a new password, visit {% ifversion fpt or ghec %}https://{% data variables.product.product_url %}/password_reset{% else %}`https://{% data variables.product.product_url %}/password_reset`{% endif %}.\n1. Enter the email address associated with your account on {% ifversion ghae %}{% data variables.product.product_name %}{% else %}{% data variables.location.product_location %}{% endif %}, then click **Send password reset email.** The email will be sent to the backup email address if you have one configured.\n1. We'll email you a link that will allow you to reset your password. You must click on this link within 3 hours of receiving the email. If you didn't receive an email from us, make sure to check your spam folder.\n1. If you have enabled two-factor authentication, you will be prompted for your 2FA credentials:\n{% ifversion fpt or ghec %}\n   - If you have {% data variables.product.prodname_mobile %}, you will be sent a push notification to verify your identity. Open the push notification or the {% data variables.product.prodname_mobile %} app and enter the two-digit code shown to you on the password reset page in your browser.\n      - To skip using {% data variables.product.prodname_mobile %} to verify, click **Enter two-factor authentication or recovery code**.\n{% endif %}\n   - Type your authentication code or one of your recovery codes and click **Verify**.\n     - If you have added a security key to your account, click **Use security key** instead of typing an authentication code.\n     {% ifversion fpt or ghec %}\n     - If you have set up {% data variables.product.prodname_mobile %}, click **Authenticate with {% data variables.product.prodname_mobile %}** instead.\n     {% endif %}\n     {% ifversion 2fa-recovery-flow %}\n     - If you have forgotten your password and you've lost access to your two-factor authentication credentials, click **Start a 2FA recovery request**. For more information, see \"AUTOTITLE.\"\n     {% endif %}\n1. In the text field under **Password**, type a", "Y2h1bmtfMV9pbmRleF82MTA=": " new password. Then, in the text field under **Confirm password**, type the password again.\n1. Click **Change password**. For help creating a strong password, see \"AUTOTITLE.\"\n\n{% tip %}\n\nTo avoid losing your password in the future, we suggest using a secure password manager.\n\n{% endtip %}\n\n\n\nChanging an existing password\n\n{% data reusables.repositories.blocked-passwords %}\n\n1. {% data variables.product.signin_link %} to {% data variables.product.product_name %}.\n{% data reusables.user-settings.access_settings %}\n{% data reusables.user-settings.security %}\n1. Under \"Change password\", type your old password, a strong new password, and confirm your new password. For help creating a strong password, see \"AUTOTITLE\"\n1. Click **Update password**.\n\n{% tip %}\n\nFor greater security, enable two-factor authentication in addition to changing your password. See About two-factor authentication for more details.\n\n{% endtip %}\n{% endif %}\n\n\n\nUpdating your access tokens\n\nSee \"AUTOTITLE\" for instructions on reviewing and deleting access tokens. To generate new access tokens, see \"AUTOTITLE.\"\n\n{% ifversion not ghae %}\n\nIf you have reset your account password and would also like to trigger a sign-out from the {% data variables.product.prodname_mobile %} app, you can revoke your authorization of the \"GitHub iOS\" or \"GitHub Android\" {% data variables.product.prodname_oauth_app %}. This will sign out all instances of the {% data variables.product.prodname_mobile %} app associated with your account. For additional information, see \"AUTOTITLE.\"\n\n{% endif %}\n\n\n\nUpdating your SSH keys\n\nSee \"AUTOTITLE\" for instructions on reviewing and deleting SSH keys. To generate and add new SSH keys, see \"AUTOTITLE.\"\n\n\n\nResetting API tokens\n\nIf you have any applications registered with {% data variables.product.product_name %}, you'll want to reset their OAuth tokens. For more information, see the \"AUTOTITLE\" endpoint.\n\n{% ifversion not ghae %}\n\n\n\nPreventing unauthorized access\n\nFor more tips on securing your account and preventing unauthorized access,", "Y2h1bmtfMl9pbmRleF82MTA=": " see \"AUTOTITLE.\"\n{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF8xMjA4": "\n\nRequirements\n\nTo be eligible for {% data variables.product.prodname_global_campus %}, including {% data variables.product.prodname_student_pack %} and other benefits, you must:\n- Be currently enrolled in a degree or diploma granting course of study such as a high school, secondary school, college, university, homeschool, or similar educational institution\n- Have a verifiable school-issued email address or upload documents that prove your current student status\n- Have a {% data variables.product.prodname_dotcom %} personal account\n- Be at least 13 years old\n\nDocuments that prove your current student status include a picture of your school ID with current enrollment date, class schedule, transcript, and affiliation or enrollment verification letter.\n\nDuring your tenure as a student, you may be prompted to periodically re-verify your current academic status.\n\n{% note %}\n\n**Note:** You cannot transfer academic discounts from one account to another. If you have more than one account you want to apply the discount to, consider merging your personal accounts and renaming the retained account if desired.\n\n{% endnote %}\n\nFor information about renewing your {% data variables.product.prodname_global_campus %} access, see \"AUTOTITLE.\"\n\n\n\nApplying to {% data variables.product.prodname_global_campus %}\n\n{% data reusables.education.benefits-page %}\n1. Under \"Individuals\", click **Get student benefits**.\n1. Under \"Select the academic status\", select **Student**.\n{% data reusables.education.select-email-address %}\n{% data reusables.education.school-name %}\n{% data reusables.education.plan-to-use-github %}\n{% data reusables.education.upload-proof-status %}\n{% data reusables.education.submit-application %}\n\n\n\nExpiration and renewals\n\nOnce your {% data variables.product.prodname_global_campus %} access expires, you may reapply if you're still eligible, although some of our partner offers for {% data variables.product.prodname_student_pack %} cannot renew. Most of the timed offers from our partners start once you set them up. To re", "Y2h1bmtfMV9pbmRleF8xMjA4": "apply, simply return to https://education.github.com, click your profile picture, then click **Reverify your academic affiliation**.\n\n!Screenshot of a profile menu on the GitHub Education website. The \"Reverify your academic affiliation\" menu option is outlined in dark orange.\n\nFor more information, see the {% data variables.product.prodname_student_pack %} page.\n\nTo see when your free access to the {% data variables.product.prodname_student_pack %} expires, visit your account's billing settings.\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- {% data variables.product.prodname_education %}\n\n", "Y2h1bmtfMF9pbmRleF8zNzE=": "\n\nInitiating an audit\n\nYou can initiate an SSH key audit from the \"All users\" tab of the site admin dashboard. After you click the **Start public key audit** button, you'll be taken to a confirmation screen explaining that initiating an SSH key audit will disable all public keys, preventing pushing and pulling over SSH. Users will be required to verify their public keys to restore SSH access.\n\nAfter you click the **Begin audit** button, all SSH keys are invalidated and will require approval. You'll see a notification indicating the audit has begun.\n\n\n\nWhat users see\n\nIf a user attempts to perform any git operation over SSH, it will fail and provide them with the following message:\n\n```shell\nERROR: Hi USERNAME. We're doing an SSH key audit.\nPlease visit http(s)://HOSTNAME/settings/ssh/audit/2\nto approve this key so we know it's safe.\nFingerprint: ed:21:60:64:c0:dc:2b:16:0f:54:5f:2b:35:2a:94:91\nfatal: The remote end hung up unexpectedly\n```\n\nWhen they follow the link, they're asked to approve the keys on their account. After they approve or reject their keys, they'll be able interact with repositories as usual.\n\n\n\nAdding an SSH key\n\n{% ifversion ghes %}\n\nWhen a new user adds an SSH key to an account, to confirm the user's access, {% data variables.product.product_name %} will prompt for authentication. For more information, see \"AUTOTITLE.\"\n\n{% endif %}\n\nWhen a user adds a key, they'll receive a notification email that will look something like this:\n\n    The following SSH key was added to your account:\n\n    [title]\n    ed:21:60:64:c0:dc:2b:16:0f:54:5f:2b:35:2a:94:91\n\n    If you believe this key was added in error, you can remove the key and disable access at the following location:\n\n    http(s)://HOSTNAME/settings/ssh\n\n", "Y2h1bmtfMF9pbmRleF8xNjMx": "\n\nAbout the {% data variables.product.prodname_container_registry %}\n\n{% data reusables.package_registry.container-registry-benefits %} For more information, see \"AUTOTITLE.\"\n\n\n\nAbout migration from the Docker registry\n\n{% data reusables.package_registry.container-registry-replaces-docker-registry %} If you've stored Docker images in the Docker registry, {% ifversion docker-ghcr-enterprise-migration %}an enterprise owner{% else %}{% data variables.product.company_short %}{% endif %} will gradually migrate the images to the {% data variables.product.prodname_container_registry %}. No action is required on your part.\n\n{% ifversion docker-ghcr-enterprise-migration %}\n\n{% note %}\n\n**Note**: {% data reusables.package_registry.container-registry-ghes-migration-availability %} For more information about finding the version of {% data variables.product.product_name %} that you use, see \"AUTOTITLE.\"\n\n{% endnote %}\n\n{% endif %}\n\nAfter a Docker image has been migrated to the {% data variables.product.prodname_container_registry %}, you'll see the following changes to the details for the package.\n\n- The package icon will be the {% data variables.product.prodname_container_registry %} logo (a {% octicon \"container\" aria-label=\"The container icon\" %} icon) instead of the Docker logo.\n- The domain in the pull URL will be {% data variables.product.prodname_container_registry_namespace %} instead of {% data variables.product.prodname_docker_registry_namespace %}.\n\n{% data reusables.package_registry.container-registry-migration-namespaces %}\n\n{% ifversion packages-rest-api %}\n\nAfter migration, you'll no longer be able to use the GraphQL API to query for packages with a `PackageType` of \"DOCKER\". Instead, you can use the REST API to query for packages with a `package_type` of \"container\". For more information, see \"AUTOTITLE\" in the REST API documentation.\n\n{% endif %}\n\n{% ifversion fpt or ghec %}\n\n\n\nAbout billing for {% data variables.product.prodname_container_registry %}\n\nFor more information about billing for the {% data variab", "Y2h1bmtfMV9pbmRleF8xNjMx": "les.product.prodname_container_registry %}, see \"AUTOTITLE.\"\n\n{% endif %}\n\n{% ifversion docker-ghcr-enterprise-migration %}\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n\n{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF80ODc=": "\n\nSelect the minimum permissions required\n\nWhen you register a {% data variables.product.prodname_github_app %}, select the minimum permissions that your {% data variables.product.prodname_github_app %} needs. If any keys or tokens for your app become compromised, this will limit the amount of damage that can occur. For more information about how to choose permissions, see \"AUTOTITLE.\"\n\nWhen your {% data variables.product.prodname_github_app %} creates an installation access token or user access token, you can further limit the repositories that the app can access and the permissions that the token has. For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n\n\n\nStay under the rate limit\n\nSubscribe to webhook events instead of polling the API for data. This will help your {% data variables.product.prodname_github_app %} stay within the API rate limit. For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n\nConsider using conditional requests to help you stay within the rate limit. For more information about conditional requests, see \"AUTOTITLE.\"\n\nIf possible, consider using consolidated GraphQL queries instead of REST API requests to help you stay within rate limits. For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n\nIf you do hit a rate limit and need to retry an API request, use the `x-ratelimit-reset` or `Retry-After` response headers. If these headers are not available, wait for an exponentially increasing amount of time between retries, and throw an error after a specific number of retries. For more information, see \"AUTOTITLE.\"\n\n\n\nSecure your app's credentials\n\nYou can generate a private key and client secret for your {% data variables.product.prodname_github_app %}. With these credentials, your app can generate installation access tokens, user access tokens, and refresh tokens. These tokens can be used to make API requests on behalf of an app installation or user.\n\nYou must store these credentials securely. The storage mechanism depends on your integrations architecture and the platform that it runs on.", "Y2h1bmtfMV9pbmRleF80ODc=": " In general, you should use a storage mechanism that is intended to store sensitive data on the platform that you are using.\n\n\n\nPrivate keys\n\nThe private key for your {% data variables.product.prodname_github_app %} grants access to every account that the app is installed on.\n\nConsider storing your {% data variables.product.prodname_github_app %}'s private key in a key vault, such as Azure Key Vault, and making it sign-only.\n\nAlternatively, you can store the key as an environment variable. However, this not as strong as storing the key in a key vault. If an attacker gains access to the environment, they can read the private key and gain persistent authentication as the {% data variables.product.prodname_github_app %}.\n\nYou should never hard code your private key in your app, even if your code is stored in a private repository. If your app is a native client, client-side app, or runs on a user device (as opposed to running on your servers), you should never ship your private key with your app.\n\nYou should not generate more private keys than you need. You should delete private keys that you no longer need. For more information, see \"AUTOTITLE.\"\n\n\n\nClient secrets\n\nClient secrets are used to generate user access tokens for your app, unless your app uses device flow. For more information, see \"AUTOTITLE.\"\n\nIf your app is a website or web app, consider storing your client secret in a key vault, such as Azure Key Vault, or as an encrypted environment variable or secret on your server.\n\nIf your app is a native client, client-side app, or runs on a user device (as opposed to running on your servers), you cannot secure your client secret. You should use caution if you plan to gate access to your own services based on tokens generated by your app because anyone can access the client secret to generate a token.\n\n\n\nInstallation access tokens, user access tokens, and refresh tokens\n\nInstallation access tokens are used to make API requests on behalf of an app installation. User access tokens are used to make API requests on beh", "Y2h1bmtfMl9pbmRleF80ODc=": "alf of a user. Refresh tokens are used to regenerate user access tokens. Your app can use its private key to generate an installation access token. Your app can use its client secret to generate a user access token and refresh token.\n\nIf your app is a website or web app, you should encrypt the tokens on your back end and ensure there is security around the systems that can access the tokens. Consider storing refresh tokens in a separate place from active access tokens.\n\nIf your app is a native client, client-side app, or runs on a user device (as opposed to running on your servers), you may not be able to secure tokens as well as an app that runs on your servers. You should not generate installation access tokens since doing so requires a private key. Instead, you should generate user access tokens. You should store tokens via the mechanism recommended for your app's platform, and keep in mind that the storage mechanism may not be fully secure.\n\n\n\nUse the appropriate token type\n\n{% data variables.product.prodname_github_apps %} can generate installation access tokens or user access tokens in order to make authenticated API requests.\n\nInstallation access tokens will attribute activity to your app. These are useful for automations that act independently of users.\n\nUser access tokens will attribute activity to a user and to your app. These are useful for taking actions based on user input or on behalf of a user.\n\nAn installation access token is restricted based on the {% data variables.product.prodname_github_app %}'s permissions and access. A user access token is restricted based on both the {% data variables.product.prodname_github_app %}'s permission and access and the user's permission and access. Therefore, if your {% data variables.product.prodname_github_app %} takes an action on behalf of a user, it should always use a user access token instead of an installation access token. Otherwise, your app might allow a user to see or do things that they shouldn't be able to see or do.\n\nYour app should never use a {% ", "Y2h1bmtfM19pbmRleF80ODc=": "data variables.product.pat_generic %} or {% data variables.product.company_short %} password to authenticate.\n\n\n\nValidate organization access for every new authentication\n\nWhen you use a user access token, you should track which organizations the token is authorized for. If an organization uses SAML SSO and a user has not performed SAML SSO, the user access token should not have access to that organization. You can use the `GET /user/installations` REST API endpoint to verify which organizations a user access token has access to. If the user is not authorized to access an organization, you should reject their access until they perform SAML SSO. For more information, see \"AUTOTITLE.\"\n\n\n\nExpire tokens\n\n{% data variables.product.company_short %} strongly encourages you to use user access tokens that expire. If you previously opted out of using user access tokens that expire but want to re-enable this feature, see \"AUTOTITLE.\"\n\nInstallation access tokens expire after one hour, expiring user access tokens expire after eight hours, and refresh tokens expire after six months. However, you can also revoke tokens as soon as you no longer need them. For more information, see \"AUTOTITLE\" to revoke an installation access token and \"AUTOTITLE\" to revoke a user access token.\n\n\n\nCache tokens\n\nUser access tokens and installation access tokens are meant to be used until they expire. You should cache tokens that you create. Before you create a new token, check your cache to see if you already have a valid token. Reusing tokens will make your app faster since it will make fewer requests to generate tokens.\n\n\n\nMake a plan for handling security breaches\n\nYou should have a plan in place so that you can handle any security breaches in a timely manner.\n\nIn the event that your app's private key or secret is compromised, you will need to generate a new key or secret, update your app to use the new key or secret, and delete your old key or secret.\n\nIn the event that installation access tokens, user access tokens, or refresh tokens are comp", "Y2h1bmtfNF9pbmRleF80ODc=": "romised, you should immediately revoke these tokens. For more information, see \"AUTOTITLE\" to revoke an installation access token and \"AUTOTITLE\" to revoke a user access token.\n\n\n\nConduct regular vulnerability scans\n\n{% data reusables.apps.app-scans %}\n\n\n\nChoose an appropriate environment\n\nIf your app runs on a server, verify that your server environment is secure and that it can handle the volume of traffic that you expect for your app.\n\n\n\nSubscribe to the minimum webhooks\n\nOnly subscribe to the webhook events that your app needs. This will help reduce latency since your app won't be receiving payloads that it doesn't need.\n\n\n\nUse a webhook secret\n\nYou should set a webhook secret for your {% data variables.product.prodname_github_app %} and verify that the signature of incoming webhook events match the secret. This helps to ensure that the incoming webhook event is a valid {% data variables.product.company_short %} event.\n\nFor more information, see \"AUTOTITLE.\" For an example, see \"AUTOTITLE.\"\n\n\n\nAllow time for users to accept new permissions\n\nWhen you add repository or organization permissions to your {% data variables.product.prodname_github_app %}, users who have the app installed on their personal account or organization will receive an email prompting them to review the new permissions. Until the user approves the new permissions, their app installation will only receive the old permissions.\n\nWhen you update permissions, you should consider making your app backwards compatible to give your users time to accept the new permissions. You can use the installation webhook with the `new_permissions_accepted` action property to learn when users accept new permissions for your app.\n\n\n\nUse services in a secure manner\n\n{% data reusables.apps.app-services %}\n\n\n\nAdd logging and monitoring\n\n{% data reusables.apps.apps-logging %}\n\n\n\nEnable data deletion\n\nIf your {% data variables.product.prodname_github_app %} is available to other users or organizations, you should give users and organization owners a way to delete thei", "Y2h1bmtfNV9pbmRleF80ODc=": "r data. Users should not need to email or call a support person in order to delete their data.\n\n\n\nFurther reading\n\n{% ifversion fpt or ghec %}\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n{% endif %}\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF80Nzk=": "\n\nAbout policies for teams in your enterprise\n\nYou can enforce policies to control how members of your enterprise on {% data variables.product.product_name %} manage teams. You can also allow organization owners to manage policies for teams. For more information, see \"AUTOTITLE.\"\n\n{% ifversion team-discussions %}\n\n\n\nEnforcing a policy for team discussions\n\nAcross all organizations owned by your enterprise, you can enable or disable team discussions, or allow owners to administer the setting on the organization level. For more information, see \"AUTOTITLE.\"\n\n{% data reusables.enterprise-accounts.access-enterprise %}\n{% data reusables.enterprise-accounts.policies-tab %}\n1. Under \"{% octicon \"law\" aria-hidden=\"true\" %} Policies\", click **Teams**.\n1. Under \"Team discussions\", review the information about changing the setting. {% data reusables.enterprise-accounts.view-current-policy-config-orgs %}\n1. Under \"Team discussions\", select the dropdown menu and click a policy.\n{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF8xNDcy": "\n\nAbout required access for {% data variables.product.prodname_importer_proper_name %}\n\nTo protect your data, {% data variables.product.company_short %} enforces specific access requirements to use {% data variables.product.prodname_importer_proper_name %}. To prevent errors, you should review this article carefully and verify that you meet all of the requirements for the task you want to complete.\n\nTo run a migration, you need sufficient access to both the source and the destination for your migration. For repository migrations, the destination is an organization. For organization migrations, the destination is an enterprise account.\n\nBefore you can migrate from {% data variables.product.prodname_ghe_server %} 3.8 or higher for the first time, you also need someone with access to the {% data variables.enterprise.management_console %} to set up blob storage for {% data variables.location.product_location_enterprise %}.\n\nFor other tasks, you only need access to the target of the operation. For example, to grant the migrator role for an organization, you only need access to that organization.\n\nTo have sufficient access for either the source or destination, you need both of the following:\n- A required role in the {% data variables.product.company_short %} organization or enterprise account\n- For Bitbucket Server, required permissions and SFTP or SMB access\n- For {% data variables.product.prodname_dotcom %} products and Azure DevOps, a {% data variables.product.pat_generic %} that can access the organization or enterprise account\n  - The {% data variables.product.pat_generic %} must have all the required scopes, which depend on your role and the task you want to complete.\n  - If the source or destination uses SAML single sign-on for {% data variables.product.prodname_dotcom_the_website %}, you must authorize the {% data variables.product.pat_generic %} for SSO.\n\nAdditionally, if you use IP allow lists with the source or destination, you may need to configure the allow lists to allow access by {% data variables.produc", "Y2h1bmtfMV9pbmRleF8xNDcy": "t.prodname_importer_proper_name %}.\n\n\n\nRequired roles for {% data variables.product.company_short %}\n\nWhen migrating to or from {% data variables.product.prodname_dotcom %} products, different roles are required for different tasks.\n\nTask | Enterprise owner | Organization owner | Migrator |\n---- | ------------ | ------- | ----- |\nRunning a migration (source organization) | | X | X |\nRunning an organization migration (destination enterprise) | X | | |\nAssigning the migrator role for repository migrations | | X | |\nRunning a repository migration (destination organization) | | X | X |\nDownloading a migration log | | X | X |\nReclaiming mannequins | | X | |\n\n\n\nRequired permissions for Bitbucket Server\n\nTo migrate from Bitbucket Server, you need:\n\n- The username and password of a Bitbucket Server account that has admin or super admin permissions\n- If your Bitbucket Server instances runs on Linux, SFTP access to the Bitbucket Server instance (see \"SSH keys\"). In general, if you can access the server via SSH, then you can also use SFTP.\n- If your Bitbucket Server instance runs on Windows, file sharing (SMB) access to the Bitbucket Server instance\n\n\n\nSSH keys\n\nIf your Bitbucket Server instance runs on Linux, you must use an SSH key that meets the following requirements:\n\n- Does not have a passphrase\n- Uses one of the following ciphers\n  - `aes256-ctr`\n  - `3des-cbc`\n  - `aes128-cbc`\n  - `aes192-cbc`\n  - `aes256-cbc`\n  - `blowfish-cbc`\n  - `twofish-cbc`\n  - `twofish192-cbc`\n  - `twofish128-cbc`\n  - `twofish256-cbc`\n  - `arcfour`\n  - `arcfour128`\n  - `arcfour256`\n  - `cast128-cbc`\n  - `aes128-ctr`\n  - `aes192-ctr`\n\nIf you receive an error like `cipher name aes256-ctr for openssh key file is not supported` when running a migration, your SSH private key uses an unsupported cipher. For more information about how to generate a compatible private key, see \"AUTOTITLE.\"\n\n\n\nRequired scopes for {% data variables.product.pat_generic %}s\n\nTo run a migration, you need a {% data variables.product.pat_generic %} that can access the desti", "Y2h1bmtfMl9pbmRleF8xNDcy": "nation organization (for repository migrations) or enterprise account (for organization migrations). If your source is a {% data variables.product.prodname_dotcom %} product or Azure DevOps, you also need another {% data variables.product.pat_generic %} that can access the source organization.\n\nFor other tasks, such as downloading a migration log, you only need one {% data variables.product.pat_generic %} that can access the target of the operation.\n\n\n\n{% data variables.product.pat_generic_caps %}s for {% data variables.product.prodname_dotcom %} products\n\nThe scopes that are required for your {% data variables.product.prodname_dotcom %} {% data variables.product.pat_v1 %} depend on your role and the task you want to complete.\n\n{% note %}\n\n**Note**: {% data reusables.user-settings.generic-classic-pat-only %} This means that you cannot use {% data variables.product.prodname_importer_proper_name %} if your organization uses the \"Restrict {% data variables.product.pat_v1_plural %} from accessing your organizations\" policy. For more information, see \"AUTOTITLE.\"\n\n{% endnote %}\n\nTask | Enterprise owner | Organization owner | Migrator\n---- | ------------------ | -------- | ----- |\nRunning a migration (source organization) | - | `read:org`, `repo` | `read:org`, `repo` |\nRunning an organization migration (destination enterprise) | `read:enterprise`, `admin:org`, `repo`, `workflow` | - | - |\nAssigning the migrator role for repository migrations | - | `admin:org` | -\nRunning a repository migration (destination organization) | - | `repo`, `admin:org`, `workflow` | `repo`, `read:org`, `workflow`\nDownloading a migration log | - | `repo`, `admin:org`, `workflow` | `repo`, `read:org`, `workflow`\nReclaiming mannequins | - | `admin:org` | -\n\n\n\n{% data variables.product.pat_generic_caps %}s for Azure DevOps\n\nTo run a migration from Azure DevOps (ADO), your ADO {% data variables.product.pat_generic %} must have `work item (read)`, `code (read)`, and `identity (read)` scopes.\n\nIf you want to migrate from multiple organizations, allo", "Y2h1bmtfM19pbmRleF8xNDcy": "w the {% data variables.product.pat_generic %} to access all accessible organizations. For more information, see Use {% data variables.product.pat_generic %}s in Microsoft Docs.\n\n\n\nCreating a {% data variables.product.pat_generic %} for {% data variables.product.prodname_importer_proper_name %}\n\n1. Verify that you have a sufficient role for the task you want to complete. For more information, see \"Required roles.\"\n1. Create a {% data variables.product.pat_v1 %}, making sure to grant all the scopes required for the task you want to complete. {% data reusables.user-settings.generic-classic-pat-only %} For more information, \"AUTOTITLE\" and \"Required scopes for {% data variables.product.pat_generic %}.\"\n1. If SAML single sign-on is enforced for the organization(s) you need to access, authorize the {% data variables.product.pat_generic %} for SSO. For more information, see \"AUTOTITLE.\"\n\n\n\nConfiguring IP allow lists for migrations\n\nIf you use IP allow lists with your migration source or destination, you may need to configure the lists to allow access to {% data variables.product.prodname_importer_proper_name %}.\n\nTo configure IP allow lists correctly, please read the following sections carefully. Depending on your migration, more than one section may apply to you.\n\n\n\nThe source or destination of your migration is {% data variables.product.prodname_dotcom_the_website %}\n\nYou need to configure IP allow lists on {% data variables.product.prodname_dotcom_the_website %} if **both** of the following apply to your migration:\n\n- The source or destination of your migration is {% data variables.product.prodname_dotcom_the_website %}\n- The source or destination uses an IP allow list, either {% data variables.product.company_short %}'s IP allow list feature or your identity provider's (IdP) IP allow list restrictions (such as Azure CAP)\n\nIf you use {% data variables.product.company_short %}'s IP allow list feature, you must add the {% data variables.product.prodname_dotcom %} IP ranges below to the allow list for the source and/or", "Y2h1bmtfNF9pbmRleF8xNDcy": " destination organizations.\n\nIf you use your IdP's IP allow list to restrict access to your enterprise on {% data variables.product.prodname_dotcom_the_website %}, you should disable these restrictions in your enterprise account settings until after your migration is complete.\n\nFor more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n\n\n\nThe source of your migration is {% data variables.product.prodname_ghe_server %}\n\nIf the source of your migration is {% data variables.product.prodname_ghe_server %}, you do not need to add any {% data variables.product.prodname_dotcom %} IP ranges to your firewall configuration or the IP allow list on {% data variables.location.product_location_enterprise %}.\n\nHowever, depending on the setup of your blob storage provider, you may need to update your blob storage provider's configuration to allow access to the {% data variables.product.prodname_dotcom %} IP ranges below.\n\n\n\nIdentifying {% data variables.product.prodname_dotcom %}'s IP ranges\n\nYou'll need to add the following IP ranges to your IP allowlist(s):\n\n- 192.30.252.0/22\n- 185.199.108.0/22\n- 140.82.112.0/20\n- 143.55.64.0/20\n- 40.71.233.224/28\n- 2a0a:a440::/29\n- 2606:50c0::/32\n- 20.125.12.8/29 _(active from 00:00 UTC on November 8, 2023)_\n\nYou can get an up-to-date list of IP ranges used by {% data variables.product.prodname_importer_proper_name %} at any time with the \"Get {% data variables.product.prodname_dotcom %} meta information\" endpoint of the REST API.\n\nThe `github_enterprise_importer` key in the response contains a list of IP ranges used for migrations.\n\nFor more information, see \"AUTOTITLE\" in the REST API documentation.\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8yMDk1": "\n\nJoining {% data variables.product.prodname_sponsors %}\n\n{% data reusables.sponsors.you-can-be-a-sponsored-organization %} {% data reusables.sponsors.stripe-supported-regions %}\n\nAfter you receive an invitation for your organization to join {% data variables.product.prodname_sponsors %}, you can complete the steps below to become a sponsored organization.\n\nTo join {% data variables.product.prodname_sponsors %} as an individual contributor outside an organization, see \"AUTOTITLE.\"\n\n{% data reusables.sponsors.navigate-to-github-sponsors %}\n{% data reusables.sponsors.view-eligible-accounts %}\n1. To the right of your organization, click **Join the waitlist**.\n{% data reusables.sponsors.contact-info %}\n{% data reusables.sponsors.payout-choice %}\n{% data reusables.sponsors.accept-legal-terms %}\n\n\n\nCompleting your sponsored organization profile\n\n{% data reusables.sponsors.navigate-to-sponsors-dashboard %}\n{% data reusables.sponsors.navigate-to-profile-tab %}\n{% data reusables.sponsors.short-bio %}\n{% data reusables.sponsors.add-introduction %}\n{% data reusables.sponsors.meet-the-team %}\n{% data reusables.sponsors.edit-featured-work %}\n{% data reusables.sponsors.opt-in-to-being-featured %}\n{% data reusables.sponsors.save-profile %}\n\n\n\nCreating sponsorship tiers\n\n{% data reusables.sponsors.tier-details %}\n\n{% data reusables.sponsors.maximum-tier %}\n\n{% data reusables.sponsors.navigate-to-sponsors-dashboard %}\n{% data reusables.sponsors.navigate-to-sponsor-tiers-tab %}\n{% data reusables.sponsors.click-add-tier %}\n{% data reusables.sponsors.tier-price-description %}\n{% data reusables.sponsors.add-welcome-message %}\n{% data reusables.sponsors.save-tier-draft %}\n{% data reusables.sponsors.review-and-publish-tier %}\n{% data reusables.sponsors.add-more-tiers %}\n\n\n\nSubmitting your bank information\n\nAs a sponsored organization, you will receive payouts to a bank account in a supported region or via a fiscal host.\n\n{% data reusables.sponsors.bank-info-fiscal-host-reminder %} For more information about setting up and using fiscal ", "Y2h1bmtfMV9pbmRleF8yMDk1": "hosts, see \"AUTOTITLE.\"\n\nIf you choose to receive payouts to a bank account, your bank account can be a dedicated bank account for your organization or a personal bank account. You can get a business bank account through services like Stripe Atlas. The person setting up {% data variables.product.prodname_sponsors %} for the organization must live in the same supported region, too. {% data reusables.sponsors.stripe-supported-regions %}\n\n{% data reusables.sponsors.double-check-stripe-info %}\n\n{% data reusables.sponsors.navigate-to-sponsors-dashboard %}\n{% data reusables.sponsors.create-stripe-account %}\n\n\n\nSubmitting your tax information\n\n{% data reusables.sponsors.tax-form-information-org %}\n\n{% data reusables.sponsors.navigate-to-sponsors-dashboard %}\n{% data reusables.sponsors.overview-tab %}\n{% data reusables.sponsors.tax-form-link %}\n\n\n\nEnabling two-factor authentication (2FA) on your {% data variables.product.prodname_dotcom %} account\n\nBefore your organization can become a sponsored organization, you must enable 2FA for your account on {% data variables.location.product_location %}. For more information, see \"AUTOTITLE.\"\n\n\n\nSubmitting your application to {% data variables.product.prodname_dotcom %} for approval\n\n{% data reusables.sponsors.navigate-to-sponsors-dashboard %}\n{% data reusables.sponsors.request-approval %}\n\n{% data reusables.sponsors.github-review-app %}\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF81ODA=": "\n\nAbout passkeys\n\n{% data reusables.passkeys.about-passkeys %}\n\nPasskeys are pairs of cryptographic keys (a public key and a private key) that are stored by an authenticator you control. The authenticator can prove that a user is present and is authorized to use the passkey. Authenticators prove authorization with a PIN, passcode, biometric, or device password, depending on the authenticator's capabilities and configuration. Authenticators come in many forms, such as an iPhone or Android device, Windows Hello, a FIDO2 hardware security key, or a password manager.\n\nWhen you sign in to {% data variables.product.prodname_dotcom_the_website %} using a passkey, your authenticator uses public key cryptography to prove your identity to {% data variables.product.company_short %} without ever sending the passkey. Passkeys are bound to a website domain, like `{% data variables.product.prodname_dotcom_the_website %}`, and require a secure connection, meaning that the web browser will refuse to authenticate to a lookalike phishing website. These properties make passkeys highly phishing-resistant, and much harder to attack than SMS or TOTP 2FA, which can be phished.\n\nCloud-backed passkey services allow passkeys to be synced across devices (such as Apple devices, Android devices, or password managers) so they can be used from more places and are less easily lost. Once you have set up a synced passkey on one device, that passkey is available to use across multiple devices using the same service. For example, if you register a passkey with your iCloud account using your MacBook's Touch ID, you can then use that passkey with your face, fingerprint, PIN, or device password interchangeably across multiple devices tied to the same iCloud account.\n\nFor more information about adding a passkey to your account, see \"AUTOTITLE.\"\n\nFor 2FA users, if you already have passkey-eligible security keys registered to your account for 2FA, you can upgrade these existing credentials into passkeys in your account settings. When you use an eligible s", "Y2h1bmtfMV9pbmRleF81ODA=": "ecurity key to sign in, you'll also be asked if you want to upgrade it to a passkey. For more information, see \"AUTOTITLE.\"\n\n\n\nAbout authenticators\n\nSome authenticators allow passkeys to be used with nearby devices. For example, perhaps you want to sign in to {% data variables.product.prodname_dotcom_the_website %} using a bluetooth-enabled laptop that's not set up with a passkey. If you have registered a passkey on your phone, you might opt to scan a QR code, or trigger a push notification to your phone, in order to complete the sign in securely. For more information, see \"AUTOTITLE.\"\n\nOther authenticators create device-bound passkeys, meaning they can only be used on a single authenticator. These passkeys cannot be backed up or moved to another authenticator. Some passkey providers may offer device-bound passkeys as an option during passkey creation, while other providers may not offer the choice between device-bound and synced passkeys.\n\nAuthenticators can also be portable devices. Passkeys stored on FIDO2 hardware security keys are also \"device-bound,\" but they have the advantage of being portable and can be attached to other devices in a variety of ways (USB, NFC or Bluetooth). On some platform and web browser combinations, FIDO2 security keys may be the only way to use passkeys.\n\nFor information on whether your device and operating system support passkeys, see Device support in the Passkeys.dev documentation, and Web Authentication API in the CanIUse documentation.\n\n\n\nFeedback\n\nYou can share your feedback on passkeys with {% data variables.product.company_short %}. To join the conversation, see \"[Feedback] Passkeys for passwordless authentication.\"\n\n\n\nFurther reading\n\n- AUTOTITLE\n- AUTOTITLE\n- AUTOTITLE\n\n", "Y2h1bmtfMF9pbmRleF8xODk0": "\n\nAbout repository pre-receive hooks\n\n{% data reusables.user-settings.enterprise-admin-api-classic-pat-only %}\n\n| Name                | Type     | Description                                               |\n|---------------------|----------|-----------------------------------------------------------|\n| `name`              | `string` | The name of the hook.                                     |\n| `enforcement`       | `string` | The state of enforcement for the hook on this repository. |\n| `configuration_url` | `string` | URL for the endpoint where enforcement is set.            |\n\nPossible values for _enforcement_ are `enabled`, `disabled` and`testing`. `disabled` indicates the pre-receive hook will not run. `enabled` indicates it will run and reject any pushes that result in a non-zero status. `testing` means the script will run but will not cause any pushes to be rejected.\n\n`configuration_url` may be a link to this repository, it's organization owner or global configuration. Authorization to access the endpoint at `configuration_url` is determined at the owner or site admin level.\n\n\n\n", "Y2h1bmtfMF9pbmRleF8xNDE=": "\n\nIntroduction\n\nThis tutorial demonstrates how to use the `alex-page/github-project-automation-plus` action to automatically move an issue to a specific column on a project board when the issue is assigned. For example, when an issue is assigned, you can move it into the `In Progress` column your project board.\n\nIn the tutorial, you will first make a workflow file that uses the `alex-page/github-project-automation-plus` action. Then, you will customize the workflow to suit your needs.\n\n\n\nCreating the workflow\n\n1. {% data reusables.actions.choose-repo %}\n1. In your repository, choose a project board. You can use an existing project, or you can create a new project. For more information about creating a project, see \"AUTOTITLE.\"\n1. {% data reusables.actions.make-workflow-file %}\n1. Copy the following YAML contents into your workflow file.\n\n    ```yaml copy\n    {% data reusables.actions.actions-not-certified-by-github-comment %}\n\n    {% data reusables.actions.actions-use-sha-pinning-comment %}\n\n    name: Move assigned card\n    on:\n      issues:\n        types:\n          - assigned\n    jobs:\n      move-assigned-card:\n        runs-on: ubuntu-latest\n        steps:\n          - uses: alex-page/github-project-automation-plus@7ffb872c64bd809d23563a130a0a97d01dfa8f43\n            with:\n              project: Docs Work\n              column: In Progress\n              repo-token: {% raw %}${{ secrets.PERSONAL_ACCESS_TOKEN }}{% endraw %}\n    ```\n\n1. Customize the parameters in your workflow file:\n   - Change the value for `project` to the name of your project board. If you have multiple project boards with the same name, the `alex-page/github-project-automation-plus` action will act on all projects with the specified name.\n   - Change the value for `column` to the name of the column where you want issues to move when they are assigned.\n   - Change the value for `repo-token`:\n     1. Create a {% data variables.product.pat_v1 %} with the `repo` scope. For more information, see \"AUTOTITLE.\"\n     1. Store this {% data variables.produ", "Y2h1bmtfMV9pbmRleF8xNDE=": "ct.pat_generic %} as a secret in your repository. For more information about storing secrets, see \"AUTOTITLE.\"\n     1. In your workflow file, replace `PERSONAL_ACCESS_TOKEN` with the name of your secret.\n1. {% data reusables.actions.commit-workflow %}\n\n\n\nTesting the workflow\n\nWhenever an issue in your repository is assigned, the issue will be moved to the specified project board column. If the issue is not already on the project board, it will be added to the project board.\n\nIf your repository is user-owned, the `alex-page/github-project-automation-plus` action will act on all projects in your repository or personal account that have the specified project name and column. Likewise, if your repository is organization-owned, the action will act on all projects in your repository or organization that have the specified project name and column.\n\nTest your workflow by assigning an issue in your repository.\n\n1. Open an issue in your repository. For more information, see \"AUTOTITLE.\"\n1. Assign the issue. For more information, see \"AUTOTITLE.\"\n1. To see the workflow run that assigning the issue triggered, view the history of your workflow runs. For more information, see \"AUTOTITLE.\"\n1. When the workflow completes, the issue that you assigned should be added to the specified project board column.\n\n\n\nNext steps\n\n- To learn more about additional things you can do with the `alex-page/github-project-automation-plus` action, like deleting or archiving project cards, visit the `alex-page/github-project-automation-plus` action documentation.\n\n", "Y2h1bmtfMF9pbmRleF82ODQ=": "\n\nExample of canceling a paid subscription for a personal account or organization\n\nKumiko pays for a monthly subscription on the 5th of every month. If Kumiko downgrades from the paid subscription to {% data variables.product.prodname_free_user %} on October 10th, her paid subscription will remain in effect until the end of her current billing cycle on November 4th. On November 5th, her account will move to {% data variables.product.prodname_free_user %}.\n\n\n\nExample of changing from a yearly to a monthly subscription for a personal account or organization\n\nRavi pays for a yearly subscription on October 5th every year. If Ravi switches from a yearly to monthly billing on December 10th, his account remains on the yearly subscription until the end of its current billing cycle on October 4th the next year. On October 5th of the next year, Ravi will be charged for a month of service. His next billing date will be November 5th.\n\n\n\nExample of adding paid seats to your organization\n\nMada's organization pays for 25 seats on the 15th of every month. If Mada adds ten paid seats on June 4th, her organization is immediately charged a prorated amount for ten additional seats for the time between June 4th and June 14th, and the seats are available to use immediately. On June 15th, Mada's organization will pay for 35 seats.\n\n\n\nExample of removing paid seats from your organization\n\nStefan's organization pays for 50 seats every year on May 20th. If Stefan removes 20 seats and downgrades to a new total of 30 paid seats on September 30, his organization can still access its 50 paid seats until the end of its current billing cycle on May 19th. On May 20th, the downgrade will take effect - Stefan's organization will pay for 30 seats and will have access to 30 paid seats.\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8xNTE=": "\n\nDeleting an artifact\n\n{% warning %}\n\n**Warning:** Once you delete an artifact, it cannot be restored.\n\n{% endwarning %}\n\n{% data reusables.repositories.permissions-statement-write %}\n\n{% data reusables.actions.artifact-log-retention-statement %}\n\n{% data reusables.repositories.navigate-to-repo %}\n{% data reusables.repositories.actions-tab %}\n{% data reusables.repositories.navigate-to-workflow %}\n{% data reusables.repositories.view-run %}\n1. Under **Artifacts**, click {% octicon \"trash\" aria-label=\"Remove artifact ARTIFACT-NAME\" %} next to the artifact you want to remove.\n\n    !Screenshot showing artifacts created during a workflow run. A trash can icon, used to remove an artifact, is outlined in dark orange.\n\n\n\nSetting the retention period for an artifact\n\nRetention periods for artifacts and logs can be configured at the repository, organization, and enterprise level. For more information, see {% ifversion fpt or ghec or ghes %}\"AUTOTITLE.\"{% elsif ghae %}\"AUTOTITLE,\" \"AUTOTITLE,\" or \"AUTOTITLE.\"{% endif %}\n\nYou can also define a custom retention period for individual artifacts using the `actions/upload-artifact` action in a workflow. For more information, see \"AUTOTITLE.\"\n\n\n\nFinding the expiration date of an artifact\n\nYou can use the API to confirm the date that an artifact is scheduled to be deleted. For more information, see the `expires_at` value returned by \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF8xMjQ3": "---\ntitle: About using integrations\nintro: 'Integrations are tools and services that connect with {% data variables.product.product_name %} to complement and extend your workflow.'\nredirect_from:\n  - /articles/about-integrations\n  - /github/customizing-your-github-workflow/about-integrations\n  - /github/customizing-your-github-workflow/exploring-integrations/about-integrations\n  - /get-started/customizing-your-github-workflow/exploring-integrations/about-integrations\n  - /articles/about-github-marketplace\n  - /github/customizing-your-github-workflow/about-github-marketplace\n  - /github/customizing-your-github-workflow/exploring-integrations/about-github-marketplace\n  - /get-started/customizing-your-github-workflow/exploring-integrations/about-github-marketplace\n  - /get-started/exploring-integrations/about-github-marketplace\n  - /get-started/exploring-integrations/about-integrations\nversions:\n  fpt: '*'\n  ghes: '*'\n  ghae: '*'\n  ghec: '*'\n---\n\nIntegrations are tools that extend {% data variables.product.company_short %}'s functionality. Integrations can do things on {% data variables.product.company_short %} like open issues, comment on pull requests, and manage projects. They can also do things outside of {% data variables.product.company_short %} based on events that happen on {% data variables.product.company_short %}. For example, an integration can post on Slack when an issue is opened on {% data variables.product.company_short %}.\n\nYou can discover many integrations in {% data variables.product.prodname_marketplace %}. {% data variables.product.prodname_marketplace %} includes {% data variables.product.prodname_github_apps %}, {% data variables.product.prodname_oauth_apps %}, and custom actions that you can use in {% data variables.product.prodname_actions %} workflows. You can also get integrations directly from the integration creator.\n\n{% ifversion fpt or ghec or ghes > 3.7 %} For a list of featured {% data variables.product.company_short %} integrations, see \"AUTOTITLE.\"{% endif %}\n\n{% ifversion ghes %}", "Y2h1bmtfMV9pbmRleF8xMjQ3": "\n\nIf you want your {% data variables.product.prodname_ghe_server %} instance to use a third-party {% data variables.product.prodname_github_app %}, you can contact the app developer about making the {% data variables.product.prodname_github_app %} available for {% data variables.product.prodname_ghe_server %}. For more information, see \"AUTOTITLE.\"\n\nIf you want your {% data variables.product.prodname_ghe_server %} instance to use third-party custom actions, you need to enable {% data variables.product.prodname_github_connect %}. For more information, see \"AUTOTITLE.\"\n\n{% endif %}\n\nFor more information about using integrations, see:\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\nYou can also build your own integrations. For more information, see \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF8xNTc3": "\n\nAbout SAML and SCIM with Okta\n\nYou can control access to your organization on {% data variables.location.product_location %} and other web applications from one central interface by configuring the organization to use SAML SSO and SCIM with Okta, an Identity Provider (IdP).\n\n{% data reusables.saml.ghec-only %}\n\nSAML SSO controls and secures access to organization resources like repositories, issues, and pull requests. SCIM automatically adds, manages, and removes members' access to your organization on {% data variables.location.product_location %} when you make changes in Okta. For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n\nAfter you enable SCIM, the following provisioning features are available for any users that you assign your {% data variables.product.prodname_ghe_cloud %} application to in Okta.\n\n| Feature | Description |\n| --- | --- |\n| Push New Users | When you create a new user in Okta, the user will receive an email to join your organization on {% data variables.location.product_location %}. |\n| Push User Deactivation | When you deactivate a user in Okta, Okta will remove the user from your organization on {% data variables.location.product_location %}. |\n| Push Profile Updates | When you update a user's profile in Okta, Okta will update the metadata for the user's membership in your organization on {% data variables.location.product_location %}. |\n| Reactivate Users | When you reactivate a user in Okta, Okta will send an email invitation for the user to rejoin your organization on {% data variables.location.product_location %}. |\n\nAlternatively, you can configure SAML SSO for an enterprise using Okta. SCIM for enterprise accounts is only available with Enterprise Managed Users. For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n\n\n\nConfiguring SAML in Okta\n\n{% data reusables.saml.okta-ae-applications-menu %}\n{% data reusables.saml.okta-browse-app-catalog %}\n{% data reusables.saml.okta-add-ghec-org-integration %}\n1. Fill out the form, providing the name of your organization on {% data vari", "Y2h1bmtfMV9pbmRleF8xNTc3": "ables.product.prodname_dotcom %} and a unique name in the \"Application Label\" field.\n{% data reusables.saml.assign-yourself-to-okta %}\n{% data reusables.saml.okta-sign-on-tab %}\n{% data reusables.saml.okta-view-setup-instructions %}\n1. Enable and test SAML SSO on {% data variables.product.prodname_dotcom %} using the sign on URL, issuer URL, and public certificates from the \"How to Configure SAML 2.0\" guide. For more information, see \"AUTOTITLE.\"\n\n\n\nConfiguring access provisioning with SCIM in Okta\n\n{% data reusables.scim.dedicated-configuration-account %}\n\n1. Sign into {% data variables.product.prodname_dotcom_the_website %} using an account that is an organization owner and is ideally used only for SCIM configuration.\n1. To create an active SAML session for your organization, navigate to `https://github.com/orgs/ORGANIZATION-NAME/sso`. For more information, see \"AUTOTITLE.\"\n1. Navigate to Okta.\n{% data reusables.saml.okta-dashboard-click-applications %}\n{% data reusables.saml.okta-applications-click-ghec-application-label %}\n{% data reusables.saml.okta-provisioning-tab %}\n{% data reusables.saml.okta-configure-api-integration %}\n{% data reusables.saml.okta-enable-api-integration %}\n1. Click **Authenticate with {% data variables.product.prodname_ghe_cloud %} - Organization**.\n1. To the right of your organization's name, click **Grant**.\n\n   {% note %}\n\n   **Note:** If you cannot see your organization, this may be because {% data variables.product.prodname_oauth_app %} access restrictions are enabled for the organization. To continue, you will need to approve the \"OKTA SCIM Integration\" app for the organization. For more information, see \"AUTOTITLE.\"\n\n   {% endnote %}\n\n1. Click **Authorize OktaOAN**.\n{% data reusables.saml.okta-save-provisioning %}\n{% data reusables.saml.okta-edit-provisioning %}\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n- Understanding SAML in the Okta documentation\n- Understanding SCIM in the Okta documentation\n\n", "Y2h1bmtfMF9pbmRleF8xNDEy": "\n\nAdding a single select field\n\n{% data reusables.projects.new-field %}\n1. Select **Single select**\n1. Below \"Options\", type the first option.\n   - To add additional options, click **Add option**.\n1. Click **Save**.\n\nAlternatively, open the project command palette by pressing {% data variables.projects.command-palette-shortcut %} and start typing \"Create new field.\"\n\n\n\nEditing a single select field\n\n{% ifversion projects-v2-colorful-selects %}\n\nYou can set descriptions and colors for each of your single select options.\n\n1. Access your project's settings.\n1. To the right of the single select field you want to edit, click {% octicon \"pencil\" aria-label=\"The pencil icon\" %}.\n\n   !Screenshot of the single select options. The pencil icon, by one of the options, is highlighted with an orange outline.\n\n1. In the modal that opens, under **Label text**, type the name of this option.\n1. Optionally, under **Color**, select the color you want to use to represent this option.\n\n   !Screenshot of the modal for editing a single select option. The blue color option is highlighted with an orange outline.\n\n1. Optionally, under **Description**, type a description for this option.\n1. Click **Save** to save your changes.\n\n{% else %}\n\n{% data reusables.projects.project-settings %}\n1. Click the name of the single select field you want to adjust.\n1. Edit existing options or click **Add option**.\n1. Optionally, to delete an option, click {% octicon \"x\" aria-label=\"Remove option\" %}.\n1. Click **Save options**.\n\n{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF84NzI=": "\n\nAbout custom queries and the {% data variables.product.prodname_codeql_cli %}\n\n\n\nYou can customize your {% data variables.product.prodname_codeql %} analyses by writing your own queries to highlight specific vulnerabilities or errors.\n\nThis topic is specifically about writing queries to use with the AUTOTITLE command to produce interpreted results.\n\n{% data reusables.codeql-cli.advanced-query-execution %}\n\n\n\n\n\nWriting a valid query\n\nBefore running a custom analysis you need to write a valid query, and save it in a file with a `.ql` extension. There is extensive documentation available to help you write queries. For more information, see \"{% data variables.product.prodname_codeql %} queries.\"\n\n\n\nIncluding query metadata\n\nQuery metadata is included at the top of each query file. It provides users with information about the query, and tells the {% data variables.product.prodname_codeql_cli %} how to process the query results.\n\nWhen running queries with the `database analyze` command, you must include the following two properties to ensure that the results are interpreted correctly:\n\n- Query identifier (`@id`): a sequence of words composed of lowercase letters or digits, delimited by `/` or `-`, identifying and classifying the query.\n\n- Query type (`@kind`): identifies the query as a simple alert (`@kind problem`), an alert documented by a sequence of code locations (`@kind path-problem`), for extractor troubleshooting (`@kind diagnostic`), or a summary metric (`@kind metric` and `@tags summary`).\n\nFor more information about these metadata properties, see \"Metadata for {% data variables.product.prodname_codeql %} queries\" and the Query metadata style guide.\n\n{% note %}\n\n**Note:** Metadata requirements may differ if you want to use your query with other applications. For more information, see \"Metadata for {% data variables.product.prodname_codeql %} queries.\"\n\n{% endnote %}\n\n{% ifversion codeql-packs %}\n\n\n\nPackaging custom QL queries\n\n{% data reusables.codeql-cli.beta-note-package-management %}\n\n\n\nWhen you write yo", "Y2h1bmtfMV9pbmRleF84NzI=": "ur own queries with the intention to share them with others, you should save them in a custom {% data variables.product.prodname_codeql %} pack. You can publish the pack as a {% data variables.product.prodname_codeql %} pack to {% data variables.product.prodname_registry %} - the {% data variables.product.prodname_dotcom %} {% data variables.product.prodname_container_registry %}. For more information, see \"AUTOTITLE.\"\n\n\n\n{% data variables.product.prodname_codeql %} packs organize the files used in {% data variables.product.prodname_codeql %} analysis and can store queries, library files, query suites, and important metadata. Their root directory must contain a file named `qlpack.yml`. Your custom queries should be saved in the {% data variables.product.prodname_codeql %} pack root, or its subdirectories.\n\nFor each {% data variables.product.prodname_codeql %} pack, the `qlpack.yml` file includes information that tells the {% data variables.product.prodname_codeql_cli %} how to compile the queries, which other {% data variables.product.prodname_codeql %} packs and libraries the pack depends on, and where to find query suite definitions. For more information about what to include in this file, see \"AUTOTITLE.\"\n\n{% endif %}\n\n\n\nIncluding query help for custom {% data variables.product.prodname_codeql %} queries in SARIF files\n\nIf you use the {% data variables.product.prodname_codeql_cli %} to run code scanning analyses on third party CI/CD systems,\nyou can include the query help for your custom queries in SARIF files generated during an analysis.\nAfter uploading the SARIF file to {% data variables.product.prodname_dotcom %}, the query help is shown in the code scanning UI for any\nalerts generated by the custom queries.\n\nFrom {% data variables.product.prodname_codeql_cli %} v2.7.1 onwards, you can include markdown-rendered query help in SARIF files\nby providing the `--sarif-add-query-help` option when running\n`codeql database analyze`.\n\nYou can write query help for custom queries directly in a markdown file and save i", "Y2h1bmtfMl9pbmRleF84NzI=": "t alongside the\ncorresponding query. Alternatively, for consistency with the standard {% data variables.product.prodname_codeql %} queries,\nyou can write query help in the `.qhelp` format. Query help written in `.qhelp`\nfiles can\u2019t be included in SARIF files, and they can\u2019t be processed by code\nscanning so must be converted to markdown before running\nthe analysis. For more information, see \"Query help files\"\nand \"AUTOTITLE.\"\n\n\n\nContributing to the {% data variables.product.prodname_codeql %} repository\n\nIf you would like to share your query with other {% data variables.product.prodname_codeql %} users, you can open a pull request in the {% data variables.product.prodname_codeql %} repository. For more information, see Contributing to {% data variables.product.prodname_codeql %}.\n\n\n\n\n\nFurther reading\n\n- \"{% data variables.product.prodname_codeql %} queries\"\n\n", "Y2h1bmtfMF9pbmRleF8xMzc4": "\n\nAdding notes to a {% data variables.projects.projects_v1_board %}\n\n1. Navigate to the {% data variables.projects.projects_v1_board %} where you want to add notes.\n1. In the column you want to add a note to, click {% octicon \"plus\" aria-label=\"Add a note to this column\" %}.\n   !Screenshot showing a project column. The 'add a note to this column' button is highlighted with an orange outline.\n1. Type your note, then click **Add**.\n\n   {% tip %}\n\n   **Tip:** You can reference an issue or pull request in your note by typing its URL in the card.\n\n   {% endtip %}\n\n\n\nConverting a note to an issue\n\nIf you've created a note and find that it isn't sufficient for your needs, you can convert it to an issue.\n\nWhen you convert a note to an issue, the issue is automatically created using the content from the note. The first line of the note will be the issue title and any additional content from the note will be added to the issue description.\n\n{% tip %}\n\n**Tip:** You can add content in the body of your note to @mention someone, link to another issue or pull request, and add emoji. These {% data variables.product.prodname_dotcom %} Flavored Markdown features aren't supported within {% data variables.projects.projects_v1_board %} notes, but once your note is converted to an issue, they'll appear correctly. For more information on using these features, see \"AUTOTITLE.\"\n\n{% endtip %}\n\n1. Navigate to the note that you want to convert to an issue.\n{% data reusables.project-management.project-note-more-options %}\n1. Click **Convert to issue**.\n1. If the card is on an organization-wide {% data variables.projects.projects_v1_board %}, in the drop-down menu, choose the repository you want to add the issue to.\n1. Optionally, edit the pre-filled issue title, and type an issue body.\n1. Click **Convert to issue**.\n1. The note is automatically converted to an issue. In the {% data variables.projects.projects_v1_board %}, the new issue card will be in the same location as the previous note.\n\n\n\nEditing and removing a note\n\n1. Navigate to the ", "Y2h1bmtfMV9pbmRleF8xMzc4": "note that you want to edit or remove.\n{% data reusables.project-management.project-note-more-options %}\n1. To edit the contents of the note, click **Edit note**.\n1. To delete the contents of the notes, click **Delete note**.\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8xMDQ2": "\n\nFurther reading\n\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF82ODY=": "\n\nAbout the Reserve Bank of India's recurring payments regulation\n\nA new payments regulation from the Reserve Bank of India (RBI) recently came into effect. This regulation places additional requirements on recurring online transactions and has prevented some {% data variables.product.company_short %} customers in India from making recurring payments. Customers using payment methods issued in India for any recurring transactions on {% data variables.product.product_name %} may find that their payments are declined by their banks or card issuers. For more information, see the RBI's press release.\n\nThe regulation applies to all recurring transactions, including:\n- {% data variables.product.prodname_dotcom %} plan subscriptions (Pro, Team, Enterprise)\n- {% data variables.product.prodname_marketplace %} purchases\n- {% data variables.product.prodname_sponsors %} transactions\n- Git Large File Storage purchases\n- {% data variables.product.prodname_actions %}, {% data variables.product.prodname_registry %}, and {% data variables.product.prodname_github_codespaces %} consumption\n\nIn order to minimize disruption, recurring payments for our affected customers were paused on October 29th, 2021. Paid features and services have remained available to customers impacted by the RBI regulation.\n\n\n\nAbout one-time payments on {% data variables.product.company_short %}\n\nAs we work with our payment gateway provider to meet the new requirements, we are providing a temporary one-time payment option for impacted customers in India. From February 15th 2022, {% data variables.product.company_short %} customers in India who have been affected by the new RBI regulation will be able to make one-time payments on their regular billing cycle cadence.\n\n\n\nFor customers on monthly billing\n\nCustomers on monthly billing plans will be able to make a one-time payment on the same day their billing cycle usually renews. For example, if you're usually billed on the 7th of each month, you will now be able to make a one-time payment from your account from t", "Y2h1bmtfMV9pbmRleF82ODY=": "he 7th of each month. Your first one-time payment will also include any accrued usage from October 2021 onwards.\n\nIf you are currently billed monthly, and would like to switch to yearly billing, you can reduce the frequency of your one-time payments. For more information, see \"AUTOTITLE.\"\n\n\n\nFor customers on yearly billing\n\nIf you are billed yearly, and your renewal date was between October 1st, 2021 and February 14th, 2022, you will be able to make a one-time payment for your annual subscriptions from February 15th. This initial payment will include the prorated outstanding cost of your subscription for the period since your previous billing cycle ended.\n\nIf your billing cycle is due to renew after February 15th, we will attempt to take the recurring payment. If the payment attempt is declined, you will then be able to make a one-time payment through your account's billing page.\n\nIn the meantime, we are actively working with our payment partners to restore recurring payments for impacted customers. For more information or questions, you can contact {% data variables.contact.contact_support %}.\n\n\n\nImpact to {% data variables.product.prodname_sponsors %}\n\nExisting sponsorships will remain in place during this period and maintainers will continue to be paid out as expected. Payments for the accrued sponsorship amounts from the funding account will be collected at the same time as other accrued charges.\n\n\n\nMaking a one-time payment for a GitHub subscription\n\n{% note %}\n\n**Note**: Affected customers will receive an email notification with a link to their billing settings when payment is due. Two further reminder emails will be sent 7 and 14 days later if payment has not been made. After 14 days, paid features and services will be locked until payment is made.\n\n{% endnote %}\n\n{% data reusables.user-settings.access_settings %}\n{% data reusables.user-settings.billing_plans_payment %}\n1. At the top of the page, click **Pay now**.\n1. Review your billing and payment information.\n1. Optionally, if you need to make an edit, ", "Y2h1bmtfMl9pbmRleF82ODY=": "click **Edit** next to the relevant section.\n1. Click **Submit payment**.\n1. Once payment for the current billing cycle has been successfully made, the **Pay now** button on your \"Billing & plans\" page will be disabled until your next payment is due.\n\n", "Y2h1bmtfMF9pbmRleF8xOTMy": "\n\nAbout source imports\n\n{% warning %}\n\n**Warning**: Due to very low levels of usage and available alternatives, the Source Imports API is deprecated and will no longer be available from 00:00 UTC on April 12, 2024. For more details and alternatives, see the changelog.\n\n{% endwarning %}\n\n{% data variables.migrations.source_imports_intro %} A typical source import would start the import and then (optionally) update the authors and/or update the preference for using Git LFS if large files exist in the import. You can also create a webhook that listens for the `RepositoryImportEvent` to find out the status of the import.\n\n{% data reusables.user-settings.imports-api-classic-pat-only %}\n\nThe following diagram provides a more detailed example:\n\n```text\n+---------+                     +--------+                              +---------------------+\n| Tooling |                     | GitHub |                              | Original Repository |\n+---------+                     +--------+                              +---------------------+\n     |                              |                                              |\n     |  Start import                |                                              |\n     |----------------------------->|                                              |\n     |                              |                                              |\n     |                              |  Download source data                        |\n     |                              |--------------------------------------------->|\n     |                              |                        Begin streaming data  |\n     |                              |<---------------------------------------------|\n     |                              |                                              |\n     |  Get import progress         |                                              |\n     |----------------------------->|                                              |\n     |       \"status\": \"importing\"  |                                ", "Y2h1bmtfMV9pbmRleF8xOTMy": "              |\n     |<-----------------------------|                                              |\n     |                              |                                              |\n     |  Get commit authors          |                                              |\n     |----------------------------->|                                              |\n     |                              |                                              |\n     |  Map a commit author         |                                              |\n     |----------------------------->|                                              |\n     |                              |                                              |\n     |                              |                                              |\n     |                              |                       Finish streaming data  |\n     |                              |<---------------------------------------------|\n     |                              |                                              |\n     |                              |  Rewrite commits with mapped authors         |\n     |                              |------+                                       |\n     |                              |      |                                       |\n     |                              |<-----+                                       |\n     |                              |                                              |\n     |                              |  Update repository on GitHub                 |\n     |                              |------+                                       |\n     |                              |      |                                       |\n     |                              |<-----+                                       |\n     |                              |                                              |\n     |  Map a commit author         |                                              |\n     |----------------------------->|                                        ", "Y2h1bmtfMl9pbmRleF8xOTMy": "      |\n     |                              |  Rewrite commits with mapped authors         |\n     |                              |------+                                       |\n     |                              |      |                                       |\n     |                              |<-----+                                       |\n     |                              |                                              |\n     |                              |  Update repository on GitHub                 |\n     |                              |------+                                       |\n     |                              |      |                                       |\n     |                              |<-----+                                       |\n     |                              |                                              |\n     |  Get large files             |                                              |\n     |----------------------------->|                                              |\n     |                              |                                              |\n     |  opt_in to Git LFS           |                                              |\n     |----------------------------->|                                              |\n     |                              |  Rewrite commits for large files             |\n     |                              |------+                                       |\n     |                              |      |                                       |\n     |                              |<-----+                                       |\n     |                              |                                              |\n     |                              |  Update repository on GitHub                 |\n     |                              |------+                                       |\n     |                              |      |                                       |\n     |                              |<-----+                                       |\n", "Y2h1bmtfM19pbmRleF8xOTMy": "     |                              |                                              |\n     |  Get import progress         |                                              |\n     |----------------------------->|                                              |\n     |        \"status\": \"complete\"  |                                              |\n     |<-----------------------------|                                              |\n     |                              |                                              |\n     |                              |                                              |\n```\n\n\n\n", "Y2h1bmtfMF9pbmRleF8xMjU4": "---\ntitle: Git workflows\nintro: '{% data variables.product.prodname_dotcom %} flow is a lightweight, branch-based workflow that supports teams and projects that deploy regularly.'\nredirect_from:\n  - /articles/what-is-a-good-git-workflow\n  - /articles/git-workflows\n  - /github/using-git/git-workflows\n  - /github/getting-started-with-github/git-workflows\n  - /github/getting-started-with-github/getting-started-with-git/git-workflows\nversions:\n  fpt: '*'\n  ghes: '*'\n  ghae: '*'\n  ghec: '*'\n---\nYou can adopt the {% data variables.product.prodname_dotcom %} flow method to standardize how your team functions and collaborates on {% data variables.product.prodname_dotcom %}. For more information, see \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF8xODU5": "\n\nAbout {% data variables.product.prodname_codespaces %} organizations\n\nYou can manage {% data variables.product.prodname_codespaces %} that are billed to your\norganization. For more information,\nsee \"AUTOTITLE.\"\n\n\n\n", "Y2h1bmtfMF9pbmRleF80MTU=": "\n\nAbout high availability replication for clusters\n\n{% data reusables.enterprise_clustering.high-availability-requires-391 %}\n\nYou can provide protection against disruption in a datacenter or cloud region by configuring a cluster deployment of {% data variables.product.prodname_ghe_server %} for high availability. In a high availability configuration, an identical set of replica nodes sync with the nodes in your active cluster. If hardware or software failures affect the datacenter with your active cluster, you can manually fail over to the replica nodes and continue processing user requests, minimizing the impact of the outage.\n\nIn a high availability configuration, nodes that host data services sync regularly with the replica cluster. Replica nodes run in standby and do not serve applications or process user requests.\n\nWe recommend configuring high availability as a part of a comprehensive disaster recovery plan for {% data variables.product.prodname_ghe_server %} clustering. We also recommend performing regular backups. For more information, see \"AUTOTITLE.\"\n\n\n\nPrerequisites\n\n\n\nHardware and software\n\nFor each existing node in your active cluster, you'll need to provision a second virtual machine with identical hardware resources. For example, if your cluster has 13 nodes and each node has 12 vCPUs, 96 GB of RAM, and 750 GB of attached storage, you must provision 13 new virtual machines that each have 12 vCPUs, 96 GB of RAM, and 750 GB of attached storage.\n\nOn each new virtual machine, install the same version of {% data variables.product.prodname_ghe_server %} that runs on the nodes in your active cluster. You don't need to upload a license or perform any additional configuration. For more information, see \"AUTOTITLE.\"\n\n{% note %}\n\n**Note**: The nodes that you intend to use for high availability replication should be standalone {% data variables.product.prodname_ghe_server %} instances. Don't initialize the replica nodes as a second cluster.\n\n{% endnote %}\n\n\n\nNetwork\n\nYou must assign a static IP address to eac", "Y2h1bmtfMV9pbmRleF80MTU=": "h new node that you provision, and you must configure a load balancer to accept connections and direct them to the nodes in your cluster's front-end tier.\n\n{% data reusables.enterprise_clustering.network-latency %} For more information about network connectivity between nodes in the replica cluster, see \"AUTOTITLE.\"\n\n\n\nCreating a high availability replica for a cluster\n\n- Assigning active nodes to the primary datacenter\n- Adding replica nodes to the cluster configuration file\n- Example configuration\n\n\n\nAssigning active nodes to the primary datacenter\n\nBefore you define a secondary datacenter for your replica nodes, ensure that you assign your active nodes to the primary datacenter.\n\n{% data reusables.enterprise_clustering.ssh-to-a-node %}\n{% data reusables.enterprise_clustering.open-configuration-file %}\n1. Note the name of your cluster's primary datacenter. The `[cluster]` section at the top of the cluster configuration file defines the primary datacenter's name, using the `primary-datacenter` key-value pair.\n\n    ```text\n    [cluster]\n      mysql-master = HOSTNAME\n      redis-master = HOSTNAME\n      primary-datacenter = primary\n    ```\n\n    - Optionally, change the name of the primary datacenter to something more descriptive or accurate by editing the value of `primary-datacenter`.\n\n1. {% data reusables.enterprise_clustering.configuration-file-heading %} Under each node's heading, add a new key-value pair to assign the node to a datacenter. Use the same value as `primary-datacenter` from step 3 above. For example, if you want to use the default name (`default`), add the following key-value pair to the section for each node.\n\n    ```text\n    datacenter = primary\n    ```\n\n    When you're done, the section for each node in the cluster configuration file should look like the following example. {% data reusables.enterprise_clustering.key-value-pair-order-irrelevant %}\n\n    ```text\n    [cluster \"HOSTNAME\"]\n      datacenter = default\n      hostname = HOSTNAME\n      ipv4 = IP-ADDRESS\n      ...\n    ...\n    ```\n\n    {% n", "Y2h1bmtfMl9pbmRleF80MTU=": "ote %}\n\n    **Note**: If you changed the name of the primary datacenter in step 3, find the `consul-datacenter` key-value pair in the section for each node and change the value to the renamed primary datacenter. For example, if you named the primary datacenter `primary`, use the following key-value pair for each node.\n\n    ```text\n    consul-datacenter = primary\n    ```\n\n    {% endnote %}\n\n{% data reusables.enterprise_clustering.apply-configuration %}\n{% data reusables.enterprise_clustering.configuration-finished %}\n\nAfter {% data variables.product.prodname_ghe_server %} returns you to the prompt, you've finished assigning your nodes to the cluster's primary datacenter.\n\n\n\nAdding replica nodes to the cluster configuration file\n\nTo configure high availability, you must define a corresponding replica node for every active node in your cluster. To create a new cluster configuration that defines both active and replica nodes, you'll complete the following tasks.\n\n- Create a copy of the active cluster configuration file.\n- Edit the copy to define replica nodes that correspond to the active nodes, adding the IP addresses of the new virtual machines that you provisioned.\n- Merge the modified copy of the cluster configuration back into your active configuration.\n- Apply the new configuration to start replication.\n\nFor an example configuration, see \"Example configuration.\"\n\n1. For each node in your cluster, provision a matching virtual machine with identical specifications, running the same version of  {% data variables.product.prodname_ghe_server %}. Note the IPv4 address and hostname for each new cluster node. For more information, see \"Prerequisites.\"\n\n    {% note %}\n\n    **Note**: If you're reconfiguring high availability after a failover, you can use the old nodes from the primary datacenter instead.\n\n    {% endnote %}\n\n{% data reusables.enterprise_clustering.ssh-to-a-node %}\n1. Back up your existing cluster configuration.\n\n    ```shell\n    cp /data/user/common/cluster.conf ~/$(date +%Y-%m-%d)-cluster.conf.backup\n   ", "Y2h1bmtfM19pbmRleF80MTU=": " ```\n\n1. Create a copy of your existing cluster configuration file in a temporary location, like `/home/admin/cluster-replica.conf`.\n\n    ```shell\n    grep -Ev \"(?:|ipv|uuid)\" /data/user/common/cluster.conf > ~/cluster-replica.conf\n    ```\n\n1. Remove the `[cluster]` section from the temporary cluster configuration file that you copied in the previous step.\n\n    ```shell\n    git config -f ~/cluster-replica.conf --remove-section cluster\n    ```\n\n1. Decide on a name for the secondary datacenter where you provisioned your replica nodes, then update the temporary cluster configuration file with the new datacenter name. Replace `SECONDARY` with the name you choose.\n\n    ```shell\n    sed -i 's/datacenter = default/datacenter = SECONDARY/g' ~/cluster-replica.conf\n    ```\n\n1. Decide on a pattern for the replica nodes' hostnames.\n\n    {% warning %}\n\n    **Warning**: Hostnames for replica nodes must be unique and differ from the hostname for the corresponding active node.\n\n    {% endwarning %}\n\n1. Open the temporary cluster configuration file from step 3 in a text editor. For example, you can use Vim.\n\n    ```shell\n    sudo vim ~/cluster-replica.conf\n    ```\n\n1. In each section within the temporary cluster configuration file, update the node's configuration. {% data reusables.enterprise_clustering.configuration-file-heading %}\n\n    - Change the quoted hostname in the section heading and the value for `hostname` within the section to the replica node's hostname, per the pattern you chose in step 7 above.\n    - Add a new key named `ipv4`, and set the value to the replica node's static IPv4 address.\n    - Add a new key-value pair, `replica = enabled`.\n\n    ```shell\n    [cluster \"NEW REPLICA NODE HOSTNAME\"]\n      ...\n      hostname = NEW REPLICA NODE HOSTNAME\n      ipv4 = NEW REPLICA NODE IPV4 ADDRESS\n      replica = enabled\n      ...\n    ...\n    ```\n\n1. Append the contents of the temporary cluster configuration file that you created in step 4 to the active configuration file.\n\n    ```shell\n    cat ~/cluster-replica.conf >> /da", "Y2h1bmtfNF9pbmRleF80MTU=": "ta/user/common/cluster.conf\n    ```\n\n1. Designate the primary MySQL and Redis nodes in the secondary datacenter. Replace `REPLICA MYSQL PRIMARY HOSTNAME` and `REPLICA REDIS PRIMARY HOSTNAME` with the hostnames of the replica node that you provisioned to match your existing MySQL and Redis primaries.\n\n    ```shell\n    git config -f /data/user/common/cluster.conf cluster.mysql-master-replica REPLICA-MYSQL-PRIMARY-HOSTNAME\n    git config -f /data/user/common/cluster.conf cluster.redis-master-replica REPLICA-REDIS-PRIMARY-HOSTNAME\n    ```\n\n    {% warning %}\n\n    **Warning**: Review your cluster configuration file before proceeding.\n\n    - In the top-level `[cluster]` section, ensure that the values for `mysql-master-replica` and `redis-master-replica` are the correct hostnames for the replica nodes in the secondary datacenter that will serve as the MySQL and Redis primaries after a failover.\n    - In each section for an active node named [cluster \"ACTIVE NODE HOSTNAME\"], double-check the following key-value pairs.\n      - `datacenter` should match the value of `primary-datacenter` in the top-level `[cluster]` section.\n      - `consul-datacenter` should match the value of `datacenter`, which should be the same as the value for `primary-datacenter` in the top-level `[cluster]` section.\n    - Ensure that for each active node, the configuration has **one** corresponding section for **one** replica node with the same roles. In each section for a replica node, double-check each key-value pair.\n      - `datacenter` should match all other replica nodes.\n      - `consul-datacenter` should match all other replica nodes.\n      - `hostname` should match the hostname in the section heading.\n      - `ipv4` should match the node's unique, static IPv4 address.\n      - `replica` should be configured as `enabled`.\n    - Take the opportunity to remove sections for offline nodes that are no longer in use.\n\n    To review an example configuration, see \"Example configuration.\"\n\n    {% endwarning %}\n\n1. Initialize the new cluster configurat", "Y2h1bmtfNV9pbmRleF80MTU=": "ion. {% data reusables.enterprise.use-a-multiplexer %}\n\n    ```shell\n    ghe-cluster-config-init\n    ```\n\n1. After the initialization finishes, {% data variables.product.prodname_ghe_server %} displays the following message.\n\n    ```shell\n    Finished cluster initialization\n    ```\n\n{% data reusables.enterprise_clustering.apply-configuration %}\n1. After the configuration run finishes, verify that cluster replication is correctly set up and working.\n\n    ```shell\n    ghe-cluster-repl-status\n    ```\n\n{% data reusables.enterprise_clustering.configuration-finished %}\n1. Configure a load balancer that will accept connections from users after you fail over to the replica nodes. For more information, see \"AUTOTITLE.\"\n\nYou've finished configuring high availability replication for the nodes in your cluster. Each active node begins replicating configuration and data to its corresponding replica node, and you can direct traffic to the load balancer for the secondary datacenter in the event of a failure. For more information about failing over, see \"AUTOTITLE.\"\n\n\n\nExample configuration\n\nThe top-level `[cluster]` configuration should look like the following example.\n\n```shell\n[cluster]\n  mysql-master = HOSTNAME-OF-ACTIVE-MYSQL-MASTER\n  redis-master = HOSTNAME-OF-ACTIVE-REDIS-MASTER\n  primary-datacenter = PRIMARY-DATACENTER-NAME\n  mysql-master-replica = HOSTNAME-OF-REPLICA-MYSQL-MASTER\n  redis-master-replica = HOSTNAME-OF-REPLICA-REDIS-MASTER\n  mysql-auto-failover = false\n...\n```\n\nThe configuration for an active node in your cluster's storage tier should look like the following example.\n\n```shell\n...\n[cluster \"UNIQUE ACTIVE NODE HOSTNAME\"]\n  datacenter = default\n  hostname = UNIQUE-ACTIVE-NODE-HOSTNAME\n  ipv4 = IPV4-ADDRESS\n  consul-datacenter = default\n  consul-server = true\n  git-server = true\n  pages-server = true\n  mysql-server = true\n  elasticsearch-server = true\n  redis-server = true\n  memcache-server = true\n  metrics-server = true\n  storage-server = true\n  uuid = UUID SET AUTOMATICALLY\n...\n```\n\nThe configuration for the", "Y2h1bmtfNl9pbmRleF80MTU=": " corresponding replica node in the storage tier should look like the following example.\n\n- Important differences from the corresponding active node are **bold**.\n- {% data variables.product.prodname_ghe_server %} assigns the value for `uuid` automatically, so you shouldn't define this value for replica nodes that you will initialize.\n- The server roles, defined by `*-server` keys, match the corresponding active node.\n\n```shell\n...\n[cluster \"UNIQUE REPLICA NODE HOSTNAME\"]\n  replica = enabled\n  ipv4 = IPV4 ADDRESS OF NEW VM WITH IDENTICAL RESOURCES\n  datacenter = SECONDARY DATACENTER NAME\n  hostname = UNIQUE REPLICA NODE HOSTNAME\n  consul-datacenter = SECONDARY DATACENTER NAME\n  consul-server = true\n  git-server = true\n  pages-server = true\n  mysql-server = true\n  elasticsearch-server = true\n  redis-server = true\n  memcache-server = true\n  metrics-server = true\n  storage-server = true\n  uuid = DO NOT DEFINE\n...\n```\n\n\n\nMonitoring replication between active and replica cluster nodes\n\nInitial replication between the active and replica nodes in your cluster takes time. The amount of time depends on the amount of data to replicate and the activity levels for {% data variables.product.prodname_ghe_server %}.\n\nYou can monitor the progress on any node in the cluster, using command-line tools available via the {% data variables.product.prodname_ghe_server %} administrative shell. For more information about the administrative shell, see \"AUTOTITLE.\"\n\nTo monitor the replication of all services, use the following command.\n\n```shell\nghe-cluster-repl-status\n```\n\nYou can use `ghe-cluster-status` to review the overall health of your cluster. For more information, see  \"AUTOTITLE.\"\n\n\n\nReconfiguring high availability replication after a failover\n\nAfter you fail over from the cluster's active nodes to the cluster's replica nodes, you can reconfigure high availability in one of two ways. The method you choose will depend on the reason that you failed over, and the state of the original active nodes.\n\n- Provision and configure a new se", "Y2h1bmtfN19pbmRleF80MTU=": "t of replica nodes for each of the new active nodes in your secondary datacenter.\n- Use the original active nodes as the new replica nodes.\n\nThe process for reconfiguring high availability is identical to the initial configuration of high availability. For more information, see \"Creating a high availability replica for a cluster.\"\n\nIf you use the original active nodes, after reconfiguring high availability, you will need to unset maintenance mode on the nodes. For more information, see \"AUTOTITLE.\"\n\n\n\nDisabling high availability replication for a cluster\n\nYou can stop replication to the replica nodes for your cluster deployment of {% data variables.product.prodname_ghe_server %}.\n\n{% data reusables.enterprise_clustering.ssh-to-a-node %}\n{% data reusables.enterprise_clustering.open-configuration-file %}\n1. In the top-level `[cluster]` section, delete the `redis-master-replica`, and `mysql-master-replica` key-value pairs.\n1. Delete each section for a replica node. For replica nodes, `replica` is configured as `enabled`.\n{% data reusables.enterprise_clustering.apply-configuration %}\n{% data reusables.enterprise_clustering.configuration-finished %}\n\nAfter {% data variables.product.prodname_ghe_server %} returns you to the prompt, you've finished disabling high availability replication.\n\n", "Y2h1bmtfMF9pbmRleF8xMjgy": "---\ntitle: Git cheatsheet\nredirect_from:\n  - /articles/git-cheatsheet\n  - /github/getting-started-with-github/git-cheatsheet\n  - /github/getting-started-with-github/quickstart/git-cheatsheet\nversions:\n  fpt: '*'\n  ghes: '*'\n  ghae: '*'\n  ghec: '*'\nintro: This Git cheat sheet is a time saver when you forget a command or don't want to use help in the CLI.\n---\nLearning all available Git commands at once can be a daunting task. You can use \"Git Cheat Sheets\" for a quick reference to frequently used commands. The \"Using Git\" cheat sheet is available in several languages.\n\nIn addition, take a look at our Git and GitHub learning resources page that links to guides, videos and more.\n\n", "Y2h1bmtfMF9pbmRleF81MDQ=": "\n\nAbout visibility for {% data variables.product.prodname_github_apps %}\n\nYou can make your {% data variables.product.prodname_github_app %} registration public or private. {% ifversion fpt %}If you set your {% data variables.product.prodname_github_app %} registration to public, any user on {% data variables.product.prodname_dotcom_the_website %} or {% data variables.product.prodname_ghe_cloud %} can install it. If you set your {% data variables.product.prodname_github_app %} registration to private, it can only be installed on the account that owns the app.\n\n{% elsif ghes %}If you set your {% data variables.product.prodname_github_app %} registration to public, anyone on your {% data variables.product.prodname_ghe_server %} instance can install it, but the app is not available outside of your instance. If you set your {% data variables.product.prodname_github_app %} registration to private, it can only be installed on the account that owns the app.\n\n{% elsif ghec %}If you set your {% data variables.product.prodname_github_app %} registration to public, and the {% data variables.product.prodname_github_app %} registration is owned by an {% data variables.product.prodname_emu %} account, accounts owned by your enterprise can install it, but the app cannot be installed on accounts outside of your enterprise. If a {% data variables.product.prodname_github_app %} registration is owned by an account that is not an {% data variables.product.prodname_emu %}, and the app is set to public, any user on {% data variables.product.prodname_dotcom_the_website %} or {% data variables.product.prodname_ghe_cloud %} can install the app. If you set your {% data variables.product.prodname_github_app %} registration to private, it can only be installed on the account that owns the app.{% endif %}\n\n{% ifversion fpt or ghec %}You can register a {% data variables.product.prodname_github_app %} under your personal account or organization and make it available for other organizations to install. You do not need an enterprise plan or an o", "Y2h1bmtfMV9pbmRleF81MDQ=": "rganization account to make your {% data variables.product.prodname_github_app %} available to an organization even if the organization is owned by an enterprise on {% data variables.product.prodname_ghe_cloud %}.{% endif %}\n\nIf you want to make your app available to {% ifversion ghes %}other {% endif %}{% data variables.product.prodname_ghe_server %} instances, then you need to take additional steps. For more information, see \"AUTOTITLE.\"\n\nIf it is important for {% ifversion ghes %}other {% endif %}{% data variables.product.prodname_ghe_server %} users to be able to use your tool, consider using {% data variables.product.prodname_actions %} instead of a {% data variables.product.prodname_github_app %}. Public actions are available on {% data variables.product.prodname_ghe_server %} instances with GitHub Connect. For more information, see \"AUTOTITLE\" and \"AUTOTITLE{% ifversion ghes %}.\"{% else %}\" in the {% data variables.product.prodname_ghe_server %} documentation.{% endif %}\n\nFor information about changing the visibility of a {% data variables.product.prodname_github_app %} registration, see \"AUTOTITLE.\"\n\n\n\nPublic installation flow\n\nPublic {% data variables.product.prodname_github_apps %} have a landing page with an **Install** button, so that other people can install the app in their repositories. {% ifversion fpt or ghec %}If your {% data variables.product.prodname_github_app %} is public to all users on {% data variables.product.prodname_dotcom_the_website %}, you can also choose to publish it to {% data variables.product.prodname_marketplace %}. For more information, see \"AUTOTITLE.\"{% endif %}\n\n\n\nPrivate installation flow\n\nPrivate {% data variables.product.prodname_github_apps %} can only be installed on the user or organization account of the app owner. Limited information about the app will exist on a landing page for the app, but the **Install** button will only be available to organization owners and app managers for the organization that owns the app, or the personal account if the {% data variables.", "Y2h1bmtfMl9pbmRleF81MDQ=": "product.prodname_github_app %} is owned by an individual account.\n\n", "Y2h1bmtfMF9pbmRleF85Mjk=": "\n\nAbout privately reporting a security vulnerability\n\nSecurity researchers often feel responsible for alerting users to a vulnerability that could be exploited. If there are no clear instructions about contacting maintainers of the repository containing the vulnerability, security researchers may have no other choice but to post about the vulnerability on social media, send direct messages to the maintainer, or even create public issues. This situation can potentially lead to a public disclosure of the vulnerability details.\n\n{% data reusables.security-advisory.private-vulnerability-reporting-overview %}\n\nFor maintainers, the benefits of using private vulnerability reporting are:\n{% data reusables.security-advisory.private-vulnerability-reporting-benefits %}\n\nThe instructions in this article refer to enablement at repository level. For information about enabling the feature at organization level, see \"AUTOTITLE.\"\n\n\n\nEnabling or disabling private vulnerability reporting for a repository\n\n{% data reusables.repositories.navigate-to-repo %}\n{% data reusables.repositories.sidebar-settings %}\n{% data reusables.repositories.navigate-to-code-security-and-analysis %}\n1. Under \"Code security and analysis\", to the right of \"Private vulnerability reporting\", click **Enable** or **Disable**, to enable or disable the feature, respectively.\n   !Screenshot of the \"Code security and analysis\" page, showing the \"Private vulnerability reporting\" setting. The \"Enable\" button is outlined in dark orange.\n\n{% data reusables.security-advisory.private-vulnerability-reporting-security-researcher %}\n\n{% data reusables.security-advisory.private-vulnerability-api %}\n\n\n\nConfiguring notifications for private vulnerability reporting\n\n{% data reusables.security-advisory.private-vulnerability-reporting-configure-notifications %}\n\nNotifications depend on the user's notification preferences. You will receive an email notification if:\n- You are watching the repository.\n- You have enabled notifications for \"All Activity\".\n- In your notification setti", "Y2h1bmtfMV9pbmRleF85Mjk=": "ngs, under \"Subscriptions\", then under \"Watching\", you have selected to receive notifications by email.\n\n{% data reusables.repositories.navigate-to-repo %}\n1. To start watching the repository, select **{% octicon \"eye\" aria-hidden=\"true\" %} Watch**.\n\n   !Screenshot of the repository's main page. A dropdown menu, titled \"Watch\", is highlighted with an orange outline.\n\n1. In the dropdown menu, click **All Activity**.\n1. Navigate to the notification settings for your personal account. These are available at https://github.com/settings/notifications.\n1. On your notification settings page, under \"Subscriptions,\" then under \"Watching,\" select the **Notify me** dropdown.\n1. Select \"Email\" as a notification option, then click **Save**.\n\n   !Screenshot of the notification settings for a user account. An element header, titled \"Subscriptions\", and a sub-header, titled \"Watching\", are shown. A checkbox, titled \"Email\", is highlighted with an orange outline.\n\n{% data reusables.notifications.watch-settings %}\n\n", "Y2h1bmtfMF9pbmRleF8xMzMx": "\n\nAbout {% data variables.product.prodname_cli %} extensions\n\n{% data reusables.cli.cli-extensions %} For more information about how to use {% data variables.product.prodname_cli %} extensions, see \"AUTOTITLE.\"\n\nYou need a repository for each extension that you create. The repository name must start with `gh-`. The rest of the repository name is the name of the extension. The repository must have an executable file at its root with the same name as the repository or a set of precompiled binary executables attached to a release.\n\n{% note %}\n\n**Note**: When relying on an executable script, we recommend using a bash script because bash is a widely available interpreter. You may use non-bash scripts, but the user must have the necessary interpreter installed in order to use the extension. If you would prefer to not rely on users having interpreters installed, consider a precompiled extension.\n\n{% endnote %}\n\n\n\nCreating an interpreted extension with `gh extension create`\n\n{% note %}\n\n**Note**: Running `gh extension create` with no arguments will start an interactive wizard.\n\n{% endnote %}\n\nYou can use the `gh extension create` command to create a project for your extension, including a bash script that contains some starter code.\n\n1. Set up a new extension by using the `gh extension create` subcommand. Replace `EXTENSION-NAME` with the name of your extension.\n\n    ```shell\n    gh extension create EXTENSION-NAME\n    ```\n\n1. Follow the printed instructions to finalize and optionally publish your extension.\n\n\n\nCreating a precompiled extension in Go with `gh extension create`\n\nYou can use the `--precompiled=go` argument to create a Go-based project for your extension, including Go scaffolding, workflow scaffolding, and starter code.\n\n1. Set up a new extension by using the `gh extension create` subcommand. Replace `EXTENSION-NAME` with the name of your extension and specify `--precompiled=go`.\n\n    ```shell\n    gh extension create --precompiled=go EXTENSION-NAME\n    ```\n\n1. Follow the printed instructions to finalize and o", "Y2h1bmtfMV9pbmRleF8xMzMx": "ptionally publish your extension.\n\n\n\nCreating a non-Go precompiled extension with `gh extension create`\n\nYou can use the `--precompiled=other` argument to create a project for your non-Go precompiled extension, including workflow scaffolding.\n\n1. Set up a new extension by using the `gh extension create` subcommand. Replace `EXTENSION-NAME` with the name of your extension and specify `--precompiled=other`.\n\n    ```shell\n    gh extension create --precompiled=other EXTENSION-NAME\n    ```\n\n1. Add some initial code for your extension in your compiled language of choice.\n\n1. Fill in `script/build.sh` with code to build your extension to ensure that your extension can be built automatically.\n\n1. Follow the printed instructions to finalize and optionally publish your extension.\n\n\n\nCreating an interpreted extension manually\n\n1. Create a local directory called `gh-EXTENSION-NAME` for your extension. Replace `EXTENSION-NAME` with the name of your extension. For example, `gh-whoami`.\n\n1. In the directory that you created, add an executable file with the same name as the directory.\n\n   {% note %}\n\n   **Note:** Make sure that your file is executable. On Unix, you can execute `chmod +x file_name` in the command line to make `file_name` executable. On Windows, you can run `git init -b main`, `git add file_name`, then `git update-index --chmod=+x file_name`.\n\n   {% endnote %}\n\n1. Write your script in the executable file. For example:\n\n   ```bash\n   #!/usr/bin/env bash\n   set -e\n   exec gh api user --jq '\"You are @\\(.login) (\\(.name)).\"'\n   ```\n\n1. From your directory, install the extension as a local extension.\n\n   ```shell\n   gh extension install .\n   ```\n\n1. Verify that your extension works. Replace `EXTENSION-NAME` with the name of your extension. For example, `whoami`.\n\n   ```shell\n   gh EXTENSION-NAME\n   ```\n\n1. From your directory, create a repository to publish your extension. Replace `EXTENSION-NAME` with the name of your extension.\n\n   ```shell\n   git init -b main\n   git add . && git commit -m \"initial commit\"\n   gh repo", "Y2h1bmtfMl9pbmRleF8xMzMx": " create gh-EXTENSION-NAME --source=. --public --push\n   ```\n\n1. Optionally, to help other users discover your extension, add the repository topic `gh-extension`. This will make the extension appear on the `gh-extension` topic page. For more information about how to add a repository topic, see \"AUTOTITLE.\"\n\n\n\nTips for writing interpreted {% data variables.product.prodname_cli %} extensions\n\n\n\nHandling arguments and flags\n\nAll command line arguments following a `gh my-extension-name` command will be passed to the extension script. In a bash script, you can reference arguments with `$1`, `$2`, etc. You can use arguments to take user input or to modify the behavior of the script.\n\nFor example, this script handles multiple flags. When the script is called with the `-h` or `--help` flag, the script prints help text instead of continuing execution. When the script is called with the `--name` flag, the script sets the next value after the flag to `name_arg`. When the script is called with the `--verbose` flag, the script prints a different greeting.\n\n```bash\n#!/usr/bin/env bash\nset -e\n\nverbose=\"\"\nname_arg=\"\"\nwhile [ $# -gt 0 ]; do\n  case \"$1\" in\n  --verbose)\n    verbose=1\n    ;;\n  --name)\n    name_arg=\"$2\"\n    shift\n    ;;\n  -h|--help)\n    echo \"Add help text here.\"\n    exit 0\n    ;;\n  esac\n  shift\ndone\n\nif [ -z \"$name_arg\" ]\nthen\n  echo \"You haven't told us your name.\"\nelif [ -z \"$verbose\" ]\nthen\n  echo \"Hi $name_arg\"\nelse\n  echo \"Hello and welcome, $name_arg\"\nfi\n```\n\n\n\nCalling core commands in non-interactive mode\n\nSome {% data variables.product.prodname_cli %} core commands will prompt the user for input. When scripting with those commands, a prompt is often undesirable. To avoid prompting, supply the necessary information explicitly via arguments.\n\nFor example, to create an issue programmatically, specify the title and body:\n\n```shell\ngh issue create --title \"My Title\" --body \"Issue description\"\n```\n\n\n\nFetching data programmatically\n\nMany core commands support the `--json` flag for fetching data programmatically. For", "Y2h1bmtfM19pbmRleF8xMzMx": " example, to return a JSON object listing the number, title, and mergeability status of pull requests:\n\n```shell\ngh pr list --json number,title,mergeStateStatus\n```\n\nIf there is not a core command to fetch specific data from GitHub, you can use the `gh api` command to access the GitHub API. For example, to fetch information about the current user:\n\n```shell\ngh api user\n```\n\nAll commands that output JSON data also have options to filter that data into something more immediately usable by scripts. For example, to get the current user's name:\n\n```shell\ngh api user --jq '.name'\n```\n\nFor more information, see `gh help formatting`.\n\n\n\nCreating a precompiled extension manually\n\n1. Create a local directory called `gh-EXTENSION-NAME` for your extension. Replace `EXTENSION-NAME` with the name of your extension. For example, `gh-whoami`.\n\n1. In the directory you created, add some source code. For example:\n\n    ```golang\n    package main\n    import (\n      \"github.com/cli/go-gh\"\n      \"fmt\"\n    )\n\n    func main() {\n      args := []string{\"api\", \"user\", \"--jq\", `\"You are @\\(.login) (\\(.name))\"` }\n      stdOut, _, err := gh.Exec(args...)\n      if err != nil {\n        fmt.Println(err)\n        return\n      }\n      fmt.Println(stdOut.String())\n    }\n    ```\n\n1. From your directory, install the extension as a local extension.\n\n    ```shell\n    gh extension install .\n    ```\n\n1. Build your code. For example, with Go, replacing `YOUR-USERNAME` with your GitHub username:\n\n    ```shell\n    go mod init github.com/YOUR-USERNAME/gh-whoami\n    go mod tidy\n    go build\n    ```\n\n1. Verify that your extension works. Replace `EXTENSION-NAME` with the name of your extension. For example, `whoami`.\n\n    ```shell\n    gh EXTENSION-NAME\n    ```\n\n1. From your directory, create a repository to publish your extension. Replace `EXTENSION-NAME` with the name of your extension.\n\n   {% note %}\n\n   **Note:** Be careful not to commit the binary produced by your compilation step to version control.\n\n   {% endnote %}\n\n   ```shell\n    git init -b main\n   echo", "Y2h1bmtfNF9pbmRleF8xMzMx": " \"gh-EXTENSION-NAME\" >> .gitignore\n   git add main.go go.* .gitignore && git commit -m 'Initial commit'\n   gh repo create \"gh-EXTENSION-NAME\"\n   ```\n\n1. Create a release to share your precompiled extension with others. Compile for each platform you want to support, attaching each binary to a release as an asset. Binary executables attached to releases must follow a naming convention and have a suffix of OS-ARCHITECTURE\\[EXTENSION\\].\n\n   For example, an extension named `whoami` compiled for Windows 64bit would have the name `gh-whoami-windows-amd64.exe` while the same extension compiled for Linux 32bit would have the name `gh-whoami-linux-386`. To see an exhaustive list of OS and architecture combinations recognized by `gh`, see this source code.\n\n   {% note %}\n\n   **Note:** For your extension to run properly on Windows, its asset file must have a `.exe` extension. No extension is needed for other operating systems.\n\n   {% endnote %}\n\n   Releases can be created from the command line. For example:\n\n   ```shell\n   git tag v1.0.0\n   git push origin v1.0.0\n   GOOS=windows GOARCH=amd64 go build -o gh-EXTENSION-NAME-windows-amd64.exe\n   GOOS=linux GOARCH=amd64 go build -o gh-EXTENSION-NAME-linux-amd64\n   GOOS=darwin GOARCH=amd64 go build -o gh-EXTENSION-NAME-darwin-amd64\n   gh release create v1.0.0 ./*amd64*\n\n1. Optionally, to help other users discover your extension, add the repository topic `gh-extension`. This will make the extension appear on the `gh-extension` topic page. For more information about how to add a repository topic, see \"Classifying your repository with topics.\"\n\n\n\nTips for writing precompiled {% data variables.product.prodname_cli %} extensions\n\n\n\nAutomating releases\n\nConsider adding the gh-extension-precompile action to a workflow in your project. This action will automatically produce cross-compiled Go binaries for your extension and supplies build scaffolding for non-Go precompiled extensions.\n\n\n\nUsing {% data variables.product.prodname_cli %} features from Go-based extensions\n\nConsider using go-gh", "Y2h1bmtfNV9pbmRleF8xMzMx": ", a Go library that exposes pieces of `gh` functionality for use in extensions.\n\n\n\nNext steps\n\nTo see more examples of {% data variables.product.prodname_cli %} extensions, look at repositories with the `gh-extension` topic.\n\n", "Y2h1bmtfMF9pbmRleF8xMjE1": "\n\nApplying to the {% data variables.product.prodname_student_leader_program %} program\n\nTo apply to the {% data variables.product.prodname_student_leader_program %} program, you must first submit an application form, then submit a video resume. Applications to the program open in February and August, and you\u2019ll have a full month to apply.\n\n{% note %}\n\n**Note:** The application process helps us get to know the applicant. Here are some things we want to learn about you:\n- Motivation: What makes you tick? What drives you?\n- Interest: Why do you want to be part of the program?\n- Growth and potential: What skills do you want to learn, and how will they help you grow personally and professionally?\n- Contribution: What impact do you want to make on your campus?\n\n{% endnote %}\n\n\n\nEligibility criteria\n\nTo become a {% data variables.product.prodname_student_leader_program_singular %}, you must:\n\n- Be a {% data variables.product.prodname_dotcom %} user for at least six months.\n- Be at least 18 years of age.\n- Be enrolled in a formal higher education institution.\n- Have more than one year left as a student before graduating.\n- Not be enrolled in the {% data variables.product.prodname_dotcom %} Campus Advisors Program.\n- Validate your student status through the {% data variables.product.prodname_student_pack %}.\n\n\n\nSubmitting your application form\n\nIn the application form, we\u2019re looking for students to tell us about the challenges their student community faces, what opportunities they want to build for their peers, and the potential they see for growth.\n1. Go to https://education.github.com/experts.\n1. To learn if applications are open, click **Become a Campus Expert** {% octicon \"arrow-right\" aria-label=\"The right arrow icon\" %}.\n1. If applications are open, a new page will appear titled \u201cYour journey starts here\u201d. To start your application, click **Apply Now**.\n\n   Otherwise, if applications are closed, a message will appear with the dates of the next application cycle.\n1. Following the prompts in the form, complete the app", "Y2h1bmtfMV9pbmRleF8xMjE1": "lication.\n1. Click **Submit Application**.\n1. Optionally, to confirm your application was submitted successfully, check the email address you provided for an email confirming your submission.\n1. Two weeks after the program applications close, check for an email containing an update on your application status and instructions to submit your video resume.\n\n\n\nSubmitting your video resume\n\nIn your video resume, we look forward to getting to know you as an individual.\n\n{% note %}\n\n**Note:** A video using your webcam and computer microphone is more than enough! We understand this process might not be accessible to all students. If you require an alternative method to make your submission, please reach out to the GitHub Education team.\n\n{% endnote %}\n\n1. Open the email you received after submitting your application form.\n1. Using the guidelines included in the application status email, record your video resume.\n1. Once your video is ready to be submitted, click **Upload video** at the bottom of the application status email.\n1. On the video submission form, add your email address and upload your video.\n1. Click **Submit** at the bottom of the form to send your video in for review.\n\n   After your video has been submitted, we\u2019ll take about a week to review it. If the program is the right fit, you\u2019ll be accepted and receive invitations to start the {% data variables.product.prodname_student_leader_program %} training and join an onboarding call.\n\n", "Y2h1bmtfMF9pbmRleF8yMDcw": "---\ntitle: GitHub Subprocessors\nversions:\n  fpt: '*'\ntopics:\n  - Policy\n  - Legal\n---\n\nGitHub defines customer data as all data provided by the customer to GitHub through their use of GitHub services. Some customer data is personal data as defined under GDPR.\n\nThe GitHub Subprocessor List identifies subprocessors authorized to subprocess customer or personal data on behalf of GitHub to provide services to our Enterprise customers. This list is applicable for all GitHub services governed by the GitHub Data Protection Agreement.\n\nGitHub publishes the names of any new subprocessors for its online services at least 30 days in advance of the subprocessor\u2019s authorization to perform services that may involve access to customer data or personal data.\n\nTo receive notifications of updates to this Subprocessor list, please follow the instructions provided in AUTOTITLE.\n\nIf you have questions about this list, please contact us at privacy@github.com.\n\nName of Subprocessor | Description of Processing | Location of Processing | Corporate Location\n---------------------|---------------------------|------------------------|-------------------\nAmazon Web Services (AWS) | Cloud Hosted Infrastructure and Data Hosting | United States | United States\nAzure (Microsoft) | Cloud Hosted Infrastructure and Data Hosting | United States |United States\nAzure Cognitive Services | Customer support ticketing analysis | United States | United States\nCloudflare | Content delivery service | United States | United States\nFastly | Content delivery service | United States | United States\nGoogle Cloud Platform (GCP) | Cloud Hosted Infrastructure | United States | United States\nMicrosoft | Technical Services | United States | United States\nMoveworks | Customer support ticketing analysis | United States | United States\nNexMo (aka Vonage) | SMS notification provider for 2 Factor Authentication | United States | United States\nObsidian Security | Security management | United States | United States\nPusher | Building and managing real-time infrastructure for w", "Y2h1bmtfMV9pbmRleF8yMDcw": "eb and mobile applications | United States | United States\nSendGrid | SMS notification provider for 2 Factor Authentication | United States | United States\nSplunk | Logging pipeline for security log, storage, and search | United States | United States\nTwilio | SMS notification provider for 2 Factor Authentication | United States | United States\nVividCortex | Monitor database performance, efficiency, and uptime | United States | United States\nZapier | App infrastructure and support | United States | United States\nZendesk | Customer support ticketing system | United States | United States\n\n", "Y2h1bmtfMF9pbmRleF8yMDcx": "\n\nBounty Program\n\nLike several other large software companies, GitHub provides a bug bounty to better engage with security researchers. The idea is simple: hackers and security researchers (like you) find and report vulnerabilities through our coordinated disclosure process. Then, to recognize the significant effort that these researchers often put forth when hunting down bugs, we reward them with some cold hard cash.\n\nCheck out the GitHub Bug Bounty site for bounty details, review our comprehensive Legal Safe Harbor Policy terms as well, and happy hunting!\n\n", "Y2h1bmtfMF9pbmRleF83NzM=": "\n\nAbout this warning\n\n```text\nWarning: 1 issue was detected with this workflow: git checkout HEAD^2 is no longer\nnecessary. Please remove this step as Code Scanning recommends analyzing the merge\ncommit for best results.\n```\n\nIf you're using an old {% data variables.product.prodname_codeql %} workflow you may receive this warning from the \"Initialize {% data variables.product.prodname_codeql %}\" action.\n\n\n\nConfirm the cause of the problem\n\nCheck for the following lines from the {% data variables.product.prodname_codeql %} workflow. These lines were included in the `steps` section of the `Analyze` job in initial versions of the {% data variables.product.prodname_codeql %} workflow.\n\n```yaml\n        with:\n          # We must fetch at least the immediate parents so that if this is\n          # a pull request then we can checkout the head.\n          fetch-depth: 2\n\n      # If this run was triggered by a pull request event, then checkout\n      # the head of the pull request instead of the merge commit.\n      - run: git checkout HEAD^2\n        if: {% raw %}${{ github.event_name == 'pull_request' }}{% endraw %}\n```\n\n\n\nFixing the problem\n\nRemove the lines from the {% data variables.product.prodname_codeql %} workflow. The revised `steps` section of the workflow should now look like this:\n\n```yaml\n    steps:\n      - name: Checkout repository\n        uses: {% data reusables.actions.action-checkout %}\n\n      # Initializes the {% data variables.product.prodname_codeql %} tools for scanning.\n      - name: Initialize {% data variables.product.prodname_codeql %}\n        uses: {% data reusables.actions.action-codeql-action-init %}\n\n      ...\n```\n\nFor more information about editing the {% data variables.product.prodname_codeql %} workflow file, see \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF81MDc=": "\n\nAbout webhooks and {% data variables.product.prodname_github_apps %}\n\nWebhooks enable your {% data variables.product.prodname_github_app %} to receive real-time notifications when events happen on {% data variables.product.prodname_dotcom %}, such as when someone pushes a commit or opens a pull request in a repository that your app can access. For more information about webhooks, see \"AUTOTITLE.\" For a tutorial that demonstrates how to use webhooks with a {% data variables.product.prodname_github_app %}, see \"AUTOTITLE.\"\n\nYou can configure your {% data variables.product.prodname_github_app %} to receive webhooks for specific events on {% data variables.product.prodname_dotcom %} and automatically take action on them. For more information about the types of webhooks you can receive, see \"AUTOTITLE.\"\n\nTo receive webhook events in your {% data variables.product.prodname_github_app %}, you must enable webhooks for your {% data variables.product.prodname_github_app %} registration and specify a webhook URL where {% data variables.product.prodname_dotcom %} will send the webhook payloads.\n\nIf your {% data variables.product.prodname_github_app %} does not need to respond to webhooks or will only be used for authentication, you can turn off the webhook function for your {% data variables.product.prodname_github_app %} registration. You do not need to specify a webhook URL.\n\nFor more information about registering a {% data variables.product.prodname_github_app %}, see \"AUTOTITLE.\" For more information about changing the webhooks that a {% data variables.product.prodname_github_app %} registration subscribes to, see \"AUTOTITLE.\"\n\n\n\nChoosing a webhook URL\n\nWhen you activate webhooks for your {% data variables.product.prodname_github_app %} registration, you will need to specify a webhook URL. The webhook URL is the address of a web server that will receive the webhook event payloads sent to your {% data variables.product.prodname_github_app %}. The server can then take action based on the content of the payload. You shoul", "Y2h1bmtfMV9pbmRleF81MDc=": "d choose a web server that's appropriate for the volume of webhook traffic that your {% data variables.product.prodname_github_app %} will encounter.\n\n\n\nChoosing a webhook URL for development and testing\n\nWhile you develop and test your app, you can use a webhook payload delivery service like Smee to capture and forward webhook payloads to your local development environment. Never use Smee for an application in production, because Smee channels are not authenticated or secure. Alternatively, you can use a tool like ngrok, localtunnel, or the Hookdeck Console that exposes your local machine to the internet to receive the payloads.\n\n\n\nCreating a webhook URL with Smee\n\nYou can use Smee to create a unique domain where {% data variables.product.prodname_dotcom %} can send webhook payloads, without exposing your local development to the internet. Smee calls this unique domain a \"Webhook Proxy URL.\" You can use Smee's Webhook Proxy URL as the webhook URL for your {% data variables.product.prodname_github_app %}.\n\n1. To use Smee to create a unique domain, go to https://smee.io and click **Start a new channel**.\n1. On the Smee channel page, follow the instructions under \"Use the CLI\" to install and run the Smee client.\n1. To connect your Smee webhook URL to your {% data variables.product.prodname_github_app %}, enter your unique Smee domain in the \"Webhook URL\" field on your {% data variables.product.prodname_github_app %} registration page. For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n\n\n\nChoosing a webhook URL for production\n\nFor an application in production that receives a low volume of webhook traffic, you can host it on any dynamic application server. The server-side code for handling the webhook can receive the event, deserialize its JSON payload, and decide what action to take, such as storing the data in a database or calling the {% data variables.product.prodname_dotcom %} API.\n\nTo handle a higher volume of webhook traffic for a large app in production, consider using asynchronous webhook handling on a d", "Y2h1bmtfMl9pbmRleF81MDc=": "edicated server. You can achieve this by employing a queue, where the webhook handler pushes data to the queue, and separate processes perform subsequent actions based on the events. Additionally, you can use cloud functions such as Azure Functions, AWS Lambda, or Hookdeck to help scale the app for handling large volumes of webhook events.\n\n\n\nSecuring your webhooks with a webhook secret\n\nOnce you've configured your server to receive payloads, it will listen for any payload sent to the server. For security reasons, you should limit incoming requests to only those originating from {% data variables.product.prodname_dotcom %}. You can do that by creating a webhook secret for your app.\n\nTo create a webhook secret for your GitHub App, type a secret token under \"Webhook secret\" on your {% data variables.product.prodname_github_app %} registration page. You should choose a random string of text with high entropy. For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n\nAfter creating a webhook secret for your app, you will need to configure your server to securely store and validate the webhook secret token. For more information, see \"AUTOTITLE.\"\n\n\n\nSubscribing to webhook events\n\nYou can subscribe your {% data variables.product.prodname_github_app %} to receive webhook payloads for specific events. {% data reusables.apps.webhooks-and-apps %} For more information, see \"AUTOTITLE.\"\n\nFor example, if you would like your app to receive a webhook event payload whenever a new issue is opened in your repository, you would first need to give your app permission to access \"Issues\" under \"Repository permissions.\" Then under \"Subscribe to events\" you can select \"Issues.\"\n\nFor more information about the permissions that are required for each webhook event, see \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF8xNjM4": "\n\nPrerequisites\n\n- You must have RubyGems 2.4.1 or higher. To find your RubyGems version:\n\n  ```shell\n  gem --version\n  ```\n\n- You must have bundler 1.6.4 or higher. To find your Bundler version:\n\n  ```shell\n  $ bundle --version\n  Bundler version 1.13.7\n  ```\n\n\n\nAuthenticating to {% data variables.product.prodname_registry %}\n\n{% data reusables.package_registry.authenticate-packages %}\n\n{% ifversion packages-rubygems-v2 %}\n\n\n\nAuthenticating in a {% data variables.product.prodname_actions %} workflow\n\nThis registry supports granular permissions. {% data reusables.package_registry.authenticate_with_pat_for_v2_registry %}\n\n{% data reusables.package_registry.v2-actions-codespaces %}\n\n{% endif %}\n\n\n\nAuthenticating with a {% data variables.product.pat_generic %}\n\n{% data reusables.package_registry.required-scopes %}\n\nTo publish and install gems, you can configure RubyGems or Bundler to authenticate to {% data variables.product.prodname_registry %} using your {% data variables.product.pat_generic %}.\n\nTo publish new gems, you need to authenticate to {% data variables.product.prodname_registry %} with RubyGems by editing your _~/.gem/credentials_ file to include your {% data variables.product.pat_v1 %}. Create a new _~/.gem/credentials_ file if this file doesn't exist.\n\nFor example, you would create or edit a _~/.gem/credentials_ to include the following, replacing TOKEN with your {% data variables.product.pat_generic %}.\n\n```shell\n---\n:github: Bearer TOKEN\n```\n\nTo install gems, you need to authenticate to {% data variables.product.prodname_registry %} by updating your gem sources to include `https://USERNAME:TOKEN@{% ifversion fpt or ghec %}rubygems.pkg.github.com{% else %}REGISTRY_URL{% endif %}/NAMESPACE/`. You must replace:\n- `USERNAME` with your {% data variables.product.prodname_dotcom %} username.\n- `TOKEN` with your {% data variables.product.pat_v1 %}.\n- `NAMESPACE` with the name of the personal account or organization {% ifversion packages-rubygems-v2 %}to which the gem is scoped{% else %}that owns the repositor", "Y2h1bmtfMV9pbmRleF8xNjM4": "y containing the gem{% endif %}.{% ifversion ghes %}\n- `REGISTRY_URL` with the URL for your instance's Rubygems registry. If your instance has subdomain isolation enabled, use `rubygems.HOSTNAME`. If your instance has subdomain isolation disabled, use `HOSTNAME/_registry/rubygems`. In either case, replace HOSTNAME with the hostname of your {% data variables.product.prodname_ghe_server %} instance.\n{% elsif ghae %}\n- `REGISTRY_URL` with the URL for your instance's Rubygems registry, `rubygems.HOSTNAME`. Replace HOSTNAME with the hostname of {% data variables.location.product_location %}.\n{% endif %}\n\nIf you would like your package to be available globally, you can run the following command to add your registry as a source.\n\n```shell\ngem sources --add https://USERNAME:TOKEN@{% ifversion fpt or ghec %}rubygems.pkg.github.com{% else %}REGISTRY_URL{% endif %}/NAMESPACE/\n```\n\nTo authenticate with Bundler, configure Bundler to use your {% data variables.product.pat_v1 %}, replacing USERNAME with your {% data variables.product.prodname_dotcom %} username, TOKEN with your {% data variables.product.pat_generic %}, and NAMESPACE with the name of the personal account or organization {% ifversion packages-rubygems-v2 %}to which the gem is scoped{% else %}that owns the repository containing the gem{% endif %}.{% ifversion ghes %} Replace `REGISTRY_URL` with the URL for your instance's RubyGems registry. If your instance has subdomain isolation enabled, use `rubygems.HOSTNAME`. If your instance has subdomain isolation disabled, use `HOSTNAME/_registry/rubygems`. In either case, replace HOSTNAME with the hostname of your {% data variables.product.prodname_ghe_server %} instance.{% elsif ghae %}Replace `REGISTRY_URL` with the URL for your instance's Rubygems registry, `rubygems.HOSTNAME`. Replace HOSTNAME with the hostname of {% data variables.location.product_location %}.{% endif %}\n\n```shell\nbundle config https://{% ifversion fpt or ghec %}rubygems.pkg.github.com{% else %}REGISTRY_URL{% endif %}/NAMESPACE USERNAME:TOKEN\n```\n\n\n\n", "Y2h1bmtfMl9pbmRleF8xNjM4": "Publishing a package\n\n{% ifversion packages-rubygems-v2 %}{% data reusables.package_registry.publishing-user-scoped-packages %}{% else %}By default, GitHub publishes the package to an existing repository with the same name as the package. For example, when you publish `GEM_NAME` to the `octo-org` organization, GitHub Packages publishes the gem to the `octo-org/GEM_NAME` repository.{% endif %} For more information on creating your gem, see \"Make your own gem\" in the RubyGems documentation.\n\n{% data reusables.package_registry.auto-inherit-permissions-note %}\n\n{% data reusables.package_registry.authenticate-step %}\n\n1. Build the package from the _gemspec_ to create the _.gem_ package. Replace `GEM_NAME` with the name of your gem.\n\n   ```shell\n   gem build GEM_NAME.gemspec\n   ```\n\n1. Publish a package to {% data variables.product.prodname_registry %}, replacing `NAMESPACE` with the name of the personal account or organization {% ifversion packages-rubygems-v2 %}to which the package will be scoped{% else %}that owns the repository containing your project{% endif %} and `GEM_NAME` with the name of your gem package.{% ifversion ghes %} Replace `REGISTRY_URL` with the URL for your instance's Rubygems registry. If your instance has subdomain isolation enabled, use `rubygems.HOSTNAME`. If your instance has subdomain isolation disabled, use `HOSTNAME/_registry/rubygems`. In either case, replace `HOSTNAME` with the host name of your {% data variables.product.prodname_ghe_server %} instance.{% elsif ghae %} Replace `REGISTRY_URL` with the URL for your instance's Rubygems registry, `rubygems.HOSTNAME`. Replace `HOSTNAME` with the hostname of {% data variables.location.product_location %}.{% endif %}\n\n   {% note %}\n\n   **Note:** The maximum uncompressed size of a gem's `metadata.gz` file must be less than {% data variables.package_registry.limit_rubygems_max_metadata_size %}. Requests to push gems that exceed that limit will fail.\n\n   {% endnote %}\n\n   ```shell\n   $ gem push --key github \\\n   --host https://{% ifversion fpt or ", "Y2h1bmtfM19pbmRleF8xNjM4": "ghec %}rubygems.pkg.github.com{% else %}REGISTRY_URL{% endif %}/NAMESPACE \\\n   GEM_NAME-0.0.1.gem\n   ```\n\n{% ifversion packages-rubygems-v2 %}\n\n\n\nConnecting a package to a repository\n\nThe RubyGems registry stores packages within your organization or personal account, and allows you to associate packages with a repository. You can choose whether to inherit permissions from a repository, or set granular permissions independently of a repository.\n\nYou can ensure gems will be linked to a repository as soon as they are published by including the URL of the {% data variables.product.prodname_dotcom %} repository in the `github_repo` field in `gem.metadata`. You can link multiple gems to the same repository. {% ifversion ghes %} In the following example, replace HOSTNAME with the host name of {% data variables.location.product_location %}.{% endif %}\n\n```ruby\ngem.metadata = { \"github_repo\" => \"ssh://{% ifversion fpt or ghec %}github.com{% else %}HOSTNAME{% endif %}/OWNER/REPOSITORY\" }\n```\n\nFor information on linking a published package with a repository, see \"AUTOTITLE.\"\n\n{% else %}\n\n\n\nPublishing multiple packages to the same repository\n\nTo publish multiple gems to the same repository, you can include the URL to the {% data variables.product.prodname_dotcom %} repository in the `github_repo` field in `gem.metadata`. If you include this field, {% data variables.product.prodname_dotcom %} matches the repository based on this value, instead of using the gem name.{% ifversion ghes or ghae %} Replace HOSTNAME with the host name of {% data variables.location.product_location %}.{% endif %}\n\n```ruby\ngem.metadata = { \"github_repo\" => \"ssh://{% ifversion fpt or ghec %}github.com{% else %}HOSTNAME{% endif %}/OWNER/REPOSITORY\" }\n```\n\n{% endif %}\n\n\n\nInstalling a package\n\nYou can use gems from {% data variables.product.prodname_registry %} much like you use gems from _rubygems.org_. You need to authenticate to {% data variables.product.prodname_registry %} by adding your {% data variables.product.prodname_dotcom %} user or organizat", "Y2h1bmtfNF9pbmRleF8xNjM4": "ion as a source in the _~/.gemrc_ file or by using Bundler and editing your _Gemfile_.\n\n{% data reusables.package_registry.authenticate-step %}\n1. For Bundler, add your {% data variables.product.prodname_dotcom %} user or organization as a source in your _Gemfile_ to fetch gems from this new source. For example, you can add a new `source` block to your _Gemfile_ that uses {% data variables.product.prodname_registry %} only for the packages you specify, replacing `GEM_NAME` with the package you want to install from {% data variables.product.prodname_registry %} and `NAMESPACE` with the personal account or organization {% ifversion packages-rubygems-v2 %}to which the gem you want to install is scoped{% else %}that owns the repository containing the gem you want to install{% endif %}.{% ifversion ghes %} Replace `REGISTRY_URL` with the URL for your instance's Rubygems registry. If your instance has subdomain isolation enabled, use `rubygems.HOSTNAME`. If your instance has subdomain isolation disabled, use `HOSTNAME/_registry/rubygems`. In either case, replace `HOSTNAME` with the host name of your {% data variables.product.prodname_ghe_server %} instance.{% elsif ghae %} Replace `REGISTRY_URL` with the URL for your instance's Rubygems registry, `rubygems.HOSTNAME`. Replace `HOSTNAME` with the hostname of {% data variables.location.product_location %}.{% endif %}\n\n   ```ruby\n   source \"https://rubygems.org\"\n\n   gem \"rails\"\n\n   source \"https://{% ifversion fpt or ghec %}rubygems.pkg.github.com{% else %}REGISTRY_URL{% endif %}/NAMESPACE\" do\n     gem \"GEM_NAME\"\n   end\n   ```\n\n1. For Bundler versions earlier than 1.7.0, you need to add a new global `source`. For more information on using Bundler, see the bundler.io documentation.\n\n   ```ruby\n   source \"https://{% ifversion fpt or ghec %}rubygems.pkg.github.com{% else %}REGISTRY_URL{% endif %}/NAMESPACE\"\n   source \"https://rubygems.org\"\n\n   gem \"rails\"\n   gem \"GEM_NAME\"\n   ```\n\n1. Install the package:\n\n   ```shell\n   gem install GEM_NAME --version \"0.1.1\"\n   ```\n\n\n\nFurther", "Y2h1bmtfNV9pbmRleF8xNjM4": " reading\n\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8xNjgy": "\n\nFurther Reading\n\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8xMzM3": "\n\nGraphQL terminology\n\nThe GitHub GraphQL API represents an architectural and conceptual shift from the GitHub REST API. You will likely encounter some new terminology in the GraphQL API reference docs.\n\n\n\nSchema\n\nA schema defines a GraphQL API's type system. It describes the complete set of possible data (objects, fields, relationships, everything) that a client can access. Calls from the client are validated and executed against the schema. A client can find information about the schema via introspection. A schema resides on the GraphQL API server. For more information, see \"Discovering the GraphQL API.\"\n\n\n\nField\n\nA field is a unit of data you can retrieve from an object. As the official GraphQL docs say:\n\"The GraphQL query language is basically about selecting fields on objects.\"\n\nThe official spec also says about fields:\n\n> All GraphQL operations must specify their selections down to fields which return scalar values to ensure an unambiguously shaped response.\n\nThis means that if you try to return a field that is not a scalar, schema validation will throw an error. You must add nested subfields until all fields return scalars.\n\n\n\nArgument\n\nAn argument is a set of key-value pairs attached to a specific field. Some fields require an argument. Mutations require an input object as an argument.\n\n\n\nImplementation\n\nA GraphQL schema may use the term _implements_ to define how an object inherits from an interface.\n\nHere's a contrived example of a schema that defines interface `X` and object `Y`:\n\n```graphql\ninterface X {\n  some_field: String!\n  other_field: String!\n}\n\ntype Y implements X {\n  some_field: String!\n  other_field: String!\n  new_field: String!\n}\n```\n\nThis means object `Y` requires the same fields/arguments/return types that interface `X` does, while adding new fields specific to object `Y`. (The `!` means the field is required.)\n\nIn the reference docs, you'll find that:\n\n- Each object lists the interface(s) _from which it inherits_ under **Implements**.\n\n- Each interface lists the objects _that inherit from", "Y2h1bmtfMV9pbmRleF8xMzM3": " it_ under **Implementations**.\n\n\n\nConnection\n\nConnections let you query related objects as part of the same call. With connections, you can use a single GraphQL call where you would have to use multiple calls to a REST API. For more information, see \"AUTOTITLE.\"\n\nIt's helpful to picture a graph: dots connected by lines. The dots are nodes, the lines are edges. A connection defines a relationship between nodes.\n\n\n\nEdge\n\nEdges represent connections between nodes. When you query a connection, you traverse its edges to get to its nodes. Every `edges` field has a `node` field and a `cursor` field. Cursors are used for pagination. For more information, see \"AUTOTITLE.\"\n\n\n\nNode\n\n_Node_ is a generic term for an object. You can look up a node directly, or you can access related nodes via a connection. If you specify a `node` that does not return a scalar, you must include subfields until all fields return scalars. For information on accessing node IDs via the REST API and using them in GraphQL queries, see \"AUTOTITLE.\"\n\n\n\nDiscovering the GraphQL API\n\nGraphQL is introspective. This means you can query a GraphQL schema for details about itself.\n\n- Query `__schema` to list all types defined in the schema and get details about each:\n\n  ```graphql\n  query {\n    __schema {\n      types {\n        name\n        kind\n        description\n        fields {\n          name\n        }\n      }\n    }\n  }\n  ```\n\n- Query `__type` to get details about any type:\n\n  ```graphql\n  query {\n    __type(name: \"Repository\") {\n      name\n      kind\n      description\n      fields {\n        name\n      }\n    }\n  }\n  ```\n\n- You can also run an _introspection query_ of the schema via a `GET` request:\n\n  ```shell\n  curl -H \"Authorization: bearer TOKEN\" {% data variables.product.graphql_url_pre %}\n  ```\n\n  {% note %}\n\n  **Note**: If you get the response `\"message\": \"Bad credentials\"` or `401 Unauthorized`, check that you are using a valid token. {% ifversion pat-v2 %}If you receive a `403` error with `Resource not accessible by {% data variables.product.pat_ge", "Y2h1bmtfMl9pbmRleF8xMzM3": "neric %}`, ensure that your {% data variables.product.pat_v2 %} is targeted to the correct resource owner. For example, it must target the organization that owns the repository you are trying to access.{% endif %}\n\n  {% endnote %}\n\n  The results are in JSON, so we recommend pretty-printing them for easier reading and searching. You can use a command-line tool like jq or pipe the results into `python -m json.tool` for this purpose.\n\n  Alternatively, you can pass the `idl` media type to return the results in IDL format, which is a condensed version of the schema:\n\n  ```shell\n  $ curl -H \"Authorization: bearer TOKEN\" -H \"Accept: application/vnd.github.v4.idl\" \\\n  {% data variables.product.graphql_url_pre %}\n  ```\n\n  {% note %}\n\n  **Note**: The introspection query is probably the only `GET` request you'll run in GraphQL. If you're passing a body, the GraphQL request method is `POST`, whether it's a query or a mutation.\n\n  {% endnote %}\n\n  For more information about performing queries, see \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF84MTY=": "\n\nSynopsis\n\n```shell copy\ncodeql generate query-help --format= [--output=] ... -- ...\n```\n\n\n\nDescription\n\nGenerate end-user query help from .qhelp files.\n\n\n\nOptions\n\n\n\nPrimary Options\n\n\n\n`<qhelpdir|suite>...`\n\n\\[Mandatory] Query help files to render. Each argument is one of:\n\n- A .qhelp file to render.\n- A .ql file with a corresponding .qhelp file to render.\n- A directory that will be searched recursively for .ql files with\n  corresponding .qhelp files.\n- A .qls file that defines a particular set of queries.\n- The basename of a \"well-known\" .qls file exported by one of the\n  installed QL packs.\n\n\n\n`--format=<format>`\n\n\\[Mandatory] The format in which to render the documentation. One of:\n\n`markdown`: GitHub flavored markdown.\n\n`sarif-latest`: Static Analysis Results Interchange Format (SARIF), a\nJSON-based format for describing static analysis results. This format\noption uses the most recent supported version (v2.1.0). This option is\nnot suitable for use in automation as it will produce different versions\nof SARIF between different CodeQL versions.\n\n`sarifv2.1.0`: SARIF v2.1.0.\n\n\n\n`-o, --output=<dir|file>`\n\nA path to write the rendered documentation to. Usually this is a\ndirectory into which the rendered output will be written.\n\nIf only a single .qhelp or .ql file is provided, and no directory exists\nat the output path, the output will be written to a single file at that\npath.\n\nIf no output path is provided, only a single .qhelp or .ql file will be\naccepted, and the output will be written to stdout.\n\nIf an output directory is used, filenames _within_ the output directory\nwill be derived from the .qhelp file names.\n\n\n\n`--warnings=<mode>`\n\nHow to handle warnings from the query help renderer. One of:\n\n`hide`: Suppress warnings.\n\n`show` _(default)_: Print warnings but continue with rendering.\n\n`error`: Treat warnings as errors.\n\n\n\nOptions for finding QL packs (which may be necessary to resolve query suites)\n\n\n\n`--search-path=<dir>[:<dir>...]`\n\nA list of directories under which QL packs may be found. Each directory\ncan", "Y2h1bmtfMV9pbmRleF84MTY=": " either be a QL pack (or bundle of packs containing a\n`.codeqlmanifest.json` file at the root) or the immediate parent of one\nor more such directories.\n\nIf the path contains more than one directory, their order defines\nprecedence between them: when a pack name that must be resolved is\nmatched in more than one of the directory trees, the one given first\nwins.\n\nPointing this at a checkout of the open-source CodeQL repository ought\nto work when querying one of the languages that live there.\n\nIf you have checked out the CodeQL repository as a sibling of the\nunpacked CodeQL toolchain, you don't need to give this option; such\nsibling directories will always be searched for QL packs that cannot be\nfound otherwise. (If this default does not work, it is strongly\nrecommended to set up `--search-path` once and for all in a per-user\nconfiguration file).\n\n(Note: On Windows the path separator is `;`).\n\n\n\n`--additional-packs=<dir>[:<dir>...]`\n\nIf this list of directories is given, they will be searched for packs\nbefore the ones in `--search-path`. The order between these doesn't\nmatter; it is an error if a pack name is found in two different places\nthrough this list.\n\nThis is useful if you're temporarily developing a new version of a pack\nthat also appears in the default path. On the other hand, it is _not\nrecommended_ to override this option in a config file; some internal\nactions will add this option on the fly, overriding any configured\nvalue.\n\n(Note: On Windows the path separator is `;`).\n\n\n\nOptions for configuring the CodeQL package manager\n\n\n\n`--registries-auth-stdin`\n\nAuthenticate to GitHub Enterprise Server Container registries by passing\na comma-separated list of \\=\\ pairs.\n\nFor example, you can pass\n`https://containers.GHEHOSTNAME1/v2/=TOKEN1,https://containers.GHEHOSTNAME2/v2/=TOKEN2`\nto authenticate to two GitHub Enterprise Server instances.\n\nThis overrides the CODEQL\\_REGISTRIES\\_AUTH and GITHUB\\_TOKEN environment\nvariables. If you only need to authenticate to the github.com Container\nregistry, you can instead auth", "Y2h1bmtfMl9pbmRleF84MTY=": "enticate using the simpler\n`--github-auth-stdin` option.\n\n\n\n`--github-auth-stdin`\n\nAuthenticate to the github.com Container registry by passing a\ngithub.com GitHub Apps token or personal access token via standard\ninput.\n\nTo authenticate to GitHub Enterprise Server Container registries, pass\n`--registries-auth-stdin` or use the CODEQL\\_REGISTRIES\\_AUTH environment\nvariable.\n\nThis overrides the GITHUB\\_TOKEN environment variable.\n\n\n\nCommon options\n\n\n\n`-h, --help`\n\nShow this help text.\n\n\n\n`-J=<opt>`\n\n\\[Advanced] Give option to the JVM running the command.\n\n(Beware that options containing spaces will not be handled correctly.)\n\n\n\n`-v, --verbose`\n\nIncrementally increase the number of progress messages printed.\n\n\n\n`-q, --quiet`\n\nIncrementally decrease the number of progress messages printed.\n\n\n\n`--verbosity=<level>`\n\n\\[Advanced] Explicitly set the verbosity level to one of errors,\nwarnings, progress, progress+, progress++, progress+++. Overrides `-v`\nand `-q`.\n\n\n\n`--logdir=<dir>`\n\n\\[Advanced] Write detailed logs to one or more files in the given\ndirectory, with generated names that include timestamps and the name of\nthe running subcommand.\n\n(To write a log file with a name you have full control over, instead\ngive `--log-to-stderr` and redirect stderr as desired.)\n\n\n\n`--common-caches=<dir>`\n\n\\[Advanced] Controls the location of cached data on disk that will\npersist between several runs of the CLI, such as downloaded QL packs and\ncompiled query plans. If not set explicitly, this defaults to a\ndirectory named `.codeql` in the user's home directory; it will be\ncreated if it doesn't already exist.\n\nAvailable since `v2.15.2`.\n\n", "Y2h1bmtfMF9pbmRleF8xMTE4": "\n\nIntroduction\n\n{% data variables.product.prodname_copilot %} is an AI pair programmer. You can use {% data variables.product.prodname_copilot %} to get suggestions for whole lines or entire functions right inside your editor.\n\nThis guide will show you how to set up a {% data variables.product.prodname_copilot %} subscription for your personal {% ifversion fpt %}or organization{% else %}, organization, or enterprise{% endif %} account, install the {% data variables.product.prodname_copilot %} extension in {% data variables.product.prodname_vscode %}, and get your first suggestion. For more information on {% data variables.product.prodname_copilot %}, see \"AUTOTITLE.\" For more in-depth information on how to use {% data variables.product.prodname_copilot %} in a variety of environments, see \"AUTOTITLE.\"\n\n\n\nSigning up for {% data variables.product.prodname_copilot %} for your personal account\n\nBefore you can start using {% data variables.product.prodname_copilot %}, you will need to set up a free trial or subscription for your personal account.\n\n{% data reusables.copilot.tp-users-trial-eligibility %}\n\n{% data reusables.copilot.signup-procedure %}\n\n{% note %}\n\n**Note:** As a member of an organization owned by a {% data variables.product.prodname_ghe_cloud %} account with a {% data variables.product.prodname_copilot %} subscription, you must be assigned a {% data variables.product.prodname_copilot %} seat by your organization before you can use {% data variables.product.prodname_copilot %}.\n{% endnote %}\n\n{% ifversion fpt %}\n\n\n\nSigning up for {% data variables.product.prodname_copilot %} for your organization account\n\nBefore you can start using {% data variables.product.prodname_copilot %} in your organization account, you will need to set up a subscription.\n\n{% data reusables.copilot.signup-procedure-org %}\n{% endif %}\n\n{% ifversion ghec %}\n\n\n\nSigning up for {% data variables.product.prodname_copilot %} for your enterprise account\n\n{% note %}\n\n**Note:** If you already have a payment method set up for your enterprise ", "Y2h1bmtfMV9pbmRleF8xMTE4": "account and are billed by {% data variables.product.prodname_dotcom %}, you can skip this section.\n\n{% endnote %}\n\n\n\nCustomers under a Microsoft Enterprise Agreement\n\n{% data reusables.copilot.signup-procedure-enterprise-msft-ea %}\n\n\n\nCustomers under a direct GitHub contract\n\n{% data reusables.copilot.signup-procedure-enterprise %}\n\n\n\nEnabling {% data variables.product.prodname_copilot %} for your enterprise account\n\n{% data reusables.copilot.enabling-in-enterprise %}\n\nFor more information, see \"AUTOTITLE.\"\n\n{% endif %}\n\n\n\nInstalling the {% data variables.product.prodname_copilot %} extension for {% data variables.product.prodname_vscode %}\n\nTo use {% data variables.product.prodname_copilot %}, you must first install the {% data variables.product.prodname_vscode %} extension.\n\n1. In the {% data variables.product.prodname_vscode %} Marketplace, go to the {% data variables.product.prodname_copilot %} extension page and click **Install**.\n1. A popup will appear, asking to open {% data variables.product.prodname_vscode %}. Click **Open {% data variables.product.prodname_vscode %}**.\n1. In the \"Extension: {% data variables.product.prodname_copilot %}\" tab in {% data variables.product.prodname_vscode %}, click **Install**.\n1. If you have not previously authorized {% data variables.product.prodname_vscode %} in your {% data variables.product.prodname_dotcom %} account, you will be prompted to sign in to {% data variables.product.prodname_dotcom %} in {% data variables.product.prodname_vscode %}.\n\n   - If you have previously authorized {% data variables.product.prodname_vscode %} in your {% data variables.product.prodname_dotcom %} account, {% data variables.product.prodname_copilot %} will be automatically authorized.\n\n1. In your browser, {% data variables.product.prodname_dotcom %} will request the necessary permissions for {% data variables.product.prodname_copilot %}. To approve these permissions, click **Authorize {% data variables.product.prodname_vscode %}**.\n1. In {% data variables.product.prodname_vscode %}, in ", "Y2h1bmtfMl9pbmRleF8xMTE4": "the \"{% data variables.product.prodname_vscode %}\" dialogue box, to confirm the authentication, click **Open**.\n\n\n\nGetting your first suggestion\n\n{% data reusables.copilot.code-examples-limitations %}\n\n{% data reusables.copilot.supported-languages %} The following samples are in JavaScript, but other languages will work similarly.\n\n1. Open {% data variables.product.prodname_vscode %}.\n{% data reusables.copilot.create-js-file %}\n{% data reusables.copilot.type-function-header %}\n   {% data variables.product.prodname_copilot %} will automatically suggest an entire function body in grayed text. The exact suggestion may vary.\n{% data reusables.copilot.accept-suggestion %}\n\n\n\nNext steps\n\n{% data reusables.copilot.next-steps %}\n\n- AUTOTITLE: You've learned how to get your first suggestion in {% data variables.product.prodname_vscode %}. These guides show you how to set up and navigate the various functions of {% data variables.product.prodname_copilot %} across all of the supported environments.\n- {% data variables.product.prodname_copilot %}: See practical examples of how {% data variables.product.prodname_copilot %} can help you work.\n- AUTOTITLE: These guides provide details on how to configure {% data variables.product.prodname_copilot %} to your personal preferences.\n\n\n\nFurther reading\n\n- AUTOTITLE\n- AUTOTITLE\n\n", "Y2h1bmtfMF9pbmRleF8xNjg1": "\n\nCreating a branch\n\nYou can create a branch in different ways on {% data variables.product.product_name %}.\n\n{% note %}\n\n**Note:** You can only create a branch in a repository to which you have push access.\n\n{% endnote %}\n\n{% ifversion create-branch-from-overview %}\n\n\n\nCreating a branch via the branches overview\n\n{% data reusables.repositories.navigate-to-repo %}\n{% data reusables.repositories.navigate-to-branches %}\n1. Click **New branch**.\n\n   !Screenshot of the \"Branches\" page for a repository. A green button, labeled \"New branch\", is highlighted with an orange outline.\n1. Under \"Branch name\", type a name for the branch.\n1. Under \"Branch source\", choose a source for your branch.\n   - If your repository is a fork, select the repository dropdown menu and click your fork or the upstream repository.\n   - Select the branch dropdown menu and click a branch.\n1. Click **Create branch**.\n{% endif %}\n\n\n\nCreating a branch using the branch dropdown\n\n{% data reusables.repositories.navigate-to-repo %}\n{% ifversion code-search-code-view %}\n1. Select the {% octicon \"git-branch\" aria-hidden=\"true\" %} branch dropdown menu, in the file tree view or at the top of the integrated file editor.\n\n   !Screenshot of the file tree view for a repository. A dropdown menu for branches is outlined in dark orange.\n{% else %}\n1. Select the branch selector dropdown menu.\n\n{% ifversion global-nav-update %}\n\n   !Screenshot of the repository page. A dropdown menu, labeled with a branch icon and \"main\", is highlighted with an orange outline.\n\n{% else %}\n\n   !Screenshot of the repository page. A dropdown menu, labeled with a branch icon and \"main\", is highlighted with an orange outline.\n\n{% endif %}\n{% endif %}\n1. Optionally, if you want to create the new branch from a branch other than the default branch of the repository, click another branch, then select the branch dropdown menu again.\n1. In the \"Find or create a branch...\" text field, type a unique name for your new branch, then click **Create branch**.\n\n   !Screenshot of the branch selector dr", "Y2h1bmtfMV9pbmRleF8xNjg1": "opdown menu. \"Create branch: new-branch\" is highlighted with an orange outline.\n\n{% ifversion fpt or ghec or ghes %}\n\n\n\nCreating a branch for an issue\n\nYou can create a branch to work on an issue directly from the issue page and get started right away. For more information, see \"AUTOTITLE\".\n{% endif %}\n\n\n\nDeleting a branch\n\n{% data reusables.pull_requests.automatically-delete-branches %}\n\n{% note %}\n\n**Note:** If the branch you want to delete is the repository's default branch, you must choose a new default branch before deleting the branch. For more information, see \"AUTOTITLE.\"\n\n{% endnote %}\n\nIf the branch you want to delete is associated with an open pull request, you must merge or close the pull request before deleting the branch. For more information, see \"AUTOTITLE\" or \"AUTOTITLE.\"\n\n{% data reusables.repositories.navigate-to-repo %}\n{% data reusables.repositories.navigate-to-branches %}\n1. Next to the branch that you want to delete, click {% octicon \"trash\" aria-label=\"The trash icon\" %} .\n\n   !Screenshot of a branch in the branch list. A trash icon is highlighted with an orange outline.\n{%- ifversion fpt or ghes or ghae > 3.5 or ghec %}\n1. If the branch is associated with at least one open pull request, deleting the branch will close the pull requests. Read the warning, then click **Delete**.\n{%- endif %}\n\n{% data reusables.pull_requests.retargeted-on-branch-deletion %}\nFor more information, see \"AUTOTITLE.\"\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8xMTcy": "---\ntitle: Reverting a commit in GitHub Desktop\nshortTitle: Reverting a commit\nintro: 'You can use {% data variables.product.prodname_desktop %} to revert a specific commit to remove its changes from your branch.'\nredirect_from:\n  - /desktop/contributing-to-projects/reverting-a-commit\n  - /desktop/contributing-and-collaborating-using-github-desktop/reverting-a-commit\n  - /desktop/contributing-and-collaborating-using-github-desktop/managing-commits/reverting-a-commit\n  - /desktop/contributing-and-collaborating-using-github-desktop/managing-commits/reverting-a-commit-in-github-desktop\nversions:\n  feature: desktop\n---\nWhen you revert to a previous commit, the revert is also a commit. The original commit also remains in the repository's history.\n\n{% tip %}\n\n**Tip:** When you revert multiple commits, it's best to revert in order from newest to oldest. If you revert commits in a different order, you may see merge conflicts.\n\n{% endtip %}\n\n{% data reusables.desktop.history-tab %}\n{% data reusables.desktop.revert-commit %}\n\n", "Y2h1bmtfMF9pbmRleF8xODAz": "\n\nFurther reading\n\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8xMjU=": "\n\nOverview\n\nYou can authenticate {% data variables.product.prodname_actions_runner_controller %} (ARC) to the {% data variables.product.prodname_dotcom %} API by using a {% data variables.product.prodname_github_app %} or by using a {% data variables.product.pat_v1 %}.\n\n{% note %}\n\n**Note:** You cannot authenticate using a {% data variables.product.prodname_github_app %} for runners at the enterprise level. For more information, see \"AUTOTITLE.\"\n\n{% endnote %}\n\n\n\nAuthenticating ARC with a {% data variables.product.prodname_github_app %}\n\n1. Create a {% data variables.product.prodname_github_app %} that is owned by an organization. For more information, see \"AUTOTITLE\". Configure the {% data variables.product.prodname_github_app %} as follows.\n\n   1. For \"Homepage URL,\" enter `http://github.com/actions/actions-runner-controller`.\n\n   1. Under \"Permissions,\" click **Repository permissions**. Then use the dropdown menus to select the following access permissions.\n      - **Administration**: Read and write\n      - **Metadata**: Read-only\n\n   1. Under \"Permissions,\" click **Organization permissions**. Then use the dropdown menus to select the following access permissions.\n      - **Self-hosted runners**: Read and write\n\n{% data reusables.actions.arc-app-post-install-steps %}\n\n1. In the menu at the top-left corner of the page, click **Install app**, and next to your organization, click **Install** to install the app on your organization.\n\n1. After confirming the installation permissions on your organization, note the app installation ID. You will use it later. You can find the app installation ID on the app installation page, which has the following URL format:\n\n   `https://{% data variables.product.product_url %}/organizations/ORGANIZATION/settings/installations/INSTALLATION_ID`\n\n{% data reusables.actions.arc-app-post-install-set-secrets %}\n\n\n\nAuthenticating ARC with a {% data variables.product.pat_v1 %}\n\nARC can use {% data variables.product.pat_v1_plural %} to register self-hosted runners.\n\n{% ifversion ghec or ghes", "Y2h1bmtfMV9pbmRleF8xMjU=": " %}\n{% note %}\n**Note:** Authenticating ARC with a {% data variables.product.pat_v1 %} is the only supported authentication method to register runners at the enterprise level.\n{% endnote %}\n{% endif %}\n\n1. Create a {% data variables.product.pat_v1 %} with the required scopes. The required scopes are different depending on whether you are registering runners at the repository{% ifversion ghec or ghes %}, organization, or enterprise{% else %} or organization{% endif %} level. For more information on how to create a {% data variables.product.pat_v1 %}, see \"AUTOTITLE.\"\n\n    The following is the list of required {% data variables.product.pat_generic %} scopes for ARC runners.\n    - Repository runners: `repo`\n    - Organization runners: `admin:org`\n    {% ifversion ghec or ghes %}\n    - Enterprise runners: `manage_runners:enterprise`\n    {% endif %}\n1. To create a Kubernetes secret with the value of your {% data variables.product.pat_v1 %}, use the following command.\n\n   {% data reusables.actions.arc-runners-namespace %}\n\n   ```bash copy\n   kubectl create secret generic pre-defined-secret \\\n      --namespace=arc-runners \\\n      --from-literal=github_token='YOUR-PAT'\n   ```\n\n1. In your copy of the `values.yaml` file, pass the secret name as a reference.\n\n   ```yaml\n   githubConfigSecret: pre-defined-secret\n   ```\n\n   {% data reusables.actions.actions-runner-controller-helm-chart-options %}\n\n\n\nLegal notice\n\n{% data reusables.actions.actions-runner-controller-legal-notice %}\n\n", "Y2h1bmtfMF9pbmRleF8zNw==": "\n\nAbout management of security and analysis settings\n\n{% data variables.product.prodname_dotcom %} can help secure your repositories. This topic tells you how you can manage the security and analysis features for all your existing or new repositories.\n\nYou can still manage the security and analysis features for individual repositories. For more information, see \"AUTOTITLE.\"\n\nYou can also review the security log for all activity on your personal account. For more information, see \"AUTOTITLE.\"\n\n{% data reusables.security.some-security-and-analysis-features-are-enabled-by-default %}\n\n{% data reusables.security.security-and-analysis-features-enable-read-only %}\n\nFor an overview of repository-level security, see \"AUTOTITLE.\"\n\n\n\nEnabling or disabling features for existing repositories\n\n{% data reusables.user-settings.access_settings %}\n{% data reusables.user-settings.security-analysis %}\n1. Under \"Code security and analysis\", to the right of the feature, click **Disable all** or **Enable all**.\n1. Optionally, enable the feature by default for new repositories that you own.{% ifversion not ghes %}\n\n   !Screenshot of the \"Enable FEATURE\" modal dialog, with the \"Enable by default for new private repositories\" option highlighted with a dark orange outline.{% endif %}\n\n1. Click **Disable FEATURE** or **Enable FEATURE** to disable or enable the feature for all the repositories you own.\n\n{% data reusables.security.displayed-information %}\n\n\n\nEnabling or disabling features for new repositories\n\n{% data reusables.user-settings.access_settings %}\n{% data reusables.user-settings.security-analysis %}\n1. Under \"Code security and analysis\", to the right of the feature, enable or disable the feature by default for new repositories that you own.\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8yMTY=": "\n\nOverview\n\nIf you need to share workflows and other {% data variables.product.prodname_actions %} features with your team, then consider collaborating within a {% data variables.product.prodname_dotcom %} organization. An organization allows you to centrally store and manage secrets, artifacts, and self-hosted runners. You can also create starter workflows in the `.github` repository and share them with other users in your organization.\n\n\n\nSharing {% ifversion internal-actions %}actions and {% endif %}workflows\n\n{% ifversion internal-actions %}\nYou can share both individual actions and entire workflows with your organization, with or without publishing the actions or workflows publicly. You can reuse actions and workflows exactly by referencing them in your workflow file, and you can create starter workflows that provide templates for new workflows.\n{% else %}\nYour organization can share workflows by reusing the workflows exactly or by creating starter workflows that provide templates for new workflows.\n{% endif %}\n\n{% ifversion internal-actions %}\n\n\n\nSharing actions with your enterprise\n\n{% data reusables.actions.internal-actions-summary %}\n{% endif %}\n\n\n\nReusing workflows\n\n{% data reusables.actions.reusable-workflows %}\n\n\n\nUsing starter workflows\n\n{% data reusables.actions.workflow-organization-templates %} For more information, see \"AUTOTITLE.\"\n\n\n\nSharing secrets{% ifversion actions-configuration-variables %} and variables{% endif %} within an organization\n\nYou can centrally manage your secrets {% ifversion actions-configuration-variables %} and variables{% endif %} within an organization, and then make them available to selected repositories. This also means that you can update a secret {% ifversion actions-configuration-variables %} or variable{% endif %} in one location, and have the change apply to all repository workflows that use it.\n\nWhen creating a secret {% ifversion actions-configuration-variables %} or variable{% endif %} in an organization, you can use a policy to limit which repositories can acce", "Y2h1bmtfMV9pbmRleF8yMTY=": "ss it. For example, you can grant access to all repositories, or limit access to only private repositories or a specified list of repositories.\n\n{% data reusables.actions.permissions-statement-secrets-and-variables-organization %}\n\n{% data reusables.organizations.navigate-to-org %}\n{% data reusables.organizations.org_settings %}\n{% data reusables.actions.sidebar-secrets-and-variables %}\n{%- ifversion actions-configuration-variables %}\n1. Click the **Secrets** or **Variables** tab, and create the secret or variable with your desired values and options.\n\n   For more information, see \"AUTOTITLE\" or \"AUTOTITLE.\"\n{%- else %}\n1. Click **New secret**.\n1. Type a name for your secret in the **Name** input box.\n1. Enter the **Value** for your secret.\n1. From the **Repository access** dropdown list, choose an access policy.\n1. Click **Add secret**.\n{%- endif %}\n\n\n\nShare self-hosted runners within an organization\n\nOrganization owners can add their self-hosted runners to groups, and then create policies that control which repositories can access the group.\n\nFor more information, see \"AUTOTITLE.\"\n\n\n\nNext steps\n\nTo continue learning about {% data variables.product.prodname_actions %}, see \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF8xNjkx": "\n\nModifying an active pull request locally\n\n{% webui %}\n\n{% data reusables.repositories.sidebar-pr %}\n1. In the list of pull requests, click the pull request you'd like to modify.{% ifversion fpt or ghec %}\n1. To choose where you'd like to open the pull request, select the **{% octicon \"code\" aria-hidden=\"true\" %} Code** dropdown and click one of the tabs.\n\n   !Screenshot of a pull request title. A button with an arrow indicating a dropdown menu, labeled \"Code,\" is outlined in dark orange.{% else %}\n\n1. In the merge box, click **command line instructions**. Follow the sequence of steps to bring down the proposed pull request.\n\n   !Screenshot of the merge box in a pull request. The link to access command line pull request instructions is outlined in dark orange.\n\n1. Optionally, to view proposed changes in {% data variables.product.prodname_desktop %}, next to the **Merge pull request** button, click **open this in {% data variables.product.prodname_desktop %}**.\n\n   !Screenshot of the \"merge messages\" section on a pull request page. A link, labeled \"Open this in GitHub Desktop\", is outlined in orange.{% endif %}\n\n{% endwebui %}\n\n{% cli %}\n\n{% data reusables.cli.cli-learn-more %}\n\nTo check out a pull request locally, use the `gh pr checkout` subcommand. Replace `pull-request` with the number, URL, or head branch of the pull request.\n\n```shell\ngh pr checkout PULL-REQUEST\n```\n\n{% endcli %}\n\n\n\nModifying an inactive pull request locally\n\nIf a pull request\u2019s author is unresponsive to requests or has deleted their fork, the changes proposed in that pull request can still be merged via a new pull request. However, if you want to make changes to a pull request and the author is not responding, you'll need to perform some additional steps to update the pull request.\n\nOnce a pull request is opened, {% data variables.product.product_name %} stores all of the changes remotely. In other words, commits in a pull request are available in a repository even before the pull request is merged. You can fetch an open pull request and r", "Y2h1bmtfMV9pbmRleF8xNjkx": "ecreate it as your own.\n\nAnyone can work with a previously opened pull request to continue working on it, test it out, or even open a new pull request with additional changes. However, only collaborators with push access can merge pull requests.\n\n{% data reusables.repositories.sidebar-issue-pr %}\n1. In the \"Pull Requests\" list, click the pull request you'd like to merge.\n1. Find the ID number of the inactive pull request. This is the sequence of digits right after the pull request's title.\n\n   !Screenshot of the title of a pull request. The pull request's ID number is outlined in dark orange.\n\n{% data reusables.command_line.open_the_multi_os_terminal %}\n1. Fetch the reference to the pull request based on its ID number, creating a new branch in the process.\n\n   ```shell\n   git fetch origin pull/ID/head:BRANCH_NAME\n   ```\n\n1. Switch to the new branch that's based on this pull request:\n\n   ```shell\n   [main] $ git switch BRANCH_NAME\n   > Switched to a new branch 'BRANCH_NAME'\n   ```\n\n1. At this point, you can do anything you want with this branch. You can run some local tests, or merge other branches into the branch.\n1. When you're ready, you can push the new branch up:\n\n   ```shell\n   [pull-inactive-pull-request] $ git push origin BRANCH_NAME\n   > Counting objects: 32, done.\n   > Delta compression using up to 8 threads.\n   > Compressing objects: 100% (26/26), done.\n   > Writing objects: 100% (29/29), 74.94 KiB | 0 bytes/s, done.\n   > Total 29 (delta 8), reused 0 (delta 0)\n   > To https://{% data variables.command_line.codeblock %}/USERNAME/REPOSITORY.git\n   >  * [new branch]      BRANCH_NAME -> BRANCH_NAME\n   ```\n\n1. Create a new pull request with your new branch.\n\n\n\nError: Failed to push some refs\n\nThe remote `refs/pull/` namespace is _read-only_. If you try to push any commits there, you'll see this error:\n\n```shell\n! [remote rejected] HEAD -> refs/pull/1/head (deny updating a hidden ref)\nerror: failed to push some refs to 'git@github.local:USERNAME/REPOSITORY.git'\n```\n\n{% tip %}\n\n**Tip:** When you remove or rena", "Y2h1bmtfMl9pbmRleF8xNjkx": "me a remote reference, your local `refs/pull/origin/` namespace will not be affected by calls to `git-remote`.\n\n{% endtip %}\n\n", "Y2h1bmtfMF9pbmRleF82Mjg=": "\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8xMjc=": "\n\nIntroduction\n\n{% data reusables.actions.actions-runner-controller-about-arc %}\n\nYou can set up ARC on Kubernetes using Helm, then create and run a workflow that uses runner scale sets. For more information about runner scale sets, see \"AUTOTITLE.\"\n\n\n\nPrerequisites\n\nIn order to use ARC, ensure you have the following.\n\n- A Kubernetes cluster\n  - For a managed cloud environment, you can use AKS. For more information, see Azure Kubernetes Service in the Azure documentation.\n  - For a local setup, you can use minikube or kind. For more information, see minikube start in the minikube documentation and kind in the kind documentation.\n\n    {% note %}\n\n    **Note:** OpenShift clusters are currently unsupported.\n\n    {% endnote %}\n\n- Helm 3\n  - For more information, see Installing Helm in the Helm documentation.\n\n\n\nInstalling Actions Runner Controller\n\n1. To install the operator and the custom resource definitions (CRDs) in your cluster, do the following.\n    1. In your Helm chart, update the `NAMESPACE` value to the location you want your operator pods to be created. This namespace must allow access to the Kubernetes API server.\n    1. Install the Helm chart.\n\n    The following example installs the latest version of the chart. To install a specific version, you can pass the `--version` argument along with the version of the chart you wish to install. You can find the list of releases in the GitHub Container Registry.\n\n    ```bash copy\n    NAMESPACE=\"arc-systems\"\n    helm install arc \\\n        --namespace \"{% raw %}${NAMESPACE}{% endraw %}\" \\\n        --create-namespace \\\n        oci://ghcr.io/actions/actions-runner-controller-charts/gha-runner-scale-set-controller\n    ```\n\n    For additional Helm configuration options, see `values.yaml` in the ARC documentation.\n\n1. To enable ARC to authenticate to {% data variables.product.company_short %}, generate a {% data variables.product.pat_v1 %}. For more information, see AUTOTITLE.\n\n\n\nConfiguring a runner scale set\n\n1. To configure your runner scale set, run the following comma", "Y2h1bmtfMV9pbmRleF8xMjc=": "nd in your terminal, using values from your ARC configuration.\n\n    When you run the command, keep the following in mind.\n\n    - Update the `INSTALLATION_NAME` value carefully. You will use the installation name as the value of `runs-on` in your workflows. For more information, see \"AUTOTITLE.\"\n    - Update the `NAMESPACE` value to the location you want the runner pods to be created.\n    - Set `GITHUB_CONFIG_URL` to the URL of your repository, organization, or enterprise. This is the entity that the runners will belong to.\n    - This example command installs the latest version of the Helm chart. To install a specific version, you can pass the `--version` argument with the version of the chart you wish to install. You can find the list of releases in the GitHub Container Registry.\n\n        {% note %}\n\n        **Note:**\n        - {% data reusables.actions.actions-runner-controller-security-practices-namespace %}\n        - {% data reusables.actions.actions-runner-controller-security-practices-secret %} For more information, see \"AUTOTITLE.\"\n\n        {% endnote %}\n\n        ```bash copy\n        INSTALLATION_NAME=\"arc-runner-set\"\n        NAMESPACE=\"arc-runners\"\n        GITHUB_CONFIG_URL=\"https://github.com/\"\n        GITHUB_PAT=\"\"\n        helm install \"{% raw %}${INSTALLATION_NAME}{% endraw %}\" \\\n            --namespace \"{% raw %}${NAMESPACE}{% endraw %}\" \\\n            --create-namespace \\\n            --set githubConfigUrl=\"{% raw %}${GITHUB_CONFIG_URL}{% endraw %}\" \\\n            --set githubConfigSecret.github_token=\"{% raw %}${GITHUB_PAT}{% endraw %}\" \\\n            oci://ghcr.io/actions/actions-runner-controller-charts/gha-runner-scale-set\n        ```\n\n        For additional Helm configuration options, see `values.yaml` in the ARC documentation.\n\n1. From your terminal, run the following command to check your installation.\n\n    ```bash copy\n    helm list -A\n    ```\n\n    You should see an output similar to the following.\n\n    ```bash\n    NAME            NAMESPACE       REVISION        UPDATED                            ", "Y2h1bmtfMl9pbmRleF8xMjc=": "     STATUS          CHART                                       APP VERSION\n    arc             arc-systems     1               2023-04-12 11:45:59.152090536 +0000 UTC deployed        gha-runner-scale-set-controller-0.4.0       0.4.0\n    arc-runner-set  arc-runners     1               2023-04-12 11:46:13.451041354 +0000 UTC deployed        gha-runner-scale-set-0.4.0                  0.4.0\n    ```\n\n1. To check the manager pod, run the following command in your terminal.\n\n    ```bash copy\n    kubectl get pods -n arc-systems\n    ```\n\n    If everything was installed successfully, the status of the pods shows as **Running**.\n\n    ```bash\n    NAME                                                   READY   STATUS    RESTARTS   AGE\n    arc-gha-runner-scale-set-controller-594cdc976f-m7cjs   1/1     Running   0          64s\n    arc-runner-set-754b578d-listener                       1/1     Running   0          12s\n    ```\n\nIf your installation was not successful, see \"AUTOTITLE\" for troubleshooting information.\n\n\n\nUsing runner scale sets\n\nNow you will create and run a simple test workflow that uses the runner scale set runners.\n\n1. In a repository, create a workflow similar to the following example. The `runs-on` value should match the Helm installation name you used when you installed the autoscaling runner set.\n\n    For more information on adding workflows to a repository, see \"AUTOTITLE.\"\n\n    ```yaml copy\n    name: Actions Runner Controller Demo\n    on:\n      workflow_dispatch:\n\n    jobs:\n      Explore-GitHub-Actions:\n        # You need to use the INSTALLATION_NAME from the previous step\n        runs-on: arc-runner-set\n        steps:\n        - run: echo \"\ud83c\udf89 This job uses runner scale set runners!\"\n    ```\n\n1. Once you've added the workflow to your repository, manually trigger the workflow. For more information, see \"AUTOTITLE.\"\n\n1. To view the runner pods being created while the workflow is running, run the following command from your terminal.\n\n    ```bash copy\n    kubectl get pods -n arc-runners\n    ```\n\n    A success", "Y2h1bmtfM19pbmRleF8xMjc=": "ful output will look similar to the following.\n\n    ```bash\n    NAMESPACE     NAME                                                  READY   STATUS    RESTARTS      AGE\n    arc-runners   arc-runner-set-rmrgw-runner-p9p5n                     1/1     Running   0             21s\n    ```\n\n\n\nNext steps\n\n{% data variables.product.prodname_actions_runner_controller %} can help you efficiently manage your {% data variables.product.prodname_actions %} runners. Ready to get started? Here are some helpful resources for taking your next steps with ARC:\n\n- For detailed authentication information, see \"AUTOTITLE.\"\n- For help using ARC runners in your workflows, see \"AUTOTITLE.\"\n- For deployment information, see \"AUTOTITLE.\"\n\n\n\nLegal notice\n\n{% data reusables.actions.actions-runner-controller-legal-notice %}\n\n", "Y2h1bmtfMF9pbmRleF8xNTk5": "---\ntitle: Converting an admin team to improved organization permissions\nintro: 'If your organization was created after September 2015, your organization has improved organization permissions by default. Organizations created before September 2015 may need to migrate older Owners and Admin teams to the improved permissions model. Members of legacy admin teams automatically retain the ability to create repositories until those teams are migrated to the improved organization permissions model.'\nredirect_from:\n  - /articles/converting-your-previous-admin-team-to-the-improved-organization-permissions\n  - /articles/converting-an-admin-team-to-improved-organization-permissions\n  - /github/setting-up-and-managing-organizations-and-teams/converting-an-admin-team-to-improved-organization-permissions\nversions:\n  fpt: '*'\n  ghes: '*'\n  ghec: '*'\ntopics:\n  - Organizations\n  - Teams\nshortTitle: Convert admin team\n---\n\nYou can remove the ability for members of legacy admin teams to create repositories by creating a new team for these members, ensuring that the team has necessary access to the organization's repositories, then deleting the legacy admin team.\n\nFor more information, see \"AUTOTITLE.\"\n\n{% warning %}\n\n**Warnings:**\n- If there are members of your legacy Admin team who are not members of other teams, deleting the team will remove those members from the organization. Before deleting the team, ensure members are already direct members of the organization, or have collaborator access to necessary repositories.\n- To prevent the loss of private forks made by members of the legacy Admin team, you must follow steps 1-3 below before deleting the legacy Admin team.\n- Because \"admin\" is a term for organization members with specific access to certain repositories in the organization, we recommend you avoid that term in any team name you decide on.\n\n{% endwarning %}\n\n1. Create a new team.\n1. Add each of the members of your legacy admin team to the new team.\n1. Give the new team equivalent access to each of the repositories the le", "Y2h1bmtfMV9pbmRleF8xNTk5": "gacy team could access.\n1. Delete the legacy admin team.\n\n", "Y2h1bmtfMF9pbmRleF8yNjg=": "\n\nAbout rate limits for  {% data variables.product.product_name %}\n\nTo prevent excessive use of resources on {% data variables.location.product_location %} that could affect the instance's availability or performance for all users, you can configure rate limits. Rate limits are configurable for the {% data variables.product.prodname_enterprise_api %} and {% data variables.product.prodname_actions %}.\n\nImplement rate limits carefully and communicate frequently with your users as you tune the limits. To avoid interrupting your users' work, {% data variables.product.company_short %} recommends that you start with permissive rate limits, and gradually tune the limits to suit your environment.\n\nYou can also configure rate limits for authentication attempts to the {% data variables.enterprise.management_console %}. For more information, see \"AUTOTITLE.\"\n\n\n\nEnabling rate limits for the {% data variables.product.prodname_enterprise_api %}\n\nExcessive numbers of requests to the {% data variables.product.prodname_enterprise_api %} can affect the availability and performance of your instance. For more information about how rate limits for the API affect your users, see \"AUTOTITLE.\"\n\n{% ifversion ghes %}\nYou can exempt a list of users from API rate limits using the `ghe-config` utility in the administrative shell. For more information, see \"AUTOTITLE.\"\n{% endif %}\n\n{% note %}\n\n**Note:** The {% data variables.enterprise.management_console %} lists the time period (per minute or per hour) for each rate limit.\n\n{% endnote %}\n\n{% data reusables.enterprise_site_admin_settings.access-settings %}\n{% data reusables.enterprise_site_admin_settings.management-console %}\n1. Under \"Rate Limiting\", select **Enable HTTP API Rate Limiting**.\n1. Type limits for authenticated and unauthenticated requests for each API, or accept the pre-filled default limits.\n{% data reusables.enterprise_management_console.save-settings %}\n\n\n\nEnabling secondary rate limits\n\nSetting secondary rate limits protects the overall level of service on {% data variables", "Y2h1bmtfMV9pbmRleF8yNjg=": ".location.product_location %}.\n\n{% data reusables.enterprise_site_admin_settings.access-settings %}\n{% data reusables.enterprise_site_admin_settings.management-console %}\n{%- ifversion ghes %}\n1. Under \"Rate Limiting\", select **Enable Secondary Rate Limiting**.\n{%- else %}\n1. Under \"Rate Limiting\", select **Enable Abuse Rate Limiting**.\n{%- endif %}\n1. Type limits for Total Requests, CPU Limit, and CPU Limit for Searching, or accept the pre-filled default limits.\n{% data reusables.enterprise_management_console.save-settings %}\n\n\n\nEnabling rate limits for Git\n\nIf a member of {% data variables.product.company_short %}'s staff has recommended it, you can apply Git rate limits per repository network or per user ID. Git rate limits are expressed in concurrent operations per minute, and are adaptive based on the current CPU load.\n\n{% warning %}\n\n**Warning:** We encourage you to leave this setting disabled unless directly recommended by a member of {% data variables.product.company_short %}'s staff. Git operations are rarely the leading driver of CPU and RAM usage. Enabling this feature can make Git operations more likely to fail under high load conditions but does not address the underlying cause of those conditions.\n\n{% endwarning %}\n\n{% data reusables.enterprise_site_admin_settings.access-settings %}\n{% data reusables.enterprise_site_admin_settings.management-console %}\n1. Under \"Rate Limiting\", select **Enable Git Rate Limiting**.\n1. Under \"Repository Network Limit\", type a limit for each repository network.\n1. Under \"User ID Limit\", type a limit for each user ID.\n{% data reusables.enterprise_management_console.save-settings %}\n\n{% ifversion ghes %}\n\n\n\nConfiguring rate limits for {% data variables.product.prodname_actions %}\n\nYou can apply a rate limit to {% data variables.product.prodname_actions %} workflow runs. For more information about {% data variables.product.prodname_actions %}, see \"AUTOTITLE.\"\n\n\n\nAbout rate limits for {% data variables.product.prodname_actions %}\n\nYour {% data variables.product.product_na", "Y2h1bmtfMl9pbmRleF8yNjg=": "me %} instance assigns each {% data variables.product.prodname_actions %} workflow job to a runner. If your instance cannot immediately assign a job to an available runner, the job will wait in a queue until a runner is available. If {% data variables.product.prodname_actions %} experiences sustained high load, the queue can back up, and the performance of {% data variables.location.product_location %} may degrade.\n\nTo avoid this performance degradation, you can configure a rate limit for {% data variables.product.prodname_actions %}. This rate limit is expressed in job runs per minute. {% data variables.product.product_name %} calculates and applies the rate limit for the sum total of all job runs on the instance. If runs exceed the rate limit, additional runs will fail instead of entering the queue. The following error will appear in the run's annotations.\n\n> You've exceeded the rate limit for workflow run requests. Please wait before retrying the run.\n\nAn appropriate rate limit protects {% data variables.location.product_location %} from abnormal usage of {% data variables.product.prodname_actions %} without interfering with day-to-day operations. The exact threshold depends on your instance's available resources and overall load profile. For more information about the hardware requirements for {% data variables.product.prodname_actions %}, see \"AUTOTITLE.\"\n\nBy default, the rate limit for {% data variables.product.prodname_actions %} is disabled. Because {% data variables.product.product_name %} can handle temporary spikes in usage without performance degradation, this rate limit is intended to protect against sustained high load. We recommend leaving the rate limit disabled unless you are experiencing performance problems. In some cases, {% data variables.contact.github_support %} may recommend that you enable a rate limit for {% data variables.product.prodname_actions %}.\n\n\n\nEnabling or disabling rate limits for {% data variables.product.prodname_actions %}\n\n{% data reusables.enterprise_installation.ssh-into", "Y2h1bmtfM19pbmRleF8yNjg=": "-instance %}\n1. To enable and configure the rate limit, run the following two commands, replacing **RUNS-PER-MINUTE** with the value of your choice.\n\n   ```shell\n   ghe-config actions-rate-limiting.enabled true\n   ghe-config actions-rate-limiting.queue-runs-per-minute RUNS-PER-MINUTE\n   ```\n\n1. To disable the rate limit after it's been enabled, run the following command.\n\n   ```shell\n   ghe-config actions-rate-limiting.enabled false\n   ```\n\n1. To apply the configuration, run the following command.\n\n   ```shell\n   ghe-config-apply\n   ```\n\n1. Wait for the configuration run to complete.\n\n{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF8xODQ4": "\n\nAbout billing\n\nYou can get billing information for an enterprise. For more information, see \"AUTOTITLE.\"\n\n\n\n", "Y2h1bmtfMF9pbmRleF83Mjc=": "\n\nAbout configuring default setup at scale\n\nWith default setup for {% data variables.product.prodname_code_scanning %}, you can quickly secure code in repositories across your organization.\n\nYou can use the organization settings page labeled \"Code security and analysis\" to enable {% data variables.product.prodname_code_scanning %} for all repositories in your organization that are eligible for default setup. For more information, see \"Configuring default setup for all eligible repositories in an organization.\"\n\n{% ifversion code-security-multi-repo-enablement %}\n\nYou can also use security overview to find a set of repositories in your organization and enable or disable default setup for all of them at the same time. For more information, see \"Configuring default setup for a subset of repositories in an organization.\"\n\n{% endif %}\n\nYou can also create different default setup configurations for individual repositories. For more information on configuring default setup at the repository level, see \"AUTOTITLE.\"\n\nFor repositories that are not eligible for default setup, you can configure advanced setup at the repository level, or at the organization level using a script. For more information, see \"AUTOTITLE.\"\n\n\n\n\n\n\nEligible repositories for {% data variables.product.prodname_codeql %} default setup at scale\n\n{% data reusables.code-scanning.beta-org-enable-all %}\n\nA repository must meet all the following criteria to be eligible for default setup, otherwise you need to use advanced setup.\n\n- {% data variables.product.prodname_code_scanning_caps %} is not already enabled.\n- {% data variables.product.prodname_actions %} are enabled.{% ifversion code-scanning-default-setup-recommended-languages %}\n- Uses {% ifversion code-scanning-default-setup-go %} Go, {% endif %}JavaScript/TypeScript, Python, or Ruby.{% else %}\n- Uses any {% data variables.product.prodname_codeql %}-supported language.{% endif %}{% ifversion fpt %}\n- Publicly visible.{%- elsif ghec %}\n- Publicly visible, or {% data variables.product.prodname_GH_advanced", "Y2h1bmtfMV9pbmRleF83Mjc=": "_security %} is enabled.{%- elsif ghes or ghae %}\n- {% data variables.product.prodname_GH_advanced_security %} is enabled.{% endif %}\n\n{% ifversion code-scanning-default-setup-automatic-311 %}\n\n\n\nAbout adding languages to an existing default setup configuration\n\nIf the code in a repository changes to include {% ifversion code-scanning-default-setup-recommended-languages %}{% ifversion code-scanning-default-setup-go %}Go, {% endif %}JavaScript/TypeScript, Python, or Ruby,{% else %}a {% data variables.product.prodname_codeql %}-supported language,{% endif %} {% data variables.product.prodname_dotcom %} will automatically update the {% data variables.product.prodname_code_scanning %} configuration to include the new language. If {% data variables.product.prodname_code_scanning %} fails with the new configuration, {% data variables.product.prodname_dotcom %} will resume the previous configuration automatically so the repository does not lose {% data variables.product.prodname_code_scanning %} coverage.\n\n{% endif %}\n{% ifversion org-enable-code-scanning %}\n\n\n\nConfiguring default setup for all eligible repositories in an organization\n\nThrough the \"Code security and analysis\" page of your organization's settings, you can enable default setup for all eligible repositories in your organization. For more information on repository eligibility, see \"Eligible repositories for {% data variables.product.prodname_codeql %} default setup at scale.\"\n\n{% data reusables.code-scanning.beta-org-enable-all %}\n\n1. Click your profile photo, then click **Organizations**.\n1. Click **Settings** next to your organization.\n1. Click **Code security & analysis**.\n1. Click **Enable all** next to \"{% data variables.product.prodname_code_scanning_caps %}\".{% ifversion bulk-code-scanning-query-suite%}\n1. In the \"Query suites\" section of the \"Enable {% data variables.product.prodname_code_scanning %} default setup\" dialog box displayed, select the query suite your configuration of default setup will run. For more information, see \"AUTOTITLE.\"\n1. To ", "Y2h1bmtfMl9pbmRleF83Mjc=": "enable your configuration of default setup, click **Enable for eligible repositories**.\n1. Optionally, to recommend the \"Extended\" query suite throughout your organization when enabling default setup, select \"Recommend the extended query suite for repositories enabling default setup.\"{% else %}\n1. In the \"Enable {% data variables.product.prodname_code_scanning %} for eligible repositories\" dialog box displayed, click **Enable for eligible repositories** to enable your configuration of default setup.{% endif %}\n\n{% note %}\n\n**Notes:**\n  - {% data reusables.code-scanning.limitation-org-enable-all %}\n  - Enabling {% data variables.product.prodname_code_scanning %} for all eligible repositories in an organization will not override existing {% data variables.product.prodname_code_scanning %} configurations. For information on configuring default setup with different settings for specific repositories, see \"AUTOTITLE{% ifversion code-security-multi-repo-enablement %}\" and \"Configuring default setup for a subset of repositories in an organization{% endif %}.\"\n\n{% endnote %}\n{% else %}\n{% data variables.product.prodname_code_scanning_caps %} is configured at the repository level. For more information, see \"AUTOTITLE.\"\n{% endif %}\n{% ifversion code-security-multi-repo-enablement %}\n\n\n\nConfiguring default setup for a subset of repositories in an organization\n\nThrough security overview for your organization, you can find eligible repositories for default setup, then enable default setup across each of those repositories simultaneously. For more information on repository eligibility, see \"Eligible repositories for {% data variables.product.prodname_codeql %} default setup at scale.\"\n\n\n\nFinding repositories that are eligible for default setup\n\n{% data reusables.organizations.navigate-to-org %}\n{% data reusables.organizations.security-overview %}\n{% data reusables.security-overview.security-overview-coverage-view %}\n1. In the search bar, enter one of the following queries:\n\n{%- ifversion ghec %}\n    - `code-scanning-default-se", "Y2h1bmtfM19pbmRleF83Mjc=": "tup:eligible is:public` shows repositories that have languages suitable for default setup and are eligible because they are visible to the public.\n    - `code-scanning-default-setup:eligible advanced-security:enabled` shows private or internal repositories that have languages suitable for default setup and are eligible because they have {% data variables.product.prodname_GH_advanced_security %} enabled.\n    - `code-scanning-default-setup:eligible is:private,internal advanced-security:not-enabled` shows private or internal repositories that have languages suitable for default setup but do not have {% data variables.product.prodname_GH_advanced_security %} enabled. Once you enable {% data variables.product.prodname_GH_advanced_security %} for these repositories, they can also be added to default setup.\n{%- elsif ghes or ghae %}\n    - `code-scanning-default-setup:eligible advanced-security:enabled` shows which repositories can be added to default setup immediately.\n    - `code-scanning-default-setup:eligible advanced-security:not-enabled` shows which repositories have languages suitable for default setup but do not have {% data variables.product.prodname_GH_advanced_security %} enabled. Once you enable {% data variables.product.prodname_GH_advanced_security %} for these repositories, they can also be added to default setup.\n{%- endif %}\n    - `code-scanning-default-setup:not-eligible` shows repositories that either have advanced setup configured already, or where the languages not are suitable for default setup.\n\n{% ifversion code-security-multi-repo-enablement %}\n\nYou can select all of the displayed repositories, or a subset of them, and enable or disable default setup for {% data variables.product.prodname_code_scanning %} for them all at the same time. For more information, see step 5 of \"Configuring default setup at scale for multiple repositories in an organization.\"\n\n{% endif %}\n\n\n\nConfiguring default setup at scale for multiple repositories in an organization\n\n{% data reusables.organizations.navigate-to-org %", "Y2h1bmtfNF9pbmRleF83Mjc=": "}\n{% data reusables.organizations.security-overview %}\n{% data reusables.security-overview.security-overview-coverage-view %}\n1. You can use the search bar to narrow down visible repositories in the \"Security coverage\" view based on name, or on the enablement status of security features. For example, to filter for repositories that are eligible for default setup and do not currently have default setup enabled, search for `code-scanning-default-setup:eligible`.\n1. In the list of repositories, select each repository you want to enable {% data variables.product.prodname_code_scanning %} for. To select all repositories on the page, click the checkbox next to **NUMBER Active**. To select all repositories that match the current search, click the checkbox next to **NUMBER Active** and then click **Select all NUMBER repos**.\n1. Click **Security settings** next to **NUMBER selected**.\n1. In the side panel, in the \"{% data variables.product.prodname_codeql %} Default Setup\" section, select **No change**, then click **Enable**.{% ifversion bulk-code-scanning-query-suite %}\n1. Optionally, to choose a different query suite than your organization's default query suite, select **Query suite: SUITE NAME**, then click the query suite your configuration of default setup should use. For more information, see \"AUTOTITLE.\"{% endif %}\n1. To confirm the enablement of {% data variables.product.prodname_code_scanning %} for the selected repositories, click **Apply changes NUMBER**. Alternatively, to select or deselect more repositories for {% data variables.product.prodname_code_scanning %} enablement, click {% octicon \"x\" aria-label=\"Close\" %} to close the panel without applying your changes.\n\n  {% note %}\n\n  **Note:** Enabling {% data variables.product.prodname_code_scanning %} for multiple repositories in an organization using security overview will override any existing {% data variables.product.prodname_code_scanning %} configurations for the selected repositories, including any previous query suite selections and workflows for adva", "Y2h1bmtfNV9pbmRleF83Mjc=": "nced setups.\n\n  {% endnote %}\n\n  !Screenshot of the \"Security coverage\" view with the side panel open. The \"Apply changes\" button is highlighted in a dark orange outline.\n\n  If you're blocked from enabling {% data variables.product.prodname_code_scanning %} due to an enterprise policy, you will still be able to see the affected repository in the \"Security Coverage\" view and access the side panel from the **{% octicon \"gear\" aria-hidden=\"true\" %} Security settings** button. However, you will see a message in the side panel indicating that you cannot enable {% data variables.product.prodname_code_scanning %} for the selected repositories. For more information about enterprise policies, see \"AUTOTITLE.\"\n\n{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF8xMzM5": "\n\nDifferences in API logic\n\n{% data variables.product.company_short %} provides two APIs: a REST API and a GraphQL API. For more information about {% data variables.product.company_short %}'s APIs, see \"AUTOTITLE.\"\n\nMigrating from REST to GraphQL represents a significant shift in API logic. The differences between REST as a style and GraphQL as a specification make it difficult&mdash;and often undesirable&mdash;to replace REST API calls with GraphQL API queries on a one-to-one basis. We've included specific examples of migration below.\n\nTo migrate your code from the REST API to the GraphQL API:\n\n- Review the GraphQL spec\n- Review GitHub's GraphQL schema\n- Consider how any existing code you have currently interacts with the GitHub REST API\n- Use Global Node IDs to reference objects between API versions\n\nSignificant advantages of GraphQL include:\n\n- Getting the data you need and nothing more\n- Nested fields\n- Strong typing\n\nHere are examples of each.\n\n\n\nExample: Getting the data you need and nothing more\n\nA single REST API call retrieves a list of your organization's members:\n\n```shell\ncurl -v {% data variables.product.api_url_pre %}/orgs/:org/members\n```\n\nThe REST payload contains excessive data if your goal is to retrieve only member names and links to avatars. However, a GraphQL query returns only what you specify:\n\n```graphql\nquery {\n    organization(login:\"github\") {\n    membersWithRole(first: 100) {\n      edges {\n        node {\n          name\n          avatarUrl\n        }\n      }\n    }\n  }\n}\n```\n\nConsider another example: retrieving a list of pull requests and checking if each one is mergeable. A call to the REST API retrieves a list of pull requests and their summary representations:\n\n```shell\ncurl -v {% data variables.product.api_url_pre %}/repos/:owner/:repo/pulls\n```\n\nDetermining if a pull request is mergeable requires retrieving each pull request individually for its detailed representation (a large payload) and checking whether its `mergeable` attribute is true or false:\n\n```shell\ncurl -v {% data variab", "Y2h1bmtfMV9pbmRleF8xMzM5": "les.product.api_url_pre %}/repos/:owner/:repo/pulls/:number\n```\n\nWith GraphQL, you could retrieve only the `number` and `mergeable` attributes for each pull request:\n\n```graphql\nquery {\n    repository(owner:\"octocat\", name:\"Hello-World\") {\n    pullRequests(last: 10) {\n      edges {\n        node {\n          number\n          mergeable\n        }\n      }\n    }\n  }\n}\n```\n\n\n\nExample: Nesting\n\nQuerying with nested fields lets you replace multiple REST calls with fewer GraphQL queries. For example, retrieving a pull request along with its commits, non-review comments, and reviews using the **REST API** requires four separate calls:\n\n```shell\ncurl -v {% data variables.product.api_url_pre %}/repos/:owner/:repo/pulls/:number\ncurl -v {% data variables.product.api_url_pre %}/repos/:owner/:repo/pulls/:number/commits\ncurl -v {% data variables.product.api_url_pre %}/repos/:owner/:repo/issues/:number/comments\ncurl -v {% data variables.product.api_url_pre %}/repos/:owner/:repo/pulls/:number/reviews\n```\n\nUsing the **GraphQL API**, you can retrieve the data with a single query using nested fields:\n\n```graphql\n{\n  repository(owner: \"octocat\", name: \"Hello-World\") {\n    pullRequest(number: 1) {\n      commits(first: 10) {\n        edges {\n          node {\n            commit {\n              oid\n              message\n            }\n          }\n        }\n      }\n      comments(first: 10) {\n        edges {\n          node {\n            body\n            author {\n              login\n            }\n          }\n        }\n      }\n      reviews(first: 10) {\n        edges {\n          node {\n            state\n          }\n        }\n      }\n    }\n  }\n}\n```\n\nYou can also extend the power of this query by substituting a variable for the pull request number.\n\n\n\nExample: Strong typing\n\nGraphQL schemas are strongly typed, making data handling safer.\n\nConsider an example of adding a comment to an issue or pull request using a GraphQL mutation, and mistakenly specifying an integer rather than a string for the value of `clientMutationId`:\n\n```graphql\nmutation {", "Y2h1bmtfMl9pbmRleF8xMzM5": "\n  addComment(input:{clientMutationId: 1234, subjectId: \"MDA6SXNzdWUyMjcyMDA2MTT=\", body: \"Looks good to me!\"}) {\n    clientMutationId\n    commentEdge {\n      node {\n        body\n        repository {\n          id\n          name\n          nameWithOwner\n        }\n        issue {\n          number\n        }\n      }\n    }\n  }\n}\n```\n\nExecuting this query returns errors specifying the expected types for the operation:\n\n```json\n{\n  \"data\": null,\n  \"errors\": [\n    {\n      \"message\": \"Argument 'input' on Field 'addComment' has an invalid value. Expected type 'AddCommentInput!'.\",\n      \"locations\": [\n        {\n          \"line\": 3,\n          \"column\": 3\n        }\n      ]\n    },\n    {\n      \"message\": \"Argument 'clientMutationId' on InputObject 'AddCommentInput' has an invalid value. Expected type 'String'.\",\n      \"locations\": [\n        {\n          \"line\": 3,\n          \"column\": 20\n        }\n      ]\n    }\n  ]\n}\n```\n\nWrapping `1234` in quotes transforms the value from an integer into a string, the expected type:\n\n```graphql\nmutation {\n  addComment(input:{clientMutationId: \"1234\", subjectId: \"MDA6SXNzdWUyMjcyMDA2MTT=\", body: \"Looks good to me!\"}) {\n    clientMutationId\n    commentEdge {\n      node {\n        body\n        repository {\n          id\n          name\n          nameWithOwner\n        }\n        issue {\n          number\n        }\n      }\n    }\n  }\n}\n```\n\n", "Y2h1bmtfMF9pbmRleF8xMzA2": "\n\nExecutable files (`svn:executable`)\n\nWe convert `svn:executable` properties by updating the file mode directly before adding it to the Git repository.\n\n\n\nMIME types (`svn:mime-type`)\n\n{% data variables.product.product_name %} internally tracks the mime-type properties of files and the commits that added them.\n\n\n\nIgnoring unversioned items (`svn:ignore`)\n\nIf you've set files and directories to be ignored in Subversion, {% data variables.product.product_name %} will track them internally. Files ignored by subversion clients are completely distinct from entries in a _.gitignore_ file.\n\n\n\nCurrently unsupported properties\n\n{% data variables.product.product_name %} doesn't currently support `svn:externals`, `svn:global-ignores`, or any properties not listed above, including custom properties.\n\n", "Y2h1bmtfMF9pbmRleF83OA==": "\n\nAbout publishing actions\n\nBefore you can publish an action, you'll need to create an action in your repository. For more information, see \"AUTOTITLE.\"\n\nWhen you plan to publish your action to {% data variables.product.prodname_marketplace %}, you'll need to ensure that the repository only includes the metadata file, code, and files necessary for the action. Creating a single repository for the action allows you to tag, release, and package the code in a single unit. {% data variables.product.prodname_dotcom %} also uses the action's metadata on your {% data variables.product.prodname_marketplace %} page.\n\nActions are published to {% data variables.product.prodname_marketplace %} immediately and aren't reviewed by {% data variables.product.prodname_dotcom %} as long as they meet these requirements:\n\n- The action must be in a public repository.\n- Each repository must contain a single action.\n- Each repository must _not_ contain any workflow files.\n- The action's metadata file (`action.yml` or `action.yaml`) must be in the root directory of the repository.\n- The `name` in the action's metadata file must be unique.\n  - The `name` cannot match an existing action name published on {% data variables.product.prodname_marketplace %}.\n  - The `name` cannot match a user or organization on {% data variables.product.prodname_dotcom %}, unless the user or organization owner is publishing the action. For example, only the {% data variables.product.prodname_dotcom %} organization can publish an action named `github`.\n  - The `name` cannot match an existing {% data variables.product.prodname_marketplace %} category.\n  - {% data variables.product.prodname_dotcom %} reserves the names of {% data variables.product.prodname_dotcom %} features.\n\n\n\nPublishing an action\n\nYou can add the action you've created to {% data variables.product.prodname_marketplace %} by tagging it as a new release and publishing it.\n\nTo draft a new release and publish the action to {% data variables.product.prodname_marketplace %}, follow these instructions:", "Y2h1bmtfMV9pbmRleF83OA==": "\n\n{% data reusables.repositories.navigate-to-repo %}\n1. Navigate to the action metadata file in your repository (`action.yml` or `action.yaml`), and you'll see a banner to publish the action to {% data variables.product.prodname_marketplace %}. Click **Draft a release**.\n1. Under \"Release Action\", select **Publish this Action to the {% data variables.product.prodname_marketplace %}**.\n\n   {% note %}\n\n   **Note**: The \"Publish\" checkbox is disabled if the account that owns the repository has not yet accepted the {% data variables.product.prodname_marketplace %} Developer Agreement. If you own the repository or are an organization owner, click the link to \"accept the GitHub Marketplace Developer Agreement\", then accept the agreement. If there is no link, send the organization owner a link to this \"Release Action\" page and ask them to accept the agreement.\n\n   {% endnote %}\n1. If the labels in your metadata file contain any problems, you will see an error message. Address them by updating your metadata file. Once complete, you will see an \"Everything looks good!\" message.\n1. Select the **Primary Category** dropdown menu and click a category that will help people find your action in {% data variables.product.prodname_marketplace %}.\n1. Optionally, select the **Another Category** dropdown menu and click a secondary category.\n1. In the tag field, type a version for your action. This helps people know what changes or features the release includes. People will see the version in the action's dedicated {% data variables.product.prodname_marketplace %} page.\n1. In the title field, type a release title.\n1. Complete all other fields and click **Publish release**. Publishing requires you to use two-factor authentication. For more information, see \"AUTOTITLE.\"\n\n\n\nRemoving an action from {% data variables.product.prodname_marketplace %}\n\nTo remove a published action from {% data variables.product.prodname_marketplace %}, you'll need to update each published release. Perform the following steps for each release of the action you", "Y2h1bmtfMl9pbmRleF83OA==": "'ve published to {% data variables.product.prodname_marketplace %}.\n\n{% data reusables.repositories.navigate-to-repo %}\n{% data reusables.repositories.releases %}\n{% data reusables.releases.edit-release %}\n1. Select **Publish this action to the {% data variables.product.prodname_marketplace %}** to remove the check from the box.\n1. Click **Update release** at the bottom of the page.\n\n\n\nTransferring an action repository\n\nYou can transfer an action repository to another user or organization. For more information, see \"AUTOTITLE.\"\n\nWhen a repository admin transfers an action repository, {% data variables.product.prodname_dotcom %} automatically creates a redirect from the previous URL to the new URL, meaning workflows that use the affected action do not need to be updated.\n\nActions published on {% data variables.product.prodname_marketplace %} are linked to a repository by their unique `name` identifier, meaning you can publish new releases of an action from the transferred repository under the same {% data variables.product.prodname_marketplace %} listing. If an action repository is deleted, the {% data variables.product.prodname_marketplace %} listing is also deleted, and the unique `name` identifier becomes available.\n\n{% note %}\n\n**Note:** The \"Verified\" badge seen on an organization's {% data variables.product.prodname_dotcom %} profile is different from the verified creator badge on {% data variables.product.prodname_marketplace %}. If you transfer an action repository, the {% data variables.product.prodname_marketplace %} listing will lose the verified creator badge unless the new owner is also a verified creator.\n\n{% endnote %}\n  \n\n\nAbout badges in {% data variables.product.prodname_marketplace %}\n\nActions with the {% octicon \"verified\" aria-label=\"The verified badge\" %}, or  verified creator badge,  indicate that {% data variables.product.prodname_dotcom %} has verified the creator of the action as a partner organization. Partners can email partnerships@github.com to request the verified creator badge.\n\n!Sc", "Y2h1bmtfM19pbmRleF83OA==": "reenshot of {% data variables.product.prodname_actions %} with the verified creator badge.\n\n", "Y2h1bmtfMF9pbmRleF81ODY=": "\n\nFurther reading\n\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8xMTYx": "\n\nUpdating {% data variables.product.prodname_desktop %}\n\n1. In the menu bar, select **{% data variables.product.prodname_desktop %}**, then click **About {% data variables.product.prodname_desktop %}**.\n\n   !Screenshot of the menu bar on a Mac. Under the open \"GitHub Desktop\" dropdown menu, a cursor hovers over \"About GitHub Desktop\", highlighted in blue.\n\n1. In the modal window, click **Check for Updates**.\n   !Screenshot of the \"GitHub Desktop\" window. Under version details and links to external resources, a button, labeled \"Check for Updates\", is outlined in orange.\n1. If an update is available, quit and relaunch {% data variables.product.prodname_desktop %} to install the update.\n\n\n\nResolving a crash at launch by updating {% data variables.product.prodname_desktop %}\n\nIf you encounter a crash when attempting to launch {% data variables.product.prodname_desktop %} versions 3.0.2 through 3.1.3, download the latest version from the {% data variables.product.prodname_desktop %} site, then replace your existing application with the new version. Your preferences and tracked repositories will be retained.\n\n1. Navigate to the {% data variables.product.prodname_desktop %} site.\n1. Download the latest version of {% data variables.product.prodname_desktop %}.\n1. In your \"Downloads\" folder, locate the downloaded application.\n1. If the downloaded application is in a zip file, unpack the file by double clicking on the zip file.\n1. Drag the {% data variables.product.prodname_desktop %} application from your \"Downloads\" folder to the \"Applications\" folder.\n1. Approve the dialog asking if you want to replace the existing application.\n1. Launch {% data variables.product.prodname_desktop %}.\n1. Approve the prompt stating that that application was downloaded from the internet.\n\n{% endmac %}\n\n{% windows %}\n\n1. In the menu bar, select **Help**, then click **About GitHub Desktop**.\n\n   !Screenshot of the \"GitHub Desktop\" menu bar on Windows. In the open \"Help\" dropdown menu, an option labeled \"About GitHub Desktop\" is outlined in ", "Y2h1bmtfMV9pbmRleF8xMTYx": "orange.\n\n1. Click **Check for Updates**.\n\n   !Screenshot of the \"GitHub Desktop\" window. Under version details and links to external resources, a button, labeled \"Check for Updates\", is outlined in orange.\n\n1. If an update is available, quit and relaunch {% data variables.product.prodname_desktop %} to install the update.\n\n{% endwindows %}\n\n", "Y2h1bmtfMF9pbmRleF8xMjY1": "\n\nAbout access permissions on {% data variables.product.prodname_dotcom %}\n\n{% data reusables.organizations.about-roles %}\n\nRoles work differently for different types of accounts. For more information about accounts, see \"AUTOTITLE.\"\n\n\n\nPersonal accounts\n\nA repository owned by a personal account has two permission levels: the _repository owner_ and _collaborators_. For more information, see \"AUTOTITLE.\"\n\n\n\nOrganization accounts\n\nOrganization members can have _owner_{% ifversion fpt or ghec %}, _billing manager_,{% endif %} or _member_ roles. Owners have complete administrative access to your organization{% ifversion fpt or ghec %}, while billing managers can manage billing settings{% endif %}. Member is the default role for everyone else. You can manage access permissions for multiple members at a time with teams. For more information, see:\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n\n\nEnterprise accounts\n\n{% ifversion fpt %}\n{% data reusables.gated-features.enterprise-accounts %}\n\nFor more information about permissions for enterprise accounts, see the {% data variables.product.prodname_ghe_cloud %} documentation.\n{% else %}\n_Enterprise owners_ have ultimate power over the enterprise account and can take every action in the enterprise account.{% ifversion ghec or ghes %} _Billing managers_ can manage your enterprise account's billing settings.{% endif %} Members and outside collaborators of organizations owned by your enterprise account are automatically members of the enterprise account, although they have no access to the enterprise account itself or its settings. For more information, see \"AUTOTITLE.\"\n\n{% ifversion ghec %}\nIf an enterprise uses {% data variables.product.prodname_emus %}, members are provisioned as new personal accounts on {% data variables.product.prodname_dotcom %} and are fully managed by the identity provider. The {% data variables.enterprise.prodname_managed_users %} have read-only access to repositories that are not a part of their enterprise and cannot interact with users th", "Y2h1bmtfMV9pbmRleF8xMjY1": "at are not also members of the enterprise. Within the organizations owned by the enterprise, the {% data variables.enterprise.prodname_managed_users %} can be granted the same granular access levels available for regular organizations. For more information, see \"AUTOTITLE.\"\n{% endif %}\n{% endif %}\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF80OTI=": "\n\nAbout authentication as a {% data variables.product.prodname_github_app %}\n\nYou must authenticate as a {% data variables.product.prodname_github_app %} in order to make REST API requests as the application. For example, if you want to use the API to generate an installation access token for accessing organization resources, list installations across organizations for your app, or suspend an app installation, you must authenticate as an app.\n\nIf a REST API endpoint requires you to authenticate as an app, the documentation for that endpoint will indicate that you must use a JWT to access the endpoint. The GraphQL API does not support any queries or mutations that require you to authenticate as an app.\n\n\n\nUsing a JSON Web Token (JWT) to authenticate as a {% data variables.product.prodname_github_app %}\n\n1. Generate a JSON Web Token (JWT) for your app. For more information, see \"AUTOTITLE.\"\n1. Include the JWT in the `Authorization` header of your request. In the following example, replace `YOUR_JWT` with your JWT.\n\n   ```shell\n   curl --request GET \\\n   --url \"{% data variables.product.api_url_pre %}/app/installations\" \\\n   --header \"Accept: application/vnd.github+json\" \\\n   --header \"Authorization: Bearer YOUR_JWT\"{% ifversion api-date-versioning %} \\\n   --header \"X-GitHub-Api-Version: {{ allVersions[currentVersion].latestApiVersion }}\"{% endif %}\n   ```\n\n\n\nUsing the Octokit.js SDK to authenticate as a {% data variables.product.prodname_github_app %}\n\nYou can use {% data variables.product.company_short %}'s Octokit.js SDK to authenticate as a {% data variables.product.prodname_github_app %}. One advantage of using the SDK to authenticate is that you do not need to generate a JSON web token (JWT) yourself. Additionally, the SDK will take care of regenerating the JWT when it expires.\n\n{% note %}\n\n**Note**: You must install and import `octokit` in order to use the Octokit.js library. The following example uses import statements in accordance with ES6. For more information about different installation and import metho", "Y2h1bmtfMV9pbmRleF80OTI=": "ds, see Usage in the octokit/octokit repository.\n\n{% endnote %}\n\n1. Get the ID of your app. You can find your app's ID on the settings page for your {% data variables.product.prodname_github_app %}. For more information about navigating to the settings page for your {% data variables.product.prodname_github_app %}, see \"AUTOTITLE.\"\n1. Generate a private key. For more information, see \"AUTOTITLE.\"\n1. Import `App` from `octokit`.\n\n   ```javascript copy\n   import { App } from \"octokit\";\n   ```\n\n1. Create a new instance of `App`. In the following example, replace `APP_ID` with a reference to your app's ID. Replace `PRIVATE_KEY` with a reference to the value of your app's private key.\n\n   ```javascript copy\n    const app = new App({\n     appId: APP_ID,\n     privateKey: PRIVATE_KEY,\n   });\n   ```\n\n1. Use an `octokit` method to make a request to a REST API endpoint that requires a JWT. For example:\n\n   ```javascript copy\n   await app.octokit.request(\"/app\")\n   ```\n\n", "Y2h1bmtfMF9pbmRleF8xODkw": "\n\nAbout organization pre-receive hooks\n\n{% data reusables.user-settings.enterprise-admin-api-classic-pat-only %}\n\n\n\nObject attributes\n\n| Name                             | Type      | Description                                               |\n|----------------------------------|-----------|-----------------------------------------------------------|\n| `name`                           | `string`  | The name of the hook.                                     |\n| `enforcement`                    | `string`  | The state of enforcement for the hook on this repository. |\n| `allow_downstream_configuration` | `boolean` | Whether repositories can override enforcement.            |\n| `configuration_url`              | `string`  | URL for the endpoint where enforcement is set.            |\n\nPossible values for `enforcement` are `enabled`, `disabled` and`testing`. `disabled` indicates the pre-receive hook will not run. `enabled` indicates it will run and reject any pushes that result in a non-zero status. `testing` means the script will run but will not cause any pushes to be rejected.\n\n`configuration_url` may be a link to this endpoint or this hook's global configuration. Only site admins are able to access the global configuration.\n\n\n\n", "Y2h1bmtfMF9pbmRleF8xMDYz": "\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF81MjA=": "---\ntitle: About marketplace badges\nintro: 'Learn about the badges that you may see for some apps listings on {% data variables.product.prodname_marketplace %}.'\nredirect_from:\n  - /developers/github-marketplace/about-verified-creator-badges\n  - /developers/github-marketplace/about-marketplace-badges\n  - /developers/github-marketplace/github-marketplace-overview/about-marketplace-badges\n  - /apps/publishing-apps-to-github-marketplace/github-marketplace-overview/about-marketplace-badges\nversions:\n  fpt: '*'\n  ghec: '*'\n---\n\n{% data reusables.marketplace.marketplace-apps-not-actions %}\n\nCertain apps on the {% data variables.product.prodname_marketplace %} have the {% octicon \"verified\" aria-label=\"The verified badge\" %} badge and a tooltip that says \"Publisher domain and email verified\". This means that the app is owned by an organization that has:\n\n- Verified ownership of their domain and has a verified badge on their profile\n- Confirmed their email address so {% data variables.product.prodname_dotcom %} Support can reach the organization\n- Required two-factor authentication for their organization. For more information, see \"AUTOTITLE.\"\n\n!Screenshot of a marketplace badge for a {% data variables.product.prodname_github_app %}. The mouse pointer is hovering over an icon displaying the tooltip \"Publisher domain and email verified.\"\n\n{% note %}\n{% data variables.product.prodname_dotcom %} does not analyze the app. The marketplace badge {% octicon \"verified\" aria-label=\"The verified badge\" %} only confirms that the publisher meets the requirements listed above.\n{% endnote %}\n\nTo learn how you can add this badge to your app, see \"AUTOTITLE.\"\n\nSome apps on the {% data variables.product.prodname_marketplace %} have the {% octicon \"verified\" aria-label=\"The verified badge\" %} badge and a tooltip that says \"App meets the requirements for listing\" instead of, \"Publisher domain and email verified.\" This means that the app meets the listing requirements described in \"AUTOTITLE,\" but the publisher has not been verified, as des", "Y2h1bmtfMV9pbmRleF81MjA=": "cribed in \"AUTOTITLE\". Apps with this badge cannot change their pricing plan until the publisher successfully applies for verification.\n\n!Screenshot of a marketplace badge for a {% data variables.product.prodname_github_app %}. The mouse pointer is hovering over an icon displaying the tooltip \"App meets the requirements for listing.\"\n\nFor more information about the requirements for listing an app on {% data variables.product.prodname_marketplace %}, see \"AUTOTITLE.\"\n\nFor information on finding apps to use, see \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF8xNTM3": "\n\nAbout base permissions for {% data variables.projects.projects_v2 %}\n\nYou can set a project's base permission to control the level of access for all members of your organization. You can then specify individual and team permissions for each project in addition to the base permission. For more information on setting permissions for individual projects, see \"AUTOTITLE.\"\n\nWhen you set the base permission for projects in your organization's settings, the base permission will apply to any new projects created by organization members and existing projects that do not currently have a base permission configured in the project's settings.\n\n{% note %}\n\n**Note:** {% data reusables.projects.migration-permissions-warning %}\n\n{% endnote %}\n\n\n\nSetting a base permission for {% data variables.projects.projects_v2  %} in your organization\n\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n{% data reusables.organizations.member-privileges %}\n1. Under \"Projects base permissions\", select the dropdown menu and click a permissions level.\n1. In the pop-up window, review the changes and number of projects that will be affected. To confirm, click **Change default permission to PERMISSION**.\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8yOTE=": "\n\nAbout {% data variables.product.prodname_actions %} on {% data variables.product.prodname_ghe_cloud %}\n\n{% data variables.product.prodname_actions %} is enabled for your enterprise by default. To get started using {% data variables.product.prodname_actions %} within your enterprise, you can manage the policies that control how enterprise members use {% data variables.product.prodname_actions %} and optionally add self-hosted runners to run workflows.\n\n{% data reusables.actions.introducing-enterprise %}\n\n{% data reusables.actions.migrating-enterprise %}\n\n\n\nManaging policies for {% data variables.product.prodname_actions %}\n\nYou can use policies to control how enterprise members use {% data variables.product.prodname_actions %}. For example, you can restrict which actions are allowed and configure artifact and log retention. For more information, see \"AUTOTITLE.\"\n\n\n\nAdding runners\n\nTo run {% data variables.product.prodname_actions %} workflows, you need to use runners. {% data reusables.actions.about-runners %} If you use {% data variables.product.company_short %}-hosted runners, you will be be billed based on consumption after exhausting the minutes included in {% data variables.product.product_name %}, while self-hosted runners are free. For more information, see \"AUTOTITLE.\"\n\nFor more information, see \"AUTOTITLE.\"\n\nIf you choose self-hosted runners, you can add runners at the enterprise, organization, or repository levels. For more information, see \"AUTOTITLE.\"\n\n{% data reusables.actions.general-security-hardening %}\n\n", "Y2h1bmtfMF9pbmRleF82MDA=": "\n\nAbout {% data variables.product.pat_generic %}s\n\n{% data variables.product.pat_generic_caps %}s are an alternative to using passwords for authentication to {% data variables.product.product_name %} when using the {% data variables.product.prodname_dotcom %} API or the command line.\n\n{% data variables.product.pat_generic_caps %}s are intended to access {% data variables.product.company_short %} resources on behalf of yourself. To access resources on behalf of an organization, or for long-lived integrations, you should use a {% data variables.product.prodname_github_app %}. For more information, see \"AUTOTITLE.\"\n\n{% ifversion pat-v2 %}\n\n\n\nTypes of {% data variables.product.pat_generic %}s\n\n{% data variables.product.company_short %} currently supports two types of {% data variables.product.pat_generic %}s: {% data variables.product.pat_v2 %}s and {% data variables.product.pat_v1_plural %}. {% data variables.product.company_short %} recommends that you use {% data variables.product.pat_v2 %}s instead of {% data variables.product.pat_v1_plural %} whenever possible.\n\nBoth {% data variables.product.pat_v2 %}s and {% data variables.product.pat_v1_plural %} are tied to the user who generated them and will become inactive if the user loses access to the resource.\n\n{% ifversion pat-v2 %}\n\nOrganization owners can set a policy to restrict the access of {% data variables.product.pat_v1_plural %} to their organization{% ifversion ghec or ghes or ghae %}, and enterprise owners can restrict the access of {% data variables.product.pat_v1_plural %} to the enterprise or organizations owned by the enterprise{% endif %}. For more information, see \"AUTOTITLE.\"\n\n{% endif %}\n\n\n\n{% data variables.product.pat_v2_caps %}s\n\n{% data variables.product.pat_v2_caps %}s have several security advantages over {% data variables.product.pat_v1_plural %}:\n\n- Each token can only access resources owned by a single user or organization.\n- Each token can only access specific repositories.\n- Each token is granted specific permissions, which offer more co", "Y2h1bmtfMV9pbmRleF82MDA=": "ntrol than the scopes granted to {% data variables.product.pat_v1_plural %}.\n- Each token must have an expiration date.\n- Organization owners can require approval for any {% data variables.product.pat_v2 %}s that can access resources in the organization.{% ifversion ghec or ghes or ghae %}\n- Enterprise owners can require approval for any {% data variables.product.pat_v2 %}s that can access resources in organizations owned by the enterprise.{% endif %}\n\n\n\n{% data variables.product.pat_v1_caps_plural %}\n\n{% data reusables.user-settings.patv2-limitations %}\n\nIf you choose to use a {% data variables.product.pat_v1 %}, keep in mind that it will grant access to all repositories within the organizations that you have access to, as well as all personal repositories in your personal account.\n\n{% endif %}\n\n{% ifversion fpt or ghec %}{% data reusables.user-settings.removes-personal-access-tokens %}\n{% endif %}\n\n{% ifversion pat-v2 %}\n\n\n\nKeeping your {% data variables.product.pat_generic %}s secure\n\n{% data variables.product.pat_generic_caps %}s are like passwords, and they share the same inherent security risks. Before creating a new {% data variables.product.pat_generic %}, consider if there is a more secure method of authentication available to you:\n\n- To access {% data variables.product.company_short %} from the command line, you can use {% data variables.product.prodname_cli %} or Git Credential Manager instead of creating a {% data variables.product.pat_generic %}.\n- When using a {% data variables.product.pat_generic %} in a {% data variables.product.prodname_actions %} workflow, consider whether you can use the built-in `GITHUB_TOKEN` instead. For more information, see \"AUTOTITLE.\"\n\nIf these options are not possible, and you must create a {% data variables.product.pat_generic %}, consider using another CLI service to store your token securely.\n\nWhen using a {% data variables.product.pat_generic %} in a script, you can store your token as a secret and run your script through {% data variables.product.prodname_actions %", "Y2h1bmtfMl9pbmRleF82MDA=": "}. For more information, see \"AUTOTITLE.\"{%- ifversion ghec or fpt %} You can also store your token as a {% data variables.product.prodname_codespaces %} secret and run your script in {% data variables.product.prodname_codespaces %}. For more information, see \"AUTOTITLE.\"{% endif %}\n\nFor more information about best practices, see \"AUTOTITLE.\"\n\n\n\nCreating a {% data variables.product.pat_v2 %}\n\n{% note %}\n\n**Note**: {% data reusables.user-settings.pat-v2-beta %}\n\n{% endnote %}\n\n{% ifversion fpt or ghec %}1. Verify your email address, if it hasn't been verified yet.{% endif %}\n{% data reusables.user-settings.access_settings %}\n{% data reusables.user-settings.developer_settings %}\n1. In the left sidebar, under **{% octicon \"key\" aria-hidden=\"true\" %} {% data variables.product.pat_generic_caps %}s**, click **Fine-grained tokens**.\n1. Click **Generate new token**.\n1. Under **Token name**, enter a name for the token.\n1. Under **Expiration**, select an expiration for the token.\n1. Optionally, under **Description**, add a note to describe the purpose of the token.\n1. Under **Resource owner**, select a resource owner. The token will only be able to access resources owned by the selected resource owner. Organizations that you are a member of will not appear unless the organization opted in to {% data variables.product.pat_v2 %}s. For more information, see \"AUTOTITLE.\"{% ifversion ghec or ghae %} You may be required to perform SAML single sign-on (SSO) if the selected organization requires it and you do not already have an active SAML session.{% endif %}\n1. Optionally, if the resource owner is an organization that requires approval for {% data variables.product.pat_v2 %}s, below the resource owner, in the box, enter a justification for the request.\n1. Under **Repository access**, select which repositories you want the token to access. You should choose the minimal repository access that meets your needs. Tokens always include read-only access to all public repositories on {% data variables.product.prodname_dotcom %}.\n1. If y", "Y2h1bmtfM19pbmRleF82MDA=": "ou selected **Only select repositories** in the previous step, under the **Selected repositories** dropdown, select the repositories that you want the token to access.\n1. Under **Permissions**, select which permissions to grant the token. Depending on which resource owner and which repository access you specified, there are repository, organization, and account permissions. You should choose the minimal permissions necessary for your needs. For more information about what permissions are required for each REST API operation, see \"AUTOTITLE.\"\n1. Click **Generate token**.\n\nIf you selected an organization as the resource owner and the organization requires approval for {% data variables.product.pat_v2 %}s, then your token will be marked as `pending` until it is reviewed by an organization administrator. Your token will only be able to read public resources until it is approved. If you are an owner of the organization, your request is automatically approved. For more information, see \"AUTOTITLE.\"\n\n{% endif %}\n\n\n\nCreating a {% data variables.product.pat_v1 %}\n\n{% ifversion pat-v2 %}\n\n{% note %}\n\n**Note**: Organization owners can restrict the access of {% data variables.product.pat_v1 %} to their organization. If you try to use a {% data variables.product.pat_v1 %} to access resources in an organization that has disabled {% data variables.product.pat_v1 %} access, your request will fail with a 403 response. Instead, you must use a {% data variables.product.prodname_github_app %}, {% data variables.product.prodname_oauth_app %}, or {% data variables.product.pat_v2 %}.\n\n{% endnote %}\n\n{% endif %}\n\n{% ifversion pat-v2 %}\n\n{% warning %}\n\n**Note**: Your {% data variables.product.pat_v1 %} can access every repository that you can access. {% data variables.product.company_short %} recommends that you use {% data variables.product.pat_v2 %}s instead, which you can restrict to specific repositories. {% data variables.product.pat_v2_caps %}s also enable you to specify fine-grained permissions instead of broad scopes.\n\n{% endwarn", "Y2h1bmtfNF9pbmRleF82MDA=": "ing %}\n\n{% endif %}\n\n{% ifversion fpt or ghec %}1. Verify your email address, if it hasn't been verified yet.{% endif %}\n{% data reusables.user-settings.access_settings %}\n{% data reusables.user-settings.developer_settings %}\n{% ifversion pat-v2 %}1. In the left sidebar, under **{% octicon \"key\" aria-hidden=\"true\" %} {% data variables.product.pat_generic_caps %}s**, click **Tokens (classic)**.{% else %}{% data reusables.user-settings.personal_access_tokens %}{% endif %}\n{% ifversion pat-v2%}1. Select **Generate new token**, then click **Generate new token (classic)**.{% else %}{% data reusables.user-settings.generate_new_token %}{% endif %}\n1. In the \"Note\" field, give your token a descriptive name.\n1. To give your token an expiration, select **Expiration**, then choose a default option or click **Custom** to enter a date.\n1. Select the scopes you'd like to grant this token. To use your token to access repositories from the command line, select **repo**. A token with no assigned scopes can only access public information. For more information, see \"AUTOTITLE.\"\n1. Click **Generate token**.\n1. Optionally, to copy the new token to your clipboard, click {% octicon \"copy\" aria-label=\"Copy token\" %}.\n\n   !Screenshot of the \"{% data variables.product.pat_generic_caps_plural %}\" page. Next to a blurred-out token, an icon of two overlapping squares is outlined in orange.{% ifversion fpt or ghec %}\n1. To use your token to access resources owned by an organization that uses SAML single sign-on, authorize the token. For more information, see \"AUTOTITLE{% ifversion fpt %}\" in the {% data variables.product.prodname_ghe_cloud %} documentation.{% else %}.\"{% endif %}{% endif %}\n\n\n\nDeleting a {% data variables.product.pat_generic %}\n\nYou should delete a {% data variables.product.pat_generic %} if it is no longer needed. If you delete a {% data variables.product.pat_generic %} that was used to create a deploy key, the deploy key will also be deleted.\n\n{% data reusables.user-settings.access_settings %}\n{% data reusables.user-setting", "Y2h1bmtfNV9pbmRleF82MDA=": "s.developer_settings %}\n{% ifversion pat-v2 %}1. In the left sidebar, under **{% octicon \"key\" aria-hidden=\"true\" %} {% data variables.product.pat_generic_caps %}s**, click either **Fine-grained tokens** or **Tokens (classic)**, depending on which type of {% data variables.product.pat_generic %} you'd like to delete.{% else %}{% data reusables.user-settings.personal_access_tokens %}{% endif %}\n1. To the right of the {% data variables.product.pat_generic %} you want to delete, click **Delete**.\n\n\n\nUsing a {% data variables.product.pat_generic %} on the command line\n\nOnce you have a {% data variables.product.pat_generic %}, you can enter it instead of your password when performing Git operations over HTTPS.\n\nFor example, to clone a repository on the command line you would enter the following `git clone` command. You would then be prompted to enter your username and password. When prompted for your password, enter your {% data variables.product.pat_generic %} instead of a password.\n\n```shell\n$ git clone https://{% data variables.command_line.codeblock %}/USERNAME/REPO.git\nUsername: YOUR_USERNAME\nPassword: YOUR_PERSONAL_ACCESS_TOKEN\n```\n\n{% data variables.product.pat_generic_caps %}s can only be used for HTTPS Git operations. If your repository uses an SSH remote URL, you will need to switch the remote from SSH to HTTPS.\n\nIf you are not prompted for your username and password, your credentials may be cached on your computer. You can update your credentials in the Keychain to replace your old password with the token.\n\nInstead of manually entering your {% data variables.product.pat_generic %} for every HTTPS Git operation, you can cache your {% data variables.product.pat_generic %} with a Git client. Git will temporarily store your credentials in memory until an expiry interval has passed. You can also store the token in a plain text file that Git can read before every request. For more information, see \"AUTOTITLE.\"\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8xMzQy": "\n\nAbout pagination\n\n{% data variables.product.company_short %}'s GraphQL API limits the number of items that you can fetch in a single request in order to protect against excessive or abusive requests to GitHub's servers. When you use the GraphQL API, you must supply a `first` or `last` argument on any connection. The value of these arguments must be between 1 and 100. The GraphQL API will return the number of connections specified by the `first` or `last` argument.\n\nIf the data that you are accessing has more connections than the number of items specified by the `first` or `last` argument, the response is divided into smaller \"pages\" of the specified size. These pages can be fetched one at a time until the entire data set has been retrieved. Each page contains the number of items specified by the `first` or `last` argument, unless it is the last page, which may contain a lower number of items.\n\nThis guide demonstrates how to request additional pages of results for paginated responses, how to change the number of results returned on each page, and how to write a script to fetch multiple pages of results.\n\n\n\nRequesting a `cursor` in your query\n\nWhen using the GraphQL API, you use cursors to traverse through a paginated data set. The cursor represents a specific position in the data set. You can get the first and last cursor on a page by querying the `pageInfo` object. For example:\n\n```graphql\nquery($owner: String!, $name: String!) {\n  repository(owner: $owner, name: $name) {\n    pullRequests(first: 100, after: null) {\n      nodes {\n        createdAt\n        number\n        title\n      }\n      pageInfo {\n        endCursor\n        startCursor\n        hasNextPage\n        hasPreviousPage\n      }\n    }\n  }\n}\n```\n\nIn this example, `pageInfo.startCursor` gives the cursor for the first item on the page. `pageInfo.endCursor` gives the cursor for the last item on the page. `pageInfo.hasNextPage` and `pageInfo.hasPreviousPage` indicate whether there is a page before and after the page that was returned.\n\n\n\nChanging the number", "Y2h1bmtfMV9pbmRleF8xMzQy": " of items per page\n\nThe `first` and `last` arguments control how many items are returned. The maximum number of items you can fetch using the `first` or `last` argument is 100. You may need to request fewer than 100 items if your query touches a lot of data in order to avoid hitting a rate or node limit. For more information, see \"AUTOTITLE.\"\n\n\n\nTraversing the data set using pagination\n\nOnce you return a cursor from a query, you can use the cursor to request the next page of results. To do so, you will use the `after` or `before` argument and the cursor.\n\nFor example, assuming the `pageInfo.endCursor` value from the previous example was `Y3Vyc29yOnYyOpHOUH8B7g==`, you can use this query to request the next page of results:\n\n```graphql\nquery($owner: String!, $name: String!) {\n  repository(owner: $owner, name: $name) {\n    pullRequests(first: 1, after: \"Y3Vyc29yOnYyOpHOUH8B7g==\") {\n      nodes {\n        createdAt\n        number\n        title\n      }\n      pageInfo {\n        endCursor\n        hasNextPage\n        hasPreviousPage\n      }\n    }\n  }\n}\n```\n\nYou can continue to send queries with the new `pageInfo.endCursor` value returned in the response until there are no pages left to traverse, indicated by `pageInfo.hasNextPage` returning `false`.\n\nIf you specified the `last` instead of the `first` argument, the last page of results will be returned first. In this case, you will use the `pageInfo.startCursor` value and the `before` argument to get the previous page of results. Once `pageInfo.hasPreviousPage` returns `false`, you have reached the last page. For example:\n\n```graphql\nquery($owner: String!, $name: String!) {\n  repository(owner: $owner, name: $name) {\n    pullRequests(last: 1, before: \"R3Vyc29yOnYyOpHOHcfoOg==\") {\n      nodes {\n        createdAt\n        number\n        title\n      }\n      pageInfo {\n        startCursor\n        hasPreviousPage\n      }\n    }\n  }\n}\n```\n\n\n\nNext steps\n\nYou can use {% data variables.product.company_short %}'s Octokit SDK and the `octokit/plugin-paginate-graphql` plugin to support ", "Y2h1bmtfMl9pbmRleF8xMzQy": "pagination in your scripts. For more information, see \"plugin-paginate-graphql.js.\"\n\n", "Y2h1bmtfMF9pbmRleF8yMTE4": "---\ntitle: Transcript - \"Using Projects for feature planning\"\nintro: Audio and visual transcript.\nshortTitle: Projects\nallowTitleToDifferFromFilename: true\nproduct_video: 'https://www.youtube-nocookie.com/embed/yFQ-p6wMS_Y'\ntopics:\n  - Transcripts\nversions:\n  feature: projects-v2\n---\n\n[Fast-paced, techy music plays. On a dark background, GitHub's Octocat logo fades into view. Bright neon lines swirl and branch outwards. Each line leads to something different: a button labeled \"Convert to issue\"; a pull request merge button marked \"Ready\"; a comment on a pull request, a project board, and a search field. In a green box, text: \"GitHub Issues: Using Projects for feature planning.\" A pixelated cursor clicks: \"Let's go!\"]\n\n[The narrator shares her screen. She's looking at a table layout in a project on GitHub.]\n\nNarrator: Welcome. Let's take a lap around GitHub Projects and see how it supports you in tracking your feature work from beginning to end. Here we've got our OctoArcade Invaders board, and I'm ready to pick up our next feature.\n\n[She clicks a tab on the project labeled \"Features\".]\n\nNarrator: On our team, we have a simple process where we label the issue as a feature and build a view that focuses on all items with that label. Here we see all issues labeled as a feature. This way I can instantly see that this item is ready to be picked up and go ahead and open it to learn more.\n\n[She scans her cursor over rows on the table layout and clicks an item called \"Player-to-player chat capability.\" The issue opens as an overlay over the board.]\n\nNarrator: Given chat is not a small set of work, I've created another product board to track all the various tasks and items that we'll need to do to enable this functionality.\n\n[She clicks a link in the issue comment, taking her to another project named for the issue. On the \"By Area\" tab, the project has a table layout, and the rows are separated into groups, like \"Design,\" \"Storage,\" and \"Media support,\" based on labels in the \"Area\" field.]\n\nNarrator: In this main view, I'", "Y2h1bmtfMV9pbmRleF8yMTE4": "ve got my work already categorized by this custom field: Area. This is so I can split up my various issues into their appropriate workstreams or buckets. Projects is powerful because you can use these custom fields to add flexible metadata to your issues. You're not just limited by labels or adding a keyword in brackets to your issue title.\n\nAnd it's great because I can actually edit this view to group by any of these fields.\n\n[She clicks a dropdown icon next to the tab name, selects \"Group\", then scans her cursor over field options like \"Status\", \"Iteration\", and \"Assignees\".]\n\nNarrator: Now, as we're continuing to flesh out the work for this feature, I can quickly jot down additional items that we need to address by leveraging this \"Add\" bar.\n\n[She places her cursor in a text field below the \"Design\" group, labeled \"Add item\".]\n\nNarrator: I'll use this to add several draft issues. For example, our chat client needs a search UI, the ability to edit your friend list, and we definitely need dark mode.\n\n[She adds a draft issue for each requirement.]\n\nNarrator: You can see with this \"Add\" bar, I can write a title, press enter, and keep moving forward to add the next item. It's optimized to help you rapidly take notes on what needs to go into this capability.\n\nThese are draft issues now, but it's as easy as clicking \"Convert to issue\" to promote them to fully fledged issues in the appropriate repository.\n\n[She clicks a dropdown icon next to the \"Search UI\" draft issue, clicks \"Convert to issue\", and selects from a list of repositories below a search field.]\n\nNarrator: As development progresses, you'll want to be able to schedule and quickly see status for your work items. This is where our board view shines.\n\n[She clicks a tab labeled \"Iteration plan\". Issues, represented as draggable boxes, are arranged into columns for different iterations.]\n\nNarrator: I've created one here that is grouped by iterations so we can see what's currently planned, what's coming up, and we can quickly drag items to the appropriate iterat", "Y2h1bmtfMl9pbmRleF8yMTE4": "ion to create our plan.\n\n[She drags items from \"No iteration\" to \"Iteration 3\". She clicks a \"plus\" icon to create a column for \"Iteration 4\", and drags an item there. Then, she clicks a tab labeled \"By Status\". Issues are arranged into columns for statuses like \"Backlog\" and \"In Progress\".]\n\nNarrator: Finally, we have our board view grouped by status so we can understand the state of our items at a glance.\n\nI'm going to add linked pull requests as a visible field here so that my teammates can hop into a PR with just one click to start reviewing and get this issue moved to done.\n\n[She clicks the dropdown icon next to the tab name, clicks \"Title, Assignees, and Status\", then selects a checkbox next to a hidden field called \"Linked pull requests\". In some of the issue boxes, a tag with a pull request icon and number appears.]\n\nNarrator: We'll be ready to ship the chat feature in no time, with Projects.\n\n[Blocks cover the screen. The GitHub logo and the word \"Issues\" appear.]\n\nEnd of transcript. For more information about {% data variables.product.prodname_projects_v2 %}, see the {% data variables.product.prodname_github_issues %} documentation.\n\n", "Y2h1bmtfMF9pbmRleF8xNzk4": "\n\nAbout {% data variables.large_files.product_name_long %}\n\n{% data variables.large_files.product_name_short %} handles large files by storing references to the file in the repository, but not the actual file itself. To work around Git's architecture, {% data variables.large_files.product_name_short %} creates a pointer file which acts as a reference to the actual file (which is stored somewhere else). {% data variables.product.product_name %} manages this pointer file in your repository. When you clone the repository down, {% data variables.product.product_name %} uses the pointer file as a map to go and find the large file for you.\n\n{% ifversion fpt or ghec %}\nDifferent maximum size limits for {% data variables.large_files.product_name_short %} apply depending on your {% data variables.product.prodname_dotcom %} plan.\n\n| Product | Maximum file size |\n|------- | ------- |\n| {% data variables.product.prodname_free_user %} | 2 GB |\n| {% data variables.product.prodname_pro %} | 2 GB |\n| {% data variables.product.prodname_team %} | 4 GB |\n| {% data variables.product.prodname_ghe_cloud %} | 5 GB |{% else %}\nUsing {% data variables.large_files.product_name_short %}, you can store files up to {% ifversion ghae %}200 MiB{% else %}5 GB{% endif %} in your repository.\n{% endif %}\n\n{% data reusables.repositories.git-lfs %}\n\nYou can also use {% data variables.large_files.product_name_short %} with {% data variables.product.prodname_desktop %}. For more information about cloning Git LFS repositories in {% data variables.product.prodname_desktop %}, see \"AUTOTITLE.\"\n\n{% data reusables.large_files.can-include-lfs-objects-archives %}\n\n\n\nPointer file format\n\n{% data variables.large_files.product_name_short %}'s pointer file looks like this:\n\n```text\nversion {% data variables.large_files.version_name %}\noid sha256:4cac19622fc3ada9c0fdeadb33f88f367b541f38b89102a3f1261ac81fd5bcb5\nsize 84977953\n```\n\nIt tracks the `version` of {% data variables.large_files.product_name_short %} you're using, followed by a unique identifier for the fil", "Y2h1bmtfMV9pbmRleF8xNzk4": "e (`oid`). It also stores the `size` of the final file.\n\n{% note %}\n\n**Notes**:\n- {% data variables.large_files.product_name_short %} cannot be used with {% data variables.product.prodname_pages %} sites.\n- {% data variables.large_files.product_name_short %} cannot be used with template repositories.\n\n{% endnote %}\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8xOTg4": "\n\nAbout SSH signing key administration\n\n{% data reusables.user-settings.user-api %}\n\n\n\n", "Y2h1bmtfMF9pbmRleF8xMzMw": "\n\nAbout {% data variables.product.prodname_cli %}\n\n{% data reusables.cli.about-cli %}\n\n{% data reusables.cli.cli-features %}\n\nFor more information about what you can do with {% data variables.product.prodname_cli %}, see the {% data variables.product.prodname_cli %} manual.\n\n\n\nWhat's the difference between {% data variables.product.prodname_cli %} and Git on the command line?\n\nThe Git command line interface (`git`) allows you to work with a local or remote Git repository. The remote repository may be hosted on {% data variables.product.prodname_dotcom %} or it may be hosted by another service.\n\n{% data variables.product.prodname_cli %} (`gh`) is specifically for working with {% data variables.product.prodname_dotcom %}. It allows you to use the command line to interact with {% data variables.product.prodname_dotcom %} in all sorts of ways, as illustrated by the previous list. If you tend to work on the command line you may prefer using {% data variables.product.prodname_cli %} instead of using {% data variables.product.prodname_dotcom %} in a browser. {% data variables.product.prodname_cli %} also makes it easier for you to create scripts to automate {% data variables.product.prodname_dotcom %} operations.\n\n\n\nInstalling {% data variables.product.prodname_cli %}\n\n{% data reusables.cli.cli-installation %}\n\n\n\nSharing feedback\n\nIf you have feedback or feature requests, you can open an issue in the `cli/cli` repository.\n\n", "Y2h1bmtfMF9pbmRleF80OQ==": "\n\nAbout requesting organization approval for an {% data variables.product.prodname_oauth_app %}\n\nOrganization members can always request owner approval for {% data variables.product.prodname_oauth_apps %} they'd like to use, and organization owners receive a notification of pending requests.{% ifversion limit-app-access-requests %} Outside collaborators can request owner approval for {% data variables.product.prodname_oauth_apps %} they'd like to use if integration access requests are enabled. For more information, see \"AUTOTITLE.\"{% endif %}\n\n\n\nRequesting organization approval for an {% data variables.product.prodname_oauth_app %} you've already authorized for your personal account\n\n{% data reusables.user-settings.access_settings %}\n{% data reusables.user-settings.access_applications %}\n{% data reusables.user-settings.access_authorized_oauth_apps %}\n1. In the list of applications, click the name of the {% data variables.product.prodname_oauth_app %} you'd like to request access for.\n1. Next to the organization you'd like the {% data variables.product.prodname_oauth_app %} to access, click **Request access**.\n1. After you review the information about requesting {% data variables.product.prodname_oauth_app %} access, click **Request approval from owners**.\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF81NDQ=": "\n\nRegistering your app\n\nFirst, you'll need to register your application. Every\nregistered {% data variables.product.prodname_oauth_app %} is assigned a unique Client ID and Client Secret.\nThe client secret is used to get an access token for the signed-in user. You must\ninclude the client secret in your native application, however web applications should not leak this value.\n\nYou can fill out every other piece of information however you like, except the\n**Authorization callback URL**. This is the most important piece to securely setting\nup your application. It's the callback URL that {% data variables.product.product_name %}\nreturns the user to after successful authentication. Ownership of that URL is what ensures\nthat users sign into your app, instead of leaking tokens to an attacker.\n\nSince we're running a regular Sinatra server, the location of the local instance\nis set to `http://127.0.0.1:4567`. Let's fill in the callback URL as `http://127.0.0.1:4567/callback`.\n\n\n\nAccepting user authorization\n\n{% data reusables.apps.deprecating_auth_with_query_parameters %}\n\nNow, let's start filling out our simple server. Create a file called _server.rb_ and paste this into it:\n\n``` ruby\nrequire 'sinatra'\nrequire 'rest-client'\nrequire 'json'\n\nCLIENT_ID = ENV['GH_BASIC_CLIENT_ID']\nCLIENT_SECRET = ENV['GH_BASIC_SECRET_ID']\n\nget '/' do\n  erb :index, :locals => {:client_id => CLIENT_ID}\nend\n```\n\nYour client ID and client secret come from [your application's configuration\npage](https://github.com/settings/developers). We recommend storing these values as\nenvironment variables for ease of replacement and use --\nwhich is exactly what we've done here.\n\nNext, in _views/index.erb_, paste this content:\n\n```html\n\n  \n  \n  \n    \n      Well, hello there!\n    \n    \n      We're going to now talk to the GitHub API. Ready?\n      \">Click here to begin!\n    \n    \n      If that link doesn't work, remember to provide your own Client ID!\n    \n  \n\n```\n\n(If you're unfamiliar with how Sinatra works, we recommend reading the Sinatra guide.)\n\nAlso, noti", "Y2h1bmtfMV9pbmRleF81NDQ=": "ce that the URL uses the `scope` query parameter to define the\nscopes requested by the application. For our application, we're\nrequesting `user:email` scope for reading private email addresses.\n\nNavigate your browser to `http://127.0.0.1:4567`. After clicking on the link, you should be taken to {% data variables.product.product_name %}, and presented with an \"Authorize application\" dialog.\n\nIf you trust yourself, click **Authorize App**. Wuh-oh! Sinatra spits out a\n`404` error. What gives?!\n\nWell, remember when we specified a Callback URL to be `callback`? We didn't provide\na route for it, so {% data variables.product.product_name %} doesn't know where to drop the user after they authorize\nthe app. Let's fix that now!\n\n\n\nProviding a callback\n\nIn _server.rb_, add a route to specify what the callback should do:\n\n```ruby\nget '/callback' do\n  # get temporary GitHub code...\n  session_code = request.env['rack.request.query_hash']['code']\n\n  # ... and POST it back to GitHub\n  result = RestClient.post('https://github.com/login/oauth/access_token',\n                          {:client_id => CLIENT_ID,\n                           :client_secret => CLIENT_SECRET,\n                           :code => session_code},\n                           :accept => :json)\n\n  # extract the token and granted scopes\n  access_token = JSON.parse(result)['access_token']\nend\n```\n\nAfter a successful app authentication, {% data variables.product.product_name %} provides a temporary `code` value.\nYou'll need to `POST` this code back to {% data variables.product.product_name %} with your client secret\nin exchange for an `access_token`.\nTo simplify our GET and POST HTTP requests, we're using the rest-client.\nNote that you'll probably never access the API through REST. For a more serious\napplication, you should probably use a library written in the language of your choice.\n\n\n\nChecking granted scopes\n\nUsers can edit the scopes you requested by directly changing the URL. This can grant your application less access than you originally asked for. Before maki", "Y2h1bmtfMl9pbmRleF81NDQ=": "ng any requests with the token, check the scopes that were granted for the token by the user. For more information about requested and granted scopes, see \"AUTOTITLE.\"\n\nThe scopes that were granted are returned as a part of the response from\nexchanging a token.\n\n``` ruby\nget '/callback' do\n  # ...\n  # Get the access_token using the code sample above\n  # ...\n\n  # check if we were granted user:email scope\n  scopes = JSON.parse(result)['scope'].split(',')\n  has_user_email_scope = scopes.include? 'user:email' || scopes.include? 'user'\nend\n```\n\nIn our application, we're using `scopes.include?` to check if we were granted\nthe `user:email` scope needed for fetching the authenticated user's private\nemail addresses. Had the application asked for other scopes, we would have\nchecked for those as well.\n\nAlso, since there's a hierarchical relationship between scopes, you should\ncheck if you were granted any higher levels of the required scope. For example,\nif the application had asked for `user` scope, it won't have been granted explicitly the\n`user:email` scope. In that case, it would receive a token with the `user` scope, which\nwould work for requesting the user's email address, even though it doesn't explicitly include\n`user:email` on the token. Checking for both `user` and `user:email` ensures that you\ncheck for both scenarios.\n\nChecking for scopes only before making requests is not enough since it's possible\nthat users will change the scopes in between your check and the actual request.\nIn case that happens, API calls you expected to succeed might fail with a `404`\nor `401` status, or return a different subset of information.\n\nTo help you gracefully handle these situations, all API responses for requests\nmade with valid OAuth app tokens also contain an `X-OAuth-Scopes` header.\nThis header contains the list of scopes of the token that was used to make the\nrequest. In addition to that, the REST API provides an endpoint to {% ifversion fpt or ghes or ghec %}\ncheck a token for validity{% else %}check a token for validity{% e", "Y2h1bmtfM19pbmRleF81NDQ=": "ndif %}.\nUse this information to detect changes in token scopes, and inform your users of\nchanges in available application functionality.\n\n\n\nMaking authenticated requests\n\nAt last, with this access token, you'll be able to make authenticated requests as\nthe logged in user:\n\n``` ruby\n\n\nfetch user information\nauth_result = JSON.parse(RestClient.get('{% data variables.product.api_url_code %}/user',\n                                        {:params => {:access_token => access_token}}))\n\n\n\nif the user authorized it, fetch private emails\nif has_user_email_scope\n  auth_result['private_emails'] =\n    JSON.parse(RestClient.get('{% data variables.product.api_url_code %}/user/emails',\n                              {:params => {:access_token => access_token}}))\nend\n\nerb :basic, :locals => auth_result\n```\n\nWe can do whatever we want with our results. In this case, we'll just dump them straight into _basic.erb_:\n\n```html\nHello, !\n\n   It looks like your public email address is .\n   It looks like you don't have a public email. That's cool.\n  \n\n\n  \n  With your permission, we were also able to dig up your private email addresses:\n  \n  \n  Also, you're a bit secretive about your private email addresses.\n  \n\n```\n\n\n\nImplementing \"persistent\" authentication\n\nIt'd be a pretty bad model if we required users to log into the app every single\ntime they needed to access the web page. For example, try navigating directly to\n`http://127.0.0.1:4567/basic`. You'll get an error.\n\nWhat if we could circumvent the entire\n\"click here\" process, and just _remember_ that, as long as the user's logged into\n{% data variables.product.product_name %}, they should be able to access this application? Hold on to your hat,\nbecause _that's exactly what we're going to do_.\n\nOur little server above is rather simple. In order to wedge in some intelligent\nauthentication, we're going to switch over to using sessions for storing tokens.\nThis will make authentication transparent to the user.\n\nAlso, since we're persisting scopes within the session, we'll need to\nhandle c", "Y2h1bmtfNF9pbmRleF81NDQ=": "ases when the user updates the scopes after we checked them, or revokes\nthe token. To do that, we'll use a `rescue` block and check that the first API\ncall succeeded, which verifies that the token is still valid. After that, we'll\ncheck the `X-OAuth-Scopes` response header to verify that the user hasn't revoked\nthe `user:email` scope.\n\nCreate a file called _advanced_server.rb_, and paste these lines into it:\n\n``` ruby\nrequire 'sinatra'\nrequire 'rest_client'\nrequire 'json'\n\n\n\nDon't use hard-coded values in your app\n\nCLIENT_ID = ENV['GH_BASIC_CLIENT_ID']\nCLIENT_SECRET = ENV['GH_BASIC_SECRET_ID']\n\nuse Rack::Session::Pool, :cookie_only => false\n\ndef authenticated?\n  session[:access_token]\nend\n\ndef authenticate!\n  erb :index, :locals => {:client_id => CLIENT_ID}\nend\n\nget '/' do\n  if !authenticated?\n    authenticate!\n  else\n    access_token = session[:access_token]\n    scopes = []\n\n    begin\n      auth_result = RestClient.get('{% data variables.product.api_url_code %}/user',\n                                   {:params => {:access_token => access_token},\n                                    :accept => :json})\n    rescue => e\n      # request didn't succeed because the token was revoked so we\n      # invalidate the token stored in the session and render the\n      # index page so that the user can start the OAuth flow again\n\n      session[:access_token] = nil\n      return authenticate!\n    end\n\n    # the request succeeded, so we check the list of current scopes\n    if auth_result.headers.include? :x_oauth_scopes\n      scopes = auth_result.headers[:x_oauth_scopes].split(', ')\n    end\n\n    auth_result = JSON.parse(auth_result)\n\n    if scopes.include? 'user:email'\n      auth_result['private_emails'] =\n        JSON.parse(RestClient.get('{% data variables.product.api_url_code %}/user/emails',\n                       {:params => {:access_token => access_token},\n                        :accept => :json}))\n    end\n\n    erb :advanced, :locals => auth_result\n  end\nend\n\nget '/callback' do\n  session_code = request.env['rack.request.quer", "Y2h1bmtfNV9pbmRleF81NDQ=": "y_hash']['code']\n\n  result = RestClient.post('https://github.com/login/oauth/access_token',\n                          {:client_id => CLIENT_ID,\n                           :client_secret => CLIENT_SECRET,\n                           :code => session_code},\n                           :accept => :json)\n\n  session[:access_token] = JSON.parse(result)['access_token']\n\n  redirect '/'\nend\n```\n\nMuch of the code should look familiar. For example, we're still using `RestClient.get`\nto call out to the {% ifversion fpt or ghec %}{% data variables.product.prodname_dotcom %}{% else %}{% data variables.product.product_name %}{% endif %} API, and we're still passing our results to be rendered\nin an ERB template (this time, it's called `advanced.erb`).\n\nAlso, we now have the `authenticated?` method which checks if the user is already\nauthenticated. If not, the `authenticate!` method is called, which performs the\nOAuth flow and updates the session with the granted token and scopes.\n\nNext, create a file in _views_ called _advanced.erb_, and paste this markup into it:\n\n```html\n\n  \n  \n  \n    Well, well, well, !\n    \n       It looks like your public email address is .\n       It looks like you don't have a public email. That's cool.\n      \n    \n    \n      \n      With your permission, we were also able to dig up your private email addresses:\n      \n      \n      Also, you're a bit secretive about your private email addresses.\n      \n    \n  \n\n```\n\nFrom the command line, call `ruby advanced_server.rb`, which starts up your\nserver on port `4567` -- the same port we used when we had a simple Sinatra app.\nWhen you navigate to `http://127.0.0.1:4567`, the app calls `authenticate!`\nwhich redirects you to `/callback`. `/callback` then sends us back to `/`,\nand since we've been authenticated, renders _advanced.erb_.\n\nWe could completely simplify this roundtrip routing by simply changing our callback\nURL in {% data variables.product.product_name %} to `/`. But, since both _server.rb_ and _advanced.rb_ are relying on\nthe same callback URL, we've got ", "Y2h1bmtfNl9pbmRleF81NDQ=": "to do a little bit of wonkiness to make it work.\n\nAlso, if we had never authorized this application to access our {% data variables.product.product_name %} data,\nwe would've seen the same confirmation dialog from earlier pop-up and warn us.\n\n", "Y2h1bmtfMF9pbmRleF85OTY=": "\n\nOverview\n\n{% data reusables.codespaces.automatic-deletion %}\n\n{% data variables.product.prodname_dotcom %} users can set a personal retention period of less than 30 days for codespaces they create. For more information, see \"AUTOTITLE.\"\n\nAs an organization owner, you may want to configure constraints on the maximum retention period for codespaces created for the repositories owned by your organization. This can help you to limit the storage costs associated with codespaces that are stopped and then left unused until they are automatically deleted. For more information about storage charges, see \"AUTOTITLE.\" You can set a maximum retention period for all, or for specific, repositories owned by your organization.\n\n{% note %}\n\n**Note**: Setting a maximum retention policy for a repository prevents people from exempting a codespace from automatic deletion. The \"Keep codespace\" option will be unavailable for codespaces created for that repository. For more information, see \"AUTOTITLE.\"\n\n{% endnote %}\n\n\n\nSetting organization-wide and repository-specific policies\n\nWhen you create a policy, you choose whether it applies to all repositories in your organization, or only to specified repositories. If you create an organization-wide policy with a codespace retention constraint, then the retention constraints in any policies that are targeted at specific repositories should be shorter than the restriction configured for the entire organization, or they will have no effect. The shortest retention period - in an organization-wide policy, a policy targeted at specified repositories, or the default retention period in someone's personal settings - is applied.\n\nIf you add an organization-wide policy with a retention constraint, you should set the retention period to the longest acceptable period. You can then add separate policies that set the maximum retention to a shorter period for specific repositories in your organization.\n\n{% data reusables.codespaces.codespaces-org-policies-note %}\n\n\n\nAdding a policy to set a maximum code", "Y2h1bmtfMV9pbmRleF85OTY=": "space retention period\n\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n{% data reusables.codespaces.codespaces-org-policies %}\n1. Click **Add constraint** and choose **Retention period**.\n1. Click {% octicon \"pencil\" aria-label=\"Edit policy\" %} to edit the constraint.\n1. Enter the maximum number of days codespaces can remain stopped before they are automatically deleted, then click **Save**.\n\n   !Screenshot of a dropdown with a field labeled \"Maximum value\" set to 8 days. Below this are \"Cancel\" and \"Save\" buttons.\n\n   {% note %}\n\n   **Notes**\n   - A day, in this context, is a 24-hour period, beginning at the time of day when the codespace was stopped.\n   - The valid range is 0-30 days.\n   - Setting the period to `0` will result in codespaces being immediately deleted when they are stopped, or when they timeout due to inactivity.\n\n   {% endnote %}\n\n{% data reusables.codespaces.codespaces-policy-targets %}\n1. If you want to add another constraint to the policy, click **Add constraint** and choose another constraint. For information about other constraints, see:\n   - \"AUTOTITLE\"\n   - \"AUTOTITLE\"\n   - \"AUTOTITLE\"\n   - \"AUTOTITLE\"\n   - \"AUTOTITLE\"\n\n1. After you've finished adding constraints to your policy, click **Save**.\n\nThe policy will be applied to all new codespaces that are billable to your organization. The retention period constraint is only applied on codespace creation.\n\n\n\nEditing a policy\n\nYou can edit an existing policy. For example, you may want to add or remove constraints to or from a policy.\n\nThe retention period constraint is only applied to codespaces when they are created. Editing a policy has no effect on existing codespaces.\n\n1. Display the \"Codespaces policies\" page. For more information, see \"Adding a policy to set a maximum codespace retention period.\"\n1. Click the name of the policy you want to edit.\n1. Beside the \"Retention period\" constraint, click {% octicon \"pencil\" aria-label=\"Edit policy\" %}.\n1. Make the required changes then click **Save**.\n\n\n\nDeleti", "Y2h1bmtfMl9pbmRleF85OTY=": "ng a policy\n\nYou can delete a policy at any time. Deleting a policy has no effect on existing codespaces.\n\n1. Display the \"Codespaces policies\" page. For more information, see \"Adding a policy to set a maximum codespace retention period.\"\n1. Click the delete button to the right of the policy you want to delete.\n{% data reusables.codespaces.delete-codespace-policy %}\n\n", "Y2h1bmtfMF9pbmRleF80NTI=": "\n\nAbout {% data variables.product.prodname_dotcom %} for enterprises\n\n{% data variables.product.prodname_dotcom %} is a complete developer platform to build, scale, and deliver secure software. Businesses use our suite of products to support the entire software development lifecycle, increasing development velocity and improving code quality.\n\nDevelopers can store and version control your source code in repositories, using issues and projects to plan and track their work. They can code in a cloud-hosted development environment, {% data variables.product.prodname_github_codespaces %}, then review each other's code changes with pull requests, using code security features to keep secrets and vulnerabilities out of your codebase. Finally, you can automate your build, test, and deployment pipeline with {% data variables.product.prodname_actions %} and host software packages with {% data variables.product.prodname_registry %}.\n\nWhen businesses adopt {% data variables.product.prodname_enterprise %}, their return on investment (ROI) is high. For example, their developers save 45 minutes per day, and onboarding and training time is reduced by 40%. For more information, see The Total Economic Impact of {% data variables.product.prodname_enterprise %}.\n\nTo simplify administration for all the stages in the software development lifecycle, we provide a single point of visibility and management called an enterprise account. Enterprise accounts enable you to manage billing and settings, enforce policy, and audit the people with access to your enterprise's resources. For more information, see \"AUTOTITLE.\"\n\nOptionally, you can add extra code security features with {% data variables.product.prodname_GH_advanced_security %}, and enhanced support options with {% data variables.contact.premium_support %}. For more information, see \"AUTOTITLE\" and \"About {% data variables.contact.premium_support %}{% ifversion ghae %}\" in the {% data variables.product.prodname_ghe_cloud %} documentation.{% else %}.\"{% endif %}\n\nFor a full list of featu", "Y2h1bmtfMV9pbmRleF80NTI=": "res available with {% data variables.product.prodname_enterprise %}, see \"AUTOTITLE\" and {% data variables.product.pricing_link %}.\n\n\n\nAbout deployment options\n\n{% data reusables.enterprise.ghe-includes-ghec-and-ghes %} {% data variables.product.prodname_ghe_cloud %} is a set of advanced functionality on {% data variables.product.prodname_dotcom_the_website %}, while {% data variables.product.prodname_ghe_server %} is self-hosted platform. For more information, see \"AUTOTITLE\"{% ifversion not ghec %} in the {% data variables.product.prodname_ghe_cloud%} documentation{% endif %} and \"About {% data variables.product.prodname_ghe_server %}{% ifversion not ghes %}\" in the {% data variables.product.prodname_ghe_server %} documentation.{% else %}.\"{% endif %}\n\nFor {% data variables.product.prodname_ghe_cloud %}, you can allow developers to create and manage their own personal accounts, or you can use {% data variables.product.prodname_emus %}, which enables you to create and manage the user accounts for your developers. For more information, see \"AUTOTITLE.\"\n\nYou can benefit from the power of {% data variables.product.prodname_dotcom_the_website %} even while using {% data variables.product.prodname_ghe_server %}{% ifversion ghae %} or {% data variables.product.prodname_ghe_managed %}{% endif %} by enabling {% data variables.product.prodname_github_connect %}, which allows you to configure additional features and workflows such as {% data variables.product.prodname_dependabot_alerts %} for insecure dependencies. For more information, see \"About {% data variables.product.prodname_github_connect %}{% ifversion ghes or ghae %}.\"{% elsif ghec %}\" in the {% data variables.product.prodname_ghe_server %} documentation.{% endif %}\n\n\n\nFurther reading\n\n- Compare {% data variables.product.prodname_dotcom %} to other DevOps solutions in {% data variables.product.company_short %} Resources\n\n", "Y2h1bmtfMF9pbmRleF8zMzE=": "\n\nAbout authentication and user provisioning with Azure AD\n\nAzure Active Directory (Azure AD) is a service from Microsoft that allows you to centrally manage user accounts and access to web applications. For more information, see What is Azure Active Directory? in the Microsoft Docs.\n\n{% data reusables.saml.idp-saml-and-scim-explanation %}\n\n{% data reusables.scim.ghes-beta-note %}\n\nAfter you enable SAML SSO and SCIM for {% data variables.product.product_name %} using Azure AD, you can accomplish the following from your Azure AD tenant.\n\n- Assign the {% data variables.product.product_name %} application on Azure AD to a user account to automatically create and grant access to a corresponding user account on {% data variables.product.product_name %}.\n- Unassign the {% data variables.product.product_name %} application to a user account on Azure AD to deactivate the corresponding user account on {% data variables.product.product_name %}.\n- Assign the {% data variables.product.product_name %} application to an IdP group on Azure AD to automatically create and grant access to user accounts on {% data variables.product.product_name %} for all members of the IdP group. In addition, the IdP group is available on {% data variables.product.product_name %} for connection to a team and its parent organization.\n- Unassign the {% data variables.product.product_name %} application from an IdP group to deactivate the {% data variables.product.product_name %} user accounts of all IdP users who had access only through that IdP group and remove the users from the parent organization. The IdP group will be disconnected from any teams on {% data variables.product.product_name %}.\n\nFor more information about managing identity and access for your enterprise on {% data variables.location.product_location %}, see \"AUTOTITLE.\"\n\n\n\nPrerequisites\n\n- To configure authentication and user provisioning for {% data variables.product.product_name %} using Azure AD, you must have an Azure AD account and tenant. For more information, see the Azure A", "Y2h1bmtfMV9pbmRleF8zMzE=": "D website and Quickstart: Create an Azure Active Directory tenant in the Microsoft Docs.\n\n{%- ifversion scim-for-ghes %}\n- {% data reusables.saml.ghes-you-must-configure-saml-sso %}\n{%- endif %}\n\n- {% data reusables.saml.create-a-machine-user %}\n\n\n\nConfiguring authentication and user provisioning with Azure AD\n\n{% ifversion ghae %}\n\nIn your Azure AD tenant, add the application for {% data variables.product.product_name %}, then configure provisioning.\n\n1. In Azure AD, add the {% data variables.enterprise.ae_azure_ad_app_link %} to your tenant and configure single sign-on. For more information, see Tutorial: Azure Active Directory single sign-on (SSO) integration with {% data variables.product.product_name %} in the Microsoft Docs.\n\n1. In {% data variables.product.product_name %}, enter the details for your Azure AD tenant.\n\n    - {% data reusables.saml.ae-enable-saml-sso-during-bootstrapping %}\n\n    - If you've already configured SAML SSO for {% data variables.location.product_location %} using another IdP and you want to use Azure AD instead, you can edit your configuration. For more information, see \"AUTOTITLE.\"\n\n1. Enable user provisioning in {% data variables.product.product_name %} and configure user provisioning in Azure AD. For more information, see \"AUTOTITLE.\"\n\n{% elsif scim-for-ghes %}\n\n1. Configure SAML SSO for {% data variables.location.product_location %}. For more information, see \"AUTOTITLE.\"\n1. Configure user provisioning with SCIM for your instance. For more information, see \"AUTOTITLE.\"\n\n{% endif %}\n\n\n\nManaging enterprise owners\n\nThe steps to make a person an enterprise owner depend on whether you only use SAML or also use SCIM. For more information about enterprise owners, see \"AUTOTITLE.\"\n\nIf you configured provisioning, to grant the user enterprise ownership in {% data variables.product.product_name %}, assign the enterprise owner role to the user in Azure AD.\n\nIf you did not configure provisioning, to grant the user enterprise ownership in {% data variables.product.product_name %}, include t", "Y2h1bmtfMl9pbmRleF8zMzE=": "he `administrator` attribute in the SAML assertion for the user account on the IdP, with the value of `true`. For more information about including the `administrator` attribute in the SAML claim from Azure AD, see How to: customize claims issued in the SAML token for enterprise applications in the Microsoft Docs.\n\n", "Y2h1bmtfMF9pbmRleF8xNDEw": "\n\nAdding a date field\n\n{% data reusables.projects.new-field %}\n1. Select **Date**\n1. Click **Save**.\n\nAlternatively, open the project command palette by pressing {% data variables.projects.command-palette-shortcut %} and start typing \"Create new field.\"\n\n", "Y2h1bmtfMF9pbmRleF8yMDg2": "---\ntitle: Getting started with the Sponsors GraphQL API\nintro: 'Using the GraphQL API, you can build custom integrations to manage or review your sponsorships.'\nversions:\n  fpt: '*'\n  ghec: '*'\ntype: overview\ntopics:\n  - GraphQL\n  - API\nshortTitle: Sponsors GraphQL API\n---\n\nTo get started with the GraphQL API, see \"AUTOTITLE.\"\n\nYou can find the details about the Sponsors GraphQL API in the reference docs. For more information, see \"AUTOTITLE.\" We recommend using the GraphQL explorer to build your GraphQL calls. For more information, see \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF8xNjA5": "---\ntitle: Disabling team discussions for your organization\nintro: Organization owners can choose to disable or enable team discussions across the organization.\nredirect_from:\n  - /articles/disabling-team-discussions-for-your-organization\n  - /github/setting-up-and-managing-organizations-and-teams/disabling-team-discussions-for-your-organization\nversions:\n  feature: team-discussions\ntopics:\n  - Organizations\n  - Teams\nshortTitle: Disable team discussions\n---\n\n{% ifversion team-discussions-migration %}\n{% data reusables.organizations.team-discussions-migration %}\n{% endif %}\n\n{% data reusables.organizations.team-discussions-default %} For more information on team discussions, see \"AUTOTITLE.\"\n\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n{% data reusables.organizations.teams_sidebar %}\n1. Under \"Team discussions\", unselect **Enable team discussions for this organization**.\n1. Click **Save**.\n\n", "Y2h1bmtfMF9pbmRleF8xMjI1": "\n\nAbout assignment deadlines\n\nYour teacher can set an assignment deadline for assignments on {% data variables.product.prodname_classroom %}. If your teacher makes a deadline a hard cutoff, unless you or your group have received an extension, you will lose write access to your assignment repository after the deadline passes. You can easily monitor the deadline for an assignment through the README in your assignment repository.\n\n\n\nViewing an assignment's deadline\n\n1. Navigate to your assignment repository.\n1. On the main page of your repository, scroll down until you see the repository's README, then click {% octicon \"calendar\" aria-hidden=\"true\" %} **Review the assignment due date**. Your assignment deadline is visible below the link to your assignment repository. The deadline shown updates automatically any time your teacher alters the assignment deadline.\n\n", "Y2h1bmtfMF9pbmRleF8xMTM5": "\n\nAbout {% data variables.product.prodname_copilot %}\n\n{% data variables.product.prodname_copilot %} is an AI pair programmer that offers autocomplete-style suggestions as you code. You can receive suggestions from {% data variables.product.prodname_copilot %} either by starting to write the code you want to use, or by writing a natural language comment describing what you want the code to do. {% data variables.product.prodname_copilot %} analyzes the context in the file you are editing, as well as related files, and offers suggestions from within your text editor. {% data variables.product.prodname_copilot %} is powered by a generative AI model developed by {% data variables.product.prodname_dotcom %}, OpenAI, and Microsoft.\n\n{% data variables.product.prodname_copilot %} is trained on all languages that appear in public repositories. For each language, the quality of suggestions you receive may depend on the volume and diversity of training data for that language. For example, JavaScript is well-represented in public repositories and is one of {% data variables.product.prodname_copilot %}'s best supported languages. Languages with less representation in public repositories may produce fewer or less robust suggestions.\n\n{% data reusables.copilot.supported-tools %}\n\n\n\nUnderstanding the differences between {% data variables.product.prodname_copilot_individuals_short %} and {% data variables.product.prodname_copilot_business_short %}\n\n{% data reusables.copilot.differences-cfi-cfb-table %}\n\n\n\nUsing {% data variables.product.prodname_copilot %}\n\nYou can see real-world examples of {% data variables.product.prodname_copilot %} in action. For more information, see the {% data variables.product.prodname_copilot %} website.\n\n{% data variables.product.prodname_copilot %} offers suggestions from a model that OpenAI built from billions of lines of open source code. As a result, the training set for {% data variables.product.prodname_copilot %} may contain insecure coding patterns, bugs, or references to outdated APIs or idiom", "Y2h1bmtfMV9pbmRleF8xMTM5": "s. When {% data variables.product.prodname_copilot %} produces suggestions based on this training data, those suggestions may also contain undesirable patterns.\n\nYou are responsible for ensuring the security and quality of your code. We recommend you take the same precautions when using code generated by {% data variables.product.prodname_copilot %} that you would when using any code you didn't write yourself. These precautions include rigorous testing, IP scanning, and tracking for security vulnerabilities. {% data variables.product.company_short %} provides a number of features to help you monitor and improve code quality, such as {% data variables.product.prodname_actions %}, {% data variables.product.prodname_dependabot %}, {% data variables.product.prodname_codeql %} and {% data variables.product.prodname_code_scanning %}. All these features are free to use in public repositories. For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n\n{% data variables.product.prodname_copilot %} uses filters to block offensive words in the prompts and avoid producing suggestions in sensitive contexts. We are committed to constantly improving the filter system to more intelligently detect and remove offensive suggestions generated by {% data variables.product.prodname_copilot %}, including biased, discriminatory, or abusive outputs. If you see an offensive suggestion generated by {% data variables.product.prodname_copilot %}, please report the suggestion directly to copilot-safety@github.com so that we can improve our safeguards.\n\n\n\nAbout billing for {% data variables.product.prodname_copilot %}\n\n{% data variables.product.prodname_copilot %} is a paid feature, requiring a monthly or yearly subscription. {% data variables.product.prodname_copilot %} subscriptions can be paid for and managed through a personal account on {% data variables.product.prodname_dotcom_the_website %} with {% data variables.product.prodname_copilot_individuals_short %}, or paid for and managed centrally through {% ifversion fpt %} an organization acc", "Y2h1bmtfMl9pbmRleF8xMTM5": "ount {% else %}an enterprise account on {% data variables.product.prodname_ghe_cloud %}{% endif %} with {% data variables.product.prodname_copilot_for_business %}.\n\nVerified students, teachers, and maintainers of popular open source projects on {% data variables.product.prodname_dotcom %} are eligible to use {% data variables.product.prodname_copilot_individuals_short %} for free. If you meet the criteria for a free {% data variables.product.prodname_copilot_individuals_short %} subscription, you will be automatically notified when you visit the {% data variables.product.prodname_copilot %} subscription page. {% ifversion fpt %}If you do not meet the criteria for a free {% data variables.product.prodname_copilot_individuals_short %} subscription, you will be offered a {% data reusables.copilot.trial-period %}-day free trial, after which a paid subscription is required for continued use.{% endif %} For more information, see \"AUTOTITLE.\"\n\n\n\nAbout the license for the {% data variables.product.prodname_copilot %} plugin in JetBrains IDEs\n\n{% data variables.product.prodname_dotcom %}, Inc. is the licensor of the JetBrains plugin. The end user license agreement for this plugin is the {% data variables.product.prodname_dotcom %} Terms for Additional Products and Features and use of this plugin is subject to those terms. JetBrains has no responsibility or liability in connection with the plugin or such agreement. By using the plugin, you agree to the foregoing terms.\n\n\n\nAbout privacy for {% data variables.product.prodname_copilot_for_individuals %}\n\nYou have the ability to manage and make choices regarding the collection, retention, and processing of your data, allowing you to maintain control over your privacy while using {% data variables.product.prodname_copilot_for_individuals %}.\n\n\n\nWhat data does {% data variables.product.prodname_copilot_for_individuals %} collect?\n\n{% data variables.product.prodname_copilot_for_individuals %} relies on file content and additional data to work. It collects data to provide the serv", "Y2h1bmtfM19pbmRleF8xMTM5": "ice, some of which is then retained for further analysis and product improvements. {% data variables.product.prodname_copilot %} processes the following data for individual users.\n\n\n\nUser Engagement Data\n\nWhen you use {% data variables.product.prodname_copilot %} it will collect usage information about events generated when interacting with the IDE or editor. These events include user edit actions like if Suggestions are accepted or dismissed, and error and general usage data to identify metrics like latency and features engagement. This information may include personal data, such as pseudonymous identifiers.\n\n\n\nPrompts\n\nA Prompt is the bundle of contextual information the {% data variables.product.prodname_copilot %} extension sends when a user is working on a file and pauses typing, or when the user opens the {% data variables.product.prodname_copilot_short %} pane. Prompts are retained unless you have disabled code snippet collection in your settings.\n\n\n\nSuggestions\n\nA Suggestion is one or more lines of proposed text returned to the {% data variables.product.prodname_copilot %} extension after a Prompt is received and processed by the AI-model. Suggestions are retained unless you disable code snippet collection in your settings.\n\n\n\nHow is the data in {% data variables.product.prodname_copilot_for_individuals %} used and shared?\n\nUser Engagement Data, Prompts and Suggestions are used by {% data variables.product.company_short %} and Microsoft to improve {% data variables.product.prodname_copilot %} and related services and to conduct product and academic research.\n\n- Enhancing {% data variables.product.prodname_copilot %}: The data collected is utilized to improve {% data variables.product.prodname_copilot %} by evaluating different strategies for processing and predicting suggestions that users may find valuable.\n- Developing related developer products and services: The insights gained from the data help in the development and improvement of other developer tools and services offered by {% data variables.produ", "Y2h1bmtfNF9pbmRleF8xMTM5": "ct.company_short %} and Microsoft.\n- Detecting abuse and policy violations: The data is examined to investigate and identify any potential misuse or violation of the Acceptable Use Policies associated with {% data variables.product.prodname_copilot %}.\n- Conducting experiments and research: The data is used for conducting experiments and research related to developers and their utilization of developer tools and services. This aids in gaining valuable insights into user behavior and preferences.\n- Evaluating {% data variables.product.prodname_copilot %}: The impact of {% data variables.product.prodname_copilot %} on users is assessed by measuring its positive effects and benefits.\n- Improving code generation models: The collected data is employed to refine and enhance the underlying models responsible for generating code. This is achieved by utilizing both positive and negative examples.\n- Fine-tuning ranking and sorting algorithms: The data helps in the optimization and improvement of algorithms used for ranking and sorting suggestions, thereby enhancing the overall user experience.\n\n\n\nHow is the transmitted Code Snippets data protected?\n\nTo ensure the protection of sensitive data such as user edit actions, source code snippets, and repository URLs/file paths, several protective measures are implemented. These measures include:\n\n- Encryption of transmitted data: All data is encrypted both during transit and while at rest, ensuring that it remains secure and inaccessible to unauthorized parties.\n- Strict access control: Access to the data is tightly regulated and limited to specific individuals, including:\n    - Named {% data variables.product.company_short %} personnel working on the {% data variables.product.prodname_copilot %} team or the {% data variables.product.company_short %} platform health team.\n    - Microsoft personnel involved with the {% data variables.product.prodname_copilot %} team.\n- Role-based access controls and multi-factor authentication: People who require access to code snippet data must a", "Y2h1bmtfNV9pbmRleF8xMTM5": "dhere to role-based access controls. Additionally, multi-factor authentication is implemented to add an extra layer of security, ensuring that only authorized individuals can access the data.\n\n\n\nHow can users of {% data variables.product.prodname_copilot_for_individuals %} control use of their Code Snippets Data?\n\n{% data variables.product.prodname_copilot %} gives you choices about how it uses the data it collects.\n\n- User Engagement Data: User Engagement Data, including pseudonymous identifiers and general usage data, is necessary for the proper functioning of {% data variables.product.prodname_copilot %}. This data is collected, processed, and shared with Microsoft while you use {% data variables.product.prodname_copilot %}.\n- Retention of Prompts and Suggestions: You have the option to decide whether Prompts and Suggestions are retained by {% data variables.product.company_short %} and shared with Microsoft. These preferences can be adjusted in the {% data variables.product.prodname_copilot %} settings.\n- Requesting Deletion: If you wish to delete Prompts and Suggestions associated with your {% data variables.product.company_short %} identity, contact {% data variables.contact.contact_support %}.\n\n\n\nWill my private code be shared with other users?\n\nNo. We follow responsible practices in accordance with our Privacy Statement to ensure that your code snippets will not be used as suggested code for other users of {% data variables.product.prodname_copilot %}.\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"{% ifversion ghec %}\n- \"AUTOTITLE\"{% endif %}\n- \"{% data variables.product.prodname_copilot %} FAQ\"\n\n", "Y2h1bmtfMF9pbmRleF8yMzY=": "\n\nAbout {% data variables.product.prodname_code_scanning %}\n\n{% data reusables.code-scanning.about-code-scanning %}\n\nYou can configure {% data variables.product.prodname_code_scanning %} to run {% data variables.product.prodname_codeql %} analysis and third-party analysis. {% data variables.product.prodname_code_scanning_caps %} also supports running analysis natively using {% data variables.product.prodname_actions %} or externally using existing CI/CD infrastructure. The bullets below summarize the options available to users when you configure {% data variables.location.product_location %} to allow {% data variables.product.prodname_code_scanning %} using actions.\n\n{% data reusables.code-scanning.enabling-options %}\n\n\n\nChecking whether your license includes {% data variables.product.prodname_GH_advanced_security %}\n\n{% data reusables.advanced-security.check-for-ghas-license %}\n\n\n\nPrerequisites for {% data variables.product.prodname_code_scanning %}\n\n- A license for {% data variables.product.prodname_GH_advanced_security %}{% ifversion ghes %} (see \"AUTOTITLE\"){% endif %}\n\n- {% data variables.product.prodname_code_scanning_caps %} enabled in the management console (see \"AUTOTITLE\")\n\n- A VM or container for {% data variables.product.prodname_code_scanning %} analysis to run in.\n\n\n\n\n\n\n\nRunning {% data variables.product.prodname_code_scanning %} using {% data variables.product.prodname_actions %}\n\n\n\nSetting up a self-hosted runner\n\n{% data variables.product.prodname_ghe_server %} can run {% data variables.product.prodname_code_scanning %} using a {% data variables.product.prodname_actions %} workflow. First, you need to provision one or more self-hosted {% data variables.product.prodname_actions %} runners in your environment. You can provision self-hosted runners at the repository, organization, or enterprise account level. For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n\n{% ifversion code-scanning-runner-label %}\nIf you are provisioning a self-hosted runner for {% data variables.product.prodname_codeql %} ", "Y2h1bmtfMV9pbmRleF8yMzY=": "analysis, your runner must use a {% data variables.product.prodname_codeql %}-supported operating system version and CPU architecture. For more information, see the {% data variables.product.prodname_codeql %} system requirements.\n\nIf you are using default setup for {% data variables.product.prodname_code_scanning %}, assign the `code-scanning` label to your self-hosted runner. For more information about using labels with self-hosted runners, see \"AUTOTITLE.\"{% ifversion code-scanning-default-setup-self-hosted-310 %} For more information about using default setup for code scanning analysis of compiled languages, see \"AUTOTITLE.\"{% endif %}\n\n{% endif %}\n\nYou must ensure that Git is in the PATH variable on any self-hosted runners you use to run {% data variables.product.prodname_codeql %} actions.\n\n{% ifversion ghes > 3.7 or ghae > 3.7 %}\n{% note %}\n\nIf you use {% data variables.product.prodname_codeql %} {% data variables.product.prodname_code_scanning %} to analyze code written in Python in your enterprise, you must make sure that your self-hosted runner has Python 3 installed.\n\n{% endnote %}\n{% endif %}\n\n\n\nProvisioning the actions for {% data variables.product.prodname_code_scanning %}\n\n{% ifversion ghes %}\nIf you want to use actions to run {% data variables.product.prodname_code_scanning %} on {% data variables.product.prodname_ghe_server %}, the actions must be available on your appliance.\n\nThe {% data variables.product.prodname_codeql %} action is included in your installation of {% data variables.product.prodname_ghe_server %}. If both {% data variables.product.prodname_ghe_server %} {{ allVersionscurrentVersion].currentRelease }} and your {% data variables.product.prodname_actions %} runner have access to the internet, the action will automatically download the {% data variables.product.prodname_codeql %} {% data variables.product.codeql_cli_ghes_recommended_version %} bundle required to perform analysis. Alternatively, you can use a synchronization tool to make the latest released version of the {% data va", "Y2h1bmtfMl9pbmRleF8yMzY=": "riables.product.prodname_codeql %} analysis bundle available locally. For more information, see \"[Configuring {% data variables.product.prodname_codeql %} analysis on a server without internet access\" below.\n\nYou can also make third-party actions available to users for {% data variables.product.prodname_code_scanning %}, by setting up {% data variables.product.prodname_github_connect %}. For more information, see \"AUTOTITLE\" below.\n\n\n\nConfiguring {% data variables.product.prodname_codeql %} analysis on a server without internet access\n\nIf the server on which you are running {% data variables.product.prodname_ghe_server %} is not connected to the internet, and you want to allow users to enable {% data variables.product.prodname_codeql %} {% data variables.product.prodname_code_scanning %} for their repositories, you must use the {% data variables.product.prodname_codeql %} action sync tool to copy the {% data variables.product.prodname_codeql %} analysis bundle from {% data variables.product.prodname_dotcom_the_website %} to your server. The tool, and details of how to use it, are available at https://github.com/github/codeql-action-sync-tool.\n\nIf you configure the {% data variables.product.prodname_codeql %} action sync tool, you can use it to sync the latest releases of the {% data variables.product.prodname_codeql %} action and associated {% data variables.product.prodname_codeql %} analysis bundle. These are compatible with {% data variables.product.prodname_ghe_server %}.\n\n{% endif %}\n\n\n\nConfiguring {% data variables.product.prodname_github_connect %} to sync {% data variables.product.prodname_actions %}\n\n1. If you want to download action workflows on demand from {% data variables.product.prodname_dotcom_the_website %}, you need to enable {% data variables.product.prodname_github_connect %}. For more information, see \"AUTOTITLE.\"\n1. You'll also need to enable {% data variables.product.prodname_actions %} for {% data variables.location.product_location %}. For more information, see \"AUTOTITLE.\"\n1. The next ste", "Y2h1bmtfM19pbmRleF8yMzY=": "p is to configure access to actions on {% data variables.product.prodname_dotcom_the_website %} using {% data variables.product.prodname_github_connect %}. For more information, see \"AUTOTITLE.\"\n1. Add a self-hosted runner to your repository, organization, or enterprise account. For more information, see \"AUTOTITLE.\"\n\n\n\nRunning code scanning using the {% data variables.product.prodname_codeql_cli %}\n\nIf you don't want to use {% data variables.product.prodname_actions %}, you should run {% data variables.product.prodname_code_scanning %} using the {% data variables.product.prodname_codeql_cli %}.\n\nThe {% data variables.product.prodname_codeql_cli %} is a command-line tool that you use to analyze codebases on any machine, including a third-party CI/CD system. For more information, see \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF8xNDY1": "\n\nAbout repository migrations with {% data variables.product.prodname_importer_proper_name %}\n\n{% data reusables.enterprise-migration-tool.tool-options %}\n\n{% cli %}\n{% data reusables.enterprise-migration-tool.gei-tool-switcher-api %}\n{% endcli %}\n{% api %}\n{% data reusables.enterprise-migration-tool.gei-tool-switcher-cli %}\n{% endapi %}\n\n\n\nPrerequisites\n\n{% data reusables.enterprise-migration-tool.migration-prerequisites %}\n- You must be either an organization owner or be granted the migrator role for both the source and destination organizations. For more information, see \"AUTOTITLE.\"\n\n{% api %}\n\n\n\nStep 0: Get ready to use the {% data variables.product.prodname_dotcom %} GraphQL API\n\n{% data reusables.enterprise-migration-tool.migration-query-method %}\n\n\n\nStep 1: Get the `ownerId` for your migration destination\n\n{% data reusables.enterprise-migration-tool.get-destination-ownerId-ec %}\n\n{% data reusables.enterprise-migration-tool.migration-destination-query %}\n\n\n\nStep 2: Identify where you're migrating from\n\n{% data reusables.enterprise-migration-tool.identify-migration-source-intro %}\n\nYour migration source is an organization on {% data variables.product.prodname_dotcom_the_website %}.\n\n\n\n`createMigrationSource` mutation\n\n```graphql\nmutation createMigrationSource($name: String!, $ownerId: ID!) {\n  createMigrationSource(input: {name: $name, url: \"https://github.com\", ownerId: $ownerId, type: GITHUB_ARCHIVE}) {\n    migrationSource {\n      id\n      name\n      url\n      type\n    }\n  }\n}\n```\n\n{% data reusables.enterprise-migration-tool.type-note-github-archive %}\n\n{% data reusables.enterprise-migration-tool.createMigrationSource-table-ec %}\n\n\n\n`createMigrationSource` response\n\n```json\n{\n  \"data\": {\n    \"createMigrationSource\": {\n      \"migrationSource\": {\n        \"id\": \"MS_kgDaACQxYmYxOWU4Yi0wNzZmLTQ3NTMtOTdkZC1hNGUzZmYxN2U2YzA\",\n        \"name\": \"GitHub.com Source\",\n        \"url\": \"https://github.com\",\n        \"type\": \"GITHUB_SOURCE\"\n      }\n    }\n  }\n}\n```\n\nIn this example, `MS_kgDaACQxYmYxOWU4Yi0wNzZmLTQ3NTMtOTdkZ", "Y2h1bmtfMV9pbmRleF8xNDY1": "C1hNGUzZmYxN2U2YzA` is the migration source ID, which we'll use in the next step.\n\n\n\nStep 3: Start your repository migration\n\n{% data reusables.enterprise-migration-tool.start-repository-migration-ec %}\n\n\n\n`startRepositoryMigration` mutation\n\n```graphql\nmutation startRepositoryMigration (\n  $sourceId: ID!,\n  $ownerId: ID!,\n  $sourceRepositoryUrl: URI!,\n  $repositoryName: String!,\n  $continueOnError: Boolean!,\n  $accessToken: String!,\n  $githubPat: String!,\n  $targetRepoVisibility: String!\n){\n  startRepositoryMigration( input: {\n    sourceId: $sourceId,\n    ownerId: $ownerId,\n    repositoryName: $repositoryName,\n    continueOnError: $continueOnError,\n    accessToken: $accessToken,\n    githubPat: $githubPat,\n    targetRepoVisibility: $targetRepoVisibility\n    sourceRepositoryUrl: $sourceRepositoryUrl,\n  }) {\n    repositoryMigration {\n      id\n      migrationSource {\n        id\n        name\n        type\n      }\n      sourceUrl\n    }\n  }\n}\n```\n\n{% data reusables.enterprise-migration-tool.startRepositoryMigration-table-ec %}\n| `sourceRepositoryUrl` | The URL of your source repository, using the format `https://github.com/{organization}/{repository}`.\n\n{% data reusables.enterprise-migration-tool.next-check-status %}\n\n\n\nStep 4: Check the status of your migration\n\n{% data reusables.enterprise-migration-tool.check-migration %}\n\n\n\nStep 5: Validate your migration and check the error log\n\n{% data reusables.enterprise-migration-tool.validate-migration-log %}\n\n{% endapi %}\n\n{% cli %}\n\n\n\nStep 1: Install the {% data variables.product.prodname_gei_cli %}\n\n{% data reusables.enterprise-migration-tool.install-gei-extension-intro %}\n\n{% data reusables.enterprise-migration-tool.install-github-cli %}\n{% data reusables.enterprise-migration-tool.install-gei-extension %}\n\n{% data reusables.enterprise-migration-tool.gei-help-flag %}\n\n\n\nStep 2: Update the {% data variables.product.prodname_gei_cli %}\n\n{% data reusables.enterprise-migration-tool.update-gei-cli %}\n\n\n\nStep 3: Set environment variables\n\n{% data reusables.enterprise-migration-to", "Y2h1bmtfMl9pbmRleF8xNDY1": "ol.set-env-variables-gei %}\n\n{% data reusables.enterprise-migration-tool.create-pats %}\n{% data reusables.enterprise-migration-tool.env-variables-gei %}\n\n\n\nStep 4: Generate a migration script\n\n{% data reusables.enterprise-migration-tool.generate-migration-script %}\n\nIf you want to migrate a single repository, skip to the next step.\n\n\n\nGenerating a migration script\n\n{% data reusables.enterprise-migration-tool.gh-gei-generate-script %}\n\n```shell copy\ngh gei generate-script --github-source-org SOURCE --github-target-org DESTINATION --output FILENAME\n```\n\n{% data reusables.enterprise-migration-tool.download-migration-logs-flag %}\n\n{% data reusables.enterprise-migration-tool.generate-script-table %}\n\n\n\nReviewing the migration script\n\n{% data reusables.enterprise-migration-tool.review-migration-script %}\n\n{% data reusables.enterprise-migration-tool.skip-releases %}\n\n\n\nStep 5: Migrate repositories\n\n{% data reusables.enterprise-migration-tool.migrate-repos-gei %}\n\n\n\nMigrate multiple repositories\n\n{% data reusables.enterprise-migration-tool.migrate-multiple-repos %}\n\n\n\nMigrate a single repository\n\n{% data reusables.enterprise-migration-tool.gei-migrate-repo %}\n\n```shell copy\ngh gei migrate-repo --github-source-org SOURCE --source-repo CURRENT-NAME --github-target-org DESTINATION --target-repo NEW-NAME\n```\n\n{% data reusables.enterprise-migration-tool.skip-releases %}\n\n{% data reusables.enterprise-migration-tool.migrate-repo-table-ec %}\n\n\n\nStep 6: Validate your migration and check the error log\n\n{% data reusables.enterprise-migration-tool.validate-migration-logs %}\n\n{% endcli %}\n\n", "Y2h1bmtfMF9pbmRleF8yMDc5": "\n\nUptime Guarantee\n\n\u201c**Uptime**\u201d is the percentage of total possible minutes the applicable GitHub service was available in a given calendar quarter. GitHub commits to maintain at least 99.9% Uptime for the applicable GitHub service. The Uptime calculation for each Service Feature that may be included with the applicable GitHub service is described below (\u201c**Uptime Calculation**\u201d). If GitHub does not meet the SLA, Customer will be entitled to Service Credits based on the calculation below (\u201c**Service Credits Calculation**\u201d). Note, Downtime does not affect every customer at the same time or in the same way.\n\n| **Service Feature** | **Uptime Calculation** | **Definitions** | **Service Credits Calculation** |\n|---|---|---|---|\n| **Issues**,**Pull&nbsp;Requests**,**Git&nbsp;Operations**,**API&nbsp;Requests (for Service Features only)**,**Webhooks**,**Pages** | (total minutes in a calendar quarter - Downtime) / total minutes in a calendar quarter | \u201c**Downtime**\u201d is a period of time where either (a) the error rate exceeds five percent (5%) in a given minute for any Service Feature or (b) the Service was unavailable as determined by a combination of GitHub's internal and external monitoring systems. | A Service Credits claim may be based on either (not both) of the following calculations: 10% of the amount Customer paid for a Service Feature in a calendar quarter where the Uptime for that Service Feature was less than or equal to 99.9%, but greater than 99.0%. OR 25% of the amount Customer paid for a Service Feature in a calendar quarter where the Uptime of that Service Feature was less than 99.0%. | |\n| **Actions** | (Total Triggered Executions \u2013 Unavailable Executions) / (Total Triggered Executions) x 100 | \u201c**Total Triggered Executions**\u201d is the total number of all Actions executions triggered by Customer in a calendar quarter.  \u201c**Unavailable Executions**\u201d is the total number of executions within Total Triggered Executions which failed to run in a calendar quarter.  An execution failed to run when the Actions histo", "Y2h1bmtfMV9pbmRleF8yMDc5": "ry log did not capture any output five (5) minutes after the trigger was successfully fired. | Same as above |\n| **Packages** | Transfers Uptime = same as Actions   Storage Uptime = 100% - Average Error Rate* *The Uptime Calculation excludes public usage and storage transactions that do not count toward either Total Storage Transactions or Failed Storage Transactions (including pre-authentication failures; authentication failures; attempted transactions for storage accounts over their prescribed quotas). | \u201c**Error Rate**\u201d is the total number of Failed Storage Transactions divided by the Total Storage Transactions during a set time interval (currently set at one hour). If the Total Storage Transactions in a given one-hour interval is zero, the error rate for that interval is 0%.  \u201c**Average Error Rate**\u201d is the sum of Error Rates for each hour in a calendar quarter divided by the total number of hours in a calendar quarter. | Same as above |\n\n\n\nExclusions\n\nExcluded from the Uptime Calculation are Service Feature failures resulting from (i) Customer\u2019s acts, omissions, or misuse of the applicable GitHub service including violations of the Agreement; (ii) failure of Customer\u2019s internet connectivity; (iii) factors outside GitHub's reasonable control, including force majeure events; or (iv) Customer\u2019s equipment, services, or other technology.\n\n\n\nService Credits Redemption\n\nIf GitHub does not meet this SLA, Customer may redeem Service Credits only upon written request to GitHub within thirty (30) days of the end of the calendar quarter. Written requests for Service Credits redemption and GitHub Enterprise Cloud custom monthly or quarterly reports should be sent to GitHub using the contact form available at GitHub Support.\n\nService Credits may take the form of a refund or credit to Customer\u2019s account, cannot be exchanged into a cash amount, are limited to a maximum of ninety (90) days of paid service per calendar quarter, require Customer to have paid any outstanding invoices, and expire upon termination of Customer\u2019s a", "Y2h1bmtfMl9pbmRleF8yMDc5": "greement with GitHub. Service Credits are the sole and exclusive remedy for any failure by GitHub to meet any obligations in this SLA.\n\n", "Y2h1bmtfMF9pbmRleF8xMzk1": "\n\nCreating a project view\n\nProject views allow you to quickly view specific aspects of your project. Each view is displayed on a separate tab in your project.\n\nFor example, you can have:\n- A view that shows all items not yet started (filter on \"Status\").\n- A view that shows the workload for each team (group by a custom \"Team\" field).\n- A view that shows the items with the earliest target ship date (sort by a date field).\n\nTo add a new view:\n\n{% data reusables.projects.new-view %}\n\nAlternatively, open the project command palette by pressing {% data variables.projects.command-palette-shortcut %} and start typing \"New view.\"\n\nThe new view is automatically saved.\n\n\n\nDuplicating a view\n\nYou can duplicate an existing view and use it as a base to make further changes.\n\n1. Switch to the view you want to duplicate.\n{% data reusables.projects.open-view-menu %}\n1. Click {% octicon \"versions\" aria-hidden=\"true\" %} **Duplicate view**.\n\n\n\nSaving changes to a view\n\nWhen you make changes to a view - for example, sorting, reordering, filtering, or grouping the data in a view - a dot is displayed next to the view name to indicate that there are unsaved changes.\n\n!Screenshot of a tab for a view labeled \"Issues by priority.\" Next to the view's name, a dropdown icon is marked by a blue dot.\n\nIf you don't want to save the changes, you can ignore this indicator. No one else will see your changes.\n\n{% data reusables.projects.save-view %}\n\nAlternatively, open the project command palette by pressing {% data variables.projects.command-palette-shortcut %} and start typing \"Save view.\"\n\n\n\nReordering saved views\n\nTo change the order of the tabs that contain your saved views, click and drag a tab to a new location. The new tab order is automatically saved.\n\n\n\nRenaming a saved view\n\nYou can rename your saved views. The name change is automatically saved.\n\n1. Switch to the view you want to rename.\n{% data reusables.projects.open-view-menu %}\n1. Click {% octicon \"pencil\" aria-hidden=\"true\" %} **Rename view**.\n1. Type the new name for your view.\n1", "Y2h1bmtfMV9pbmRleF8xMzk1": ". To save your changes, press Return.\n\n\n\nDeleting a saved view\n\n1. Switch to the view you want to delete.\n{% data reusables.projects.open-view-menu %}\n1. Click {% octicon \"trash\" aria-hidden=\"true\" %} **Delete view**.\n\nAlternatively, open the project command palette by pressing {% data variables.projects.command-palette-shortcut %} and start typing \"Delete view.\"\n\n", "Y2h1bmtfMF9pbmRleF83MzM=": "\n\nAbout using {% data variables.product.prodname_code_scanning %} with your existing CI system\n\nAs an alternative to running {% data variables.product.prodname_code_scanning %} within {% data variables.product.prodname_dotcom %} using {% data variables.product.prodname_actions %}, you can analyze code in an external continuous integration or continuous delivery/deployment (CI/CD) system, then upload the results to {% data variables.product.product_name %}.\n\nYou can add the {% data variables.product.prodname_codeql_cli %} to your third-party system, or use another third-party static analysis tool that can produce results as Static Analysis Results Interchange Format (SARIF) 2.1.0 data. For more information about the supported SARIF format, see \"AUTOTITLE.\"\n\nThe {% data variables.product.prodname_codeql_cli %} is a standalone, command-line tool that you can use to analyze code. For more information, see \"AUTOTITLE.\"\n\nAlerts for {% data variables.product.prodname_code_scanning %} that you generate externally are displayed in the same way as those for  {% data variables.product.prodname_code_scanning %} that you generate within {% data variables.product.prodname_dotcom %}. {% data reusables.code-scanning.about-multiple-configurations-link %}\n\n{% data reusables.code-scanning.upload-sarif-ghas %}\n\n\n\nSetting up your analysis tool\n\nYou will first need to download your analysis tool of choice and set it up with your CI system.\n\nIf you are using the {% data variables.product.prodname_codeql_cli %}, you need to make the full contents of the {% data variables.product.prodname_codeql_cli %} bundle available to every CI server that you want to run {% data variables.product.prodname_codeql %} {% data variables.product.prodname_code_scanning %} analysis on.  For more information, see \"AUTOTITLE.\"\n\nOnce you've made your analysis tool available to servers in your CI system, you're ready to generate data.\n\n\n\nAnalyzing code\n\nTo analyze code with the {% data variables.product.prodname_codeql_cli %} or another analysis tool, you will ", "Y2h1bmtfMV9pbmRleF83MzM=": "want to check out the code you want to analyze and set up the codebase environment, making sure that any dependencies are available. You may also want to find the build command for the codebase, typically available in your CI system's configuration file.\n\nYou can then complete the steps to analyze your codebase and produce results, which will differ based on the static analysis tool you are using.\n\nIf you are using the {% data variables.product.prodname_codeql_cli %}, you will first need to create a {% data variables.product.prodname_codeql %} database from your code, then analyze the database to produce SARIF results. For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n\n\n\nGenerating a token for authentication with {% data variables.product.product_name %}\n\nEach CI server needs a {% data variables.product.prodname_github_app %} or {% data variables.product.pat_generic %} to use to upload results to {% data variables.product.product_name %}, whether you are using the {% data variables.product.prodname_codeql_cli %}, the REST API, or another method. You must use an access token or a {% data variables.product.prodname_github_app %} with the `security_events` write permission. If CI servers already use a token with this scope to checkout repositories from {% data variables.product.product_name %}, you could potentially use the same token. Otherwise, you should create a new token with the `security_events` write permission and add this to the CI system's secret store. For information, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n\nFor more information on the different methods for uploading results to {% data variables.product.product_name %}, see \"AUTOTITLE.\"\n\n\n\nUploading your results to {% data variables.product.product_name %}\n\nOnce you have analyzed your code, produced SARIF results, and ensured you can authenticate with {% data variables.product.product_name %}, you can upload the results to {% data variables.product.product_name %}. For more information on the different methods you can use to upload your results, see \"AUTO", "Y2h1bmtfMl9pbmRleF83MzM=": "TITLE.\"\n\nFor specific details on uploading your results to {% data variables.product.product_name %} using the {% data variables.product.prodname_codeql_cli %}, see \"AUTOTITLE.\"\n\nBy default, {% data variables.product.prodname_code_scanning %} expects one SARIF results file per analysis for a repository. Consequently, when you upload a second SARIF results file for a commit, it is treated as a replacement for the original set of data. You may want to upload two different SARIF files for one analysis if, for example, your analysis tool generates a different SARIF file for each language it analyzes or each set of rules it uses. If you want to upload more than one set of results for a commit in a repository, you must identify each set of results as a unique set. The way to specify a category for a SARIF upload varies according to the analysis method. For more information, see \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF8yMDMx": "---\ntitle: GitHub Threats of Violence and Gratuitously Violent Content\nshortTitle: Threats of Violence and Gratuitously Violent Content\nversions:\n  fpt: '*'\ntopics:\n  - Policy\n  - Legal\nredirect_from:\n  - /github/site-policy/github-threats-of-violence-and-gratuitously-violent-content\n  - /github/site-policy/github-community-guidelines#threats-of-violence\n  - /github/site-policy/github-community-guidelines#gratuitously-violent-content\n---\n\n\nYou may not use GitHub to organize, promote, encourage, threaten, or incite acts of violence. You may not post content that depicts or glorifies violence or physical harm against human beings or animals. This includes:\n\n- Threatening another individual or group with abuse, harm, sexual violence, or death\n- Posting text, imagery, or audio content glorifying or containing a graphic depiction of violence toward oneself, another individual, group, or animal\n- Encouraging another individual to engage in self harm\n\nWe do not allow violent content to be posted indiscriminately or in a way that is difficult for other users to avoid, such as a profile avatar or an issue comment. However, we understand there may be legitimate reasons to post violent content, such as for educational or documentary purposes, creative works, or depictions of historical events. In those cases, a clear warning or disclaimer can help users make an educated decision as to whether or not they want to engage with such content. Still, GitHub may decide to limit the visibility of such content to those who choose to opt in.\n\n", "Y2h1bmtfMF9pbmRleF84MjM=": "\n\nSynopsis\n\n```shell copy\ncodeql pack init [--dir=] [--extractor=] ... -- \n```\n\n\n\nDescription\n\n\\[Experimental] Initializes a qlpack in the specified directory.\n\nThe pack will be created in a child directory of the specified\ndirectory.\n\nAvailable since `v2.6.0`.\n\n\n\nOptions\n\n\n\nPrimary Options\n\n\n\n`<package-name>`\n\n\\[Mandatory] The scope and name of the pack to create. Scope is only\nrequired if this pack is to be published.\n\n\n\n`--version=<semver>`\n\nInitial version of the pack.\n\n\n\n`-d, --dir=<dir>`\n\nThe directory to create the pack in. Defaults to current working\ndirectory.\n\n\n\n`-e, --extractor=<extractor>`\n\nThe extractor to use for this qlpack. Only useful if this pack contains\ntests.\n\n\n\nCommon options\n\n\n\n`-h, --help`\n\nShow this help text.\n\n\n\n`-J=<opt>`\n\n\\[Advanced] Give option to the JVM running the command.\n\n(Beware that options containing spaces will not be handled correctly.)\n\n\n\n`-v, --verbose`\n\nIncrementally increase the number of progress messages printed.\n\n\n\n`-q, --quiet`\n\nIncrementally decrease the number of progress messages printed.\n\n\n\n`--verbosity=<level>`\n\n\\[Advanced] Explicitly set the verbosity level to one of errors,\nwarnings, progress, progress+, progress++, progress+++. Overrides `-v`\nand `-q`.\n\n\n\n`--logdir=<dir>`\n\n\\[Advanced] Write detailed logs to one or more files in the given\ndirectory, with generated names that include timestamps and the name of\nthe running subcommand.\n\n(To write a log file with a name you have full control over, instead\ngive `--log-to-stderr` and redirect stderr as desired.)\n\n\n\n`--common-caches=<dir>`\n\n\\[Advanced] Controls the location of cached data on disk that will\npersist between several runs of the CLI, such as downloaded QL packs and\ncompiled query plans. If not set explicitly, this defaults to a\ndirectory named `.codeql` in the user's home directory; it will be\ncreated if it doesn't already exist.\n\nAvailable since `v2.15.2`.\n\n", "Y2h1bmtfMF9pbmRleF8yNTk=": "\n\nAdministrative ports\n\nSome administrative ports are required to configure {% data variables.location.product_location %} and run certain features. Administrative ports are not required for basic application use by end users.\n\n| Port | Service | Description |\n|---|---|---|\n| 8443 | HTTPS | Secure web-based {% data variables.enterprise.management_console %}. Required for basic installation and configuration. |\n| 8080 | HTTP | Plain-text web-based {% data variables.enterprise.management_console %}. Not required unless TLS is disabled manually. |\n| 122 | SSH | Shell access for {% data variables.location.product_location %}. Required to be open to incoming connections between all nodes in a high availability configuration. The default SSH port (22) is dedicated to Git and SSH application network traffic. |\n| 1194/UDP | VPN | Secure replication network tunnel in high availability configuration. Required to be open for communication between all nodes in the configuration.|\n| 123/UDP| NTP | Required for time protocol operation. |\n| 161/UDP | SNMP | Required for network monitoring protocol operation. |\n\n\n\nApplication ports for end users\n\nApplication ports provide web application and Git access for end users.\n\n| Port | Service | Description |\n|---|---|---|\n| 443 | HTTPS | Access to the web application and Git over HTTPS. |\n| 80 | HTTP | Access to the web application. All requests are redirected to the HTTPS port if TLS is configured. |\n| 22 | SSH | Access to Git over SSH. Supports clone, fetch, and push operations to public and private repositories. |\n| 9418 | Git | Git protocol port supports clone and fetch operations to public repositories with unencrypted network communication. {% data reusables.enterprise_installation.when-9418-necessary %} |\n\n{% data reusables.enterprise_installation.terminating-tls %}\n\n\n\nEmail ports\n\nEmail ports must be accessible directly or via relay for inbound email support for end users.\n\n| Port | Service | Description |\n|---|---|---|\n| 25 | SMTP | Support for SMTP with encryption (STARTTLS). ", "Y2h1bmtfMV9pbmRleF8yNTk=": "|\n\n\n\n{% data variables.product.prodname_actions %} ports\n\n{% data variables.product.prodname_actions %} ports must be accessible for self-hosted runners to connect to {% data variables.location.product_location %}. For more information, see \"AUTOTITLE.\"\n\n| Port | Service | Description |\n|---|---|---|\n| 443 | HTTPS | Self-hosted runners connect to {% data variables.location.product_location %} to receive job assignments and to download new versions of the runner application. Required if TLS is configured.\n| 80 | HTTP | Self-hosted runners connect to {% data variables.location.product_location %} to receive job assignments and to download new versions of the runner application. Required if TLS is not configured.\n\nIf you enable automatic access to {% data variables.product.prodname_dotcom_the_website %} actions, {% data variables.product.prodname_actions %} will always search for an action on {% data variables.location.product_location %} first, via these ports, before checking {% data variables.product.prodname_dotcom_the_website %}. For more information, see \"AUTOTITLE.\"\n\n\n\n{% data variables.product.prodname_github_connect %} ports\n\nIf you enable {% data variables.product.prodname_github_connect %}, the connection between {% data variables.product.product_name %} and {% data variables.product.prodname_dotcom_the_website %} uses HTTPS over ports 443 or 80, and TLS is required. For more information, see \"AUTOTITLE.\"\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8xMzQw": "\n\nBackground\n\nThe {% data variables.product.product_name %} GraphQL API currently supports two types of global node ID formats. The legacy format will be deprecated and replaced with a new format.  This guide shows you how to migrate to the new format, if necessary.\n\nBy migrating to the new format, you ensure that the response times of your requests remain consistent and small. You also ensure that your application continues to work once the legacy IDs are fully deprecated.\n\nTo learn more about why the legacy global node ID format will be deprecated, see \"New global ID format coming to GraphQL.\"\n\n\n\nDetermining if you need to take action\n\nYou only need to follow the migration steps if you store references to GraphQL global node IDs.  These IDs correspond to the `id` field for any object in the schema.  If you don't store any global node IDs, then you can continue to interact with the API with no change.\n\nAdditionally, if you currently decode the legacy IDs to extract type information (for example, if you use the first two characters of `PR_kwDOAHz1OX4uYAah` to determine if the object is a pull request), your service will break since the format of the IDs has changed.  You should migrate your service to treat these IDs as opaque strings.  These IDs will be unique, therefore you can rely on them directly as references.\n\n\n\nMigrating to the new global IDs\n\nTo facilitate migration to the new ID format, you can use the `X-Github-Next-Global-ID` header in your GraphQL API requests. The value of the `X-Github-Next-Global-ID` header can be `1` or `0`.  Setting the value to `1` will force the response payload to always use the new ID format for any object that you requested the `id` field for.  Setting the value to `0` will revert to default behavior, which is to show the legacy ID or new ID depending on the object creation date.\n\nHere is an example request using a `curl` command:\n\n```shell\n$ curl \\\n  -H \"Authorization: Bearer $GITHUB_TOKEN\" \\\n  -H \"X-Github-Next-Global-ID: 1\" \\\n  https://api.github.com/graphql \\\n  -d '{ \"q", "Y2h1bmtfMV9pbmRleF8xMzQw": "uery\": \"{ node(id: \\\"MDQ6VXNlcjM0MDczMDM=\\\") { id } }\" }'\n```\n\nEven though the legacy ID `MDQ6VXNlcjM0MDczMDM=` was used in the query, the response will contain the new ID format:\n\n```json\n{\"data\":{\"node\":{\"id\":\"U_kgDOADP9xw\"}}}\n```\n\nWith the `X-Github-Next-Global-ID` header, you can find the new ID format for legacy IDs that you reference in your application. You can then update those references with the ID received in the response. You should update all references to legacy IDs and use the new ID format for any subsequent requests to the API.\nTo perform bulk operations, you can use aliases to submit multiple node queries in one API call. For more information, see \"the GraphQL docs.\"\n\nYou can also get the new ID for a collection of items. For example, if you wanted to get the new ID for the last 10 repositories in your organization, you could use a query like this:\n\n```graphql\n{\n  organization(login: \"github\") {\n    repositories(last: 10) {\n      edges {\n        cursor\n        node {\n          name\n          id\n        }\n      }\n    }\n  }\n}\n```\n\nNote that setting `X-Github-Next-Global-ID` to `1` will affect the return value of every `id` field in your query.  This means that even when you submit a non-`node` query, you will get back the new format ID if you requested the `id` field.\n\n\n\nSharing feedback\n\nIf you have any concerns about the rollout of this change impacting your app, please contact {% data variables.contact.contact_support %} and include information such as your app name so that we can better assist you.\n\n"}, "relevant_docs": {"3795dccd-31df-459d-b5b5-e973c95bf6e1": ["Y2h1bmtfMF9pbmRleF8xMTE="], "9a6a4eb9-d611-457b-acea-a4cfa42122fd": ["Y2h1bmtfMF9pbmRleF8xMTE="], "4446f3cb-3d1b-47ba-8755-2231a520fbb8": ["Y2h1bmtfMV9pbmRleF8xMTE="], "d4371c0e-b278-4581-ad61-9bc503620361": ["Y2h1bmtfMV9pbmRleF8xMTE="], "7aa2820c-c0c3-4733-8e1a-a6ed9f73f60a": ["Y2h1bmtfMl9pbmRleF8xMTE="], "0d285197-6d28-4c10-ad46-13f975d28a65": ["Y2h1bmtfMl9pbmRleF8xMTE="], "31b58890-a132-4b1d-8061-b8eea8243ad3": ["Y2h1bmtfM19pbmRleF8xMTE="], "51fd67cb-203a-430f-9c56-366541fbc7e6": ["Y2h1bmtfM19pbmRleF8xMTE="], "b08ba22d-7cd7-4c5a-990e-434e1965d49c": ["Y2h1bmtfNF9pbmRleF8xMTE="], "042d7e83-8b7c-4903-ab9f-033e22b0d6eb": ["Y2h1bmtfNF9pbmRleF8xMTE="], "4d3c4952-bf65-4b76-9c39-c5cc1051efce": ["Y2h1bmtfMF9pbmRleF8xMjE2"], "31f0b6f4-7a8d-4d8a-8773-887f3f7f00d7": ["Y2h1bmtfMF9pbmRleF8xMjE2"], "2ce1d1ad-e948-49c5-bb4a-27d73eba494b": ["Y2h1bmtfMF9pbmRleF81NzY="], "38aed2b7-0c1b-4190-87c5-e2440c9fe2d7": ["Y2h1bmtfMF9pbmRleF81NzY="], "168d6979-c7db-4951-b83e-84a641cc7de8": ["Y2h1bmtfMF9pbmRleF8xMTk1"], "968af780-9084-4ca9-a87f-7844d8a0ce50": ["Y2h1bmtfMF9pbmRleF8xMTk1"], "4de03c98-7c51-415b-b21d-e9c36245c8d0": ["Y2h1bmtfMV9pbmRleF8xMTk1"], "4b27c1eb-5140-432d-8882-85a0dec3fc35": ["Y2h1bmtfMV9pbmRleF8xMTk1"], "c8c09e0b-7853-4ebc-9142-716b6659bea6": ["Y2h1bmtfMl9pbmRleF8xMTk1"], "75cf5edd-9608-4d43-a3f3-9e5339c036b0": ["Y2h1bmtfMl9pbmRleF8xMTk1"], "936b418e-ccb3-4287-b68c-f0092ccbbe87": ["Y2h1bmtfMl9pbmRleF8xMTk1"], "781f694d-eabc-406b-bf1c-66136f59f510": ["Y2h1bmtfM19pbmRleF8xMTk1"], "17b18d29-6fa4-499c-8017-106dd5d6cc78": ["Y2h1bmtfM19pbmRleF8xMTk1"], "5ec813de-4aab-4f61-9d77-a43967c69f80": ["Y2h1bmtfM19pbmRleF8xMTk1"], "3b5cc1ce-b763-4544-8bba-f63577f62645": ["Y2h1bmtfNF9pbmRleF8xMTk1"], "ea9229a4-cd03-484e-87d0-7fcc64931a81": ["Y2h1bmtfMF9pbmRleF8xOTk4"], "d33c83ef-d852-4a76-9a8c-eaa7e4ece3e4": ["Y2h1bmtfMF9pbmRleF8xOTk4"], "cca463d6-cf74-4a2f-b0be-ee659f90a3f7": ["Y2h1bmtfMV9pbmRleF8xOTk4"], "25c15285-e8ad-494b-9ba6-a0dd00b182d7": ["Y2h1bmtfMV9pbmRleF8xOTk4"], "bede944d-2f2f-49bf-915e-034a5d5df242": ["Y2h1bmtfMl9pbmRleF8xOTk4"], "096a099f-26bc-44d4-83b6-5ff97c20a2f5": ["Y2h1bmtfMl9pbmRleF8xOTk4"], "b5955f9d-3621-4f38-805b-0fe21cb96d7f": ["Y2h1bmtfMl9pbmRleF8xOTk4"], "f85370c7-6d81-4913-84e0-367388fad79b": ["Y2h1bmtfMl9pbmRleF8xOTk4"], "0a9b16c6-c364-4f3a-9c4b-bfcf2db7bfcd": ["Y2h1bmtfMl9pbmRleF8xOTk4"], "39ab23ac-2e6e-41db-bf2c-b19002a3062d": ["Y2h1bmtfMl9pbmRleF8xOTk4"], "9989b8b3-ee2a-4ba6-814b-c66d836e20bd": ["Y2h1bmtfM19pbmRleF8xOTk4"], "e1f4dac1-e5ec-4c57-b4d1-cf330107bb74": ["Y2h1bmtfM19pbmRleF8xOTk4"], "189b5f03-f935-4a01-81b5-e15b20a5ac33": ["Y2h1bmtfM19pbmRleF8xOTk4"], "af98743a-26e8-4d4b-8ccf-e8f5a13dc9d2": ["Y2h1bmtfM19pbmRleF8xOTk4"], "36ecebc9-4eb1-41da-85b0-bf4e57002a0d": ["Y2h1bmtfM19pbmRleF8xOTk4"], "012012ac-ebd4-404a-ab60-1876ab3a33f9": ["Y2h1bmtfM19pbmRleF8xOTk4"], "8c0aab61-edc3-4d06-8f50-691987b2b09f": ["Y2h1bmtfNF9pbmRleF8xOTk4"], "fe24f2d3-2cfc-400e-b505-1b237cb72e4b": ["Y2h1bmtfNF9pbmRleF8xOTk4"], "25adabe5-3b4d-4123-9bd2-1ced796b01d8": ["Y2h1bmtfNV9pbmRleF8xOTk4"], "265d417a-724b-47ce-b191-d69860dabe11": ["Y2h1bmtfNV9pbmRleF8xOTk4"], "763989ed-fa0c-4c47-b4b2-ff5f100e5c50": ["Y2h1bmtfNV9pbmRleF8xOTk4"], "9df9c907-d4b1-4d8d-b8d7-935892004f93": ["Y2h1bmtfNV9pbmRleF8xOTk4"], "3ed8610b-f06e-4de3-a3b0-d51ff16ddee8": ["Y2h1bmtfNV9pbmRleF8xOTk4"], "02c6aeb7-c42a-42ba-ba57-4a1e94b7323f": ["Y2h1bmtfNV9pbmRleF8xOTk4"], "f5630487-8f16-428f-afca-e01f59b94e80": ["Y2h1bmtfNl9pbmRleF8xOTk4"], "7fe69845-dcbc-4150-b639-76254994161b": ["Y2h1bmtfNl9pbmRleF8xOTk4"], "03c3d685-ce17-43a8-bfcf-b3585c7942c5": ["Y2h1bmtfMF9pbmRleF8xNTcw"], "7e63f9b0-6eff-4237-b046-9c7fa39593ca": ["Y2h1bmtfMF9pbmRleF8xNTcw"], "038931a5-b5d8-4e5c-b220-495e417cdc11": ["Y2h1bmtfMV9pbmRleF8xNTcw"], "fbeef5ae-d1e9-453f-a70e-d3c9dc0adbd3": ["Y2h1bmtfMV9pbmRleF8xNTcw"], "281d4a56-7eb5-410d-b8f5-2f7765622d50": ["Y2h1bmtfMF9pbmRleF8xNjcw"], "d67b6659-8793-430c-bb78-07245e9a3f14": ["Y2h1bmtfMF9pbmRleF8xNjcw"], "aa0258f7-0d81-486b-a044-30154e166548": ["Y2h1bmtfMV9pbmRleF8xNjcw"], "53a412da-7cb8-41bf-824c-a8b45dc9ed45": ["Y2h1bmtfMF9pbmRleF8xNDQ1"], "8f53632f-8a7c-4e47-8f1e-1ed440b46c43": ["Y2h1bmtfMF9pbmRleF8xNDQ1"], "ae286b85-d783-44ec-81a1-39f7d186ed3f": ["Y2h1bmtfMV9pbmRleF8xNDQ1"], "27d15d33-0d93-4651-95f1-023016646e3c": ["Y2h1bmtfMl9pbmRleF8xNDQ1"], "d4993b53-88a6-4195-8f35-2bba04d6f897": ["Y2h1bmtfM19pbmRleF8xNDQ1"], "6b06a8a2-3ca7-4ed0-86c6-b23abbcbd343": ["Y2h1bmtfM19pbmRleF8xNDQ1"], "b9a6f237-5fb8-483c-b33d-afec98a26361": ["Y2h1bmtfNF9pbmRleF8xNDQ1"], "0e51aa72-a100-49b7-bd54-2014dacea566": ["Y2h1bmtfNF9pbmRleF8xNDQ1"], "21003e4e-2572-4022-9443-ed96626efac5": ["Y2h1bmtfMF9pbmRleF8xMTY0"], "566dc6cb-ff4b-45f9-afc4-97f623f85d04": ["Y2h1bmtfMF9pbmRleF8xMTY0"], "a24a5baa-2149-4802-be16-fad017cf7fbb": ["Y2h1bmtfMV9pbmRleF8xMTY0"], "3bdba4bf-4c81-4ca9-add5-a10ad31a9fb9": ["Y2h1bmtfMV9pbmRleF8xMTY0"], "e8f49753-149e-4a81-9dcc-ed66cc92ec86": ["Y2h1bmtfMF9pbmRleF8xMjkw"], "6f4cd566-02ba-4549-9c6d-863acaa7e352": ["Y2h1bmtfMF9pbmRleF8xMjkw"], "6cc30976-2a8e-43ce-a041-4ef8a287d52c": ["Y2h1bmtfMF9pbmRleF81NDc="], "aa14b430-ffcf-483d-9f68-89a07b3ec158": ["Y2h1bmtfMF9pbmRleF81NDc="], "215e1edd-30fb-475c-89f9-81276d33d6a2": ["Y2h1bmtfMF9pbmRleF8yMDQ1"], "f21f42d7-14e4-49db-ab38-c767cc15b521": ["Y2h1bmtfMF9pbmRleF8yMDQ1"], "4979c846-e4c3-4f74-b07b-bb8185160165": ["Y2h1bmtfMV9pbmRleF8yMDQ1"], "ebf32bde-56d3-44c6-a1f5-6e09539dcf61": ["Y2h1bmtfMV9pbmRleF8yMDQ1"], "8b93c11f-0c2b-4321-b9fc-1d01042b8765": ["Y2h1bmtfMl9pbmRleF8yMDQ1"], "7ea571da-8f96-4e50-b7de-37dd2fccfd8f": ["Y2h1bmtfMl9pbmRleF8yMDQ1"], "c547be1b-280d-4d13-bc5e-f08219373fa5": ["Y2h1bmtfMl9pbmRleF8yMDQ1"], "ae75f1e3-10bb-412d-b1f3-29a5094ed735": ["Y2h1bmtfMl9pbmRleF8yMDQ1"], "70e2f220-875b-4659-acb0-348180cc7c1c": ["Y2h1bmtfMl9pbmRleF8yMDQ1"], "d7ce84f3-1a5e-4424-825b-be304c308976": ["Y2h1bmtfMl9pbmRleF8yMDQ1"], "c58c3c1b-52fd-4608-ba6c-bfa2d050ee31": ["Y2h1bmtfMl9pbmRleF8yMDQ1"], "e9ba98fd-c156-45c8-acfe-bd158ae2cd6d": ["Y2h1bmtfMl9pbmRleF8yMDQ1"], "869883c5-74da-45a0-af4e-adc91da6ef63": ["Y2h1bmtfMl9pbmRleF8yMDQ1"], "7afd0ce8-d80a-4ba6-b709-00e1f1151742": ["Y2h1bmtfM19pbmRleF8yMDQ1"], "e40cfa50-2265-4e23-8702-f1f3e9d31def": ["Y2h1bmtfM19pbmRleF8yMDQ1"], "7db481e7-48a5-472c-bd4f-2b9c64b3c0e0": ["Y2h1bmtfNF9pbmRleF8yMDQ1"], "8998de0a-8a4d-4768-bb86-cf7613d569da": ["Y2h1bmtfNF9pbmRleF8yMDQ1"], "eaf15b88-32ee-4205-90db-e813890c0e53": ["Y2h1bmtfNV9pbmRleF8yMDQ1"], "cd05cd2b-c37f-4b0d-a7f1-f590818295d8": ["Y2h1bmtfNV9pbmRleF8yMDQ1"], "8ef8715a-e1ff-4351-93c0-1894763fe9a4": ["Y2h1bmtfNl9pbmRleF8yMDQ1"], "e967ea2a-5e6b-4b41-9b78-268502b96952": ["Y2h1bmtfNl9pbmRleF8yMDQ1"], "a64f8ab5-c610-4af0-ad10-94b2eabec440": ["Y2h1bmtfN19pbmRleF8yMDQ1"], "6b568672-02a0-4417-a961-9f10057bf422": ["Y2h1bmtfN19pbmRleF8yMDQ1"], "97c15873-4dd2-4bfb-9f28-c69802180bdf": ["Y2h1bmtfOF9pbmRleF8yMDQ1"], "82f6b589-a76a-4440-8226-ba3391bb66db": ["Y2h1bmtfOF9pbmRleF8yMDQ1"], "8661e043-d8b9-4811-9767-27266034dcb6": ["Y2h1bmtfOV9pbmRleF8yMDQ1"], "71c93889-aac2-485f-9df7-fa381d6ad918": ["Y2h1bmtfOV9pbmRleF8yMDQ1"], "9b06845d-6f5d-4460-9faf-83a7c842a9d4": ["Y2h1bmtfMTBfaW5kZXhfMjA0NQ=="], "ed648c56-a762-4259-898f-b4bf84593d6a": ["Y2h1bmtfMTBfaW5kZXhfMjA0NQ=="], "60881cbc-003d-42f0-b179-5597302ffdf1": ["Y2h1bmtfMTFfaW5kZXhfMjA0NQ=="], "bffeb9e8-1e55-4d3f-a22c-fb03c6f835bc": ["Y2h1bmtfMTFfaW5kZXhfMjA0NQ=="], "dbeecd8e-aed7-4693-b3b9-2360c929e149": ["Y2h1bmtfMTJfaW5kZXhfMjA0NQ=="], "5fcf01d8-e3d8-4820-81a1-574c216ce852": ["Y2h1bmtfMTJfaW5kZXhfMjA0NQ=="], "126895f1-6c10-4780-b683-d2c73a625ed3": ["Y2h1bmtfMTNfaW5kZXhfMjA0NQ=="], "54372bc7-11cf-4942-a818-2511040de884": ["Y2h1bmtfMTNfaW5kZXhfMjA0NQ=="], "ce4ef613-d128-42c6-871c-995080cc7ff7": ["Y2h1bmtfMTNfaW5kZXhfMjA0NQ=="], "1e62745a-a6ee-48b4-8b9b-ddee2d4ea9ba": ["Y2h1bmtfMTNfaW5kZXhfMjA0NQ=="], "d0c142b8-56bb-4126-a4f1-2468943cf733": ["Y2h1bmtfMTNfaW5kZXhfMjA0NQ=="], "743fe597-6a06-4b58-a8f3-4047b4b16d6b": ["Y2h1bmtfMTNfaW5kZXhfMjA0NQ=="], "35abdb45-e167-40eb-90a6-d9ec23de4d2c": ["Y2h1bmtfMTNfaW5kZXhfMjA0NQ=="], "18355108-9e79-40b1-872a-a44cafdaf736": ["Y2h1bmtfMTNfaW5kZXhfMjA0NQ=="], "7e1fa856-d244-4274-8505-7912f1537c5e": ["Y2h1bmtfMTRfaW5kZXhfMjA0NQ=="], "f9f30915-27c5-44d5-b1b0-22a320d5256b": ["Y2h1bmtfMTRfaW5kZXhfMjA0NQ=="], "e7767ee8-7042-4c62-a2cd-8d5def618ecc": ["Y2h1bmtfMTVfaW5kZXhfMjA0NQ=="], "6f57c3c5-6529-4b01-9ee4-7eb206700ddf": ["Y2h1bmtfMTVfaW5kZXhfMjA0NQ=="], "d52fa565-e619-4d23-bb6a-a5d2786d6ffc": ["Y2h1bmtfMTZfaW5kZXhfMjA0NQ=="], "4b221c35-fe5e-4fc4-bcd9-087ae7a30886": ["Y2h1bmtfMTZfaW5kZXhfMjA0NQ=="], "794f0f59-4bec-4860-bc57-905e4d8614e8": ["Y2h1bmtfMTdfaW5kZXhfMjA0NQ=="], "9f769fcd-fb2c-4122-ad06-ff386d9ce3b4": ["Y2h1bmtfMTdfaW5kZXhfMjA0NQ=="], "6c686d32-8af1-4266-9cdf-e3d66f409599": ["Y2h1bmtfMThfaW5kZXhfMjA0NQ=="], "3b4c7738-be01-4eba-b69a-afba6731d64f": ["Y2h1bmtfMThfaW5kZXhfMjA0NQ=="], "df3eab25-5aa4-467a-af4f-47311cc02958": ["Y2h1bmtfMTlfaW5kZXhfMjA0NQ=="], "59c7e9e6-330b-46cc-9bd7-eb13bc283e98": ["Y2h1bmtfMTlfaW5kZXhfMjA0NQ=="], "833fcb1a-df00-46c7-a7b0-a7db89ceef71": ["Y2h1bmtfMjBfaW5kZXhfMjA0NQ=="], "a496e337-1c89-4bcb-ba84-7c047e64103f": ["Y2h1bmtfMjBfaW5kZXhfMjA0NQ=="], "fffd81a4-986a-44ce-bdef-84ebdd5bc958": ["Y2h1bmtfMjFfaW5kZXhfMjA0NQ=="], "fcb646a4-2d78-4e35-b63a-b56f08f18f08": ["Y2h1bmtfMjFfaW5kZXhfMjA0NQ=="], "1259a347-3c12-4488-8ef8-0001c74ff2b5": ["Y2h1bmtfMF9pbmRleF82ODc="], "36960760-6a7e-4c0f-8c30-8c4667dc3f02": ["Y2h1bmtfMF9pbmRleF82ODc="], "5e921dc2-33b6-4424-a48d-4923d813aeaa": ["Y2h1bmtfMV9pbmRleF82ODc="], "dcce15b5-6d56-469f-8bf2-7ff4bf7426fb": ["Y2h1bmtfMl9pbmRleF82ODc="], "597c9b23-3944-4782-8a13-199184d61157": ["Y2h1bmtfMl9pbmRleF82ODc="], "11972cee-325f-4c1f-87ed-9d0315342940": ["Y2h1bmtfMl9pbmRleF82ODc="], "9ba5cf0a-fc97-49d0-bd3c-3d226ff2e439": ["Y2h1bmtfMl9pbmRleF82ODc="], "985a63de-083d-48a7-b98b-96ae95994271": ["Y2h1bmtfMl9pbmRleF82ODc="], "efe4aabb-5ae7-40f3-a87c-ca2302a40cc8": ["Y2h1bmtfMl9pbmRleF82ODc="], "0ee1175a-7ac0-44b9-8143-a94be874548c": ["Y2h1bmtfMl9pbmRleF82ODc="], "66a3143b-4be7-4567-bce5-505dc629c29b": ["Y2h1bmtfMF9pbmRleF8xODA4"], "3f91714e-5951-43b2-bf0f-dd6670369b27": ["Y2h1bmtfMF9pbmRleF8xODA4"], "f1021040-9f09-48f9-8e93-6445c37c74e5": ["Y2h1bmtfMF9pbmRleF8xNDY0"], "19840194-b0a4-4021-b488-280a8f500c5f": ["Y2h1bmtfMV9pbmRleF8xNDY0"], "8c6435d1-7bfb-478c-9980-38272af2913e": ["Y2h1bmtfMV9pbmRleF8xNDY0"], "964380ae-b9f3-40a4-a6d4-11a9187418db": ["Y2h1bmtfMV9pbmRleF8xNDY0"], "31ba7089-8ca2-4069-b996-f221fee96d4f": ["Y2h1bmtfMl9pbmRleF8xNDY0"], "be6957bf-1d6e-43b3-b9f2-d46e3846b492": ["Y2h1bmtfMl9pbmRleF8xNDY0"], "991c335b-a663-4a4d-b5e9-7f999c77d4f8": ["Y2h1bmtfM19pbmRleF8xNDY0"], "d0312d81-93e3-4dbc-8be0-76ef6597810c": ["Y2h1bmtfNF9pbmRleF8xNDY0"], "0724232f-8f19-4005-ac0e-912fec8e4077": ["Y2h1bmtfNF9pbmRleF8xNDY0"], "147c5e13-14ed-40bd-b80b-6bb7d42f64e9": ["Y2h1bmtfNV9pbmRleF8xNDY0"], "8a005d7e-f84a-4a76-baaf-0c87f250a608": ["Y2h1bmtfNV9pbmRleF8xNDY0"], "cfd860dc-f399-4212-9727-34bd535dab37": ["Y2h1bmtfNV9pbmRleF8xNDY0"], "80eb1d9c-a24a-432f-aa16-96852bb85001": ["Y2h1bmtfNl9pbmRleF8xNDY0"], "b8c0af07-e1f2-49a7-a6d5-9f8816c1d379": ["Y2h1bmtfNl9pbmRleF8xNDY0"], "b6432350-03b2-4f4f-8664-098d526ba9ef": ["Y2h1bmtfN19pbmRleF8xNDY0"], "e97ee951-5bbb-4e55-9c50-fb923599315d": ["Y2h1bmtfN19pbmRleF8xNDY0"], "8ae42f30-f140-4e04-be66-b8826c225502": ["Y2h1bmtfN19pbmRleF8xNDY0"], "2a851ec5-9186-4a78-8c55-c961580c9d81": ["Y2h1bmtfN19pbmRleF8xNDY0"], "5b9c7d70-05fa-4fdb-9df7-032eba4903af": ["Y2h1bmtfN19pbmRleF8xNDY0"], "1a874eec-02f4-4f35-b644-237830f9a3bf": ["Y2h1bmtfOF9pbmRleF8xNDY0"], "2354bc37-1703-4ad1-95c6-20a3e9ff01dc": ["Y2h1bmtfOV9pbmRleF8xNDY0"], "962a4e56-5ec5-4385-a691-69663ad08ba9": ["Y2h1bmtfOV9pbmRleF8xNDY0"], "1429cd83-6032-4ae7-9b31-39a4fc6bd2ac": ["Y2h1bmtfMTBfaW5kZXhfMTQ2NA=="], "d983ebb3-8e7c-4132-bf0a-17ad135454a8": ["Y2h1bmtfMTBfaW5kZXhfMTQ2NA=="], "9f2a2e07-c1e9-4068-9cca-3c202da04661": ["Y2h1bmtfMF9pbmRleF8zMjI="], "d31864f9-50f6-4f41-99f1-4a780cdae8ec": ["Y2h1bmtfMF9pbmRleF8zMjI="], "207ea5b0-9f3f-4ac2-8dba-ca62fdd9aa3a": ["Y2h1bmtfMV9pbmRleF8zMjI="], "2b1c8882-8aca-4e36-b592-3f37e20142ff": ["Y2h1bmtfMV9pbmRleF8zMjI="], "5aa7e3bf-51dd-40f2-8a7c-46aa96c07b06": ["Y2h1bmtfMF9pbmRleF8xMDQ3"], "908ad735-f0ce-4818-a088-c01cfdc854c5": ["Y2h1bmtfMF9pbmRleF8zNDE="], "93ad04ec-f8ba-4813-87fd-861d3942cad8": ["Y2h1bmtfMF9pbmRleF8zNDE="], "ac9b11c5-27b5-4981-ba74-d3b2e76889ea": ["Y2h1bmtfMV9pbmRleF8zNDE="], "c6b4810e-a4ed-49ea-a843-90ef0fc5f1d1": ["Y2h1bmtfMV9pbmRleF8zNDE="], "e7e55070-cc2e-4da6-a299-d1554fbecfcb": ["Y2h1bmtfMl9pbmRleF8zNDE="], "62ecd1ea-68a1-40d4-a1f6-b09a8a548482": ["Y2h1bmtfMl9pbmRleF8zNDE="], "a03953a3-7eb3-4e17-bc63-f1ccf48d0258": ["Y2h1bmtfMF9pbmRleF81NzU="], "ea92213d-a064-43b0-a8fc-a5173fe25279": ["Y2h1bmtfMF9pbmRleF81NzU="], "dd0105ac-f8b9-44ed-90a7-1ac4cb3c8bbd": ["Y2h1bmtfMF9pbmRleF8xMTY1"], "bc504b10-1e3c-4700-b52f-bca173a89ada": ["Y2h1bmtfMF9pbmRleF8xMTY1"], "3ffea2fb-6531-4b29-9fa3-77acd75cc67f": ["Y2h1bmtfMF9pbmRleF8xMzcx"], "6f73444f-ecf2-4fb7-9782-da12b3601874": ["Y2h1bmtfMF9pbmRleF8xMzcx"], "876b46e8-8640-4959-92f4-fb19c9e1fa9a": ["Y2h1bmtfMF9pbmRleF8xMzcx"], "c19ba626-cbd0-4f85-bee9-ce4468131c94": ["Y2h1bmtfMV9pbmRleF8xMzcx"], "048ee128-eb97-4476-9355-b942adc919e6": ["Y2h1bmtfMF9pbmRleF8xNDQy"], "91a434e6-f117-4511-a9a1-eddc18a934aa": ["Y2h1bmtfMF9pbmRleF8xNDQy"], "8ea65279-6c90-4628-bdfc-9ce0f8d14d23": ["Y2h1bmtfMF9pbmRleF8xNDQy"], "92acb9bf-f070-490c-9a3a-82f1a5ca7c24": ["Y2h1bmtfMF9pbmRleF8xNDQy"], "eddcdf02-4593-4c69-a2be-7e3f14549537": ["Y2h1bmtfMF9pbmRleF8xNDQy"], "61fb8f2c-9965-40de-9e1d-69936369b4b6": ["Y2h1bmtfMF9pbmRleF8xNDQy"], "c4a09615-1edd-445d-a46d-2f9b740b7f3f": ["Y2h1bmtfMF9pbmRleF8xNDQy"], "0914003d-9e67-40ce-8fb0-036d3b07197b": ["Y2h1bmtfMV9pbmRleF8xNDQy"], "1bf3082e-0956-47f7-8835-b6e2c18af404": ["Y2h1bmtfMV9pbmRleF8xNDQy"], "b4f8cb26-c1b4-4781-982e-fdf361086a15": ["Y2h1bmtfMF9pbmRleF81MjE="], "fc415d2f-ec4f-4936-a390-79b5f1b512dd": ["Y2h1bmtfMF9pbmRleF81MjE="], "32f34f8c-5ed3-4f12-bd12-70d1cd81e48a": ["Y2h1bmtfMF9pbmRleF85NjI="], "cfdcb39f-fef6-4454-b2e2-8295724efc82": ["Y2h1bmtfMF9pbmRleF85NjI="], "98c4e172-ea36-4800-84fa-7cd95e41695a": ["Y2h1bmtfMV9pbmRleF85NjI="], "6e1efb55-103a-49b2-bbce-8cd3121d175c": ["Y2h1bmtfMV9pbmRleF85NjI="], "857977a0-e288-4c76-900c-4fd4c8b92096": ["Y2h1bmtfMV9pbmRleF85NjI="], "b1f00039-b5f5-4e46-93f2-60eadc5f6e61": ["Y2h1bmtfMF9pbmRleF8zNzk="], "71a4a5b0-10dc-444c-8275-7daf692db468": ["Y2h1bmtfMF9pbmRleF8zNzk="], "2333df2e-14ac-4df2-a3a0-0cc92bd54f2c": ["Y2h1bmtfMV9pbmRleF8zNzk="], "2390bb9c-f7a3-4cdf-b8a4-46569ffb6cc3": ["Y2h1bmtfMV9pbmRleF8zNzk="], "e5800d2f-8f28-43c9-8fb8-27010616842a": ["Y2h1bmtfMV9pbmRleF8zNzk="], "129b6dac-2a84-49f7-a310-1bb7629542da": ["Y2h1bmtfMF9pbmRleF83MTM="], "f4a96181-7546-4ebd-a30d-283098b03c12": ["Y2h1bmtfMF9pbmRleF83MTM="], "234f6e64-ff83-4627-b6e5-bb1fa7a76c9b": ["Y2h1bmtfMF9pbmRleF8xNTY="], "85f38347-bf81-4f2f-a1d9-7ddcf59bac89": ["Y2h1bmtfMF9pbmRleF8xNTY="], "8876c0bd-a51f-46f6-972a-b191e81768c8": ["Y2h1bmtfMV9pbmRleF8xNTY="], "5f9903f7-b48a-4b66-b0cb-3aace371377c": ["Y2h1bmtfMV9pbmRleF8xNTY="], "3557ffb5-ac6a-41a3-9137-0aafa3d33c28": ["Y2h1bmtfMl9pbmRleF8xNTY="], "9ed4c465-2f17-4a2d-9793-fbcccd706edd": ["Y2h1bmtfM19pbmRleF8xNTY="], "0881b09c-8793-442a-81fb-3bceb698527f": ["Y2h1bmtfNF9pbmRleF8xNTY="], "e64928d9-aa08-4cca-a28a-d9c5022a458f": ["Y2h1bmtfNF9pbmRleF8xNTY="], "394d3c8a-7e50-4a2f-a100-507eda75e4e5": ["Y2h1bmtfNV9pbmRleF8xNTY="], "1789a17d-8a76-41a8-9bfe-0d8919e19546": ["Y2h1bmtfNl9pbmRleF8xNTY="], "2dda4761-0d67-4123-8d17-9eb4d7e815ef": ["Y2h1bmtfNl9pbmRleF8xNTY="], "d798efbb-94dd-461e-b6d3-1b85bc7cdfdf": ["Y2h1bmtfN19pbmRleF8xNTY="], "95899542-e22d-40f8-a41b-d12c3d2ecdb2": ["Y2h1bmtfN19pbmRleF8xNTY="], "0dbd519b-d70f-49f8-9e4f-0fd049125d17": ["Y2h1bmtfOF9pbmRleF8xNTY="], "fcacf02d-cc43-4db7-aba6-d35525e10e9b": ["Y2h1bmtfOV9pbmRleF8xNTY="], "bc71ccdc-4a8c-4f67-8f38-d6c806572e3a": ["Y2h1bmtfMTBfaW5kZXhfMTU2"], "241730a7-0c57-45f1-8e87-f082736d983f": ["Y2h1bmtfMTBfaW5kZXhfMTU2"], "e3b2b6a1-0ae1-4ffe-a3fb-c8745117c1c0": ["Y2h1bmtfMTBfaW5kZXhfMTU2"], "84b571fb-7875-4e2c-bf9e-c7c3cdc8b0f5": ["Y2h1bmtfMTBfaW5kZXhfMTU2"], "80c84133-50cc-4c7d-ab6d-dc5b65c3d682": ["Y2h1bmtfMTBfaW5kZXhfMTU2"], "4f846240-27a0-4880-9267-297233ea82ac": ["Y2h1bmtfMTBfaW5kZXhfMTU2"], "94906a11-97a3-45bb-ad0c-8864eb5c475c": ["Y2h1bmtfMTBfaW5kZXhfMTU2"], "96e26d91-9e0b-4dcc-8fb0-3a23930e02dd": ["Y2h1bmtfMTBfaW5kZXhfMTU2"], "5e60e3fd-00e3-4e00-b492-de9a1abae6b2": ["Y2h1bmtfMTBfaW5kZXhfMTU2"], "14662ddc-402e-448d-9435-f681b5b73513": ["Y2h1bmtfMTFfaW5kZXhfMTU2"], "5ba3579a-b86a-43ad-a9a7-e2bd20132008": ["Y2h1bmtfMTFfaW5kZXhfMTU2"], "591168f6-74ca-461f-96e7-49c47e15f53a": ["Y2h1bmtfMTFfaW5kZXhfMTU2"], "b5516460-ac85-4d6f-a597-58b22e9bf59f": ["Y2h1bmtfMTFfaW5kZXhfMTU2"], "eb9dc6c9-fff9-4a38-adf5-bbbb04e62502": ["Y2h1bmtfMTFfaW5kZXhfMTU2"], "ad10e018-360a-4a72-ac8a-2a5921a573f8": ["Y2h1bmtfMTFfaW5kZXhfMTU2"], "9724bfd3-5108-4209-9b17-cbbac3c248d3": ["Y2h1bmtfMTFfaW5kZXhfMTU2"], "c11c35b3-501d-47a0-b2d1-81bd078ea458": ["Y2h1bmtfMTJfaW5kZXhfMTU2"], "d7334f78-93c7-40ed-ac84-8210b1911f1a": ["Y2h1bmtfMTJfaW5kZXhfMTU2"], "cfdda304-29e3-4519-864d-e7c9a33ce3c8": ["Y2h1bmtfMTJfaW5kZXhfMTU2"], "9d60d360-c86d-4e4f-adff-e124c2abb131": ["Y2h1bmtfMTJfaW5kZXhfMTU2"], "3e62af24-15a7-4676-a591-513573182298": ["Y2h1bmtfMTJfaW5kZXhfMTU2"], "a328ea2e-9431-4fd3-96e2-eeb793cf249b": ["Y2h1bmtfMTJfaW5kZXhfMTU2"], "0cdca6d7-7760-4885-a5d4-371ebcffa61d": ["Y2h1bmtfMTJfaW5kZXhfMTU2"], "ad1b5766-a46e-4253-88ab-e7582032e78c": ["Y2h1bmtfMTNfaW5kZXhfMTU2"], "2a790e1f-4510-45e6-92e6-949ad5b6739c": ["Y2h1bmtfMTNfaW5kZXhfMTU2"], "c48dd822-842c-4915-9b2b-7994792fa95c": ["Y2h1bmtfMTRfaW5kZXhfMTU2"], "4bb9d619-283c-413a-8e64-e87a49379de1": ["Y2h1bmtfMTRfaW5kZXhfMTU2"], "8fad05ae-af41-4bf9-8f36-5f29ea5ddf3e": ["Y2h1bmtfMTVfaW5kZXhfMTU2"], "c1b6a317-8b88-4a5f-8705-5a398e903540": ["Y2h1bmtfMTZfaW5kZXhfMTU2"], "7c6d6c35-3230-45bc-a818-a3f43b2b9630": ["Y2h1bmtfMTZfaW5kZXhfMTU2"], "7a5dc99f-4ac6-4f80-9b3f-258ab2c3cd7f": ["Y2h1bmtfMF9pbmRleF85Njk="], "3cdfe45d-e142-4ab5-b35b-605d22b2e8ed": ["Y2h1bmtfMF9pbmRleF85Njk="], "aa421ab0-02cf-47ec-87a5-10976b6263cf": ["Y2h1bmtfMV9pbmRleF85Njk="], "51e2d8d1-2a54-45ca-ba3d-aaa3a124637e": ["Y2h1bmtfMl9pbmRleF85Njk="], "a735bbc6-da5c-437d-b892-08d9c4a1e26f": ["Y2h1bmtfMF9pbmRleF81"], "480a0ff3-8f25-4d2c-8b1c-6f0c5fc824ef": ["Y2h1bmtfMF9pbmRleF81"], "da270634-d7bd-409f-afab-97e4de870862": ["Y2h1bmtfMV9pbmRleF81"], "368f41c5-945d-4f6d-96df-04cf2eacc222": ["Y2h1bmtfMV9pbmRleF81"], "83bbb441-525e-4f9e-9ea2-d2bcf14a81b8": ["Y2h1bmtfMl9pbmRleF81"], "3656b243-3483-4961-8ce6-c56f32f5d8e8": ["Y2h1bmtfMl9pbmRleF81"], "f6a03b3f-464a-42e4-bb24-8392d38112aa": ["Y2h1bmtfM19pbmRleF81"], "0a0b6a8a-db4e-43fe-b7f7-65474e1af818": ["Y2h1bmtfNF9pbmRleF81"], "a46bf655-6ef2-4da5-a467-07780100826e": ["Y2h1bmtfMF9pbmRleF8xMDc4"], "0a7164b8-99d6-4742-8479-f271c1e92be5": ["Y2h1bmtfMF9pbmRleF8xMDc4"], "a82b7d45-2145-45a4-8409-1c05974fe9bd": ["Y2h1bmtfMF9pbmRleF85MjA="], "55c6c7c6-6ffc-4eea-b4ee-3383b3341d13": ["Y2h1bmtfMF9pbmRleF85MjA="], "adf81fd0-e5ed-49b8-9064-3578d2dd2749": ["Y2h1bmtfMV9pbmRleF85MjA="], "a38f0f47-903d-4b94-93b5-16ce9cb3e6c2": ["Y2h1bmtfMV9pbmRleF85MjA="], "ba835943-93ad-4ef5-8775-0653a2319470": ["Y2h1bmtfMF9pbmRleF8zMTc="], "a68d84af-2bb2-4d4a-9986-61f674fa1d8c": ["Y2h1bmtfMF9pbmRleF8zMTc="], "c072c923-5f22-42a1-9697-1d098b88e87e": ["Y2h1bmtfMV9pbmRleF8zMTc="], "a3877f1c-6b33-4c36-94a7-0b8393473a04": ["Y2h1bmtfMV9pbmRleF8zMTc="], "911ffa4a-c461-4d5f-a012-60adde57fec7": ["Y2h1bmtfMl9pbmRleF8zMTc="], "86131ab7-4e4d-472f-94e5-b18e236bce53": ["Y2h1bmtfMl9pbmRleF8zMTc="], "84fd8762-b38b-4aaf-b376-72062fb72d59": ["Y2h1bmtfMF9pbmRleF83NzU="], "91ba5e8f-2463-4e46-8d38-a27ca21ac3de": ["Y2h1bmtfMF9pbmRleF83NzU="], "f9bd2b97-68a4-4086-a367-31f373c207cf": ["Y2h1bmtfMV9pbmRleF83NzU="], "656d9d30-50b7-4727-a470-b609bd12f91c": ["Y2h1bmtfMV9pbmRleF83NzU="], "aaae1eb3-72d6-4336-b637-e7ec0158b43a": ["Y2h1bmtfMV9pbmRleF83NzU="], "163ba60e-1cbd-48a5-9db5-2af1c9d6cb11": ["Y2h1bmtfMV9pbmRleF83NzU="], "d55373f4-2fd9-41a6-8092-cc864f422176": ["Y2h1bmtfMV9pbmRleF83NzU="], "658cd461-b043-483e-8f93-5f29c998810d": ["Y2h1bmtfMV9pbmRleF83NzU="], "a8bf60b0-30ae-44ab-bca6-4b9025de6be5": ["Y2h1bmtfMV9pbmRleF83NzU="], "27066e06-5ca2-4fbd-940e-0df3b49a56a6": ["Y2h1bmtfMl9pbmRleF83NzU="], "7451df49-fd14-42e6-872b-033a6c9fda14": ["Y2h1bmtfMl9pbmRleF83NzU="], "11e59961-6ac6-4e7d-a981-f2f4a9b046cf": ["Y2h1bmtfM19pbmRleF83NzU="], "e916bc8f-f37f-4d06-90c2-2a9c2e3ba6d2": ["Y2h1bmtfMF9pbmRleF83OTY="], "ecf62351-d825-41d0-a68d-88f088947d93": ["Y2h1bmtfMF9pbmRleF83OTY="], "f24ba73e-0eb9-45ff-9741-b10bf5109481": ["Y2h1bmtfMV9pbmRleF83OTY="], "2baf3ceb-65f7-4e0d-9cfc-40ba089ddc72": ["Y2h1bmtfMV9pbmRleF83OTY="], "f1131ece-05bc-43ba-8ef6-34c59ddcf734": ["Y2h1bmtfMF9pbmRleF8yMDY3"], "08ac9f11-c879-4d80-92b2-072248fc9281": ["Y2h1bmtfMF9pbmRleF8yMDY3"], "070f045f-ead2-47f5-9bd3-cc8a6b442c33": ["Y2h1bmtfMV9pbmRleF8yMDY3"], "cc89112d-09eb-49a7-89c2-d31f4743a373": ["Y2h1bmtfMV9pbmRleF8yMDY3"], "7c4f3b1a-aa47-462b-a5fb-752db63a699a": ["Y2h1bmtfMF9pbmRleF8xODA5"], "0df5edae-6df1-4ca5-b7ce-456741d6e930": ["Y2h1bmtfMF9pbmRleF8xODA5"], "4a7a6eb7-3647-4e55-b60c-bd2dab6ee57d": ["Y2h1bmtfMV9pbmRleF8xODA5"], "1852f3b9-062c-49b1-a391-a7e9c9d56bd5": ["Y2h1bmtfMV9pbmRleF8xODA5"], "d4de70b5-ad4a-423b-8454-d5b5409606da": ["Y2h1bmtfMl9pbmRleF8xODA5"], "f1d61f28-dedc-4c67-8d92-d8d4c546a925": ["Y2h1bmtfMl9pbmRleF8xODA5"], "07fc25e0-e418-4737-9fad-23d2cb4897af": ["Y2h1bmtfM19pbmRleF8xODA5"], "f7559c41-22ab-4fe6-b946-bb3dc416a232": ["Y2h1bmtfNF9pbmRleF8xODA5"], "0c5dd6bc-4564-4585-b2cf-ace6e2d7627e": ["Y2h1bmtfNF9pbmRleF8xODA5"], "64fb45c2-8a04-4107-a120-6de68fd76b59": ["Y2h1bmtfNF9pbmRleF8xODA5"], "b8e12ef6-39d9-4638-9fc8-9f3293f8d149": ["Y2h1bmtfMF9pbmRleF8xNzQw"], "20aace18-3db0-4fe3-bdc6-bb0dc5fd1f44": ["Y2h1bmtfMF9pbmRleF8xNzQw"], "ca930e33-c28f-420a-9130-72d4d2c69118": ["Y2h1bmtfMV9pbmRleF8xNzQw"], "6fac88e8-31cb-4011-8b84-a1de7cdd9143": ["Y2h1bmtfMV9pbmRleF8xNzQw"], "6a79d9d2-65a0-4a77-92a1-c40b4dbe783d": ["Y2h1bmtfMl9pbmRleF8xNzQw"], "c92f7ab0-de6a-4a93-ba1e-d0dfacea899a": ["Y2h1bmtfMF9pbmRleF8xMTMx"], "81b1b985-6f97-4719-b30f-25695726eeb8": ["Y2h1bmtfMF9pbmRleF8xMTMx"], "b4070f5c-f206-426c-8df2-05d1a54ff388": ["Y2h1bmtfMF9pbmRleF8xMjU0"], "bfadf92c-8f1c-4fce-9c29-8062be326e9e": ["Y2h1bmtfMF9pbmRleF8xMjU0"], "dec89447-1ad6-43a6-ae8b-fb4027d20dee": ["Y2h1bmtfMV9pbmRleF8xMjU0"], "a7aa72e1-9ea0-4445-b0bc-be55b343ca07": ["Y2h1bmtfMV9pbmRleF8xMjU0"], "6b7fb645-5c27-4e55-948e-6fd5d11cbc27": ["Y2h1bmtfMl9pbmRleF8xMjU0"], "f76c543a-fa86-414e-a3e0-1cb5a41b655e": ["Y2h1bmtfMl9pbmRleF8xMjU0"], "2fe9acc6-19dc-4141-9f5e-a8b975b1fd91": ["Y2h1bmtfMF9pbmRleF8zOTM="], "296f7d54-5417-4bbf-a342-a608671292a4": ["Y2h1bmtfMF9pbmRleF8zOTM="], "48158619-746b-4df5-9fb4-55335765faed": ["Y2h1bmtfMF9pbmRleF8xMDg0"], "00abf7d0-bca9-432f-a78b-06a01024d10c": ["Y2h1bmtfMF9pbmRleF8xMDg0"], "26d0efb5-a694-4189-80ac-e4b4e3241372": ["Y2h1bmtfMF9pbmRleF84NDg="], "b6d48f3b-f37a-4b02-bb99-6c5f15441d2a": ["Y2h1bmtfMF9pbmRleF84NDg="], "acb9d05c-b505-45eb-8b24-9d71a706d841": ["Y2h1bmtfMV9pbmRleF84NDg="], "636a61dd-c5cb-4151-b67e-763163c83cfa": ["Y2h1bmtfMV9pbmRleF84NDg="], "5a665ab7-180f-4dab-ba65-1532fefb2b84": ["Y2h1bmtfMV9pbmRleF84NDg="], "53ec8391-ad00-4e70-8f2e-2877a8d28490": ["Y2h1bmtfMV9pbmRleF84NDg="], "4683747b-9870-49d8-95b9-b046c9e26ff1": ["Y2h1bmtfMV9pbmRleF84NDg="], "618ff66f-9b10-47cc-931b-f102ceb580fb": ["Y2h1bmtfMV9pbmRleF84NDg="], "833d5881-df29-47b6-b9b5-3c572a407bb3": ["Y2h1bmtfMV9pbmRleF84NDg="], "72cb9e68-cd17-4917-b86e-2f637e141e58": ["Y2h1bmtfMF9pbmRleF8yMTM2"], "951aa4f9-3d5e-4f0c-80df-980ae1047e46": ["Y2h1bmtfMF9pbmRleF8yMTM2"], "20eef707-f5fd-4a8d-849f-8d7a4ef005ab": ["Y2h1bmtfMF9pbmRleF8yMTM2"], "8c50a100-6226-4f04-bcc8-e0fdcab12916": ["Y2h1bmtfMF9pbmRleF8yMTM2"], "06732a9f-08a4-4b73-a132-b7d9bb818729": ["Y2h1bmtfMF9pbmRleF8yMTM2"], "4d8cc68a-d392-448d-bbf8-7ca8ae23018a": ["Y2h1bmtfMF9pbmRleF8yMTM2"], "4c078178-0149-4a15-8f2b-65b5c59345ca": ["Y2h1bmtfMF9pbmRleF8yMTM2"], "146af2d4-ec5e-4524-bf21-b7fbd17209c4": ["Y2h1bmtfMV9pbmRleF8yMTM2"], "d11c036b-6eb1-48c4-a2bb-c908b0745f1d": ["Y2h1bmtfMV9pbmRleF8yMTM2"], "dbdb68d0-282e-47d7-83c0-ee1f62d643e2": ["Y2h1bmtfMl9pbmRleF8yMTM2"], "bb2fdab6-597a-476b-896a-9c89f56fcaeb": ["Y2h1bmtfMl9pbmRleF8yMTM2"], "3d2619d5-4d80-4e8b-b273-22e7f12d7ed4": ["Y2h1bmtfMl9pbmRleF8yMTM2"], "90b0350b-dea2-44cc-b467-6e89314bf5ed": ["Y2h1bmtfMl9pbmRleF8yMTM2"], "2b4f213e-268a-4e52-b593-8620bf4c8dbd": ["Y2h1bmtfMl9pbmRleF8yMTM2"], "369f2799-ac97-4ca7-8a44-408e94683924": ["Y2h1bmtfMl9pbmRleF8yMTM2"], "ff5e9722-09aa-4760-8b80-04cd50144b00": ["Y2h1bmtfMl9pbmRleF8yMTM2"], "b5c78a9c-4a63-4871-8f92-d4fad9e1064e": ["Y2h1bmtfMl9pbmRleF8yMTM2"], "88431ba2-ed5d-4601-af7c-d4fa87d8ed10": ["Y2h1bmtfM19pbmRleF8yMTM2"], "fa68bb61-690f-4bbc-88c1-4ed5a3d9ea02": ["Y2h1bmtfNF9pbmRleF8yMTM2"], "09df19ec-8749-402c-af56-1fc4b325632d": ["Y2h1bmtfNF9pbmRleF8yMTM2"], "e7568f0c-0c76-4a3c-89fd-3a5464e81a26": ["Y2h1bmtfNV9pbmRleF8yMTM2"], "907ba5c8-d938-4528-acab-59975ee3e938": ["Y2h1bmtfNV9pbmRleF8yMTM2"], "2d4d8f39-9b00-4e18-a1ed-2a52669d9cc5": ["Y2h1bmtfNl9pbmRleF8yMTM2"], "412c39ba-2ec9-4615-a5e2-ed133b8f0022": ["Y2h1bmtfNl9pbmRleF8yMTM2"], "91b68bd9-c861-4ae8-bdaa-6555c233666b": ["Y2h1bmtfN19pbmRleF8yMTM2"], "c939a6ca-4555-4ff0-ab1d-01b01d8cd5bf": ["Y2h1bmtfOF9pbmRleF8yMTM2"], "091196ab-86cf-40de-a966-c517d720c70c": ["Y2h1bmtfOF9pbmRleF8yMTM2"], "acab5070-e860-4051-ade7-6f65e101aca0": ["Y2h1bmtfOF9pbmRleF8yMTM2"], "19ca804b-5ae9-4b30-b564-152ad56892f5": ["Y2h1bmtfOF9pbmRleF8yMTM2"], "ae39d7b6-cebc-48e2-942e-b4a3b3f1621a": ["Y2h1bmtfOF9pbmRleF8yMTM2"], "9d94d1db-f282-4de0-ba7d-98a8f5166313": ["Y2h1bmtfOF9pbmRleF8yMTM2"], "ac6a1c8c-b2e4-46ad-a38d-b7f8335e8d92": ["Y2h1bmtfMF9pbmRleF8yODI="], "a22abb0c-5b57-49f8-b2a1-559c1427a190": ["Y2h1bmtfMF9pbmRleF8yODI="], "3f116e17-f4a0-41a4-93b2-ba1016a69de1": ["Y2h1bmtfMF9pbmRleF8yODI="], "f11bca17-a615-4926-bb23-29b4dadbc234": ["Y2h1bmtfMF9pbmRleF8yODI="], "769f7a0f-f3ce-4387-a885-e9090da0f981": ["Y2h1bmtfMF9pbmRleF8yODI="], "238208d3-8be5-4510-88e0-ead611cf0fb3": ["Y2h1bmtfMV9pbmRleF8yODI="], "304c4902-bb4b-41c8-8a04-0f8de93a8f2d": ["Y2h1bmtfMV9pbmRleF8yODI="], "0afbff49-ac31-4fef-b1cd-be086348ffba": ["Y2h1bmtfMV9pbmRleF8yODI="], "c9612c92-6e07-4b13-b1cc-d62d40ed9c43": ["Y2h1bmtfMl9pbmRleF8yODI="], "2409d932-fc5c-47df-85d6-85f3660079af": ["Y2h1bmtfMl9pbmRleF8yODI="], "b1bb12a0-fc19-4e45-8bd5-6d85125db556": ["Y2h1bmtfM19pbmRleF8yODI="], "8037b044-3c15-4d57-b9eb-416154be63fa": ["Y2h1bmtfM19pbmRleF8yODI="], "06f2334e-ca08-4ff7-a79e-37c52db0369e": ["Y2h1bmtfNF9pbmRleF8yODI="], "9accfe1f-6bba-4811-85ab-5ba05843ba78": ["Y2h1bmtfNF9pbmRleF8yODI="], "94d7a162-9ee2-456a-8349-e0d0a0983437": ["Y2h1bmtfNF9pbmRleF8yODI="], "d7a0d485-3981-4131-8a3f-b6b36aedc865": ["Y2h1bmtfNF9pbmRleF8yODI="], "d85bb2e7-88b9-48c3-94a1-ce4875e37a4c": ["Y2h1bmtfNV9pbmRleF8yODI="], "d205f685-4ebe-48fd-8e9e-6a29111c4447": ["Y2h1bmtfNV9pbmRleF8yODI="], "55c5b9cb-0636-4227-af9c-d8dbd7a956f4": ["Y2h1bmtfMF9pbmRleF80MjE="], "d227bb2a-b394-42e2-94aa-ab7e7ceb20d5": ["Y2h1bmtfMF9pbmRleF80MjE="], "83aeb3f4-22cb-4532-a3ef-a3d8ac3665ce": ["Y2h1bmtfMF9pbmRleF80MjE="], "c5169601-97c2-4d99-be0b-4c0d171168d1": ["Y2h1bmtfMF9pbmRleF80MjE="], "3c6d350e-4701-4e45-8a6e-076ce03410a9": ["Y2h1bmtfMF9pbmRleF80MjE="], "595d0f17-3a7b-477d-8666-70ecadf64386": ["Y2h1bmtfMV9pbmRleF80MjE="], "a05fe25e-26c1-4e92-9906-6b29edf5a53e": ["Y2h1bmtfMl9pbmRleF80MjE="], "3a710ffd-dee1-4a2b-8245-a1971b4e6055": ["Y2h1bmtfMl9pbmRleF80MjE="], "d9717684-4318-443b-a0ee-3a015bbbab12": ["Y2h1bmtfMF9pbmRleF82MDk="], "d77b2eec-8263-46dc-afd9-1cbf7f55ed1e": ["Y2h1bmtfMF9pbmRleF82MDk="], "5a6f2bdf-d39b-4eb7-8ff8-67a29bec4e63": ["Y2h1bmtfMV9pbmRleF82MDk="], "c887a4bd-21b3-45d0-a021-bffb46c622d3": ["Y2h1bmtfMV9pbmRleF82MDk="], "c22784f2-8b39-480f-b575-2240402ddc8e": ["Y2h1bmtfMF9pbmRleF84MjA="], "d3bae138-d7ad-48c6-9e4b-17eb8571eb35": ["Y2h1bmtfMF9pbmRleF84MjA="], "746189c6-c9d6-4c7e-80ea-bb5cc998799a": ["Y2h1bmtfMV9pbmRleF84MjA="], "529383d6-90d0-4d40-861b-49ce5bc4809b": ["Y2h1bmtfMV9pbmRleF84MjA="], "9f5b59b2-1cf3-48af-8c26-ca1c926a25f8": ["Y2h1bmtfMl9pbmRleF84MjA="], "0274cd7c-2473-448b-b9e5-48f54f43a0d7": ["Y2h1bmtfMl9pbmRleF84MjA="], "bf2a6d0a-4a31-4e44-92a9-73e9c1faaa98": ["Y2h1bmtfMl9pbmRleF84MjA="], "0e7af5f1-f2db-4413-9ff6-76788fba5dcf": ["Y2h1bmtfMl9pbmRleF84MjA="], "22fda253-f877-4575-af56-b67da733c941": ["Y2h1bmtfMl9pbmRleF84MjA="], "90779621-a09b-4e31-bcff-410ff9947bed": ["Y2h1bmtfMl9pbmRleF84MjA="], "35571009-e64f-4ae0-8c38-804ed55ce97d": ["Y2h1bmtfMl9pbmRleF84MjA="], "fddd89b0-2257-4c01-8b63-b1e9dc213f37": ["Y2h1bmtfMF9pbmRleF80NDI="], "23df7011-2cd3-4768-a878-25d0dab52661": ["Y2h1bmtfMF9pbmRleF80NDI="], "aaf1a946-81f8-485d-a6fc-f8cf8b023eec": ["Y2h1bmtfMF9pbmRleF80NDI="], "a424eb55-2c63-48a0-93d3-5a69141245c2": ["Y2h1bmtfMF9pbmRleF80NDI="], "60afebce-ff76-4d93-844a-a168d6cfea6c": ["Y2h1bmtfMF9pbmRleF80NDI="], "0e9fd7a5-8c1a-4480-a07b-2268c4ec1cfa": ["Y2h1bmtfMF9pbmRleF80NDI="], "8b937991-0e56-44df-9b5c-97662005768c": ["Y2h1bmtfMV9pbmRleF80NDI="], "4add2f60-8039-4a2e-888f-0355402d94d6": ["Y2h1bmtfMV9pbmRleF80NDI="], "9194133d-901a-4d7b-a769-88737f1a94ce": ["Y2h1bmtfMF9pbmRleF8xMjYy"], "7d2665e0-d2fc-43d4-a80d-20937988c5eb": ["Y2h1bmtfMF9pbmRleF8xMzQ0"], "826e21c7-ff3e-4996-aede-5a3548121498": ["Y2h1bmtfMF9pbmRleF8xMzQ0"], "2fad7441-ff1c-4e4e-9cae-474b82da82c7": ["Y2h1bmtfMV9pbmRleF8xMzQ0"], "c22366b2-16eb-4939-8a91-a6a8bece4d14": ["Y2h1bmtfMV9pbmRleF8xMzQ0"], "1ae8ba6f-6fd3-4d02-8835-8aff7a922b61": ["Y2h1bmtfMl9pbmRleF8xMzQ0"], "fc7b333e-3001-45a5-a5d9-aa5c542bebb7": ["Y2h1bmtfM19pbmRleF8xMzQ0"], "778f1c94-365a-4fdf-94d9-c26a8d74a446": ["Y2h1bmtfM19pbmRleF8xMzQ0"], "e91fad99-21b1-4d42-8734-a79891e66f80": ["Y2h1bmtfNF9pbmRleF8xMzQ0"], "320e7cda-8f5f-4231-94bd-8139735793ee": ["Y2h1bmtfNF9pbmRleF8xMzQ0"], "8cae39ec-e8b0-4432-9d4d-29a97a4d4457": ["Y2h1bmtfNV9pbmRleF8xMzQ0"], "3e24c41a-2fed-4557-8b52-b8f5ea53a859": ["Y2h1bmtfNV9pbmRleF8xMzQ0"], "69632101-168b-4a5a-905a-67492dc33d92": ["Y2h1bmtfNl9pbmRleF8xMzQ0"], "2133174c-2047-4ace-974b-f315b8daabe0": ["Y2h1bmtfNl9pbmRleF8xMzQ0"], "060886fe-c9e1-4e01-91ea-746da38f3beb": ["Y2h1bmtfN19pbmRleF8xMzQ0"], "ba50cc36-6d76-4f5c-8a6e-a9ef826fb85e": ["Y2h1bmtfN19pbmRleF8xMzQ0"], "75eacc2d-cbb0-484e-b982-6ed727a19c50": ["Y2h1bmtfOF9pbmRleF8xMzQ0"], "da72c9f8-954e-4add-8d42-51c7a475baaf": ["Y2h1bmtfOV9pbmRleF8xMzQ0"], "d3ebe5ee-30e8-4309-b700-aeebe2dc6d72": ["Y2h1bmtfOV9pbmRleF8xMzQ0"], "4dcd1980-c23b-4958-b564-515bf7bd8dc6": ["Y2h1bmtfMTBfaW5kZXhfMTM0NA=="], "2f639651-52e1-4b76-80fc-dd4a724bdbf1": ["Y2h1bmtfMTBfaW5kZXhfMTM0NA=="], "be1860c1-1ed6-47eb-92c3-e9ef55737bf2": ["Y2h1bmtfMF9pbmRleF8xNg=="], "b91a9443-9e27-42c0-b7ea-6e553c2ce8e9": ["Y2h1bmtfMF9pbmRleF8xNg=="], "5d67f8be-64be-4279-9b9e-236c29c2cffa": ["Y2h1bmtfMV9pbmRleF8xNg=="], "351dc383-c7d4-4f52-ae57-7900b7fc8144": ["Y2h1bmtfMF9pbmRleF8xNTUy"], "ac90b81d-0884-44dd-934f-b0c75501e701": ["Y2h1bmtfMF9pbmRleF8xNTUy"], "d011deca-4bfe-400c-8c92-41d54fd36763": ["Y2h1bmtfMF9pbmRleF8zODE="], "23505011-ab01-47a8-9f4e-f5d14f2b3d27": ["Y2h1bmtfMF9pbmRleF8zODE="], "bcea9c91-6d30-42d3-8248-8d938cdc9067": ["Y2h1bmtfMF9pbmRleF8xNTg0"], "ee200a57-b098-4c36-bc3d-2ba923c0d6ce": ["Y2h1bmtfMF9pbmRleF8xNTg0"], "63a7d35d-193e-4c5a-94d0-040652bb45b6": ["Y2h1bmtfMF9pbmRleF8xNjkz"], "a44fa687-f644-414f-8957-9d3c7f2931b9": ["Y2h1bmtfMF9pbmRleF8xNjkz"], "6a5d18cf-bec9-4855-8f9b-f6768d587d8a": ["Y2h1bmtfMF9pbmRleF80MjM="], "9d6999f1-35a7-4b87-ba87-6d561675cdfb": ["Y2h1bmtfMF9pbmRleF80MjM="], "4ec1ec9a-32c5-452d-a099-2f15cb169612": ["Y2h1bmtfMV9pbmRleF80MjM="], "a485699e-08d3-441f-b095-b9ca4d4020ba": ["Y2h1bmtfMl9pbmRleF80MjM="], "2f6c0240-2706-4cda-8a5a-38c4d8cc4a22": ["Y2h1bmtfMl9pbmRleF80MjM="], "2a366a2e-81ea-42d2-bd98-1edef1bf84f2": ["Y2h1bmtfM19pbmRleF80MjM="], "a1dd3ab3-2a18-40ba-b037-3a5057fca628": ["Y2h1bmtfM19pbmRleF80MjM="], "e67c0b0b-2036-42f9-8a94-0190c44b9b1e": ["Y2h1bmtfMF9pbmRleF83MjA="], "dbaa1e33-ca6e-43b3-a19a-5597c36c7403": ["Y2h1bmtfMF9pbmRleF83MjA="], "17b2b49f-d656-4f97-9133-c2125b1a9cae": ["Y2h1bmtfMV9pbmRleF83MjA="], "a996c566-26a7-4a43-966c-8178d9c13543": ["Y2h1bmtfMV9pbmRleF83MjA="], "bcca34c7-928c-477b-8e55-acefc6134687": ["Y2h1bmtfMV9pbmRleF83MjA="], "1f9b5b02-0ddc-48e7-9876-c7a14a6db150": ["Y2h1bmtfMl9pbmRleF83MjA="], "cf0592a4-fef3-4357-93e9-ad86fa7d2ed8": ["Y2h1bmtfMl9pbmRleF83MjA="], "8f7cbc1f-68a7-48ce-87b6-e38c284e1ee3": ["Y2h1bmtfM19pbmRleF83MjA="], "bff2e71d-c7e9-4626-9eb2-951864c92c05": ["Y2h1bmtfM19pbmRleF83MjA="], "dab636d6-5a80-4854-9cce-e4552af8476d": ["Y2h1bmtfMF9pbmRleF8xNDQ0"], "10130ca4-07fe-4da9-a49d-6999db7c5205": ["Y2h1bmtfMF9pbmRleF8xNDQ0"], "3414b038-432c-4728-b0bf-bdf4ea299501": ["Y2h1bmtfMF9pbmRleF8xMzIy"], "6bcfff7d-0000-4825-8af3-4a4278b17879": ["Y2h1bmtfMV9pbmRleF8xMzIy"], "a9b8047e-3bff-4359-a8ed-fdb7775584a9": ["Y2h1bmtfMV9pbmRleF8xMzIy"], "da77b2d7-abc2-4208-8ddf-dffdfa5cdc13": ["Y2h1bmtfMF9pbmRleF8xNTgw"], "b26eff00-8f86-460f-a088-3be99a28895d": ["Y2h1bmtfMF9pbmRleF8xNTgw"], "53398d90-3f05-437f-8d18-625e592d0fab": ["Y2h1bmtfMF9pbmRleF8xNTMy"], "b2eb3a6b-c34e-4325-b2de-86ed87b59479": ["Y2h1bmtfMF9pbmRleF8xNTMy"], "fd036376-c926-4c36-890c-476873aecf35": ["Y2h1bmtfMF9pbmRleF8yODY="], "01fbacd1-48a6-4405-8fdd-93fb9756246b": ["Y2h1bmtfMF9pbmRleF8yODY="], "1ef05a78-1e30-4a9c-a89e-07e522d93a8d": ["Y2h1bmtfMV9pbmRleF8yODY="], "2a9fb419-78cb-4aa6-bc29-58bead25ed6f": ["Y2h1bmtfMV9pbmRleF8yODY="], "5083c0fe-0b0f-4fbf-be2c-2afcbdacbff4": ["Y2h1bmtfMl9pbmRleF8yODY="], "6b25b39b-7f70-49f6-a38a-81cf366cf91b": ["Y2h1bmtfMl9pbmRleF8yODY="], "8160a56d-07c7-4ed9-baaf-6b943800c4f4": ["Y2h1bmtfMl9pbmRleF8yODY="], "e868ed25-ae70-474b-8956-250892358301": ["Y2h1bmtfM19pbmRleF8yODY="], "02e8aef4-3a5e-4ec7-bfb7-c3bfb112af10": ["Y2h1bmtfM19pbmRleF8yODY="], "213f1538-1817-4f57-9a6c-0de077cf169d": ["Y2h1bmtfMF9pbmRleF8xNjY="], "c125df61-5522-4853-b991-2a31de3a98a4": ["Y2h1bmtfMF9pbmRleF8xNjY="], "ff1eab7e-54a1-4333-a6ab-cdb6a4c1a800": ["Y2h1bmtfMV9pbmRleF8xNjY="], "fcbe63d0-bf43-4652-b510-118cb93f7c85": ["Y2h1bmtfMV9pbmRleF8xNjY="], "aca17ea2-5fe2-452b-9d0d-754e238720d5": ["Y2h1bmtfMV9pbmRleF8xNjY="], "c6a7cc88-1413-4a78-814d-d95e187566f6": ["Y2h1bmtfMl9pbmRleF8xNjY="], "4371400c-b759-4e72-b349-ea624961531c": ["Y2h1bmtfMl9pbmRleF8xNjY="], "cebfee54-1b76-4baa-90e2-6b80323c2787": ["Y2h1bmtfM19pbmRleF8xNjY="], "7a6d69b9-6336-4d0c-b92d-a06792ea1a35": ["Y2h1bmtfM19pbmRleF8xNjY="], "cdd4984d-2264-4276-911d-2ebfcb5c28c4": ["Y2h1bmtfM19pbmRleF8xNjY="], "e3b7b8c9-4527-4536-b90b-1e08cf2466c0": ["Y2h1bmtfM19pbmRleF8xNjY="], "cd254133-1ef5-4758-be88-132999195a3f": ["Y2h1bmtfM19pbmRleF8xNjY="], "608aab44-0230-4750-8a92-707727a3c1ac": ["Y2h1bmtfM19pbmRleF8xNjY="], "bd73141d-2f27-4f9f-b1f2-7fee3da70cf1": ["Y2h1bmtfNF9pbmRleF8xNjY="], "0c8dd673-e8d6-4d05-88dd-58d339d86b86": ["Y2h1bmtfNF9pbmRleF8xNjY="], "0d6aeba1-d3e5-461a-a608-cb49c518dabe": ["Y2h1bmtfNV9pbmRleF8xNjY="], "aa728827-344b-4b8a-b073-e6198d271237": ["Y2h1bmtfNV9pbmRleF8xNjY="], "0daf31be-a603-4f9e-af52-4503528ee589": ["Y2h1bmtfMF9pbmRleF8xNDM0"], "aa003b48-2c13-49a2-9edd-2ce5dfc5cc35": ["Y2h1bmtfMF9pbmRleF8xNDM0"], "67a6b612-5be5-436f-8933-dd3dce2b909b": ["Y2h1bmtfMF9pbmRleF82MTA="], "03ae0a69-de8f-4f08-9b02-e9eee0bca150": ["Y2h1bmtfMF9pbmRleF82MTA="], "48cfd0a5-79af-484e-bf5e-f6d7519d7bf0": ["Y2h1bmtfMV9pbmRleF82MTA="], "c2d4c643-d248-4b7b-8621-f459acbcaee2": ["Y2h1bmtfMl9pbmRleF82MTA="], "4a4409ca-d2cd-4849-b0fb-095c303feeec": ["Y2h1bmtfMl9pbmRleF82MTA="], "49998bd9-51b5-4977-93ee-a29448b5c338": ["Y2h1bmtfMF9pbmRleF8xMjA4"], "9598377b-31f5-488e-b260-7c661090d1b0": ["Y2h1bmtfMF9pbmRleF8xMjA4"], "60f6a066-b32f-4d73-b3f7-d7c0341850d6": ["Y2h1bmtfMV9pbmRleF8xMjA4"], "87cf8b35-d31d-4053-bbb8-5bff7d5c1a8e": ["Y2h1bmtfMV9pbmRleF8xMjA4"], "90158a49-fd07-464e-bbae-6a88c86e6b74": ["Y2h1bmtfMF9pbmRleF8zNzE="], "b63497cc-c868-4867-a879-71e0e308d597": ["Y2h1bmtfMF9pbmRleF8zNzE="], "9ccd9380-11f7-45f3-ba02-dd506ecc5bce": ["Y2h1bmtfMF9pbmRleF8xNjMx"], "62963c05-4fea-4793-9e5a-5f07f568b794": ["Y2h1bmtfMF9pbmRleF8xNjMx"], "ca283a28-06f7-4e13-98fa-953e250bdf37": ["Y2h1bmtfMF9pbmRleF8xNjMx"], "352a3a97-0224-4f19-bc23-c7b6dbe422ef": ["Y2h1bmtfMF9pbmRleF8xNjMx"], "00f4e7a0-3096-482b-8f1c-5da63de75855": ["Y2h1bmtfMF9pbmRleF8xNjMx"], "6bbbdf5d-1cea-4f41-aadb-4f6093ec115e": ["Y2h1bmtfMV9pbmRleF8xNjMx"], "38823bb1-697c-41c7-8551-6bd565eb1398": ["Y2h1bmtfMV9pbmRleF8xNjMx"], "f936c73d-667b-4615-9b86-a316bce7c471": ["Y2h1bmtfMF9pbmRleF80ODc="], "a9419f3b-61b2-4129-bbe7-b21a4f765ec2": ["Y2h1bmtfMF9pbmRleF80ODc="], "82cd286f-ced3-4d22-9f9e-661f6c6402ee": ["Y2h1bmtfMV9pbmRleF80ODc="], "d1753c46-4de9-4f71-93b3-7fdfc91f5452": ["Y2h1bmtfMl9pbmRleF80ODc="], "e63211ae-6272-4bf3-8f78-8c9aac657aad": ["Y2h1bmtfM19pbmRleF80ODc="], "5f397cb9-3249-415f-8032-7a78d112089e": ["Y2h1bmtfM19pbmRleF80ODc="], "ce628638-95b6-4681-aadd-301b76978a53": ["Y2h1bmtfM19pbmRleF80ODc="], "21ca7912-8080-4c1a-a467-acbd02dfc456": ["Y2h1bmtfM19pbmRleF80ODc="], "8a7ad597-6be6-42d5-9fc4-bd2abc1465cb": ["Y2h1bmtfM19pbmRleF80ODc="], "30076280-9122-4e1e-a9fa-006becafaff8": ["Y2h1bmtfM19pbmRleF80ODc="], "4046e479-d641-423f-b710-d29a65666631": ["Y2h1bmtfM19pbmRleF80ODc="], "0b9a3cb5-2af8-47bf-bc71-914cdb18c9bd": ["Y2h1bmtfNF9pbmRleF80ODc="], "18fc0027-4321-479c-b177-28603ee0273b": ["Y2h1bmtfNF9pbmRleF80ODc="], "a880bb1f-6427-46cc-bb49-b15087de0e7c": ["Y2h1bmtfNV9pbmRleF80ODc="], "f5c8cb1d-686a-459f-9571-7af82ed3ff30": ["Y2h1bmtfNV9pbmRleF80ODc="], "075e0065-9a5e-4d63-bd81-9b55f1f5d531": ["Y2h1bmtfMF9pbmRleF80Nzk="], "626d9bc0-ab3a-4311-8b85-84d591ad309b": ["Y2h1bmtfMF9pbmRleF80Nzk="], "ca555839-4265-4b12-a24f-e9e90b2c1308": ["Y2h1bmtfMF9pbmRleF8xNDcy"], "1e891042-3355-4a86-bdae-94465af5dd5d": ["Y2h1bmtfMF9pbmRleF8xNDcy"], "7101fcfb-7680-444c-85b3-a577495d7370": ["Y2h1bmtfMV9pbmRleF8xNDcy"], "ad8d56a3-2367-46a9-893d-6f31f19388ce": ["Y2h1bmtfMV9pbmRleF8xNDcy"], "67df07a6-e73e-40c8-bd23-85cd81c31ac7": ["Y2h1bmtfMl9pbmRleF8xNDcy"], "1496fcc5-fbf3-4ed6-b77c-d3f54a540922": ["Y2h1bmtfMl9pbmRleF8xNDcy"], "5e322e6e-d3cc-4d9e-89b4-263235621d1c": ["Y2h1bmtfMl9pbmRleF8xNDcy"], "d78d45a1-3f26-49b6-adc1-0972f9f4a868": ["Y2h1bmtfMl9pbmRleF8xNDcy"], "b6ba8b77-fba1-447c-b447-9a6cf3ede8fc": ["Y2h1bmtfMl9pbmRleF8xNDcy"], "4f21c360-80db-4a13-b666-bc410e0e1d6a": ["Y2h1bmtfM19pbmRleF8xNDcy"], "573d08fa-a387-4b05-b549-2981f04a662f": ["Y2h1bmtfM19pbmRleF8xNDcy"], "8459ea51-d0bc-43c0-aafe-d207f5fb6fc8": ["Y2h1bmtfM19pbmRleF8xNDcy"], "8e1c2072-fae1-450f-bdd0-d4d1dffc34f1": ["Y2h1bmtfM19pbmRleF8xNDcy"], "3e426ac7-a1c8-4ad8-b2fb-6eee0e6eb7da": ["Y2h1bmtfM19pbmRleF8xNDcy"], "85b76acd-e03b-44ca-8107-9e4640c80619": ["Y2h1bmtfNF9pbmRleF8xNDcy"], "b337307c-aa41-4465-bae8-8906220ae789": ["Y2h1bmtfNF9pbmRleF8xNDcy"], "1e0d48b0-4a63-467e-8dd8-1c5ce2e1e92d": ["Y2h1bmtfMF9pbmRleF8yMDk1"], "210b3c34-6e2c-4c0f-a791-469b92cc09f9": ["Y2h1bmtfMF9pbmRleF8yMDk1"], "c57cf46a-d532-4c7a-add1-3b7caba73e88": ["Y2h1bmtfMV9pbmRleF8yMDk1"], "77cb1361-da8c-4ee6-985d-6d56b8fb2da1": ["Y2h1bmtfMV9pbmRleF8yMDk1"], "1cb87558-9ad3-45aa-9790-4b59985340a7": ["Y2h1bmtfMF9pbmRleF81ODA="], "383021f0-52e2-4ce9-a167-75a4a94dcfba": ["Y2h1bmtfMF9pbmRleF81ODA="], "edb9873c-3167-4080-9cb8-6a9f83af9b71": ["Y2h1bmtfMV9pbmRleF81ODA="], "f650f981-5afc-43e6-9724-71d63c887573": ["Y2h1bmtfMV9pbmRleF81ODA="], "7053675d-93e3-46ee-a0ba-6303162b7c52": ["Y2h1bmtfMV9pbmRleF81ODA="], "e0469ffe-9f29-40e7-9234-d1a18e88ce86": ["Y2h1bmtfMV9pbmRleF81ODA="], "7df251fa-3f11-419c-a0bd-db1186bf48a9": ["Y2h1bmtfMV9pbmRleF81ODA="], "6a5c35af-8f82-4411-a306-1787394c2a98": ["Y2h1bmtfMF9pbmRleF8xODk0"], "23615235-570e-4610-b90b-40bcffeb1394": ["Y2h1bmtfMF9pbmRleF8xODk0"], "c79edece-96b5-4b14-acd8-c24777442016": ["Y2h1bmtfMF9pbmRleF8xNDE="], "9b0f9a40-15ef-4712-981a-b9a94eeb1c43": ["Y2h1bmtfMV9pbmRleF8xNDE="], "9e6c293c-04dd-4a0a-a558-8520fc277119": ["Y2h1bmtfMV9pbmRleF8xNDE="], "94687445-4bc7-4b07-b4e6-94d24d3c68b7": ["Y2h1bmtfMF9pbmRleF82ODQ="], "e9dc441c-f335-49c2-8dec-e3f6ed54d558": ["Y2h1bmtfMF9pbmRleF82ODQ="], "dc1779a6-7ba9-49ce-8dde-dbcad976a850": ["Y2h1bmtfMF9pbmRleF82ODQ="], "ef3edb4e-a969-4a85-863b-fe9d6770451a": ["Y2h1bmtfMF9pbmRleF82ODQ="], "80d7bce3-fbea-418f-be0c-892e7e7ac097": ["Y2h1bmtfMF9pbmRleF82ODQ="], "94adbbed-8aea-479a-8c1c-bc8157cb59be": ["Y2h1bmtfMF9pbmRleF8xNTE="], "5241a869-c76d-4bc9-bc63-5a2d8b93877b": ["Y2h1bmtfMF9pbmRleF8xNTE="], "4befe447-0be0-486b-8f40-12f9e88c0043": ["Y2h1bmtfMF9pbmRleF8xMjQ3"], "6c65aa4a-6bc8-455d-b062-0fe84a487edc": ["Y2h1bmtfMF9pbmRleF8xMjQ3"], "e9ad844f-96e4-4736-989d-6bbb3e900c30": ["Y2h1bmtfMV9pbmRleF8xMjQ3"], "6d95bb24-3a89-4009-8d95-b8863a3b60ed": ["Y2h1bmtfMV9pbmRleF8xMjQ3"], "d884b1b1-5c87-4394-b306-1509474a6a3c": ["Y2h1bmtfMV9pbmRleF8xMjQ3"], "95ac0531-e21e-435a-bbd0-56706c431a26": ["Y2h1bmtfMF9pbmRleF8xNTc3"], "77232177-6258-484d-a88f-5a789f10212b": ["Y2h1bmtfMF9pbmRleF8xNTc3"], "6a4ea3ec-0b97-49e3-82b9-380a37c2a51b": ["Y2h1bmtfMV9pbmRleF8xNTc3"], "06482c72-11a6-432e-945a-6c235b7f80e3": ["Y2h1bmtfMV9pbmRleF8xNTc3"], "6a7e3420-a9fd-4552-bca4-2c361995b91b": ["Y2h1bmtfMF9pbmRleF8xNDEy"], "b029d3cc-fa13-45ac-8687-7b18c8d8126d": ["Y2h1bmtfMF9pbmRleF8xNDEy"], "a85126b0-1ef1-4fd8-83f1-7c3deec80812": ["Y2h1bmtfMF9pbmRleF84NzI="], "dbcf74a9-c78d-48e8-b17f-f6743a0d3d2e": ["Y2h1bmtfMF9pbmRleF84NzI="], "6a144d68-334d-4c27-a6f1-01ca63bf4ca5": ["Y2h1bmtfMV9pbmRleF84NzI="], "a3899503-3272-4747-8682-d5117f37db16": ["Y2h1bmtfMV9pbmRleF84NzI="], "64276dfa-24bc-45c9-bc85-c7a7561fae8a": ["Y2h1bmtfMl9pbmRleF84NzI="], "1aa848c2-ebaa-46ca-acf7-b8349894ceee": ["Y2h1bmtfMl9pbmRleF84NzI="], "2ad00173-8e8c-4ddd-8b2d-128e78cb0ed6": ["Y2h1bmtfMF9pbmRleF8xMzc4"], "6f9a0dca-05ab-4379-a7e1-309ee7beefd6": ["Y2h1bmtfMF9pbmRleF8xMzc4"], "dc9709bb-e03c-482c-b088-1148b4588586": ["Y2h1bmtfMV9pbmRleF8xMzc4"], "14403f5b-3326-41c9-b5c3-8763b7e8a6b0": ["Y2h1bmtfMV9pbmRleF8xMzc4"], "7d8963f4-0db8-4a16-8e27-4a82d6fc63e4": ["Y2h1bmtfMF9pbmRleF8xMDQ2"], "42af3af7-99ca-4bc4-b3ed-30a36dbef646": ["Y2h1bmtfMF9pbmRleF8xMDQ2"], "2c0c2828-4e53-49e8-8731-3d7a396c081b": ["Y2h1bmtfMF9pbmRleF82ODY="], "65b7978a-4fb5-47ee-ab77-3c3d67e8fb76": ["Y2h1bmtfMF9pbmRleF82ODY="], "ab6ed101-52a1-464c-a7be-89192c46563a": ["Y2h1bmtfMV9pbmRleF82ODY="], "827fd365-65e9-4cad-8cea-66cd75d9928c": ["Y2h1bmtfMV9pbmRleF82ODY="], "3d77d595-5467-4357-a955-c2e5bd84149a": ["Y2h1bmtfMl9pbmRleF82ODY="], "2c5264fb-a3c8-48b9-95d1-a999f770d4cd": ["Y2h1bmtfMl9pbmRleF82ODY="], "aff4058b-5efc-45ea-8133-4cd3af284e8d": ["Y2h1bmtfMl9pbmRleF82ODY="], "f80d003a-9211-480e-b4af-2297e0530cfd": ["Y2h1bmtfMF9pbmRleF8xOTMy"], "0bd992c4-83d9-404f-8349-7196a02d2b69": ["Y2h1bmtfMF9pbmRleF8xOTMy"], "df1f524a-99e2-416a-a99d-411578ca2cb1": ["Y2h1bmtfMV9pbmRleF8xOTMy"], "928fbc72-8b0a-4fd5-a13d-e35704ee3f41": ["Y2h1bmtfMV9pbmRleF8xOTMy"], "f2e5080b-766c-4b11-a74d-d5d58e1772d1": ["Y2h1bmtfMV9pbmRleF8xOTMy"], "8952572e-67b9-486c-a4b3-8c3b9470b0e5": ["Y2h1bmtfMV9pbmRleF8xOTMy"], "c1b9bcbd-8dd9-47bc-b33a-d6d78e4a9247": ["Y2h1bmtfMV9pbmRleF8xOTMy"], "026b4dbd-af81-489a-8810-ee90cd920f21": ["Y2h1bmtfMV9pbmRleF8xOTMy"], "a6dd7274-5f7c-43a4-acfb-ca6e2d1f2564": ["Y2h1bmtfMV9pbmRleF8xOTMy"], "945edb19-a1c8-429a-aab8-cf03494bbb3a": ["Y2h1bmtfMV9pbmRleF8xOTMy"], "60d1319d-4d37-4f58-ac46-fd0a37c17972": ["Y2h1bmtfMl9pbmRleF8xOTMy"], "e11022be-bbef-4af8-a157-7e9e6868e64b": ["Y2h1bmtfMl9pbmRleF8xOTMy"], "14eac87a-49b1-4e9b-989b-2c14bc9e2eca": ["Y2h1bmtfMl9pbmRleF8xOTMy"], "690fec88-11d8-48be-8ddd-d29442d5f159": ["Y2h1bmtfMl9pbmRleF8xOTMy"], "cacd79bb-f6b7-4ba2-a17d-5049332770c3": ["Y2h1bmtfMl9pbmRleF8xOTMy"], "41220361-71c7-4264-9501-c67303508a8d": ["Y2h1bmtfMl9pbmRleF8xOTMy"], "546e8257-a065-463e-a02e-2da4dd362e7d": ["Y2h1bmtfMl9pbmRleF8xOTMy"], "5fed9e0d-f0fa-4490-9215-59824828a575": ["Y2h1bmtfMl9pbmRleF8xOTMy"], "18e90838-da8a-4b0d-bedc-e84c4973e37b": ["Y2h1bmtfM19pbmRleF8xOTMy"], "88d1bbb9-287e-4220-8a40-74e9396e393e": ["Y2h1bmtfM19pbmRleF8xOTMy"], "2c694a72-27f1-4ca8-966a-878dadc52503": ["Y2h1bmtfMF9pbmRleF8xMjU4"], "32766832-827e-444c-a9c8-5f193c68f433": ["Y2h1bmtfMF9pbmRleF8xMjU4"], "39aea862-1f04-4df3-8a7d-a04ba597167c": ["Y2h1bmtfMF9pbmRleF8xODU5"], "ada1957d-c472-4314-a16f-d1e8705b727c": ["Y2h1bmtfMF9pbmRleF8xODU5"], "d5767ddd-a435-4e62-9d1a-6e6fbfa1b418": ["Y2h1bmtfMF9pbmRleF80MTU="], "52a68333-343e-4175-9d4e-01a9164cea50": ["Y2h1bmtfMF9pbmRleF80MTU="], "2438033b-1395-4a3e-8a00-d681a1a31898": ["Y2h1bmtfMV9pbmRleF80MTU="], "99e76eef-6b2a-4091-85c2-3121c5f3c643": ["Y2h1bmtfMV9pbmRleF80MTU="], "ec9f5d9c-ecb5-42f4-8693-124e75bca502": ["Y2h1bmtfMl9pbmRleF80MTU="], "aee720a9-20af-4312-b61c-27ce701eb0fe": ["Y2h1bmtfMl9pbmRleF80MTU="], "d1392502-3614-4818-8c94-e106db9c4574": ["Y2h1bmtfM19pbmRleF80MTU="], "b3395be1-55c9-467f-ac1e-e13fe4033d33": ["Y2h1bmtfM19pbmRleF80MTU="], "f43c64cd-58e2-4c1e-a978-e9fe33ca8095": ["Y2h1bmtfM19pbmRleF80MTU="], "73511181-291c-4508-8e5b-91e64f85e5f9": ["Y2h1bmtfM19pbmRleF80MTU="], "99ff899a-daa3-42b4-9ae3-7f6413db7f3d": ["Y2h1bmtfM19pbmRleF80MTU="], "e0cf39b7-526d-4c51-a2f7-9bcaca44aae8": ["Y2h1bmtfM19pbmRleF80MTU="], "295fac35-fc7c-45a6-b4bc-481ceb8806bf": ["Y2h1bmtfNF9pbmRleF80MTU="], "c2bf8dd9-a516-4336-a002-216daf62a2e3": ["Y2h1bmtfNF9pbmRleF80MTU="], "21bf0b4a-f303-4bc2-8f98-9b2c5843dabd": ["Y2h1bmtfNV9pbmRleF80MTU="], "5e8bf5ee-e449-4f49-9f9c-a4262991f7f6": ["Y2h1bmtfNV9pbmRleF80MTU="], "af25ab73-3014-48f9-a900-86eaa1832767": ["Y2h1bmtfNV9pbmRleF80MTU="], "6b03c22d-cd88-413b-b5b2-b2503f35e733": ["Y2h1bmtfNV9pbmRleF80MTU="], "137ab0a9-64b3-41f8-b27e-57f940b797fa": ["Y2h1bmtfNV9pbmRleF80MTU="], "97e7bbcc-37be-4620-8bf8-4d453121de43": ["Y2h1bmtfNl9pbmRleF80MTU="], "ba344fb6-9756-439b-8d5b-b1ba28f86b12": ["Y2h1bmtfNl9pbmRleF80MTU="], "ae9667b5-7a25-4688-b64f-e93acdf7faee": ["Y2h1bmtfN19pbmRleF80MTU="], "1a4510b1-ca38-4bc9-bb91-f6678c3757d1": ["Y2h1bmtfN19pbmRleF80MTU="], "ce71ebfc-cab3-461e-93bf-2558b560e263": ["Y2h1bmtfMF9pbmRleF8xMjgy"], "967d6f73-1009-40bc-97cd-2e55937d21da": ["Y2h1bmtfMF9pbmRleF8xMjgy"], "bf4a656c-b366-4847-90fa-2079e48b1402": ["Y2h1bmtfMF9pbmRleF81MDQ="], "49f1d723-80be-4114-9eff-79c9dcd8275d": ["Y2h1bmtfMF9pbmRleF81MDQ="], "58af2911-54a1-4096-91f9-771ab3f168c2": ["Y2h1bmtfMV9pbmRleF81MDQ="], "a4aa89ce-f047-491f-932d-022982d5500c": ["Y2h1bmtfMl9pbmRleF81MDQ="], "c18bd2c8-c151-40e5-9c0b-150315db58ae": ["Y2h1bmtfMl9pbmRleF81MDQ="], "a47ad313-3326-4bd5-b0b9-594905fd2b00": ["Y2h1bmtfMF9pbmRleF85Mjk="], "18571e5f-0b8d-4942-affd-47318f0798f2": ["Y2h1bmtfMF9pbmRleF85Mjk="], "30d48d09-ea94-42d6-a84d-352bf272807d": ["Y2h1bmtfMV9pbmRleF85Mjk="], "511ed642-f1f1-442c-bcc3-bb9cebceee54": ["Y2h1bmtfMV9pbmRleF85Mjk="], "8caf70bf-8e8e-49fb-a7d7-514ac666eabf": ["Y2h1bmtfMF9pbmRleF8xMzMx"], "c6ab86c8-ea3e-4b9c-8f47-0f694aaf4a30": ["Y2h1bmtfMF9pbmRleF8xMzMx"], "da0221b9-d785-4b8d-80b1-87c388c561be": ["Y2h1bmtfMF9pbmRleF8xMzMx"], "b757719b-6603-4541-8470-e5126358334b": ["Y2h1bmtfMF9pbmRleF8xMzMx"], "9aab6fb8-c62f-4701-bd2a-2df357f61a05": ["Y2h1bmtfMF9pbmRleF8xMzMx"], "e8deb833-4704-4587-930b-52863b64197a": ["Y2h1bmtfMF9pbmRleF8xMzMx"], "51514195-c32e-4120-9ea8-146a68820a12": ["Y2h1bmtfMF9pbmRleF8xMzMx"], "528da668-6982-4fc1-87d2-700fdc32f098": ["Y2h1bmtfMV9pbmRleF8xMzMx"], "aa8d2a74-fd57-4b38-8172-e994cbd2471d": ["Y2h1bmtfMl9pbmRleF8xMzMx"], "99628dd4-eaf0-4821-ab17-62d2ec8b652f": ["Y2h1bmtfMl9pbmRleF8xMzMx"], "81b9ffb4-ea4e-40bc-809f-cf5ca8b43156": ["Y2h1bmtfM19pbmRleF8xMzMx"], "7371f60d-53be-4cd9-b758-893105622899": ["Y2h1bmtfM19pbmRleF8xMzMx"], "308ae6cb-41e8-446c-9d1b-63d772c4ae51": ["Y2h1bmtfNF9pbmRleF8xMzMx"], "0786edb8-465d-447c-b821-8f32d6585f5a": ["Y2h1bmtfNV9pbmRleF8xMzMx"], "a0bbd5ca-ab26-4466-b722-fa1394082d78": ["Y2h1bmtfNV9pbmRleF8xMzMx"], "d2094b14-06e0-4e3d-9dd6-a1905dd2eb21": ["Y2h1bmtfMF9pbmRleF8xMjE1"], "9c07fac2-fd41-4b80-913d-68ff74865390": ["Y2h1bmtfMF9pbmRleF8xMjE1"], "778d309f-7f8b-4992-870d-5b54d8b389e2": ["Y2h1bmtfMV9pbmRleF8xMjE1"], "643b20b6-f1a4-4815-bb54-33c59e9ebe72": ["Y2h1bmtfMV9pbmRleF8xMjE1"], "92c2e4f6-f5cf-4fad-b068-d31b7a2e95c8": ["Y2h1bmtfMF9pbmRleF8yMDcw"], "907e524a-32f2-41b2-bf48-54869683a506": ["Y2h1bmtfMF9pbmRleF8yMDcw"], "56b73fac-913d-4d42-899f-55352bfba988": ["Y2h1bmtfMV9pbmRleF8yMDcw"], "3d6c647d-dd73-441f-8252-250bd37f61b4": ["Y2h1bmtfMV9pbmRleF8yMDcw"], "1b9b4e58-ec5c-4b11-9c1f-1b2e0900c108": ["Y2h1bmtfMF9pbmRleF8yMDcx"], "87f0a88a-af8e-48eb-9db8-a74e7f3e9016": ["Y2h1bmtfMF9pbmRleF8yMDcx"], "460ec051-7d15-41cc-b14f-5c4ed28b91a9": ["Y2h1bmtfMF9pbmRleF83NzM="], "108a386c-ec1e-47e8-a616-7957a5e168b6": ["Y2h1bmtfMF9pbmRleF83NzM="], "ca01245c-e9e3-4d0c-85b2-119409e0c152": ["Y2h1bmtfMF9pbmRleF81MDc="], "b49465ef-a677-4ebd-8e13-5979f7f012f7": ["Y2h1bmtfMF9pbmRleF81MDc="], "b2319ea2-0316-4fa6-a0fd-9189cb612e70": ["Y2h1bmtfMV9pbmRleF81MDc="], "48afdda9-21b1-43fa-9e68-2b3b39613211": ["Y2h1bmtfMV9pbmRleF81MDc="], "7c3cdf16-d6b5-4f16-98f6-e2509915a199": ["Y2h1bmtfMl9pbmRleF81MDc="], "7a496af4-b81a-4829-998b-b5dc7b70f9ce": ["Y2h1bmtfMl9pbmRleF81MDc="], "7d220d16-3fef-4983-8dea-be591a76445f": ["Y2h1bmtfMl9pbmRleF81MDc="], "e110d1a5-0491-4a65-add8-f80ddf20a8c6": ["Y2h1bmtfMF9pbmRleF8xNjM4"], "98fbef72-4922-46e9-9970-3ee2cc810dc1": ["Y2h1bmtfMF9pbmRleF8xNjM4"], "cfd3776e-ec61-4e74-9589-e43d36217a9d": ["Y2h1bmtfMV9pbmRleF8xNjM4"], "2e37b54a-f178-4645-b843-07c00ce0b886": ["Y2h1bmtfMV9pbmRleF8xNjM4"], "22139102-97a2-46a9-b6a8-37e04c653fdf": ["Y2h1bmtfMl9pbmRleF8xNjM4"], "b9f157d1-eb5d-4de3-9030-9658b163daac": ["Y2h1bmtfMl9pbmRleF8xNjM4"], "c72af641-a5d5-4039-8de7-89f69296ea47": ["Y2h1bmtfM19pbmRleF8xNjM4"], "4706928b-6a5b-4f14-8d3d-3410a3a6047f": ["Y2h1bmtfNF9pbmRleF8xNjM4"], "be10a0c1-8b58-45fc-b689-4964308a2ab1": ["Y2h1bmtfNF9pbmRleF8xNjM4"], "0c060c9b-2f1b-4cf2-a39d-4f4782f2803b": ["Y2h1bmtfNF9pbmRleF8xNjM4"], "693b3af5-2866-4260-98fc-3d2809c36a27": ["Y2h1bmtfNV9pbmRleF8xNjM4"], "b742aff6-4e91-4889-9561-3820d54e12fb": ["Y2h1bmtfNV9pbmRleF8xNjM4"], "2f2f9df6-2160-4ba8-9f35-2ba9a50760e2": ["Y2h1bmtfMF9pbmRleF8xNjgy"], "5af57a07-2794-41a7-ac34-2fe90acd2596": ["Y2h1bmtfMF9pbmRleF8xNjgy"], "30ee4cd2-971e-4a93-b003-86f0e26a334e": ["Y2h1bmtfMF9pbmRleF8xMzM3"], "ce3406e6-1498-4757-96cd-a00aed127347": ["Y2h1bmtfMF9pbmRleF8xMzM3"], "b9cdbf9a-18bb-4e86-837f-4782d9daab8e": ["Y2h1bmtfMV9pbmRleF8xMzM3"], "8d4b8022-97e8-493f-bc33-fd203fbde6f2": ["Y2h1bmtfMV9pbmRleF8xMzM3"], "cc02bee8-0e89-4d71-a866-d2834286e255": ["Y2h1bmtfMl9pbmRleF8xMzM3"], "d0d0d283-d81c-463a-a832-0a509dc28731": ["Y2h1bmtfMl9pbmRleF8xMzM3"], "564899c8-0db9-455a-a516-85ec2d2ac9cf": ["Y2h1bmtfMF9pbmRleF84MTY="], "e531e59a-5f2a-4f2a-b9cc-ee207c1b60aa": ["Y2h1bmtfMF9pbmRleF84MTY="], "902f98f6-a8fe-486c-954c-a76beb3a75ba": ["Y2h1bmtfMV9pbmRleF84MTY="], "d3beefeb-4bcf-4132-a07b-428162525c94": ["Y2h1bmtfMV9pbmRleF84MTY="], "60ea7c75-306a-412b-871b-271102d94ca0": ["Y2h1bmtfMl9pbmRleF84MTY="], "77e50919-7d96-4629-844f-8d3054aab8e7": ["Y2h1bmtfMl9pbmRleF84MTY="], "a7c639c6-761f-4307-a3ac-37400f4e84f2": ["Y2h1bmtfMF9pbmRleF8xMTE4"], "b6816aa6-2d61-4448-9159-67de3a71a32d": ["Y2h1bmtfMF9pbmRleF8xMTE4"], "d0e91efa-9ef1-4510-bb6e-c82abb6d3641": ["Y2h1bmtfMF9pbmRleF8xMTE4"], "6497b088-d47c-45c8-b2d0-b7a3010b0b8c": ["Y2h1bmtfMF9pbmRleF8xMTE4"], "7b2fe54d-aea6-4cbf-bcbb-0a889695869a": ["Y2h1bmtfMF9pbmRleF8xMTE4"], "78b2849d-4126-48cd-9194-cbee374326df": ["Y2h1bmtfMV9pbmRleF8xMTE4"], "887a6447-2fca-4c52-969c-3614693389b5": ["Y2h1bmtfMV9pbmRleF8xMTE4"], "36b5bd0b-8a3c-47a1-a8ba-9df27edcf70d": ["Y2h1bmtfMl9pbmRleF8xMTE4"], "755297a6-e56b-4e48-b9bc-a16810097aaf": ["Y2h1bmtfMl9pbmRleF8xMTE4"], "40a3c0e0-2a48-48c7-8bdb-c7e37d376f72": ["Y2h1bmtfMF9pbmRleF8xNjg1"], "5009510e-8e44-485c-bdd4-4832d3106518": ["Y2h1bmtfMF9pbmRleF8xNjg1"], "ac935062-e55b-4ae5-b194-eb8fd2680b25": ["Y2h1bmtfMF9pbmRleF8xNjg1"], "806703d6-e225-4de9-ab26-564b02d1afff": ["Y2h1bmtfMF9pbmRleF8xNjg1"], "71c1b782-b608-4207-9317-865e67d4951d": ["Y2h1bmtfMF9pbmRleF8xNjg1"], "4758c2c4-95f5-409d-83a9-88ef5da85406": ["Y2h1bmtfMF9pbmRleF8xNjg1"], "65de0f27-f5fa-4fcd-a3b5-bc878ef4b373": ["Y2h1bmtfMF9pbmRleF8xNjg1"], "2116ef73-5023-4d77-a2dd-fd2bf9a372c8": ["Y2h1bmtfMV9pbmRleF8xNjg1"], "ed1b8609-c0dc-43bc-bf27-9854421d7bc2": ["Y2h1bmtfMV9pbmRleF8xNjg1"], "9b977d80-6a26-4554-b855-f0d880bf927b": ["Y2h1bmtfMF9pbmRleF8xMTcy"], "46350b1b-08c7-4aa9-b657-b2e25ff42739": ["Y2h1bmtfMF9pbmRleF8xMTcy"], "f75bd87d-67f0-4ca6-8cfe-9a4657e1a39f": ["Y2h1bmtfMF9pbmRleF8xODAz"], "09340b4c-a4c4-41df-bbea-6beb16b7c3cf": ["Y2h1bmtfMF9pbmRleF8xODAz"], "1fc9d5c1-4b2d-4c83-8b9f-f84a0e04c38e": ["Y2h1bmtfMF9pbmRleF8xMjU="], "d974c83e-b07f-412d-88b1-555c34cefc35": ["Y2h1bmtfMF9pbmRleF8xMjU="], "37c5797f-2abd-4c16-ace8-73902bbaa710": ["Y2h1bmtfMF9pbmRleF8xMjU="], "29fbf48a-9324-4cd1-921e-37df54f21200": ["Y2h1bmtfMF9pbmRleF8xMjU="], "d2bc8298-e794-4ce9-b067-dd9ae2b52b56": ["Y2h1bmtfMF9pbmRleF8xMjU="], "5686d4ae-5064-4ece-90b8-814c640d9821": ["Y2h1bmtfMF9pbmRleF8xMjU="], "f4ccfe2c-0c31-4f89-8fd0-a4ee282b29cc": ["Y2h1bmtfMV9pbmRleF8xMjU="], "ee274634-cb9c-4c8e-8a52-e7a918da4ec5": ["Y2h1bmtfMV9pbmRleF8xMjU="], "30cf2039-5b77-4449-8fee-b7bf47cb56c2": ["Y2h1bmtfMF9pbmRleF8zNw=="], "f7f0b481-2efa-45c8-a996-fddb223084dc": ["Y2h1bmtfMF9pbmRleF8zNw=="], "45ad9ef2-d8be-47de-8dcb-fe6ab6db3b7b": ["Y2h1bmtfMF9pbmRleF8zNw=="], "665e540b-503b-4bc2-8d74-3d611ba98bc2": ["Y2h1bmtfMF9pbmRleF8yMTY="], "8e5efda9-b485-43b9-ba89-63084f0ac1b8": ["Y2h1bmtfMF9pbmRleF8yMTY="], "f357a508-74e7-4815-8c9c-73917535ac09": ["Y2h1bmtfMV9pbmRleF8yMTY="], "f4570d73-4a91-47b5-bfab-3ca6c9d7d321": ["Y2h1bmtfMV9pbmRleF8yMTY="], "c29348c2-fc00-4415-ba62-774d19079730": ["Y2h1bmtfMF9pbmRleF8xNjkx"], "64b2ea62-3a38-4679-975a-f221ca843230": ["Y2h1bmtfMF9pbmRleF8xNjkx"], "ca127a8e-1d62-46a5-837b-d6f6a5ce7bfc": ["Y2h1bmtfMV9pbmRleF8xNjkx"], "9d3c479f-d7af-41e0-8470-fdece601af72": ["Y2h1bmtfMV9pbmRleF8xNjkx"], "7cf35a60-114a-4a07-81e7-85edfc6ce1d6": ["Y2h1bmtfMl9pbmRleF8xNjkx"], "14f76f6b-0adb-4e4f-9290-210ea1a61649": ["Y2h1bmtfMl9pbmRleF8xNjkx"], "012c00fe-4749-490b-a0bd-ffa7cc81ab81": ["Y2h1bmtfMF9pbmRleF82Mjg="], "7b5e17d2-a649-4c83-a057-5626e1a01753": ["Y2h1bmtfMF9pbmRleF82Mjg="], "6f2bd8f1-8b18-4c07-a535-e6286520e67d": ["Y2h1bmtfMF9pbmRleF8xMjc="], "cfbf2ec8-43dd-40ed-a73d-6036009d4d8e": ["Y2h1bmtfMF9pbmRleF8xMjc="], "797b8df0-ddfc-42f4-a566-d21c2f0bd410": ["Y2h1bmtfMV9pbmRleF8xMjc="], "4af9cee6-658e-4eba-8c92-4392bef2cdd7": ["Y2h1bmtfMV9pbmRleF8xMjc="], "7a9df24a-4d44-454d-8d65-8918ecd49dd7": ["Y2h1bmtfMl9pbmRleF8xMjc="], "b0857c7f-53d2-412b-b25c-abf51b2fd644": ["Y2h1bmtfMl9pbmRleF8xMjc="], "76799ed4-a461-470a-884b-b48836364988": ["Y2h1bmtfM19pbmRleF8xMjc="], "aef69b12-15ca-49aa-8b83-75d8cb844a42": ["Y2h1bmtfM19pbmRleF8xMjc="], "3a5e22e8-ebcc-47f9-8b66-ffa66f82a7ae": ["Y2h1bmtfM19pbmRleF8xMjc="], "b5d971c5-d2a5-47d8-aa00-a3cf22cf082e": ["Y2h1bmtfMF9pbmRleF8xNTk5"], "5799ad50-4664-4607-be1b-159cba9a3ca0": ["Y2h1bmtfMF9pbmRleF8xNTk5"], "540dd840-a142-4e4c-993b-d732798cd0f3": ["Y2h1bmtfMV9pbmRleF8xNTk5"], "313f6dcc-6710-47e2-b593-135401fa0772": ["Y2h1bmtfMV9pbmRleF8xNTk5"], "a8d6c7ab-ad5c-43f8-993f-fe3ca0115a56": ["Y2h1bmtfMV9pbmRleF8xNTk5"], "dbfff971-143b-4c97-b00e-9d44f1d4806f": ["Y2h1bmtfMV9pbmRleF8xNTk5"], "1345a156-8734-4eaf-a436-3fd67aff0240": ["Y2h1bmtfMF9pbmRleF8yNjg="], "74fe928f-6251-49aa-b472-67346558c08b": ["Y2h1bmtfMF9pbmRleF8yNjg="], "17394506-14d6-4fda-8039-5c0a7f761833": ["Y2h1bmtfMV9pbmRleF8yNjg="], "2ff58089-c71f-469b-b0cb-a815f81cbe98": ["Y2h1bmtfMV9pbmRleF8yNjg="], "fb3f2e84-fc83-4162-9997-d1e6c08ef656": ["Y2h1bmtfMl9pbmRleF8yNjg="], "d3745d7f-845d-4709-b8a0-0e99a9b70770": ["Y2h1bmtfMl9pbmRleF8yNjg="], "455a1891-7d70-40e1-ac11-de342b551a0b": ["Y2h1bmtfMl9pbmRleF8yNjg="], "5e624d1b-5915-4443-b1c2-41036826d7ba": ["Y2h1bmtfMl9pbmRleF8yNjg="], "934518db-8005-4b17-aaa3-7097d323b94c": ["Y2h1bmtfMl9pbmRleF8yNjg="], "6d18b344-6493-4703-aa13-47bc26a75ea4": ["Y2h1bmtfM19pbmRleF8yNjg="], "5ef7c233-b891-4747-ac84-f349102a91b4": ["Y2h1bmtfM19pbmRleF8yNjg="], "0ddfebb3-52ad-46c7-8505-e8b6e824a8d8": ["Y2h1bmtfMF9pbmRleF8xODQ4"], "9fcf40b6-ff4c-4848-94f8-fcd586940e44": ["Y2h1bmtfMF9pbmRleF8xODQ4"], "ceaaf8cd-d1aa-450a-8841-70f3ce04ff5f": ["Y2h1bmtfMF9pbmRleF83Mjc="], "cb490f3a-72e4-439d-b8f2-acf09de53dfa": ["Y2h1bmtfMF9pbmRleF83Mjc="], "a2e3398d-5370-4519-b9d2-8284f15137f2": ["Y2h1bmtfMV9pbmRleF83Mjc="], "9b19503c-b1a4-4730-8fdd-46f4b862d117": ["Y2h1bmtfMV9pbmRleF83Mjc="], "80da11fa-c8a5-494d-8c40-e10b79d332b1": ["Y2h1bmtfMl9pbmRleF83Mjc="], "e89d1f34-3ea5-4dfa-b81d-9a96a9ee7983": ["Y2h1bmtfMl9pbmRleF83Mjc="], "d90a3343-2d3c-4a71-9b76-922526665b61": ["Y2h1bmtfMl9pbmRleF83Mjc="], "2b9bbab9-89d9-481b-b3b5-2b31f52220c1": ["Y2h1bmtfM19pbmRleF83Mjc="], "15f4659e-a58b-4c93-b83c-283acd0c05cc": ["Y2h1bmtfM19pbmRleF83Mjc="], "cd871a4b-4d2a-47d4-9eaf-7925f16c9b16": ["Y2h1bmtfNF9pbmRleF83Mjc="], "4c43af60-bd5a-4ae5-bde4-7a4ae838b4ea": ["Y2h1bmtfNF9pbmRleF83Mjc="], "722407f4-58a4-40b7-93c1-e5e242f55cfa": ["Y2h1bmtfNV9pbmRleF83Mjc="], "a18c381b-a613-4c35-a17f-14bee5a04202": ["Y2h1bmtfNV9pbmRleF83Mjc="], "5d4d3110-119d-4f89-b8cb-13fe4589d0e8": ["Y2h1bmtfMF9pbmRleF8xMzM5"], "f0e04233-7a8a-421b-8b0f-ad6a8730e5e5": ["Y2h1bmtfMF9pbmRleF8xMzM5"], "bfd1bc3e-50b3-4421-9d39-97bf1ceaf7dd": ["Y2h1bmtfMV9pbmRleF8xMzM5"], "485aa86b-bf97-4d9e-a6d9-4d4ff0fe36a8": ["Y2h1bmtfMV9pbmRleF8xMzM5"], "f38260ae-a0ab-4a4e-a4fb-e5bb6dd953e0": ["Y2h1bmtfMl9pbmRleF8xMzM5"], "23fd599e-ebcb-42eb-be62-f566fbb83d79": ["Y2h1bmtfMl9pbmRleF8xMzM5"], "eb67282e-f1a4-4d94-b4cb-570db8cc607d": ["Y2h1bmtfMF9pbmRleF8xMzA2"], "20fca698-5913-44e0-9b54-63c0d65d1663": ["Y2h1bmtfMF9pbmRleF8xMzA2"], "714c1324-ce8a-4f63-9dcf-caf34cceb912": ["Y2h1bmtfMF9pbmRleF8xMzA2"], "236d7acf-50b7-4c50-b925-6fe56e6b2f8f": ["Y2h1bmtfMF9pbmRleF8xMzA2"], "c1954b27-eb07-44c5-be1c-da7d2aa6210c": ["Y2h1bmtfMF9pbmRleF8xMzA2"], "e6c534b2-39c7-49a1-9c4c-7836aa80b849": ["Y2h1bmtfMF9pbmRleF8xMzA2"], "3558cc00-6295-47e7-af06-94b3085f5dbb": ["Y2h1bmtfMF9pbmRleF83OA=="], "ede980e4-3b7e-4a44-81a8-01a6143b9895": ["Y2h1bmtfMF9pbmRleF83OA=="], "9d91c3e1-0377-4bb0-89de-059a66848966": ["Y2h1bmtfMV9pbmRleF83OA=="], "29bb7c95-7042-4dfb-8932-8215bc8f735c": ["Y2h1bmtfMV9pbmRleF83OA=="], "434599b7-4c16-42e9-a3f2-d6cad9162b20": ["Y2h1bmtfMl9pbmRleF83OA=="], "38f376cf-49bb-4ce1-a229-bf0592bbba9e": ["Y2h1bmtfMl9pbmRleF83OA=="], "70cff438-98f6-4efa-a4d3-b741f967bc53": ["Y2h1bmtfM19pbmRleF83OA=="], "8e58dab0-9ef9-4306-966a-cc2a123c2e07": ["Y2h1bmtfM19pbmRleF83OA=="], "8983d156-2de4-42e5-939c-e553efbd0fe2": ["Y2h1bmtfMF9pbmRleF81ODY="], "8b43cedf-c84d-48fd-9b51-9d8dadb5c486": ["Y2h1bmtfMF9pbmRleF81ODY="], "16322744-18e9-4c85-b08c-317abdef69a3": ["Y2h1bmtfMF9pbmRleF8xMTYx"], "be3e1eb6-7650-45e9-aef9-aad441a5ec30": ["Y2h1bmtfMF9pbmRleF8xMTYx"], "440ae707-a6b9-4c0a-a9bc-93291f9f2b1d": ["Y2h1bmtfMV9pbmRleF8xMTYx"], "88a833ef-1257-4068-a808-75be95a91212": ["Y2h1bmtfMV9pbmRleF8xMTYx"], "b430f2c4-1ea8-4ca8-b380-de9867ad5877": ["Y2h1bmtfMF9pbmRleF8xMjY1"], "d98afb1b-b9c4-45f2-9003-224e2637f181": ["Y2h1bmtfMF9pbmRleF8xMjY1"], "a2a9316b-cc0a-4602-b116-cc0f9992ecef": ["Y2h1bmtfMV9pbmRleF8xMjY1"], "53d88af3-4720-4905-8fb2-9f5a670d6442": ["Y2h1bmtfMV9pbmRleF8xMjY1"], "02d07381-75f4-4aaa-9a41-8b81ba470891": ["Y2h1bmtfMF9pbmRleF80OTI="], "261031e1-862a-4d06-8ad8-6379cd80dbd9": ["Y2h1bmtfMF9pbmRleF80OTI="], "eedff9dc-0448-4fd4-a863-c96ef8bb873d": ["Y2h1bmtfMV9pbmRleF80OTI="], "2e9fa59d-1e4c-4834-af94-4e394325dc66": ["Y2h1bmtfMV9pbmRleF80OTI="], "4423a982-53b2-455f-835a-da8e9ebbe2eb": ["Y2h1bmtfMF9pbmRleF8xODkw"], "264f7163-b1d4-4dc2-b69c-f36155938b1b": ["Y2h1bmtfMF9pbmRleF8xODkw"], "e8eacc02-3287-4d4e-9e53-ddf454167137": ["Y2h1bmtfMF9pbmRleF8xODkw"], "afe1cee9-952c-49bb-83de-f58666545aae": ["Y2h1bmtfMF9pbmRleF8xODkw"], "4c7e3a3d-b1d5-4645-81d0-02d1934dbda9": ["Y2h1bmtfMF9pbmRleF8xODkw"], "94c4a07b-4f6e-4e67-ac8e-b5b462b9cf52": ["Y2h1bmtfMF9pbmRleF8xODkw"], "a8d4ed78-9d78-40e6-a235-e6803303a6f7": ["Y2h1bmtfMF9pbmRleF8xODkw"], "4725d1c8-da77-4ceb-84d3-3c7b7eff38aa": ["Y2h1bmtfMF9pbmRleF8xODkw"], "4e94f955-71f5-44c9-88ac-3df7c4c03122": ["Y2h1bmtfMF9pbmRleF8xMDYz"], "43b296ae-f700-4776-86b4-fcb0e13a62c1": ["Y2h1bmtfMF9pbmRleF8xMDYz"], "8e07bc88-be1f-4a8b-a944-4be6fc7d54ba": ["Y2h1bmtfMF9pbmRleF81MjA="], "4bf63918-1c8a-4f79-ad00-370f9bed79ee": ["Y2h1bmtfMF9pbmRleF81MjA="], "d03e2729-df82-4a9f-b7a7-02512ee1506e": ["Y2h1bmtfMV9pbmRleF81MjA="], "5dbcad7f-31c7-472e-858f-a8c4278c5fee": ["Y2h1bmtfMV9pbmRleF81MjA="], "5d8087d8-44e0-48cd-b1b6-038b67f31099": ["Y2h1bmtfMF9pbmRleF8xNTM3"], "5a14cd64-aae3-4b15-a3a6-4a7104a4de1a": ["Y2h1bmtfMF9pbmRleF8xNTM3"], "1b0a8e65-75d1-482b-ad58-e4f0cbed2244": ["Y2h1bmtfMF9pbmRleF8yOTE="], "9c9645ae-1f48-4de5-8f1c-5b564c3fe67b": ["Y2h1bmtfMF9pbmRleF8yOTE="], "49cff7dd-a4b1-490e-9c3e-491af37ce5f5": ["Y2h1bmtfMF9pbmRleF82MDA="], "69bd6987-2f45-4ada-980d-dc4d04f2ee99": ["Y2h1bmtfMF9pbmRleF82MDA="], "1e3f330f-f5d8-468e-b86a-8b11ed838575": ["Y2h1bmtfMV9pbmRleF82MDA="], "4f65b958-d4be-49bb-89c5-be5b43ac527a": ["Y2h1bmtfMV9pbmRleF82MDA="], "fb55b98f-9c0a-47a4-8e19-f3ad7d05ea54": ["Y2h1bmtfMl9pbmRleF82MDA="], "2810080c-9f12-487e-81dc-c716345f6cfd": ["Y2h1bmtfMl9pbmRleF82MDA="], "6bdf89b3-690f-4d85-bc4f-a72f715aad4d": ["Y2h1bmtfM19pbmRleF82MDA="], "aa95d28d-4c1b-4ed8-877c-67f680b658da": ["Y2h1bmtfM19pbmRleF82MDA="], "33a52675-575b-4e20-9264-e6aa28d07771": ["Y2h1bmtfM19pbmRleF82MDA="], "c87a67cd-c6f1-4485-bdbb-2d03f98ee05f": ["Y2h1bmtfM19pbmRleF82MDA="], "c88c2b58-2350-41b0-8a6f-de267a8cf08a": ["Y2h1bmtfM19pbmRleF82MDA="], "a171e9a6-7b8c-4678-9ace-d1ceb18a7b75": ["Y2h1bmtfNF9pbmRleF82MDA="], "23d7ee2a-16ef-4e73-b2fc-e85c5b334e1b": ["Y2h1bmtfNF9pbmRleF82MDA="], "9b8791de-499a-4e53-a198-8c288c0e304a": ["Y2h1bmtfNF9pbmRleF82MDA="], "9dd83321-e2ed-4a68-8835-1b1e230a9b4f": ["Y2h1bmtfNF9pbmRleF82MDA="], "22e8c4f9-d856-45f6-a7bb-1cbaa4dfb5c3": ["Y2h1bmtfNF9pbmRleF82MDA="], "b7f0a291-89d2-433a-b185-1f59f2e07067": ["Y2h1bmtfNF9pbmRleF82MDA="], "4341399f-9722-4109-ad86-eef958f6e2c9": ["Y2h1bmtfNF9pbmRleF82MDA="], "2d017363-1bbe-4a12-94ab-7ff17d21ca41": ["Y2h1bmtfNF9pbmRleF82MDA="], "2e42ec43-f7b1-4241-971c-f5e06a08e834": ["Y2h1bmtfNV9pbmRleF82MDA="], "ed5f97fc-bd66-41fb-b6bc-b0303a1173c6": ["Y2h1bmtfMF9pbmRleF8xMzQy"], "efbc397d-8bf5-4dee-8edf-b37f32cfdcbe": ["Y2h1bmtfMF9pbmRleF8xMzQy"], "86917650-05e8-4a5a-8582-105821fbd1c9": ["Y2h1bmtfMV9pbmRleF8xMzQy"], "09149207-b75d-4d32-adf1-22690c347f52": ["Y2h1bmtfMl9pbmRleF8xMzQy"], "0ea2856e-a7da-42d8-a804-7ce64c0f75d9": ["Y2h1bmtfMF9pbmRleF8yMTE4"], "380921d2-09f2-4643-b162-d33fe787aef2": ["Y2h1bmtfMF9pbmRleF8yMTE4"], "3b35b559-0a7a-44a3-81af-a36dd6bfa718": ["Y2h1bmtfMV9pbmRleF8yMTE4"], "adb87159-4301-443c-ad6e-e4adf470be47": ["Y2h1bmtfMV9pbmRleF8yMTE4"], "6302cc76-62cf-4b26-84b4-4a24e8b91d96": ["Y2h1bmtfMl9pbmRleF8yMTE4"], "66d9b1b0-2ee3-44e9-a83a-726dd3750adb": ["Y2h1bmtfMF9pbmRleF8xNzk4"], "9259aa2b-c41b-46ef-ba36-a33ffbddaa82": ["Y2h1bmtfMF9pbmRleF8xNzk4"], "19cb4825-7f35-4178-ba4a-8de97246b10d": ["Y2h1bmtfMV9pbmRleF8xNzk4"], "04b66e2b-158f-4ff7-8bd9-f226ed13740c": ["Y2h1bmtfMV9pbmRleF8xNzk4"], "2f0c9672-7868-41e7-b735-e1ff8e841e67": ["Y2h1bmtfMV9pbmRleF8xNzk4"], "ea0feb33-e07b-4bca-8b26-92fabb7e3cf6": ["Y2h1bmtfMV9pbmRleF8xNzk4"], "d4a23ae5-8855-41fb-a2da-34d621571079": ["Y2h1bmtfMV9pbmRleF8xNzk4"], "87e92d51-8831-48f2-a07d-5f61d4cdd8e9": ["Y2h1bmtfMV9pbmRleF8xNzk4"], "f5666903-6365-493d-a637-46fa9320959b": ["Y2h1bmtfMV9pbmRleF8xNzk4"], "28641c32-d2b9-4b85-877f-e38d3c0ceeb9": ["Y2h1bmtfMF9pbmRleF8xOTg4"], "0a8e039f-8008-4b74-8ba3-0cd4c1ba1333": ["Y2h1bmtfMF9pbmRleF8xOTg4"], "f50acce3-ed1c-462a-a62b-9272cee779c4": ["Y2h1bmtfMF9pbmRleF8xMzMw"], "f470664b-bb87-41bb-8104-84b92614427b": ["Y2h1bmtfMF9pbmRleF8xMzMw"], "c14f9dc6-b240-4e14-9920-99dd785e8078": ["Y2h1bmtfMF9pbmRleF80OQ=="], "f7333533-6300-43a6-bc4c-dad834acd320": ["Y2h1bmtfMF9pbmRleF80OQ=="], "a5fb5617-5842-4c72-a24a-88c321c41499": ["Y2h1bmtfMF9pbmRleF81NDQ="], "570b7f35-7c28-4c0a-aa20-ec68f6576714": ["Y2h1bmtfMF9pbmRleF81NDQ="], "44291d85-c5a9-4400-ab24-81a6bcb0decc": ["Y2h1bmtfMV9pbmRleF81NDQ="], "79ffb5e3-a309-4fc8-9f81-2ca176abbd7f": ["Y2h1bmtfMV9pbmRleF81NDQ="], "f7540f24-19ef-446d-a0b6-41d2d95730a0": ["Y2h1bmtfMl9pbmRleF81NDQ="], "a13936d1-a4f1-4a07-845d-2bf9f71fdf70": ["Y2h1bmtfMl9pbmRleF81NDQ="], "ddddfc3f-6fe9-4695-9e5a-deb3b32acae2": ["Y2h1bmtfM19pbmRleF81NDQ="], "46d9e143-a238-4d74-84ca-80b07f775f2e": ["Y2h1bmtfM19pbmRleF81NDQ="], "c656cb70-a800-4c71-a32a-4d75b9abd234": ["Y2h1bmtfNF9pbmRleF81NDQ="], "f15f0573-dc32-4f91-bc7a-c5a9db83101a": ["Y2h1bmtfNF9pbmRleF81NDQ="], "665cbc81-0261-4b07-ad01-cfc7484e87b9": ["Y2h1bmtfNV9pbmRleF81NDQ="], "273cdad0-c3ac-4ab0-97b0-c17db4f410b2": ["Y2h1bmtfNV9pbmRleF81NDQ="], "45558bb0-b4b5-4922-8926-ba526b882982": ["Y2h1bmtfNl9pbmRleF81NDQ="], "9b8b7a66-7659-4276-a087-98d9fdc5e178": ["Y2h1bmtfNl9pbmRleF81NDQ="], "1b7fa466-e6ae-4e0e-91cf-9dfa64839eb6": ["Y2h1bmtfMF9pbmRleF85OTY="], "2f01d9ca-9475-47a3-a049-900e84c20060": ["Y2h1bmtfMF9pbmRleF85OTY="], "ce1856c6-8400-4cd3-8d90-fe4fbade5fb2": ["Y2h1bmtfMV9pbmRleF85OTY="], "63415af4-13ee-4126-8754-43e51236498b": ["Y2h1bmtfMl9pbmRleF85OTY="], "25bcdd11-b583-4155-bd23-a8a8befc050a": ["Y2h1bmtfMl9pbmRleF85OTY="], "2a16b79a-5195-4e68-84de-232d9ffa11df": ["Y2h1bmtfMF9pbmRleF80NTI="], "06842ccb-13e5-470f-8ff5-ec6627eae62f": ["Y2h1bmtfMF9pbmRleF80NTI="], "a08bf477-0320-4931-980b-3d6d665910ad": ["Y2h1bmtfMV9pbmRleF80NTI="], "a5251d23-a875-43c3-a316-5940b50f9a2e": ["Y2h1bmtfMV9pbmRleF80NTI="], "475799cc-23c0-4dd4-9da0-2ff521bb12e2": ["Y2h1bmtfMV9pbmRleF80NTI="], "717a795c-e610-466a-96e3-56e7eadcef8a": ["Y2h1bmtfMF9pbmRleF8zMzE="], "2648147f-39ff-415e-8a70-b39df874034c": ["Y2h1bmtfMF9pbmRleF8zMzE="], "9edf2692-7cfb-4dc7-a51f-0fe8e3e7f478": ["Y2h1bmtfMV9pbmRleF8zMzE="], "c80b767f-280e-4e38-bb82-025f8a38adfb": ["Y2h1bmtfMV9pbmRleF8zMzE="], "c664a426-e8f0-4331-818c-de9a22a19052": ["Y2h1bmtfMl9pbmRleF8zMzE="], "7bfadd0a-fa1e-4681-bb4b-98f9520ad72b": ["Y2h1bmtfMl9pbmRleF8zMzE="], "53383156-5f99-4460-8876-d4dc32582b49": ["Y2h1bmtfMF9pbmRleF8xNDEw"], "1691b848-244c-4455-9853-d318de2eb672": ["Y2h1bmtfMF9pbmRleF8xNDEw"], "f7bce846-b9b7-4346-8bad-54e40c122f35": ["Y2h1bmtfMF9pbmRleF8yMDg2"], "c47e7302-0b84-4d3d-bf13-f5283d4fddd1": ["Y2h1bmtfMF9pbmRleF8yMDg2"], "705412cb-996d-43dc-9cbc-e35d759df63a": ["Y2h1bmtfMF9pbmRleF8xNjA5"], "02c55a6b-7dd5-4515-82a1-9d568f33152d": ["Y2h1bmtfMF9pbmRleF8xNjA5"], "704da88d-5def-437e-8f4a-3430a772e606": ["Y2h1bmtfMF9pbmRleF8xMjI1"], "dc2b4a08-8d53-4058-953f-9f12adecbd0c": ["Y2h1bmtfMF9pbmRleF8xMjI1"], "124e5775-c366-4076-98c7-ddd78488f480": ["Y2h1bmtfMF9pbmRleF8xMTM5"], "e7823607-7a19-437c-96ea-cda49a302dd4": ["Y2h1bmtfMF9pbmRleF8xMTM5"], "f264983d-b470-440f-9a51-7e28d4fd4062": ["Y2h1bmtfMV9pbmRleF8xMTM5"], "61ac0074-52d6-4c81-84ba-d5d5f53e9b95": ["Y2h1bmtfMV9pbmRleF8xMTM5"], "9ba70682-6fb0-4c81-949e-0f84d3f125d9": ["Y2h1bmtfMV9pbmRleF8xMTM5"], "1f0195e4-5c1c-46b5-af86-38cf02446b04": ["Y2h1bmtfMV9pbmRleF8xMTM5"], "dd00eef0-40ab-44c5-960f-263d8540ea11": ["Y2h1bmtfMV9pbmRleF8xMTM5"], "626917e5-a9a0-4cd6-855b-7776d8a0f9f9": ["Y2h1bmtfMl9pbmRleF8xMTM5"], "5e5cdd41-f44d-401e-a8c5-d1e648a94305": ["Y2h1bmtfMl9pbmRleF8xMTM5"], "675b370e-4a32-4f20-baab-01e3f0b7021c": ["Y2h1bmtfM19pbmRleF8xMTM5"], "eb970aec-b2e8-4a47-be38-99c8e71430ec": ["Y2h1bmtfM19pbmRleF8xMTM5"], "ec8d56af-7d7b-4ed4-b5bf-ed4b7fc2426a": ["Y2h1bmtfNF9pbmRleF8xMTM5"], "0fa13c71-09bb-40ae-ac1a-47ebf530b8c4": ["Y2h1bmtfNF9pbmRleF8xMTM5"], "9896da3a-bd65-4d1a-9a4b-20befe2c03ec": ["Y2h1bmtfNV9pbmRleF8xMTM5"], "074e26ca-32cf-4a43-97fb-7153050a1852": ["Y2h1bmtfNV9pbmRleF8xMTM5"], "6f32ee1e-d7a5-473a-b045-898f8e242a7f": ["Y2h1bmtfMF9pbmRleF8yMzY="], "330649eb-8221-4976-a0f7-af5c42416490": ["Y2h1bmtfMF9pbmRleF8yMzY="], "cc3a306e-7a2d-4040-8abd-32bd0fdc5e58": ["Y2h1bmtfMF9pbmRleF8yMzY="], "97cc2dd3-ebbc-41c7-934a-521ec4b2940a": ["Y2h1bmtfMV9pbmRleF8yMzY="], "eb4a5b83-e62e-461b-83c4-2cd55950cd85": ["Y2h1bmtfMV9pbmRleF8yMzY="], "4234acfd-d420-436c-b2d5-ffbffacce813": ["Y2h1bmtfMV9pbmRleF8yMzY="], "c925e8ca-f50f-4612-83f6-a3fb70674fe6": ["Y2h1bmtfMV9pbmRleF8yMzY="], "b07bbfe4-beaa-4d7b-a09c-6ade4925ff9f": ["Y2h1bmtfMV9pbmRleF8yMzY="], "d31fe62d-35d8-4d51-9610-bec7776541d1": ["Y2h1bmtfMl9pbmRleF8yMzY="], "87f2b2c2-f2d5-42e2-b470-a4408b65757a": ["Y2h1bmtfMl9pbmRleF8yMzY="], "0e1707a6-9fe0-4962-b76e-68b25e01a6de": ["Y2h1bmtfM19pbmRleF8yMzY="], "dec95dd0-0559-4860-8826-0a6390ef489d": ["Y2h1bmtfM19pbmRleF8yMzY="], "5dd41b95-f738-4057-b482-8488639c6a4e": ["Y2h1bmtfMF9pbmRleF8xNDY1"], "47681869-0492-4a11-ae82-c5cecdd83a04": ["Y2h1bmtfMF9pbmRleF8xNDY1"], "2da16e69-6255-442f-8780-8187176c791d": ["Y2h1bmtfMV9pbmRleF8xNDY1"], "2272d999-2172-42ee-8ca4-906f3606071d": ["Y2h1bmtfMV9pbmRleF8xNDY1"], "304a884b-2ad1-4264-a3f9-ca7c777c55eb": ["Y2h1bmtfMl9pbmRleF8xNDY1"], "5953b1cf-8a58-42b9-b6dd-4c541bf3d085": ["Y2h1bmtfMF9pbmRleF8yMDc5"], "a0bf70b7-b7b6-4db4-b143-4b9fa6664f1a": ["Y2h1bmtfMF9pbmRleF8yMDc5"], "6f71f06a-a4d7-406c-a0e0-cf24b16dd9f7": ["Y2h1bmtfMF9pbmRleF8yMDc5"], "985988c9-7f69-48a3-9c39-f9fa6e529e9f": ["Y2h1bmtfMF9pbmRleF8yMDc5"], "83f5de18-040b-4ae0-884d-bbd7a339253f": ["Y2h1bmtfMF9pbmRleF8yMDc5"], "f6f98b66-3547-44d3-93f9-a57696913a24": ["Y2h1bmtfMF9pbmRleF8yMDc5"], "70169ece-a2e8-48c4-9e08-163ff76e9b5a": ["Y2h1bmtfMF9pbmRleF8yMDc5"], "42d76996-1c82-4d6b-af52-e6c08337bd84": ["Y2h1bmtfMF9pbmRleF8yMDc5"], "4891b8e6-fbe7-4f99-96b4-c35a68b234f8": ["Y2h1bmtfMF9pbmRleF8yMDc5"], "6c246b76-fcd3-43b1-b3ce-eae59dfc3d81": ["Y2h1bmtfMF9pbmRleF8yMDc5"], "3b3fe031-41b5-4bf2-a6d6-6243fb9f96a6": ["Y2h1bmtfMV9pbmRleF8yMDc5"], "928c0e81-2d9e-406c-96c6-a7e45627a03d": ["Y2h1bmtfMV9pbmRleF8yMDc5"], "ee2df058-f315-4aba-b57f-f1c74d7c480d": ["Y2h1bmtfMl9pbmRleF8yMDc5"], "dcd178d1-793b-4dd7-b1d8-22a8104cc6bf": ["Y2h1bmtfMl9pbmRleF8yMDc5"], "5d9a9d1b-b136-4587-b82d-df4d937b5d6e": ["Y2h1bmtfMF9pbmRleF8xMzk1"], "8ce4e9c9-25df-4eb9-8f32-126125051bf2": ["Y2h1bmtfMF9pbmRleF8xMzk1"], "740a965c-2d08-4e36-ad68-4c039197847f": ["Y2h1bmtfMF9pbmRleF8xMzk1"], "ce0ec2da-ba1e-44bc-9682-0dd1f37fa5e0": ["Y2h1bmtfMF9pbmRleF8xMzk1"], "74301db5-f9ff-4dbf-b081-9c06cce5f842": ["Y2h1bmtfMF9pbmRleF8xMzk1"], "b53c73d2-818b-4b96-86ec-c0298af929fc": ["Y2h1bmtfMV9pbmRleF8xMzk1"], "9e11b423-3faa-46f5-aa2e-05940f2775a3": ["Y2h1bmtfMV9pbmRleF8xMzk1"], "c5882071-d604-4abe-9fc4-161f9c7fdfcc": ["Y2h1bmtfMV9pbmRleF8xMzk1"], "2fe720bd-9e95-4d3f-b25c-4659b3cc2ff1": ["Y2h1bmtfMF9pbmRleF83MzM="], "3f22d7b8-5bb5-4894-8ccb-4d24b090ac44": ["Y2h1bmtfMF9pbmRleF83MzM="], "24e70e14-d6c3-446d-8868-8455ef934e96": ["Y2h1bmtfMV9pbmRleF83MzM="], "f429c9d8-70b7-4fa2-b09b-1f7ea931bdc7": ["Y2h1bmtfMV9pbmRleF83MzM="], "4ea7fcd4-7a6b-427d-9964-392661d00e24": ["Y2h1bmtfMl9pbmRleF83MzM="], "a7b9b9c6-69ca-4483-aab9-b68d96ee4257": ["Y2h1bmtfMF9pbmRleF8yMDMx"], "06672fde-b849-4aba-a1e4-15dcc36ce022": ["Y2h1bmtfMF9pbmRleF8yMDMx"], "02a1b562-d8e1-4a42-91bf-e48f1830eff9": ["Y2h1bmtfMF9pbmRleF84MjM="], "2868fbb7-94b0-4372-9edc-971c7c1be2fa": ["Y2h1bmtfMF9pbmRleF84MjM="], "c089870c-03ca-4c13-9b05-3fc5ff8905be": ["Y2h1bmtfMF9pbmRleF8yNTk="], "c4e6fb49-2717-445d-9747-6a5dfb897b6a": ["Y2h1bmtfMV9pbmRleF8yNTk="], "cbd299f8-bed5-43c8-abc8-040deb00226d": ["Y2h1bmtfMV9pbmRleF8yNTk="], "35bd7eda-2100-499e-b800-e9d8497a75c6": ["Y2h1bmtfMV9pbmRleF8yNTk="], "86d80a02-f05b-41af-bdb9-32685a397f7e": ["Y2h1bmtfMF9pbmRleF8xMzQw"], "a68acbd9-37b8-4916-afe3-53a3486b7b69": ["Y2h1bmtfMF9pbmRleF8xMzQw"], "aadf0b1b-8d25-4c71-9911-df63e4e34007": ["Y2h1bmtfMV9pbmRleF8xMzQw"], "1f2955f2-b4cd-4d05-8b72-84b98c93eb9b": ["Y2h1bmtfMV9pbmRleF8xMzQw"]}}