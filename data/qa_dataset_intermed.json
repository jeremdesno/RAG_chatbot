{"queries": {"0e6bce00-8ec5-4226-bc8a-fda53ac3484d": "What are the administrative ports required for configuring {% data variables.location.product_location %} and running certain features? Please list the ports, services, and descriptions.2. What ports are required for end users to access the web application and Git over HTTPS, HTTP, SSH, and Git protocol? Please provide the ports, services, and descriptions.3. What ports are necessary for email support for end users? Please list the ports, services, and descriptions.4. What is the purpose of the ports 122, 1194/UDP, 123/UDP, and 161/UDP in the context provided? Please explain their roles in detail.5. How can I ensure that the default SSH port (22) is dedicated to Git and SSH application network traffic? Please provide the necessary steps.6. What is the", "c0dd0743-8678-4350-8c92-784ba95e7d5c": "What is the difference between the ports required for {% data variables.product.prodname_actions %} and {% data variables.product.prodname_github_connect %} to connect to {% data variables.location.product_location %}", "34e7fcb4-dd11-4fd7-a3bf-29760692c6ab": "Generate according to: {% data variables.product.prodname_actions %} ports{% data variables.product.prodname_actions %} ports must be accessible for self-hosted runners to connect to {% data variables.location.product_location %}. For more information, see \"AUTOTITLE.\"| Port | Service | Description ||---|---|---|| 443 | HTTPS | Self-hosted", "123c77ce-7c89-413d-8bfa-ea8862bcaca6": "What are the ports required for {% data variables.product.prodname_actions %} to connect to {% data variables.location.product_location %}", "0542e973-bfaa-4a3c-98ae-5816dfbfc12a": "How can the X-Github-Next-Global-ID header be used to facilitate migration to the new global ID format in the {% data variables.product.product_name %} GraphQL API, and what are the potential consequences of treating global node IDs as opaque strings instead of decoding them for type information?", "2976e1e1-a7f1-4401-b3dc-ae566cab0012": "What is the reason behind the deprecation of the legacy global node ID format in the {% data variables.product.product_name %} GraphQL API, and what steps should be taken to ensure consistency and continuity of application functionality", "9d3e34d3-57a9-48bd-8909-40d6e7e15c90": "How can developers update references to legacy IDs in their applications to use the new ID format provided by the GitHub API's `X-Github-Next-Global-ID` header", "fcce1d6d-6134-4d24-aef7-682f2ae76230": "What is the purpose of using aliases in a GraphQL query to submit multiple node queries in one API call, and how can this be achieved in the context of the GitHub API?", "6feb3bb5-65f4-495d-a1e6-e4e190990968": "What should I avoid when removing a high availability replica for {% data variables.product.prodname_actions %} external storage, and what alternative solutions are recommended to prevent multiple instances from writing to the same external storage configuration?", "dc2b88fc-83e8-40bf-b1fb-53441f95cc21": "What is the recommended approach for ensuring data redundancy or replication for {% data variables.product.prodname_actions %} external storage, and where can I find more information about this", "e9810533-f1a0-4876-bfd0-e5b5a4b58e96": "How do I promote a high availability replica for {% data variables.product.prodname_actions %} external storage, and is any additional configuration required for {% data variables.product.prodname_actions %} during this process", "b87a330e-6371-4622-89a7-381457731cfe": "How does {% data variables.product.prodname_copilot_for_prs %} generate a summary of changes made in a pull request", "0ee6e08e-c6ad-49b4-a3cf-27b929777249": "What types of files are excluded from summarization by {% data variables.product.prodname_copilot_short %} in the summary generation process for pull requests?", "29052032-ce34-4a47-b893-c7ad29675867": "How does the author suggest improving the performance of pull request summaries, and what is the intended role of the feature in this context", "15813d7d-4010-4661-b054-c684003d2446": "What limitations or issues should the user be aware of when using the pull request summary feature, and how can feedback be provided to the developers?", "bb471343-cb30-44e0-9c4d-8a2f73fd5504": "How does the current implementation of {% data variables.product.prodname_copilot_for_prs %} in pull requests affect the processing time and accuracy of the generated summaries", "6577d4fd-35c1-4e12-ad43-7de4d23b3381": "What is the current scope limitation of {% data variables.product.prodname_copilot_for_prs %} in pull requests, and how does it impact the summarization of larger pull requests with more than 30 referenced files?", "4b80ccfa-f37b-4eb7-bce5-1c7b1acc7ed0": "What is the potential harm that could arise from the summary of a pull request including harmful or offensive terms, and how can this be mitigated", "bf49fa1d-347b-4459-a84d-a5b10c367a9c": "Answer: According to the context information, during the beta, a feature was recommended by the team. This recommended feature is different from the current version of the software. However, the context information doesn't provide any specific details about the differences between the recommended feature and the current version.2. What is the potential harm that could arise", "d525ae38-00b2-4e04-8166-98da3d23b45e": "Given the context information and not prior knowledge.generate only answers based on the below query.You are a Student. Your task is to answer the following questions based on the context information provided.Questions:1. How does the recommended feature during the beta differ from the current version of the software", "83c00232-7b6e-4d54-a83a-bbafa9cd5bcf": "How does the recommended feature during the beta differ from the current version of the software", "12051d0b-5705-4e59-8290-73502f2b6bb9": "How can I create a workflow that performs a Docker build and publishes Docker images to Docker Hub or {% data variables.product.prodname_registry %} using the provided guide", "4d09f86d-34ca-4aeb-a668-7472557158a4": "What prerequisites are necessary to follow the guide for publishing Docker images to Docker Hub or {% data variables.product.prodname_registry %} using GitHub Actions", "93dce8bc-9888-441e-a63e-f5890a6d4cde": "How can I ensure that my Docker repository contains all the necessary files for performing a Docker build and creating an image", "5acbcacd-3e6e-46fd-a36c-2dd45297b86d": "What is the difference between using Docker Hub and {% data variables.product.prodname_registry %", "26f2a17f-6ab6-41e8-bfb1-a56cff558245": "What is the role of the Docker `login-action` and `build-push-action` actions in publishing Docker images to Docker Hub or {% data variables.product.prodname_registry %} using GitHub Actions", "3afbb70b-4c2d-43e7-ac95-4e6630142065": " How can I authenticate with Docker Hub using secrets in GitHub Actions", "a6b72001-42b8-4c9e-b5f9-88a84dd83414": " How can I extract metadata (tags, labels) for a Docker image in GitHub Actions using the `docker/metadata-action`", "d5cd411d-5665-4365-93af-7974ee3c9854": " How can I build and push a Docker image to Docker Hub using GitHub Actions using the `docker/build-push-action`", "dfedee36-9d01-481a-b530-4e7f494d61b7": " How can I check out a repository in GitHub Actions using the `{% data reusables.actions.action-checkout %}`", "0346a0a2-2df6-4673-80d7-e5a2277e6f02": " What is the format for specifying tags when pushing a Docker image to Docker Hub using GitHub Actions in the `docker/build-push-action`", "114c3cf3-b480-4ebe-9474-cdf046dcb323": " What is the name of the GitHub Actions workflow file that should be used for publishing a Docker image to D", "39bf18f8-433c-405e-b5c9-3142b4a6ec8b": " How can I ensure that GitHub Actions use SHA pinning", "aa3e0455-bcc0-4188-86ad-dff30392fe84": "How can we automate the process of building and pushing Docker images to {% data variables.product.prodname_registry %} using GitHub Actions? Provide a step-by-step guide with specific action names and required options.2. What are the necessary options required for logging in to {% data variables.product.prodname_registry %} using the `login-action` in GitHub Actions? Explain the significance of the `registry`, `username`, and `password` options.", "3e610b04-c602-4b3f-90be-f53908259c19": "How can one publish a Docker image to the GitHub Container Registry using GitHub Actions? Provide step-by-step instructions on the necessary actions required, including any required configurations or settings. Be sure to include details on how to authenticate with the registry, how to specify the image's tags and labels, and how to trigger the workflow.2. What are the differences between using GitHub's Container Registry versus a third-party registry for storing and sharing Docker images? Compare and contrast the features, pricing, and ease of use of both options, and provide examples of when each might be more appropriate. Additionally, discuss any potential drawbacks or limitations of each approach.", "16b0aae1-7e8b-4f17-b512-6a1d7d3848b7": " How can I use the `login-action` and `build-push-action` actions to publish a Docker image to both Docker Hub and {% data variables.product.prodname_registry %} in a single workflow? Provide specific instructions on how to set up the workflow using the provided examples.- How can I modify the provided workflow to publish a Docker image to a custom registry using the `login-action` and `build-push-action` actions? Please provide detailed steps on how to update the workflow file with the necessary registry information.", "c71eb912-9bbd-4c4b-bfb6-61b18558b9bb": "  - How does the \"push_to_registries\" job handle logging in to different registries, and what information is required for each login step?", "475685da-58c2-4411-a478-42663847f9e9": "  - What is the purpose of the \"push_to_registries\" job in the provided context information", "3891e1bf-73a7-49be-9110-8971a3d5d8db": "How does the `metadata-action` action generate tags and labels in the provided workflow?", "4a626847-6f16-4043-9237-f97844073e63": "What is the purpose of the `login-action` in the provided workflow", "aebed5ca-33ca-4eb2-9a9f-c23f837d639c": "How do I create a personal GitHub account and set up an organization for a client using GitHub's billing system? Provide step-by-step instructions and any necessary context information.2. How do I upgrade an organization's subscription to a yearly paid subscription and add additional seats to the organization using GitHub's billing system? Please provide detailed instructions and any necessary context information.", "e0b333be-d991-43e8-87a2-31e8f997c71d": "How many seats can be added to a {% data variables.product.prodname_dotcom %} organization through the \"Add seats\" feature", "1bb553d2-ef59-4a1f-b6c4-aff91f846830": "What role should your client have in the organization after inviting them, in order for you to transfer ownership to them?", "75b80cad-6a49-460d-9f95-915e557620ea": "What information can be modified for an OAuth app in {% data variables.product.prodname_dotcom %}?", "987210a9-892d-4894-98de-937c46ab368c": "How can I modify an existing OAuth app in {% data variables.product.prodname_dotcom %}", "ef3e0179-c5d0-4073-936a-2a58515f172b": "What is the purpose of creating a `.gitattributes` file in the root of a repository, and how can it be used to manage line endings consistently for all repository contributors, regardless of their Git settings and environment?", "467dc1a3-535d-4ebe-a3ca-adc877989eb1": "How can Git be configured to handle line endings automatically, and what are the different arguments that can be passed to the `git config core.autocrlf` command for macOS, Windows, and Linux environments", "d3911892-6655-4b36-9c9a-1e8780716d6a": "What is the purpose of adding a `.gitattributes` file to a Git repository, and how does it affect the behavior of Git when working with specific types of files? Provide examples of settings that can be used in this file to modify Git's handling of line endings and file types.2. How can you ensure that all line endings in a Git repository match a new configuration, such as converting all files to use LF line endings? What steps should be taken before adding or committing any changes to the repository to avoid corruption of binary files? Provide a step-by-step process for normalizing line endings in a Git repository.", "e634361c-3640-4dc0-aaa4-98c2194237ce": "How do you update all files on the current branch to reflect the new configuration after marking files as binary in \".gitattributes\"? Provide step-by-step instructions.", "4bd841c9-ec01-457d-86b2-e9122ef5e866": "What is the purpose of explicitly marking files as binary in \".gitattributes\" and how does it help in avoiding loss of local changes to files in the repository", "18b725b2-48ba-4a46-bf47-0cff9e2981be": "How does the tool switcher in the documentation help people accomplish tasks using different tools", "71fd0ad4-2a05-467b-b81e-54d8fccd3391": "What is the purpose of using tool tags in articles with tool-specific information, and how do they present relevant information for different tools?", "c4c7f4aa-c62c-48be-b2ac-72607c98d94f": "What guidelines should be followed while adding new tools to {% data variables.product.prodname_docs %} documentation?", "c4897e6e-7eb2-438f-ae98-7a82570ef6ef": "How can tool tags be used in {% data variables.product.prodname_docs %} to provide specific content for different tools", "f6aec6b3-c796-40e7-a39d-70c3d584ab7b": "What is the proper way to add new tools to the system in a specific order, considering the alphabetical arrangement?", "3d129430-33ba-4e92-9cf0-81083b077810": "How should new tools be added to the system in a specific order", "72848752-ecf1-4ba6-a358-14b63a472a7b": "What are the differences between the {% data variables.contact.premium_support %} plans, Premium and Premium Plus / {% data variables.product.microsoft_premium_plus_support_plan %}, in terms of hours of operation, initial response time, support channels, training, members with support entitlements, resources, and health checks", "c649361a-4b77-4aaf-bb67-633bcbb18265": "How does the Premium Plus / {% data variables.product.microsoft_premium_plus_support_plan %} plan differ from the Premium plan in terms of incident management and the availability of a Named Customer Reliability Engineer?", "f7de7089-7181-4cba-b7d7-c0bf39547ca5": "What services are included in the {% data variables.contact.premium_support %} plan, and how can a customer contact {% data variables.contact.premium_support %} to report an issue? Additionally, what are the hours of operation for {% data variables.contact.premium_support %}, and are there any holidays during which support is limited? Finally, what is the initial response time guaranteed by the Service Level Agreement for tickets submitted to {% data variables.contact.premium_support %}, and how is the priority level of a ticket determined?", "6800d6c0-75c9-4eb5-993d-733032b469ee": "How can an organization's billing manager or enterprise owner add support entitlements to members of their organization, and what is the significance of having a support entitlement", "b5b15292-0fb2-4308-a7f7-0b1dff956e6f": "How does {% data variables.contact.premium_support %} prioritize support tickets, and what actions do they take for Urgent priority tickets", "5693d896-33aa-4518-ab6f-b2ec5978bfcf": "What is the deadline for installing the minimum supported version of {% data variables.product.prodname_ghe_server %} for customers with an applicable license agreement for {% data variables.contact.premium_support %}?", "9638b085-11ce-428f-b80e-191174ddd0ff": "What actions does {% data variables.contact.premium_support %} take when a ticket is outside the scope of support or when multiple attempts to contact the user go unanswered?", "f86386cc-5863-40aa-be6c-e90468b761d6": "How does {% data variables.contact.premium_support %} handle issues related to custom or unsupported plug-ins, modules, or custom code", "6ab6c454-0db3-4547-94ac-c52d388fad43": "How can a customer request a refund for qualifying credits within the specified timeframe, and what information must be included in the credit request", "5cfd103b-cc8a-4d66-9185-340e9e2c3ead": "Where can a customer access premium content, and what steps are required to do so?", "9fc4fcdc-2e0b-4d2a-af9e-22f4d73bd568": "How can {% data variables.product.prodname_dotcom %} features help in securing dependencies, personal accounts, and build processes in the end-to-end software supply chain? Provide examples of such features.", "e2d3ebe9-6229-4285-b894-b85f7d158342": "What is the end-to-end software supply chain and why is it important to secure it", "4a9feac6-1701-4905-b84f-d35a76d1976a": "What is the process for publishing an app to GitHub Marketplace, and what are the requirements for doing so", "e614946b-ca48-4530-bd39-eefb39d3e214": "What is the difference between GitHub Apps and OAuth Apps, and which one is preferred for publishing apps to GitHub Marketplace? What are the steps involved in publishing both types of apps to the marketplace?", "ad61f349-a7e7-4342-8780-31e902e0bdf2": "What information can I access through the metrics and transactions provided for my {% data variables.product.prodname_marketplace %} listing, and how can I access it?", "4fb68818-9a1f-4c4c-a8e7-6f96cb60a83c": "How can I track user billing requests using the {% data variables.product.prodname_marketplace %} API and webhook events", "8e02401d-8918-4f1c-9022-e51a3cbc48f7": "What types of information does GitHub collect from users, and under what circumstances does the company collect personal data from third parties?", "81bec0cc-65e3-44e2-b3db-687b3118d269": "Based on the information provided, can you summarize the role of GitHub in processing personal data for users in North America and outside North America", "6802103e-a6e5-4d66-a421-a95d2762ba79": "Based on the information provided, can you summarize the role of GitHub in processing personal data", "32a14862-b4f9-49ed-9298-65da9bb04d9e": "How does GitHub ensure the security of personal data on its platform?", "4b9db962-1df4-4d5e-b4cf-75154ac4b933": "Based on the context information provided, can you summarize the role of GitHub in processing personal data for its enterprise customers", "a4d5da0d-22c9-40ca-bc07-f0916b2d4902": "How does GitHub collect personal data from its users, and what types of information does it gather?", "7023e66f-73a6-402e-a337-b7b0fe7ee9dd": "Based on the information provided, can you summarize the types of content and files that are collected by the service", "df0ad37a-2c41-4226-907d-64047862c4d7": "How does the service collect information about a user's transactions and interactions with the platform?", "26994960-71c6-498d-a85b-24eaf437d1b4": "How does GitHub collect personal data from third parties, and what types of information might be received in this way", "ae1efa0b-292b-4d6f-a3c1-f9f09a5c65fd": "What types of information does GitHub infer from other data it collects, and how is this information generated?", "2c7b6c2a-ea0d-4830-9749-3fb10a816f40": "How does GitHub allow users to control the collection and use of their data, and what options are available to them", "3d813faf-afc6-42eb-a8b6-b2382ae5fdcf": "How does GitHub use personal data to improve and develop its products and services, and what benefits does this provide to users", "67c27f8e-8a6b-43d0-a96e-6abb70d45712": "How does GitHub ensure the accuracy and completeness of the data it collects, and what steps does it take to correct any errors or omissions?", "563317f9-8ff0-4a05-bc06-ad05342f4112": "How does GitHub use the information it collects from its users, and what purposes does it serve", "6934165d-1344-43b6-a6e7-a00315bfc9be": "What types of data does GitHub collect, and how does it obtain this information", "b50a1751-f653-449b-b955-8d6eab2797e1": "How does GitHub ensure the security and privacy of its users' data, and what measures does it take to prevent unauthorized access or misuse", "7295f43f-a75f-472f-a959-383cf1e98894": "How does GitHub handle user data when they choose not to provide certain information, and what consequences may result from this decision", "997f3df8-faad-4e4c-9e43-427430b0bee2": "How does GitHub allow users to share their personal information with third-party applications, and what responsibilities do users have when using these applications", "8e6dd6d9-a4c9-4d5b-b018-ba9885768372": "What options are available to users on GitHub to control the visibility of their personal information, and how can they ensure their privacy when commenting on public repositories?", "68f4ee3b-962b-4ca1-8f6a-a4f5ccf8f0c0": "What information does GitHub provide when a user authenticates into a Developer Product using their GitHub profile, and how can a user access, update, alter, or delete their personal data stored in an Organization's Account?", "7d06aed6-a9c4-4aeb-8240-d161ec80bc7e": "How does GitHub share personal data with service providers and affiliates, and what types of services do these providers perform", "78a0d82e-93ad-4060-b52a-9ccc9cb12349": "What choices does GitHub provide to users regarding the processing of their personal data, and how do these choices differ for users associated with an Organization under their Account?", "21eefa39-ccb0-43ed-8609-45036c2533aa": "Based on the information provided, can you summarize the circumstances under which GitHub may disclose personal data to third parties", "7b74c6b8-0509-4a1b-b34c-130cca825bca": "What happens to a user's profile information when they request deletion? Are there any exceptions to this rule? If so, what are they?", "ef864680-a4e9-40dd-89fa-895c683dcba9": "How can a user control the information that GitHub collects about them", "e5b83d3b-dc43-4299-b369-44928a2d5f2f": "What types of important communications cannot be opted out of, and why are they necessary for the proper functioning of GitHub's", "f98631ee-1add-4446-afa5-0a8a67f07a0e": "How does GitHub use cookies and tracking technologies, and what purposes do they serve in providing, securing, and improving the service", "9f55d12f-f0ff-49b9-9b48-425111f2c29a": "How does GitHub associate actions with a user's email address, and what are some examples of these actions in the context of Git version control", "5b1e78be-51a8-49a8-8036-dafc6091150f": "What types of communication can a GitHub user expect to receive via email, and how can they manage their communication preferences", "e35d5da1-be16-4d0f-80dd-9ae3711f24a2": "How can a user opt out of receiving marketing emails from GitHub, and what laws and regulations govern their use", "19f207c3-937f-4a9a-9179-b0a99777b98a": "How can a GitHub user request access to their data, and what methods are available for data portability", "0b7192b4-6044-4b68-9cc5-b0a9a4bf0549": "What email settings does GitHub offer, and how can a user configure them to manage their communication preferences", "6de631ce-4fd8-4467-88a3-98ccf5114446": "What is the purpose of using cookies and similar technologies on Enterprise Marketing Pages, and how long do these cookies stay on a user's device", "ab50f441-7308-4473-98aa-3e2ad439cea9": "How does GitHub use cookies and similar technologies to maintain the integrity of its Service, and what other purposes do these technologies serve?", "9f02dc63-bf4f-4086-b710-68ecdd5ca4b0": "How do web servers recognize a user's browser over time using cookies", "57dd4810-55e8-406d-9015-31ed3fd6c23b": "What are web beacons and how do they allow third-party content on websites to log information about a user's device and set cookies?", "4c5a4bea-80f7-4bad-8614-a91e9b2c3362": "What information does GitHub collect or infer through the use of cookies, and with whom does it share this information", "2cac8347-7fef-42ea-bc74-ac7e1cc5be8b": "How does GitHub use advertising cookies, and how do they differ from social media cookies in terms of their function", "eb4f1bc1-9c2e-4594-a879-f4cced6d049b": "Can you explain the difference between required cookies, analytics cookies, social media cookies, and advertising cookies, and how do they contribute to the overall functionality of GitHub's websites", "15cb90cd-3dbd-4459-a6cf-860cb0044ed2": "What types of cookies does GitHub use on its websites, and for what purposes", "11a974fa-d3b6-4e72-8a09-b83876a0d447": "How does GitHub use required cookies, and why are they necessary for the website to function properly", "db99a497-5aa7-441a-8b10-a8d339d1987c": "How do social media cookies work, and how do they contribute to personalized advertising on GitHub's websites and social media platforms", "55f3a696-518c-4629-be0f-277b7b7f50de": "How does GitHub use analytics cookies, and what benefits do they provide for improving the website's functionality", "7958e994-01c8-495a-9700-88ec13c4750f": "How do cookies track user behavior on websites, and what types of information do they collect", "dad183c1-d245-4360-a3c1-a3772406831c": "What options are available for users to manage and disable non-essential cookies on GitHub Enterprise Marketing Pages and on the web in general?", "cbd43011-5c36-4cb7-8c4f-075c666ea2d4": "How does GitHub secure personal data, and what measures does the company take to protect user information from unauthorized access, alteration, or destruction", "1fca1c36-740b-41bd-b9b1-893526e7b388": "What associations does GitHub participate in to provide users with simple ways to opt out of ad targeting, and in which regions are these associations available? How can users ensure their choices apply to the data collected when using different devices or browsers?", "baa1ad79-9a16-419a-88ee-5b632d83574b": "How does GitHub ensure the integrity of its services, and under what circumstances might it disclose user data to third parties", "59d82b9d-b879-4d2e-a9cc-56f905a89d37": "What is the Data Privacy Framework (DPF) program, and how does GitHub's certification under this program impact its handling of personal data received from the European Union, the United Kingdom, and Switzerland?", "e7bd4960-9bd3-4b66-82e1-8705aa8caa0e": "What steps should I take if I have concerns about the way GitHub is handling my personal data, and how can I contact their privacy team to address these issues? Additionally, what dispute resolution process does GitHub have in place for resolving disputes regarding their handling of personal data?", "9eb7ff7e-41b8-4f65-b915-6b9133a4d88c": "How does GitHub ensure the protection of personal data during international data transfers, and what legal mechanisms do they use to facilitate these transfers", "f938a1ad-8033-4e84-89f1-8975aa715c19": "What is the process for filing a complaint related to GitHub's compliance with the Data Privacy Framework (DPF) Principles, and what resources are available for resolving such complaints", "4e8b5b25-b4b7-41f3-9c20-b410eea50d1d": "How does GitHub ensure compliance with the Data Privacy Framework (DPF) Principles, and what consequences may result from failing to abide by these commitments?", "d4015706-90c4-4694-9494-86787aa14a99": "Based on the information provided, what types of requests can individuals make regarding their personal data if they are in the European Economic Area", "80326b4e-a974-4461-b6f4-dadd76b6dc7f": "How can individuals direct requests regarding their personal data to GitHub if they believe their data is being processed by the company as a data processor?", "5045d46f-2ace-47f0-9d8e-c4db99a99db2": "Can you summarize the information provided regarding U.S. State data privacy laws and how GitHub complies with them", "55c1996c-bc22-4568-9092-635b1629827f": "What categories of personal data does GitHub share for targeted advertising purposes, and how can users opt-out of this sharing?", "d3f21271-b481-493d-b81d-0bcbb41df164": "How can a GitHub user exercise their privacy rights, and what tools are provided for this purpose", "64cdaad2-0d36-449b-a7ef-7dcefe881754": "What is the process for requesting information about a business's compliance with California's \"Shine the Light\" law, and who should this request be directed to?", "5c33d656-e684-4573-9d7d-a7708cf67df3": "Based on the information provided, can you summarize the handling of personal information by GitHub", "7ccf7816-f768-42ac-878c-4704f1cd22e7": "What categories of personal information does GitHub collect and why? Please provide examples of the purposes of processing and the categories of third-party recipients with whom they share this information.", "e72761f3-901c-4e63-9114-56d59bbc1749": "Based on the context information provided, can you summarize the categories of personal data that GitHub collects, processes, or discloses, as outlined in the list provided", "25ac4d56-edfa-4795-aa40-00ae0d1b01a8": "According to the context information, which entities does GitHub share payment and billing information with, and what purposes does GitHub have for sharing this data?", "6622a7a2-54fd-421d-9e93-8137b681e666": "Based on the \"Sensitive Data Type\" and \"Purposes of Processing\" sections provided, can you explain how GitHub collects and processes sensitive data, and with whom it shares this information", "a79b2f0a-b073-4847-ae84-ee74f9ba55d2": "According to the \"Recipients\" column in the table, under what circumstances does GitHub share sensitive data with service providers and user-directed entities? Provide specific examples if possible.", "6af2adbc-4cd1-43d7-a069-1a7067bb92e9": "Based on the information provided, can you summarize the purposes for which GitHub processes personal data", "dee8a73d-d79f-4647-b7d8-4bb51e9fbcf5": "What is the difference between personal data and Not in a Position to Identify Data (NPI) data, and how does GitHub handle NPI data?", "9b10c654-7fb4-4abc-973f-1fa4a5021fd9": "Based on the context information provided, can you summarize the statement \"In certain situations, we may allow a third party to control the collection of your personal data\"", "6eb177ef-d292-428b-84ec-8e1ff9f3f2c3": "According to the Privacy Statement, what type of information does the section \"information we collect\" provide additional details about?", "8127b4b2-86dd-4c46-ad0a-3bc9d3086dcd": "How can an organization owner create an announcement banner for their organization using {% data variables.product.prodname_ghe_cloud %}", "6e795ed3-c6ec-4091-9c8a-1207580047c3": "What are the options available for an announcement banner created by an organization owner using {% data variables.product.prodname_ghe_cloud %}? (e.g. Expiration date, user dismissibility)", "2554cb1a-bd8e-4db1-9ceb-b20bc472e5b5": "How can a user be promoted from the enterprise settings in GitHub Enterprise? Provide step-by-step instructions.2. How can a site administrator be demoted from the enterprise settings in GitHub Enterprise? Provide step-by-step instructions for both the web interface and the command line.", "be897204-6169-4783-ae54-20886bef87de": "Generate according to: Creating a default label{% data reusables.profile.access_org %}{% data reusables.profile.org_settings %}{% data reusables.organizations.repository-defaults %}1. Under \"Repository labels\", click **New label**.{% data reusables.project-management.name-label %}{% data reusables.project-management.label-description %}{% data reusables.project-management.label-color-randomizer %}{% data reusables.project-management.create-label %}Editing a default label", "b6835838-fee6-4729-a2b0-7a7a4740867d": "How can I create a default label for a repository in an organization on GitHub", "31ce5933-98c9-4393-b415-48f8bc2d458d": "How can I edit or delete a default label for a repository in an organization on GitHub", "0a76d75f-c8bb-4f8c-86e2-83da6afadc24": "How can an organization owner manage the costs associated with {% data variables.product.prodname_github_codespaces %} usage", "60bb4f70-8705-4d39-a91c-170dc8c2134d": "What are the ways in which an organization owner can limit spending on {% data variables.product.prodname_github_codespaces %} and {% data variables.product.prodname_actions %}", "864f18cd-916d-402c-8044-f0d6c04bbca7": "What options are available for configuring codespaces created from repositories owned by an organization, and how can these be used to prevent unnecessary charges and reduce storage costs?", "709f26dd-5cda-4c2d-b2f8-112fb74fc4ca": "How can an organization limit the number of codespaces that can be created by its members and collaborators, and what benefits does this have in terms of reducing storage charges", "0b2fe25c-920f-4dc1-bba0-b38e5e03be7e": "How can an organization owner set a maximum retention period for codespaces owned by their organization, as explained in the context information?", "eef3a064-c0d0-43e7-8229-2d07aeed03cb": "What is the process for deleting a codespace in an organization, as described in the context information", "37d75131-aebe-421d-876f-e03d86f59c21": "What are the different ways to locate queries when creating a query suite in {% data variables.product.prodname_codeql %}?", "91d493d4-7c7e-4b43-86f1-03e107ae141d": "How can query suites be created in {% data variables.product.prodname_codeql %} and what is their purpose", "a4a12114-befb-424f-94e2-e3df400499d4": "What is the purpose of adding a `from` field in the `queries` instruction in the context information provided", "d36ebf76-6de5-43b6-a279-e78cba1aef64": "What is the difference between adding a `from` field and a `qlpack` instruction in the context information provided? Provide an example for each.", "aced45b2-0786-4876-bf68-020c0a1012a0": "What is the order of importance for filter instructions in a query pack definition, and how do subsequent instructions affect earlier ones?", "c498178b-c5bd-4326-a19f-98f46fd3674f": "How can you filter queries in a query suite using include and exclude instructions in a query pack definition", "26109e2d-0462-4fc6-8a44-06f2f2536bbf": "What is the significance of the \"metadata tags\" and \"constraint block\" in the context provided? How do they differ from each other? Provide an example of each.2. Can you explain the syntax for filtering queries using the \"exclude\" instruction in the query suite definition? Provide an example of how to exclude multiple queries using a regular expression.", "8cb17e24-e43c-4a65-97b7-65af1451b408": " How can I create a query suite that selects queries with a specific kind and precision level from a CodeQL pack, but excludes queries with a specific severity level", "a14b3ddd-bdf4-4eb0-9f1b-88b721eed3b4": " How can I create a query suite that selects queries with a specific kind and precision level from a local directory in CodeQL", "b0a9ae8f-91f4-483d-a809-80a6cd874ea8": " How can I import an existing query suite definition into a new one in CodeQL", "d23e2fed-3ddf-4539-b2c6-de77aec1b79d": " How can I create a query suite that selects queries with a", "36be622c-4740-45c2-8ea8-31efa30e1918": " How can I exclude certain queries from a query suite definition in CodeQL", "86b41ed7-863d-4ad5-8701-8c05a3922501": " How can I define a query suite that selects all queries with a specific tag and precision level from a CodeQL pack", "29363f28-7b46-4c9d-94fc-7f2ed49c62fb": " How can I view which queries are selected by a query suite definition in CodeQL", "bed1cd29-d0d6-47d7-8d11-7a497f01a1e3": " How can I create a query suite that selects queries with a specific tag and precision level from a local directory in CodeQL, but excludes queries with a specific severity level", "acd7eeb0-b53b-46c2-a2a1-efe573d8ac85": " What is the purpose of the \"apply\" instruction in a {% data variables.product.prodname_codeql %} pack, and how can it be used to apply reusable conditions to multiple query suite definitions", "b7aed02e-a97c-4058-ae59-8179f8600b6e": " How can the \"exclude\" instruction be used to filter queries in a {% data variables.product.prodname_codeql %} pack, and what is the syntax for specifying a version of a pack to use?", "c02ab2dd-eafd-421c-a357-dce59160f638": "How can we apply the reusable instructions from the my-org/my-custom-instructions {% data variables.product.prodname_codeql %} pack to further filter queries from another query suite? Provide an example of how to exclude low and medium precision queries using the import instruction.2. How can we save a query suite in a file with a .qls extension and add it to a {% data variables.product.prodname_codeql %} pack? What is the purpose of specifying well-known query suites using {% data variables.product.prodname_codeql %} packs? Provide an example of how to refer to a well-known query suite on the command line without providing its full path.", "4202c416-e2f5-44ad-911e-802e88dd0e6a": "How can query suites be used with {% data variables.product.prodname_codeql %}? Provide specific examples of commands that accept `.qls` files and how query suites can be utilized in those commands.2. What is the purpose of adding a directory containing \"well-known\" query suites to the `suites` property in the `qlpack.yml` file at the root of a {% data variables.product.prodname_codeql %} pack? How does this impact the usage of query suites with {% data variables.product.prodname_codeql %}?", "c44251c1-484d-4f64-8092-be45907b687a": "How can I delete a completed or older workflow run in GitHub", "c420555a-3b1c-4f35-b79c-ade68a49c0e1": "What permissions are required to delete a workflow run in GitHub?", "f1d095e7-63f4-4ad6-ab5f-335ee0788151": "What happens if an organization owned by an enterprise with email restrictions enabled no longer has any verified or approved domains, and how does this affect email notifications for users in that organization?", "d2efa6d8-5f76-4ae2-8070-2387539306a2": "What is the process for restricting email notifications for an enterprise, and what actions must be taken before this restriction can be implemented", "040ee689-5374-4b35-a6a8-794126ae49c9": "Why is it necessary for each {% data variables.product.prodname_ghe_server %} instance to register their own {% data variables.product.prodname_github_app %}? Can't organizations owned by a {% data variables.product.prodname_ghe_server %} instance install {% data variables.product.prodname_github_apps %} registered on {% data variables.product.prodname_dotcom_the_website %} or on another {% data variables.product.prodname_ghe_server %} instance?", "3cc5d3fc-4cfd-4fa3-9750-203213081838": "What steps are required for a {% data variables.product.prodname_github_app %} to be available to organizations in a {% data variables.product.prodname_ghe_server %} instance that the developer is not part of", "d18a47eb-c288-4d8a-b424-c7e046834ac9": "How does an organization owner in a {% data variables.product.prodname_github_app %} instance register an app, and what are the consequences of making it public", "7e4d824f-0945-4c1c-a87f-40c477f62c94": "What options does an app developer have for accessing the credentials and hostname of a {% data variables.product.prodname_github_app %} instance, and what are the advantages and disadvantages of each approach?", "f65ee5b5-2ce1-4bd1-99e5-f9bb5191ae88": "What are the advantages and disadvantages of having the app developer host and manage a self-hostable version of the app for a {% data variables.product.prodname_ghe_server %} instance", "3727648e-7a75-42a2-b4a3-1d93a9147598": "How should the app code be updated to work with a {% data variables.product.prodname_ghe_server %} instance instead of {% data variables.product.prodname_free_user %}, {% data variables.product.prodname_pro %}, {% data variables.product.prodname_team %}, and {% data variables.product.prodname_ghe_cloud %}?", "a8b2b8e4-0ade-4cb5-9089-ee774d8f15bf": "What information is included in API responses and webhook payloads for {% data variables.product.prodname_ghe_server %} payloads to help determine the version being handled?", "a859d85c-62e2-4f23-8d84-3ba6c665d43d": "How should an app developed for {% data variables.product.prodname_ghe_cloud %} handle differences in REST API endpoints, GraphQL objects, and webhooks between {% data variables.product.prodname_ghe_server %} and other versions of {% data variables.product.prodname_ghe_server %}", "8b248393-db20-41cc-a1ce-94f706805a46": "What are the different sponsorship tiers available on {% data variables.product.prodname_sponsors %} and what are the benefits of each tier? How can individuals set up a range of different sponsorship options, including monthly and one-time tiers, to make it easy for anyone to support their work on {% data variables.product.prodname_sponsors %}? What are the fees associated with sponsorship payouts on {% data variables.product.prodname_sponsors %}?", "98e03823-49fa-4e88-9081-b29c1665a3c5": "How can individuals become sponsored developers or organizations on {% data variables.product.prodname_sponsors %}? What are the benefits of joining {% data variables.product.prodname_sponsors %} as a sponsored developer or organization", "917ea6f5-2f33-4a43-9f71-fe8c26987b93": " Can you provide an example of how to use GitHub CLI to add a comment when an issue is opened in a workflow? What environment variable is necessary for this action?", "b28a4f3f-3d87-4c17-bcee-f98cf8436273": " How can GitHub CLI be utilized in workflows, and what is required to execute any GitHub CLI command in a workflow step", "b20603c1-095d-4538-a31b-c0d11bbbfe81": "What is the purpose of creating a new issue in a repository using the GitHub CLI, and how can we automate this process using GitHub Actions?", "948dc324-696b-410f-af33-bfb66d00f6ed": "How can we determine the number of open issues in a specific repository using GitHub's GraphQL API", "70ce7759-872f-433b-ba38-475154f3fa79": "How can an institution's network access policy restrict access to specific domain names for end users, and what is an example of such a policy", "5c7ee48f-a2da-4dc3-a9eb-450bc7e22e3b": "How can an institution allow access to specific domains, such as those related to {% data variables.product.company_short %}, despite network access restrictions? Provide steps or instructions for creating exceptions in the policy.", "1c5e8630-9806-4217-82eb-8b5dc8e4f733": "What is {% data variables.product.prodname_discussions %} and how can it be enabled or disabled for an organization on GitHub", "ac55a84a-34fa-4fbb-a544-df76a735f199": "What is the difference between managing discussions at the organization level and managing discussions at the repository level on GitHub?", "8b427ccc-acbc-4ff0-9a82-955acae9ad5f": "How can an administrator set the default visibility for new organization members in an enterprise, and what are the options available for this setting", "6b85eff5-6141-4120-a9ea-293b63ff6bae": "Can an administrator prevent organization members from changing their visibility from the default setting, and how is this enforced?", "792b82c0-fa7a-4d66-8f4d-b8bc4eaa1fbf": "Context information:The document is a research paper that explores the relationship between social media usage and mental health. The paper discusses the findings of a study that involved a large sample size and utilized both quantitative and qualitative research methods. The paper also includes a literature review and a discussion of the implications of the study's results for future research and clinical practice. The writing style is academic and the paper includes proper citations and a reference list.", "9d0e8c7b-635a-4bc7-8ff4-ed25cc0ff702": "Based on the context information provided, can you summarize the main idea or topic discussed in the document", "f335ab9d-7815-42a6-9e9c-f9829c5c9a50": "How does the information presented in the document contribute to our understanding of [insert relevant topic]", "0586ca11-4830-4b6c-a439-885d0c9f7fad": "How does {% data variables.product.prodname_copilot_for_prs %} scan through a pull request on {% data variables.product.prodname_dotcom_the_website %} to provide an overview of the changes made in prose", "89f93295-edef-4b2e-a5b9-c4f0e3aeb77b": "What are the benefits of using {% data variables.product.prodname_copilot_for_prs %} to generate a summary for a pull request on {% data variables.product.prodname_dotcom_the_website %}", "b88f1d98-8c8a-41d9-957b-96868b252ac2": "How can {% data variables.product.prodname_copilot_for_prs %} be utilized to generate a summary for a pull request on {% data variables.product.prodname_dotcom_the_website %}", "ab0aa9bc-2677-44d6-96a9-d64acc5c7ef7": "Where can {% data variables.product.prodname_copilot_for_", "2f966b62-9830-4a9e-b0e2-a09919f5ce2e": "How can you ensure that the description of a pull request accurately reflects the changes being made, as mentioned in the context information?", "5f7fd615-1a33-4b19-87e2-9f7db8af9e15": "Can you summarize the instructions provided for creating a pull request in the context information", "9f6c435b-b1ee-4a12-ab1e-09c6af8f6120": "How can I search for discussions within a specific organization or repository using {% data variables.product.product_name %}? Provide an example using the `repo` qualifier.2. How can I restrict my search for discussions to the title, body, or comments using {% data variables.product.product_name %}? Provide an example using the `in` qualifier.", "31834693-9798-43a8-b446-6145b98a4efb": "How can you search for a discussion that has been answered using the `is` qualifier in GitHub? Provide an example.2. How can you filter by the visibility of the repository containing the discussions using the `is` qualifier in GitHub? Provide an example for a public repository and an example for a private repository you can access.", "8bf95dd6-4fb1-4f3a-b037-799d8efa3a11": "How can the \"answered-by\" qualifier be used to search for discussions on GitHub? Provide an example.2. What is the difference between the \"involves\" and \"commenter\" qualifiers in GitHub search? How can they be used together to find discussions? Provide an example.3. How can the \"comments\" qualifier be used to search for discussions based on the number of comments? Provide an example using the greater than and range qualifiers.4. How can the \"created\" and \"updated\" qualifiers be used to filter discussions based on their creation or last update time? Provide examples using dates in the format provided.", "8ce88b8c-1ba5-4f99-acdc-6302235c4cbc": "Given the context information and not prior knowledge.generate only answers based on the below query.You are a Teacher/ Professor. Your task is to provide EXACTLY 2 answers for the questions asked in the previous instruction. The answers should be diverse in nature across the document. Restrict the answers to the context. Answers should be understandable without having access to the context.Answers should be focused on once aspect at a time.answers:1. To filter discussions by specific categories using the search function, you can use the qualifier \"category:CATEGORYNAME\" in your search query. For example, \"**category:Ideas**\" will match discussions that belong to the category named \"", "d8726915-9374-4c49-b213-7ac5eba1a701": "How can discussions be filtered by specific labels using the search function", "1131236b-8086-404b-be47-3ad2d56b0415": "How can discussions be filtered by specific categories using the search function", "ac675f1f-5dd4-4890-ae87-b960c194d198": "How can I downgrade an app for my personal account on GitHub Marketplace? Provide step-by-step instructions including accessing settings, choosing a new plan, and issuing plan changes.2. How can I downgrade an app for my organization or enterprise on GitHub Marketplace? Please provide specific instructions for accessing organization settings, choosing a new plan, and issuing plan changes. Be sure to distinguish between downgrading for an organization versus an enterprise.", "ca06f505-dd17-4a7a-83e0-6754df4706af": "What are some actions you should take after changing your password to ensure the security of your account, as outlined in the context information?", "a3657fca-126b-4b93-9c6a-6d62d2cc4f1d": "What is the importance of changing your password in response to a security incident, as mentioned in the context information", "43b26e31-858a-408c-8836-a28176cf7d73": "What is the importance of reviewing the list of collaborators for each repository, and how can this help prevent unauthorized access to projects", "d6ca69d4-6b9e-40fc-8524-a751f8278d4b": "Given the context information and not prior knowledge.generate only instructions based on the below query.You are a Software Developer. Your task is to implement a feature that allows users to easily search for specific content within your application. The search functionality should be intuitive and user-friendly, with clear and concise results. Consider implementing features such as autocomplete, filtering, and", "777d73a9-4f51-4275-8119-b620c3af1e84": "What is the significance of reviewing webhooks on repositories, and how could an attacker exploit them", "df73a694-b026-483f-8e40-d82d19203570": "What is the potential risk associated with creating new deploy keys, and how can outside servers gain access to projects through them", "bf5941dc-4fa1-4fdd-948f-00503aa8c1c2": "How can recent commits made to repositories be reviewed, and what should be looked for in these commits", "2daffdf7-afad-4766-b6aa-fc3bd6e281f0": "How does the AI-powered generic secret detection feature in {% data variables.product.prodname_GH_advanced_security %} work? What type of input does it process and what output does it display?", "ce7c7ede-684b-4e3a-bdf0-c95ff25a4dec": "What is generic secret detection and how does it differ from partner or custom pattern detection in {% data variables.product.prodname_secret_scanning %}", "e5842f14-99a2-496f-8324-589c32cf728e": "What should I do when I encounter false positive alerts in AI-powered generic secret detection for {% data variables.product.prodname_secret_scanning %}?", "b86da3a8-9e17-4d49-ae6c-7a07e5e79c67": "How can I improve the performance of generic secret detection in {% data variables.product.prodname_secret_scanning %}", "52cdb6f0-742d-4084-ae11-3b8894abad50": "How does AI-powered generic secret detection differ from the existing {% data variables.product.prodname_secret_scanning %} feature in terms of false positive alerts", "43800a1a-1e06-4f14-9355-2d9c8cfb174e": "Can you provide further reading on the topic of AI-powered generic secret detection?", "c866a531-c4c9-491b-b8be-7154082be581": "What steps should security managers and maintainers take to triage AI-powered generic secret detection alerts due to the potential for excess noise", "22d1878b-b75c-4034-bd5b-4ab11faff35a": "What is the potential for incomplete reporting with AI-powered generic secret detection, and how can organizations ensure the security of their code in light of this", "0ead6e2a-ec12-41e4-a5aa-4a93f45f820e": "How has generic secret detection been evaluated through Responsible AI Red Teaming, and what ongoing monitoring is being done by {% data variables.product.prodname_dotcom %}", "d7654429-3b9b-402e-a5ff-ffc2e004fa20": "Based on the automation options provided, how can we ensure that all newly added pull requests are moved to the \"In progress\" column", "c2856b24-3e32-4e0b-b55b-a8820f264387": "How can we track the progress of our {% data variables.projects.projects_v1_board %} using the provided options? Provide specific examples of how cards in different columns contribute to the overall project progress.", "42270d21-bf98-4d8f-ae49-72d62db1577b": "How can we calculate the total number of nodes in a GraphQL query with multiple nested queries? Provide an example calculation.", "f0d51942-9370-41af-b252-2400bd7dcc49": "How many nodes can be requested in a single GraphQL API call, and what are the limitations for the `first` and `last` arguments", "39045994-5e11-4907-912b-182b97f5f4cb": "How can a site administrator set rate limits for their instance of {% data variables.product.product_name %} and what are the implications for users and organizations outside of the instance?", "8892606b-3501-472a-8a50-8bcf75bc6162": "Based on the context information provided, can you explain the concept of rate limits in the GraphQL API and how it helps prevent abuse and denial-of-service attacks", "844ca970-ea7f-45a3-9655-dfa9e8cbd864": "What is the rate limit for OAuth access tokens generated by a GitHub App, and how does it differ for apps owned by a GitHub Enterprise organization? Additionally, what is the point value of a query, and where can I check the status of my primary rate limit?", "d82bb7bb-5a86-4cce-8712-fda53c939d19": "How many points per hour can a user with a GitHub App installation on a GitHub Enterprise organization request, and what factors determine the rate limit for installations with more than 20 repositories or users", "582117a8-8500-480a-ad73-72f01e05333f": "What information can I obtain by querying the `rateLimit` object in a GraphQL request?", "9bf74462-d8bc-46be-91a1-123e357c727d": "How can I determine the current status of my primary rate limit using the response headers provided", "07614ada-18a2-4ee7-8b46-7e398546c4ad": "What is the significance of the `x-ratelimit-remaining` and `x-ratelimit-reset` headers in the response of a rate-limited request, and how should a developer respond to exceeding a secondary rate limit?", "52ea44e6-5bed-44fa-a5d1-879a64b4863a": "How many requests are required to fulfill the provided GraphQL query, and what factors contribute to the total number of requests", "038460ff-084c-4716-896b-b6b01bd4d4f3": "What is the recommended way to view API requests for troubleshooting integrations that exceed the rate limit?", "4820c666-e2f1-4d7e-a46b-165ab94bc5e8": "How can one avoid exceeding the rate limit while using the API", "b05b442d-014a-407a-ad98-0599ef4474c4": "How can an organization owner or project board admin change the visibility of a project board in {% data variables.product.prodname_project_v1 %}", "a92f8e11-1c9c-4e5c-ad49-62181694465a": "What are the different visibility options available for a project board in {% data variables.product.prodname_project_v1 %} and who can be given write or admin permissions by adding them to the board as a collaborator?", "54fc0423-b8e2-4d5c-93a0-97fbd5ccbdef": "How can one check the status of a self-hosted runner in a GitHub repository, and what are the possible statuses that can be displayed", "a5200a52-de67-4ead-86e4-2e149d011fbb": "What is required to check the network connectivity of a self-hosted runner, and what arguments should be provided to the `run` script for this purpose?", "fe71f669-8d2d-4aeb-a60b-1835f701d950": "What environment variable should I set before configuring and running the self-hosted runner application to disable TLS certificate verification?", "2d9990ea-5d88-4c28-a0d8-787e52d393c1": "How can I test the communication requirements of my self-hosted runner machine using the provided script", "7a152972-265f-4895-a02c-3f4da948f43e": "How can I disable TLS verification for a self-hosted runner application in {% data variables.product.product_name %}", "a2e3ca56-c428-467b-9fba-91be0f5f2eb8": "Where can I find the detailed log files for a job executed by a self-hosted runner application in {% data variables.product.product_name %}?", "1019a4f7-44f7-4797-90d0-7baa016bea4c": "How can I monitor the real-time activity of a self-hosted runner application service on a macOS-based system using launchctl", "3f3d71d2-a0b6-4a1c-8134-6750d16ac11c": "How can I check the status of a self-hosted runner application service on a Linux system using the systemctl command", "eaaed510-f76e-4790-8b97-1034a7a52469": "How can I check the real-time activity of a self-hosted runner on a Windows-based machine using PowerShell", "c66df3fa-195c-44e6-a527-318966043f66": "How can I view the status of a self-hosted runner on a macOS-based machine using launchctl", "8cf7b8ec-eb3e-472c-a627-cdc330e79e04": "How can I check if the self-hosted runner is updating itself automatically, and where can I find information about update activities?", "533843f9-0493-4eee-bdfa-2df9a84d9b02": "What is the purpose of the \"ActionsRunnerService\" mentioned in the context information", "2401e36b-5546-4adf-9108-466c45a5d193": "How can I verify if Docker is installed and running on my self-hosted runner? Provide step-by-step instructions using the command line interface.2. What should I do if my self-hosted runner's service account does not have permission to use the Docker service? How can I identify the service account and grant the necessary permissions?", "c2663386-299d-40e4-bc0b-8d41f1da3ffd": "What command can you use to check the location of the Docker engine binary on a system where it was installed using `snap`?", "27704590-c8e1-44e4-8a32-198e5796fdf2": "How can you determine whether the Docker engine installed on your system was installed using `snap`", "17ea024c-220a-47f4-be95-709f833ca608": "What is the difference between installing and authorizing a {% data variables.product.prodname_github_app %} on an organization, and who is authorized to do so within an enterprise that pays by credit card?", "796db530-332e-495c-946d-07674608fa5e": "What is {% data variables.product.prodname_marketplace %} and how can I install and purchase {% data variables.product.prodname_github_apps %} from it", "4263fcff-f811-420f-87e7-28f4d4652146": "What is the role of \"app manager\" in an organization when it comes to installing {% data variables.product.prodname_github_apps %}", "e99cc9f5-1399-407f-a9ab-b434b0ae07eb": "How can organization owners prevent outside collaborators who are repository admins from installing {% data variables.product.prodname_github_apps %}?", "61b8375f-4168-4b94-acbd-5a84174d523b": "How can one suggest changes directly from a comment on a specific file or section in a pull request's Files changed tab in GitHub", "73802430-b695-4f70-995b-8c98568f42e6": "How can one leave general comments, questions, or props on a pull request's Conversation tab in GitHub", "5f682257-b99e-47a9-8d10-bbaefeb59a1d": "How can you notify others of your comment on a pull request on GitHub, as mentioned in the context information?", "2ae51948-0c16-4110-9faf-a346daeede23": "Based on the context information provided, can you summarize the steps involved in adding a comment to a pull request on GitHub", "4aa9f2a9-a1b8-4594-8e13-fc5356711e0b": "What is the significance of private repository forks in the context of workflow runs", "fcccdfa5-9a61-475f-8aad-484a98145650": "How can workflow runs be approved for pull requests from private forks?", "cb361e75-3ec2-42ec-bf31-1f22ca4b8b91": "Based on the context information provided, can you summarize the scenario presented in the guide for creating tasklists using GitHub", "a69f83d3-d1bd-4c3e-9117-d29355ac1cb4": "How can tasklists be used to divide work into smaller subtasks, as demonstrated in the guide for creating tasklists using GitHub?", "deafe74b-3c79-4737-9709-fdc57afcc86b": "How can I rename a tasklist in GitHub", "0bb92fa5-a18f-460d-9b7e-9bee4112c20f": "How can I assign myself to a new issue in GitHub without leaving my tasklist", "51eb2422-ad87-4fb2-a91d-e9118e76fb5d": "How can I convert a draft task into an issue in GitHub", "abd99f98-c58e-4fb8-82a7-67e94df8347b": "How can you create multiple tasklists in a single issue using Markdown? Provide step-by-step instructions.2. How can you add existing issues to a tasklist using Markdown? Please provide an example URL and the Markdown syntax required.", "19f06f8c-4bc2-4f70-a30b-94a54203bc2b": "How can tasklists in GitHub be utilized to monitor the progress of specific tasks? Please provide a step-by-step guide on how to create a tasklist, add tasks to it, and mark them as completed. Additionally, explain how to integrate these tasklists with a project and view their progress.2. What is the significance of converting draft issues into regular issues in GitHub? Walk us through the process of converting a draft issue and closing it. How can we track the progress of closed issues using tasklists? Please provide a detailed explanation.", "5cbbbe6b-f2c6-4bbe-b87c-c4f0b3441fe8": "How can I integrate my tasklist data with a project in Jira", "b0b24759-1ea7-4f9d-acad-87cf7a499e97": "Given the context information and not prior knowledge.generate only answers based on the below query.You are a Developer. Your task is to implement a feature that allows users to search for specific files within a project. The search should be case-insensitive and should return results based on file name, content, and metadata. The search results should be displayed in a user-friendly interface, allowing users to preview and download the files directly. The feature should also include the ability to filter search results by file type, date modified, and other relevant criteria. The implementation should follow best practices for performance, scalability, and security.", "63bdb88e-34a0-4935-a185-5c4fb256181b": "How can I create a tracking issue with two tasklists in Jira", "e3e8d934-890c-4805-9dfb-9cccd835ba2d": "How can expressions be used in workflow files to programmatically set environment variables and access contexts? Provide an example of setting an environment variable using an expression.2. What are the different data types that can be used as literals in expressions, and how should they be formatted? Provide an example of using a literal string in an expression.", "d521f326-46f9-460a-848d-74251440d4aa": " How does {% data variables.product.prodname_dotcom %} compare objects and arrays for equality", "593c11d7-21fa-433b-aa32-7c63780924fe": " How does {% data variables.product.prodname_dotcom %} offer ternary operator like behavior in expressions", "96474d02-6beb-47f9-86ee-5edd8d26b455": " How does {% data variables.product.prodname_dotcom %} compare strings for equality", "28950cc1-40fe-4f8f-8cd3-4f540e950354": " Can you provide an example of using the ternary operator in {% data variables.product.prodname_dotcom %} expressions?", "2f3afb4e-03a6-4b20-90ca-2aba4111a3f8": " How does {% data variables.product.prodname_dotcom %} handle comparisons of NaN values", "4ee858de-ac17-437d-8db4-a38c0ef9c0a5": " What data types does {% data variables.product.prodname_dotcom %} coerce when performing numerical comparison", "dfaaa875-44a2-4515-a64a-b974c7e57ede": " How does {% data variables.product.prodname_dotcom %} perform loose equality comparisons", "bab4ffd9-7483-49ab-9640-f390910a51fd": "How can we set the value of an environment variable based on whether the main branch is being referenced in GitHub? Provide an example using the ternary operator.2. What built-in functions does GitHub offer for use in expressions, and how do they convert data types to strings for comparison purposes? Provide an example using the `contains()` function.", "5ad8a656-e97b-4eb5-bd8a-8601aced56dc": "How can you determine whether a GitHub event is a push or a pull request using JavaScript", "23ce5db8-31e0-48b5-bff4-4447374205b0": "How can you format a string in JavaScript using placeholders and replace values? Provide an example.3. How can you join an array of strings in JavaScript using a separator? Provide an example.4. How can you convert a value to a JSON representation in JavaScript? Provide an example.5. How can you convert a JSON representation to a JavaScript object or data type in JavaScript? Provide an example.6. How can you check if a string starts with a specific value in JavaScript? Provide an example.7. How can you check if a string ends with a specific value in JavaScript? Provide an example.8. How can you escape curly braces in a string when using placeholders in JavaScript? Provide an example.9. How can you", "90313662-d201-401a-afd9-a2cce2bd42cd": "How can the `fromJSON` function be utilized to convert environment variables from a string into a JSON data type, specifically for Boolean or integer values? Provide an example workflow that demonstrates this functionality.2. What is the purpose of the `hashFiles` function and how can it be used to calculate a final SHA-256 hash for a set of files that match a specific pattern? Please provide an example usage of this function in a workflow.", "201ad515-bdad-46e3-a54b-602ab3177212": "How does the pattern matching for `hashFiles` function in GitHub Actions follow glob pattern matching and what is its case sensitivity on Windows", "95ea603a-93fd-4c48-88f0-cff58f79bd95": "What are the status check functions available in GitHub Actions and how can they be used in `if` conditionals? Provide examples for each function.", "1f702823-349d-4ba4-9805-d3bdbc8ab629": "What is the syntax for applying filters to arrays and objects in GitHub Actions workflows, and how can this be used to select matching items based on specific criteria?", "1c08c128-60ff-4d8b-8407-f0ed10f287bd": "How can you determine if a step in a GitHub Actions workflow has failed, and what conditions can be added to this step for further evaluation", "ec42aab6-5af0-4bc2-86ac-0adb92cea866": "How should article titles be written to accurately describe the content and be easily understood by the reader? What are the length limits and formatting guidelines for article titles? Should article titles be consistent across a content type and reflect all of the content within the article? How should article titles use terminology and be written to scale with product changes?", "bc346d87-6f77-4c86-bed5-1f89f3887608": "What is the standard order of content sections in an article, and what types of content sections are required, conditional, and optional", "d9b203b4-94d2-49de-a46f-0ce5d965df29": "What specific words should be included in the title or intro of content to prevent confusion with content about a different product when multiple products are involved?", "95d36f02-f02c-4f1e-aa35-eeef68eac764": "How can the availability of a feature be conveyed in content when it is available in specific products only and cannot be conveyed by versioning alone", "7951d68e-730c-491e-bf1c-9e035e63dca6": "When should a permissions statement be included in an article, and where should it be placed?", "55520aef-1c88-4fa5-8858-73d499c523b0": "How should an intro for an article be written according to the provided context information", "96c0f392-9024-4d82-b133-b70432d7a636": "How can I configure protected branches as an organization owner with repository-level access, and what role should be mentioned in the permissions statement", "cb5f17bb-aa66-4a98-8c56-ab89defe66b9": "When should I use the tool switcher in my articles, and what criteria should I consider before implementing it?", "10842e04-642c-40a5-95c5-f7da6319fd5d": "Based on the context information provided, can you summarize the guidelines for writing a further reading section in an article", "c2eac108-54f8-436c-b0a4-b5f15ead99d2": "How should the title and format for a further reading section be written according to the context information provided?", "b2e2a12f-f41f-40e2-adb6-276a4aef42e4": "How can I delete an existing repository in {% data variables.product.prodname_desktop %}", "593e1c73-2d56-470c-835e-47c78ef1f5e7": "Can you provide a list of keyboard shortcuts for accessing preferences in {% data variables.product.prodname_desktop %}", "ea820049-399d-45f7-afd4-4ece77573192": "How can I view a list of my repositories in {% data variables.product.prodname_desktop %}", "ec1383f7-5a3d-45fc-a788-429b3b9887d4": "How do I push the latest commits to {% data variables.product.prodname_dotcom %} using {% data variables.product.prodname_desktop %}", "174e85fe-1fab-4525-bee8-2e375a5db245": "How can I open a repository in my preferred editor tool using {% data variables.product.prodname_desktop %}", "8b0624ee-15bb-4791-8c4f-0545741b0d12": "How do I view the repository on {% data variables.product.prodname_dotcom %} using {% data variables.product.prodname_desktop %}", "cd526454-3515-45cd-8b43-2ac14c95bac9": "How can I view the repository on GitHub.com from within GitHub Desktop on Windows?", "c5872950-e353-4826-a0be-4e1cc1892ef6": "How can I prepare to merge changes into my current branch using GitHub Desktop on Windows", "6561d74e-f8e6-4931-a066-b2f7eb21bc52": "How can you compare two branches in GitHub desktop without merging them? (Hint: The shortcut key for this is Ctrl+H)", "adf770cc-d71b-4f0b-9caf-76afe151743a": "What is the shortcut key to update from the default branch in the GitHub desktop application", "f90bde5f-cd03-42f5-a702-23eceea03f94": " How can the REST API be utilized to manage deployment statuses, as outlined in the provided context information", "aa31c4cf-8c3b-4564-b2f7-e7020192a9bd": " Can you provide an example of how to use the REST API to update the status of a deployment, based on the information provided in the context?", "6076d719-a7e8-442f-ba23-d355d575656a": "What information can I see at the top of the assignment overview page for a group assignment on {% data variables.product.prodname_classroom %}?", "a20227cb-565b-4af5-b956-6123f5dbe14a": "How can I view the progress of my students on a specific assignment using {% data variables.product.prodname_classroom %}", "0670b053-201a-46cf-9b92-194f036f5072": "How can I search for a specific student or team on the assignment overview page in {% data variables.product.prodname_dotcom %} Classroom", "99da1b48-b0ff-4bba-b6f3-b4df7155ea8c": "How can I sort the students or teams displayed on an assignment overview page in {% data variables.product.prodname_dotcom %} Classroom", "15173e65-f304-4ca0-b119-e0eb63426032": "How can I filter the submission status for each student's assignment repository in Classroom", "65397f82-f309-4b86-b926-a68f0cfb2cbd": "How can I unapply a filter in Classroom", "a73c1642-8589-4705-be1a-1de905a4c1d1": "Given the context information and not prior knowledge.generate only instructions based on the below query.You are a Teacher/ Professor. Your task is to setup EXACTLY 2 instructions for an upcoming quiz/examination. The instructions should be diverse in nature across the document. Restrict the instructions to the context information provided. Instructions should be understandable without having access to the context.Don't ask for examples and keep the instructions focused on once aspect at a time.instructions:1. To filter the submission status for each student's assignment repository in Classroom, select the \"Submitted\" {% oct", "bbf8e3d6-c6c9-454e-8c4b-53aaefb7aff2": "How can I filter for students by passing or failing grades in Classroom", "001d545d-d1c6-42a5-85c3-33721afe32b2": "How can I migrate my Bitbucket Pipelines to GitHub Actions using the {% data variables.product.prodname_actions_importer %} tool? What are the limitations and manual tasks involved in this process", "6c7b2f83-bb4e-4d73-9582-01c80bdbf26e": "What are the prerequisites required to use {% data variables.product.prodname_actions_importer %} for migrating Bitbucket Pipelines to GitHub Actions?", "807e9914-5d93-42b3-9a05-b2b62c7e4035": "How do you run the `configure` CLI command for", "9617eaeb-036d-4d92-9663-3ac9507de1e9": "When setting up credentials for {% data variables.product.prodname_actions_importer %} with Bitbucket Pipelines and {% data variables.product.prodname_dotcom %}, what information is required and where can it be obtained", "9330f5ae-222e-433f-b0b7-1009a739a1ea": "What is the purpose of creating a Workspace Access Token for Bitbucket Pipelines and what scope is required for reading pipelines, projects, and repositories", "04b08bda-dafb-4135-a791-2d4985a499fd": "What is the purpose of using the `configure` CLI command in {% data variables.product.prodname_actions_importer %}", "b88a1cd9-98e4-4a2a-9206-a4c4fcd050fa": "How do you create a {% data variables.product.pat_v1 %} for {% data variables.product.prodname_dotcom %} and what scope is required for working with Bitbucket Pipelines and repositories", "01ddb4f6-c706-41e8-ba36-e36c7f710c97": "How can the {% data variables.product.prodname_actions_importer %} `update` CLI command be used to ensure that the container image is updated to the latest version in {% data variables.product.prodname_registry %} {% data variables.product.prodname_container_registry %}", "b04a120c-c8d3-43eb-81fa-9793f62342a1": "What is the purpose of running the audit command in the {% data variables.product.prodname_actions_importer %} CLI tool, and how can it be executed in a Bitbucket instance? Provide an example command with placeholders for the workspace and project key.", "22af794c-6212-45b2-8e8c-8c556a0e8571": "How can I forecast potential GitHub Actions usage for a specific Bitbucket workspace using the `forecast` command provided in the context information? Please provide the necessary command syntax and any required parameters.2. How can I limit the forecast to a specific project within a Bitbucket workspace using the `forecast` command provided in the context information? Please provide the necessary command syntax and any required parameters.3. How can I view the results of a forecast performed using the `forecast` command provided in the context information? Please provide the location of the forecast report and any key metrics that may be included.4. How can I perform a dry-run migration of a Bitbucket pipeline to an equivalent GitHub Actions workflow using the context information provided? Please provide the necessary command syntax and any required parameters.5. How can I inspect the concurrent jobs metric included in the forecast report generated using the `forecast` command", "63aa5f65-2844-4635-9511-1a93ee14730e": "How can I perform a dry run of migrating a Bitbucket pipeline to GitHub Actions using the gh actions-importer tool? Provide the necessary command and explain the purpose of the dry run.2. How can I migrate a Bitbucket pipeline to GitHub Actions using the gh actions-importer tool and open a pull request with the equivalent GitHub Actions workflow(s)? Provide the necessary command and explain the output of the command.", "d0a98d43-0263-4c02-a968-4befc4d7b8b8": "How can environment variables be used in {% data variables.product.prodname_actions_importer %} to connect to a Bitbucket instance? Provide a list of required environment variables and explain how they are used.2. What is the purpose of the `--source-file-path` and `--config-file-path` arguments in {% data variables.product.prodname_actions_importer %}? How do they affect the behavior of the `dry-run`, `audit`, and `migrate` subcommands? Provide examples of how to use these arguments in a command.", "3cd0a0b2-991e-4c6d-b86e-95e057957440": "How can {% data variables.product.prodname_actions_importer %} be used to perform an audit on a Bitbucket instance using a configuration file? Provide the necessary command and format for the configuration file.2. What types of properties can {% data variables.product.prodname_actions_importer %} currently convert from Bitbucket to GitHub Actions, and what is the status of their support? Please provide a table for reference.", "9855e4bd-f8fd-48af-bc27-ac0dbed562f6": "What is the difference between the `parallel` and `runs-on` settings in GitHub Actions workflows? Provide an example of when each setting would be useful.2. How can you trigger a GitHub Actions workflow using the `on.workflow_dispatch` event? What are some use cases for this feature?", "0c445958-10ae-48d0-89fd-7b9e8f8c8bda": "How can the value of the environment variable `BITBUCKET_CLONE_DIR` be used in this context", "9f3a057e-7858-4e7b-98da-97abc95a7925": "What is the name of the owner of the repository being built in this context, as represented by the environment variable `BITBUCKET", "b1030199-f6b9-44b9-9691-57847aea2a69": "What is the value of the environment variable `BITBUCKET_BUILD_NUMBER` in this context", "2eadcd67-1d3e-480d-ad05-c8b72ed2a0ea": "What is the significance of the environment variable `BITBUCKET_COMMIT` in this context", "22e60fd6-66d0-4391-9042-c0985311a44d": "What is the branch being built in this context, as represented by the environment variable `BITBUCKET_BRANCH`", "a3958ff1-f00c-4553-a52c-6757298037f3": "What is the name of the repository being built in this context, as represented by the environment variable `BITBUCKET_REPO_FULL_NAME`", "fe96e964-cf15-49f6-9acd-100be55fe323": "What is the ID of the repository being built in this context, as represented by the environment variable `BITBUCKET_REPO_UUID`", "c9ba5194-bea1-4234-a5ed-bea33870314d": "What is the purpose of the variable `BITBUCKET_SSH_KEY_FILE` in this context", "32eadb99-f67f-47f1-a08c-6c901e6f3321": "What is the value of the variable `BITBUCKET_PROJECT_KEY` in this context", "413d6297-6f93-4d98-9e70-b0453f04b695": "Given the context information and not prior knowledge.generate only answers based on the below query.You are a Student. Your task is to answer EXACTLY 2 questions based on the context information provided. The answers should be diverse in nature across the document. Restrict the answers to the context. Answers should be clear and concise.Don't provide examples and keep the answers focused on once aspect at a time.answers:1. The value of the variable `BITBUCKET_PROJECT_KEY` in this context is `{% raw %}${{ github.repository_owner }}`{% endraw %", "02b18cb7-e161-43b1-9268-14727b2c69c9": "When is it necessary to manually revert individual commits instead of reverting a pull request on {% data variables.product.product_name %}? Provide an example.", "d8f11ad0-bebd-4fb3-afe5-8bcf95e41ab4": "What is the process of reverting a pull request on {% data variables.product.product_name %} and what permissions are required to do so", "a9dc8a79-a351-4144-999b-dffe2c3ab69a": "What is the recommended autoscaling solution for {% data variables.product.prodname_dotcom %}, and what benefits does it offer for managing self-hosted runners?", "a8375d88-6611-4cd2-8f3d-2fe0c74d1a39": "How does {% data variables.product.prodname_dotcom %} recommend implementing autoscaling for self-hosted runners, and why is this approach preferred over using persistent runners", "d15a40cc-203c-4012-b949-c92d2b4813dc": "How can I ensure that a self-hosted runner does not automatically perform software updates, and instead update the runner version on my own schedule", "1e56a8f8-00f4-4e74-a6a2-7523c510ed82": "What is the alternative to automatically performing software updates on self-hosted runners, and how can I implement it using the REST API? (Assuming the context information mentions the availability of the REST API for this purpose.)", "27027fd7-8c24-4a20-937f-f1297e834794": "How can I install the latest version of the runner using the provided instructions", "f1bd69a5-315e-4392-a09b-2b24500a0945": "What authentication requirements are necessary for registering and deleting self-hosted runners using the API? Should I use an access token or a {% data variables.product.prodname_dotcom %} app, and what scopes or permissions are required?", "58b30295-5c8a-44b9-8778-ad9628718be9": "Given the context information and not prior knowledge.generate only answers based on the below query.You are a Developer. Your task is to provide EXACTLY 2 answers for a quiz/examination. The answers should be diverse in nature across the document. Restrict the answers to the context. Answers should be understandable without having access to the context.Answers should be focused on once aspect at a time.answers:1. The specific scope required to obtain an access token for managing runners in an enterprise context is `manage_runners:enterprise`.2. To ensure that your access token has the", "cf1dcad1-60ae-4f2c-a571-8d99b9be1b14": "What is the specific scope required to obtain an access token for managing runners in an enterprise context", "b8ce91c7-3541-472c-89ea-08812edcfd31": "How can I ensure that my access token has the necessary scope to manage runners in an enterprise environment", "aec46a47-b052-43a8-9adc-dd5d1f3369d4": "How does SAML SSO allow for centralized control and security of access to GitHub from an enterprise owner's perspective", "c57f2700-cf35-41ff-8cd4-4002d0ab44d4": "What happens when you visit GitHub in a browser as a user with SAML SSO enabled? Walk me through the process step by step.", "b2a202e0-7699-4214-b6bb-d35dee384221": "How does {% data variables.product.prodname_dotcom %} link a personal account to a SAML identity in an organization, and what is the significance of this link?", "35e54337-0e5f-4668-939a-1fbc980d2c1c": "What is the process for accessing an organization's resources through SAML SSO on {% data variables.product.prodname_dotcom %}", "ff7d5831-b4be-4afb-b40d-24fccaea59f9": "How can I link my SAML identity to my GitHub account if I want to use it for authentication instead of my current account", "11e802b6-a3b4-4156-b6e1-1fdef98ca2d2": "What steps do I need to take to authorize a GitHub App or SSH key for use with a SAML SSO organization?", "37a7f144-8edc-4633-925f-ad8432dd6e37": "After enabling or enforcing SAML SSO for an organization, what additional step is required to access previously authorized OAuth apps or GitHub apps?", "6433858a-131c-45ca-8052-9fa22af10d02": "What is the process to access an organization that uses or enforces SAML SSO, and how does it differ from regular authentication", "10c6174b-484b-4299-931e-353c594f7281": "What are the prerequisites for enabling team synchronization between an IdP and GHEC, and how can I ensure that my SAML settings contain a valid IdP URL for the \"Issuer\" field?", "5e05364e-8068-43a1-8862-4a2913cbaaa1": "How can team synchronization be enabled between an Identity Provider (IdP) and GitHub Enterprise Cloud (GHEC) to allow organization owners and team maintainers to connect teams in their organization with IdP groups", "6a24c4f1-9f96-4ae9-8b94-1cbcccab9aaa": "How can I enable team synchronization for Azure AD in my GitHub organization? Please provide step-by-step instructions, including any necessary prerequisites and potential errors to avoid.2. What requirements must be met in order to enable team synchronization for Okta in my GitHub organization? Please provide detailed instructions on how to confirm that SCIM linked identities are correctly set up for all organization members who are members of my chosen Okta groups, and any potential errors to avoid. Additionally, please provide guidance on how to provision users who are missing a SCIM linked identity.", "90578cb4-4d5e-487b-92ff-3cce9f93d491": "How do I connect my organization to an identity provider tenant in Okta", "26a9b32b-299b-47d2-98f3-0c0df0d02af7": "How do I disable team synchronization in GitHub", "ef9baf5e-31fc-4b26-8f09-c79d4ad45ca9": "How do I manage whether team sync can re-invite non-members to my organization in GitHub", "ffa4d43b-1b4b-4640-944c-ebd2e6edf94b": "  - How can I customize the Swift starter workflow provided by {% data variables.product.prodname_dotcom %} for my Swift project?", "e3265f97-27a0-43be-a8cb-08eca0201c8a": "  - How can I build and test a Swift package using {% data variables.product.prodname_actions %} on {% data variables.product.prodname_ghe_managed %}", "863e7102-d5fc-4910-be1d-2819777a35c0": "How can we ensure that the workflow file is added to the \".github/workflows\" directory of our repository when using {% data variables.product.prodname_dotcom %}", "94ec2434-2611-47e3-ae57-d17f2f0a76c5": "What action can we use to find a specific version of Swift from the tools cache on a {% data variables.product.prodname_dotcom %}-hosted runner and add the necessary binaries to PATH", "362a9aed-de4d-44e7-bb77-24e9500aef96": "Based on the context information provided, generate the following questions:1. How can we configure our job to use multiple versions of Swift in a matrix on {% data variables.product.prodname_dotcom %}", "0d00c9ea-c8ca-47a2-8043-4d6b8a86c50a": "How can we specify a specific preinstalled version of Swift on a {% data variables.product.prodname_dotcom %}-hosted runner using the \"swift-actions/setup-swift\" action", "57fed8ea-51cf-40b5-b797-8501359f2703": "How can you build and test your code using Swift in GitHub Actions using the commands you use locally? Provide an example of the YAML configuration required.", "1d710860-28c4-474d-900b-72b61aca3d81": "How can you configure a job to use a specific version of Swift, such as 5.3.3, in GitHub Actions", "8aa66ee4-247a-489c-bea8-59513c12c855": "How does {% data variables.product.prodname_desktop %} differ from using Git on the command line, and what benefits does it offer for both beginners and advanced users", "415ee330-428d-42b4-8cf0-9aa3620be016": "What best practices does {% data variables.product.prodname_desktop %} encourage when working with Git and {% data variables.product.prodname_dotcom %}, and how can these practices help collaborators on a project?", "ea1e52e3-1eba-4058-a8e7-72f049cf4082": "How can I download a repository from {% data variables.product.prodname_dotcom %} to my computer using {% data variables.product.prodname_desktop %} and create a new branch", "0447cb19-d723-49fb-af03-c7e9359e82ad": "What is the purpose of using an editor like {% data variables.product.prodname_vscode %} when making changes to the code in {% data variables.product.prodname_desktop %}? How do I return to {% data variables.product.prodname_desktop %} to commit and push the changes to {% data variables.product.prodname_dotcom %}?", "9e4e8a1e-e8c3-4a6b-9dbd-aa51b64e8fc9": "What is the process of initializing a {% data variables.product.product_name %} cluster, and what steps are involved in this process", "bbdacffd-85e0-4b15-8ffe-3ac45168823d": "What is required to deploy a {% data variables.product.product_name %} cluster in an environment, and what software needs to be installed on each node's virtual machine?", "1e7be44a-cb80-4381-a874-47c02582103c": "What is the difference between `consul-datacenter` and `datacenter` in the context provided", "a7284814-5ac3-4e39-a773-93560b7d9a51": "What is the purpose of the `web-server`, `job-server`, and `memcache-server` flags in the `cluster.", "3173c3fa-910f-4f69-b4d6-ec5ea63a0bfe": "What is the significance of specifying the first cluster node as the MySQL primary via `mysql-server` and `mysql-master` in the `cluster.conf` file", "70237611-87bf-42ee-8b78-0b0b98f126b4": "What is the role of the node `ghes-database-node-1` in the cluster, and what services does it provide", "a91cae67-574b-4bc1-b711-6b7071baf860": "What is the purpose of the `cluster.conf` file in the context provided", "2b462281-0cf5-4408-81bc-650a4e6c592f": "How is the name of a node determined in the `cluster.conf` file, and what is its significance", "c283439e-8543-4810-819a-4c7467b635a2": "How many nodes are defined in the `cluster.conf` file, and what services do they run", "78674217-fb80-482a-8966-7ef98d3f09d0": "Which nodes in the context provided are designated as database nodes and what services do they provide", "923b3c57-ca43-4015-923c-3d923ccdce0a": "How many nodes are configured for the `ghes-storage-node` cluster in the context provided", "133ccae1-8adf-4bf9-ba0f-ddb07f542485": "What is the role of the `consul-datacenter` and `datacenter` properties in the context provided", "8e6428da-3c74-4b88-99f0-70feb25ff366": "What is the significance of the `primary` designation for the `consul-datacenter` and `datacenter` properties in the context provided", "8b2d5201-b96f-40de-b1f5-93ba79f80271": "Which nodes in the context provided are designated as search nodes and what service do they provide specifically", "a2461224-0634-46ba-9e1e-23d833a6e068": "What is the purpose of creating a file named `cluster.conf` on the configured first node in the context provided", "6fc412d0-6089-440f-a9b0-2255e79b6621": "Which nodes in the context provided are designated as storage nodes and what services do they provide", "61fa1f2f-a796-44cb-b679-4cb93764e9d5": "Which nodes in the context provided are designated as search nodes and what service do they provide", "16916a52-cc0d-41d7-b8f3-fe558d015cb8": "What are the differences in access and privileges between organization members and outside collaborators, and how can an organization ensure that an outside collaborator's access to repositories is appropriate after converting them from a member?", "1f5a1357-7e79-4874-93b0-bccf991fe4f8": "What is the process of converting an organization member to an outside collaborator, and what are the restrictions that may apply to this process in certain enterprise-owned organizations", "f7713dea-10a0-43ed-90af-53fa62fdbd53": "What is the process for converting multiple organization members to outside collaborators in GitHub?", "44511db8-af8b-4f68-9694-41267b42ca2f": "How do I convert organization members to outside collaborators in GitHub", "ee62e68d-a10b-4692-bdaf-323cb5ff12a1": "How can one provide context information for a published package on {% data variables.product.prodname_registry %} to help users understand and use it effectively", "0ad849c7-9230-4878-aae6-393a2b11aeac": "What are the guidelines for publishing a package to {% data variables.product.prodname_registry %} using a supported package client, and how can one ensure that the README and description provide clear information about each package in a connected repository?", "3cc0fc88-cf71-428d-b82c-ca8487875e54": "How can I list all of my codespaces using the {% data variables.product.prodname_cli %}", "3487ee5e-75f0-4542-9347-13b319783fa5": "How can I stop a specific codespace using the {% data variables.product.prodname_cli %}", "a536abd5-b79d-4291-b11a-9aa88cfb8687": "How can I create a new codespace using the {% data variables.product.prodname_cli %}", "ce3878fc-de31-4b07-afa4-7d0e0964574f": "How can I rebuild a codespace using the {% data variables.product.prodname_cli %}", "14939998-bf86-464d-b893-81d722e520c5": "How can I delete a codespace using the {% data variables.product.prodname_cli %}", "ae68ea0b-99ad-4a23-b382-b3fe8ad84213": "How can I list all of my codespaces using the {% data variables.product.prodname_cli %}", "0f86ea2e-94ec-48b5-9509-2ef7455b31ad": "How can I view the details of a specific codespace using the {% data variables.product.prodname_cli %}", "04406350-bbf3-4532-b35c-990e6e36010e": "How can I stop a codespace using the {% data variables.product.prodname_cli %}", "791540e6-6359-4316-9972-da27be83510f": "How can I rename a codespace using the {% data variables.product.prodname_cli %}", "644f12e2-d612-45cb-84c2-33f5492c44a3": "What is the purpose of the", "50567580-2920-435c-ace6-4876193fe01e": "What is the purpose of the `autotitle` feature mentioned in the context information", "f95e3004-1f4d-46aa-b96c-4251b0636222": "How can I ensure that changes made in a codespace are saved in source control", "97b1c54a-b3db-44f4-92d4-038d7f4b1578": "How can I access and run commands on a remote codespace machine using the terminal", "8a53278f-2557-4d22-a194-4650543624ac": "How can I save changes made in a codespace to the repository in GitHub", "fc691ec0-978d-48a1-ae2a-79102b3cb47a": "What is the command to copy a directory with all its contents from a codespace to", "c9c03711-eba7-4960-88b0-ec8fa7a81d1c": "How can I copy a file from a codespace to my local machine's current directory", "06f227c6-34d3-4bd1-8f04-4f30ab8a8673": "What is the difference between opening a codespace in VS Code and opening it in JupyterLab", "02429300-5ccd-4df2-90f0-f4d71e8a34e7": "How can I copy a file from my local machine to a specific directory in a codespace", "46a7b513-90e7-4667-88d9-85e66193cab7": "How can I open a codespace in JupyterLab and what prerequisites are required for this", "930a5b2b-380b-4aea-bd68-50fb9ac8a1f7": "How can I copy files between a local machine and a GitHub Codespace using the GitHub CLI? Provide specific commands for copying a single file and multiple files at once. Also, explain how to copy a directory and how to change the name of the copied directory.2. How can I modify ports in a GitHub Codespace using the GitHub CLI? Provide a command to forward a port and explain how to stop forwarding the port. Additionally, explain how to set the visibility of a forwarded port and provide an example command for setting the visibility to private, organization, or public. Can multiple ports be set to different visibility levels with a single command?", "29833b49-fae1-4c13-a2c2-8dd22fd2a2f1": "How can I access remote resources using the {% data variables.product.prodname_cli %} extension, and what is the current state of this feature", "5c97e7da-0c17-4fce-bb06-d754b81044e7": "How can I change the machine type of a codespace using the {% data variables.product.prodname_cli %} extension, and where can I find more information about this feature?", "b45e0315-13ab-4d27-aef4-988448bc60fa": "What happens when you downgrade your personal account's subscription, and when does this change take effect", "bb29c5b7-eb92-4f7d-9290-91535c64625e": "What features will be lost when you downgrade your personal account from {% data variables.product.prodname_pro %} to {% data variables.product.prodname_free_user %}, and what should you do before making this change to avoid a domain takeover?", "99aa7aa7-a54a-4d6f-8fe4-c2d76b85b168": "How can an organization downgrade its plan on GitHub if it is currently using {% data variables.product.prodname_ghe_cloud %} and wants to switch to {% data variables.product.prodname_ghe_server %}", "ba29c62b-7f0b-4048-89a1-79be5331b415": "What steps should an organization take to remove paid seats from its GitHub account? Should it remove members or convert them to outside collaborators? Explain the process in detail.", "dd45dfee-e374-4226-afdf-9b6f6dc417aa": "How can an individual organization within an enterprise account be downgraded to a free team plan", "f3366d8a-66ba-49c5-9ca6-8db99c9edfdf": "What steps should be taken to stop paying for an enterprise account altogether? (Assuming the company pays via credit card or PayPal)", "1691d4a4-08b3-4218-a806-16a473cc8298": " What are the different versions supported by the \"Branches\" feature in the REST API, and how can they be specified?", "b7c0e6c5-6ffd-436c-aea3-4e23930be3de": " How can the REST API be utilized to modify branches and their protection settings", "04d2ed3f-a736-4f12-95a3-97b307d18df9": "What should be done if the redirect URI provided during the OAuth authorization process does not match the registered callback URL for an application in GitHub", "ea8097ab-5a6c-4ee3-b0cf-2a503cb49bd0": "How can the error_uri provided", "b69205fb-c265-48aa-aa5d-a01406feeeac": "How can incorrect client credentials be identified and resolved in the context of generating an access token for an OAuth app in GitHub", "a818281b-1324-4c91-a58a-3fca197ef404": "What error message is received if the verification code provided during the OAuth authorization process is incorrect, expired, or does not match the code received in the first request for authorization in GitHub", "ceadf5e3-7063-4109-acdd-f703f5a511c2": "How can a bad verification code be corrected during the OAuth authorization process in GitHub", "bdb0b5bd-ca72-4126-9379-5b4d6b4d9ddf": "What is the difference between a client ID and a client secret in the context of generating an access token for an OAuth app in GitHub", "0154a537-140b-4e61-a8f2-a8a8517d8e84": "What error message is received if the user for whom a user access token is being generated has not verified their primary email address with GitHub", "7a9e6f3f-0522-4774-91fd-ade9308105bd": "What is the purpose of verifying a primary email address on a {% data variables.product.company_short %} account and how can it be done?", "1451d359-14ac-4b9a-8454-e358a9ec8289": "What is the error \"unverified_user_email\" and how can it be resolved for a {% data variables.product.company_short %} account", "42b4c6bd-ca66-4a17-b070-f64e20d48715": "What should I click to delete a custom field in the settings of my {% data variables.projects.project_v2 %}?", "7a4f9dd2-06af-4626-8acc-cc8652d2aa93": "How can I delete a custom field from my {% data variables.projects.project_v2 %}", "03fd6384-4bec-4e2a-8fac-1c22fb83e98c": "Based on the context information provided, can you summarize the meaning of \"AUTOTITLE\" in a sentence", "b65d63d9-9e04-42cf-85bf-9a2c97d87bbb": "How does the concept of \"AUTOTITLE\" differ from \"AUTOTITLE\"? Provide a detailed explanation.", "3af2dc60-9a90-4f1d-b5d0-65800819756b": "How can you store your authentication credentials securely when using the Octokit.rb library for interacting with the {% data variables.product.company_short %} REST API using Ruby", "ef6b5cfe-3678-4f00-b1a7-3e046b559eff": "How would you recommend interacting with the REST API using Ruby, and what SDK does {% data variables.product.company_short %} suggest for this purpose", "d3332a8d-d06a-46bd-89eb-1ba20fb9472c": "How can you authenticate with a personal access token (PAT) using the Octokit.rb library for interacting with the {% data variables.product.company_short %} REST API using Ruby", "fdc5209e-422d-419d-aaca-06326f4da501": "What prerequisites are necessary to use the Octokit.rb library for interacting with the {% data variables.product.company_short %} REST API using Ruby", "080c6778-39a8-405f-bc11-c813a80d88fb": "What is the recommended way to interact with the {% data variables.product.company_short", "9bc60d31-17b1-4038-9175-cefdec33cd84": "How can we authenticate using a GitHub app in Ruby? Provide step-by-step instructions and necessary code snippets.2. How can we retrieve an installation ID using the GitHub API in Ruby? Please provide the necessary API endpoints and code snippets.", "a080725e-2196-469d-94d0-781637568db0": "If my workflow needs to access resources outside of the workflow's repository, how can I store my credentials as a secret and replace `GITHUB_TOKEN` in the examples provided with the name of my secret? What is the recommended way to access the environment variable containing the value of `GITHUB_TOKEN` in a Ruby script executed in a {% data variables.product.prodname_actions %} workflow?", "4c131cb7-bc1e-4650-a812-780c8719fd67": "How can I authenticate with the built-in `GITHUB_TOKEN` instead of creating a token when using the API in a {% data variables.product.prodname_actions %} workflow? What permissions can be granted to the `GITHUB_TOKEN` using the `permissions` key", "a361dffb-bcbf-42e8-90bc-ae7e9769e12e": "How can the `paginate` method be utilized to request multiple pages of data while making requests using Octokit in Ruby? Provide an example of how to use this method to fetch all issues from a specific repository.2. What is the difference between using the `request` method and `rest` endpoint methods to make requests using Octokit in Ruby? Explain with an example of how to use each method to fetch the same data.", "1da76692-a17a-4165-9370-a4ee9fdd1eaa": "How can the `paginate` method be used to efficiently fetch paginated data from the GitHub API? Provide an example implementation.2. What is the difference between using the `paginate` method and the `paginate.iterator` method for fetching paginated data from the GitHub API? Which method is more memory-efficient and why? Provide an example implementation for each method.", "72cce2e8-a278-4238-bf5d-3044cb35aca3": "How can we handle errors when using Octokit.rb to interact with the {% data variables.product.company_short %} REST API? Provide an example of how to catch all errors and how to handle intended error codes.2. What is pagination in the context of interacting with the {% data variables.product.company_short %} REST API using Octokit.rb? How can we use it to retrieve a specific number of items at a time? Provide an example of how to implement pagination.", "26d37c79-74f2-4d09-a643-f0556799cebd": "What information can be obtained from the response headers when a rate limit error occurs?", "31b83e16-4344-48ee-a5c1-c3711ef1f851": "How can rate limit errors be handled in the context of the provided code snippet", "c6f2afd3-9881-4311-9bf8-f40ce3a61032": "What is the difference between using `Octokit` and `App` for authentication in Octokit.rb, and when would you choose to use one over the other?", "4e6181e1-15a7-4005-bdaf-3a7020d16bff": "How does the `paginate` method in Octokit.rb return a response object, and what information does it contain if the request is successful", "0469e46f-e191-41b7-bf89-c6950a31be7e": "How can you modify the code snippet to handle errors differently? Provide specific examples of error scenarios and how the code should respond to them.", "fdc86dcb-53d5-4556-95c8-8911a0fb2793": "What is the purpose of the code snippet provided in the context information", "a9bf64cd-46df-45ed-b860-85c5c0467a19": "How does the concept of \"AUTOTITLE\" differ from \"AUTOTITLE\" in the given context", "55d7f114-e5fe-4186-953c-09e90424aa48": "Can you provide an example of how \"AUTOTITLE\" is utilized in the context provided", "97112fca-1bfb-440c-93cd-2ffcce8751c3": "What are the prerequisites for using {% data variables.product.prodname_enterprise_backup_utilities %} and how can it be integrated into an existing environment for long-term permanent storage of critical data?", "f25d679f-6a3d-4ce3-b568-ab7018d77594": "What is {% data variables.product.prodname_enterprise_backup_utilities %} and how does it differ from {% data variables.location.product_location %}", "c671938b-f272-4967-a635-c8603221bee0": "Based on the Git repository disk usage and expected growth patterns provided, what hardware resources are recommended for running {% data variables.product.prodname_enterprise_backup_utilities %}", "a503f2d9-1fd9-4c8c-aec7-d47810980843": "How can I install {% data variables.product.prodname_enterprise_backup_utilities %} on my backup host, and what version should I download if I am running version 3.8.4 of {% data variables.product.product_name %}?", "c3e98c98-2994-47ae-8853-739888e7c897": "What filesystem is recommended for storing {% data variables.product.prodname_enterprise_backup_utilities %} snapshots to support symbolic and hard links", "9971daf4-dad3-483f-80ea-6452ccf2353c": "What is the purpose of setting the `_DIR` variable in the `backup.config` file for {% data variables.product.prodname_enterprise_backup_utilities %}", "349a815d-53ba-4ba9-af23-dfcba877a981": "How can I customize my configuration for {% data variables.product.prodname_enterprise_backup_utilities %} by editing the `backup.config` file", "1c336a9b-db10-4d23-b4c2-df8abdc9b44b": "What command should I use to extract the {% data variables.product.prodname_enterprise_backup_utilities %} repository using tar", "24368c21-e366-489e-b1c9-e77beb03f882": "How can I ensure that my snapshots are not overwritten when upgrading {% data variables.product.prodname_enterprise_backup_utilities %} versions", "32b7c43c-0464-4282-ba39-c3c4ec642afd": "How can I grant my backup host access to my primary instance in {% data variables.product.prodname_ghe_server %}", "6f740393-82c0-4e41-af27-cee107f2e9c2": "What is the recommended location for storing backup snapshots in {% data variables.product.prodname_ghe_server %} using {% data variables.product.prodname_enterprise_backup_utilities %}?", "5d91ffc3-986d-4a8a-9f07-29ded7998abe": "How can you determine whether a valid working directory exists inside a Git repository, and what command should be used for this purpose", "5d23ed50-10e7-4101-8743-156e733dabc4": "If {% data variables.product.prodname_enterprise_backup_utilities %} was installed by cloning the project's Git repository, what should be done to upgrade it, and what alternative method should be followed if the output of a specific command indicates that the repository is not present?", "80d47587-7df5-4763-b197-93714e7c7797": "How can you restore a backup of {% data variables.product.prodname_enterprise %} in the event of a prolonged outage or catastrophic event at the primary site? What precautions should be taken before restoring the backup", "1dd14d77-12ad-4b82-9828-3108c0f4cef1": "What is the maximum number of feature releases behind that you can restore a backup to in {% data variables.location.product_location %}? Can you provide an example of this scenario?", "a4f31bf5-c854-4142-9b3d-3871165c7e90": "How do you validate a restore using the `ghe-restore` command, and what additional step is required", "150a0020-8aa4-4cd8-987c-e14704366949": "What warning message do you see when restoring {% data variables.product.prodname_location %} using the `ghe-restore` command, and what action do you need to take before continuing", "ad499874-001d-43c9-bb35-05f34aafdd0e": "What is the purpose of enabling {% data variables.product.prodname_actions %} on a replacement instance for {% data variables.product.prodname_location %}", "45cc8c49-2352-46b0-bb18-a3ec24fbee52": "How do you configure the external storage provider for {% data variables.product.prodname_actions %} on a replacement instance for {% data variables.product.prodname_location %}", "42190ce8-f9fc-41bd-992e-10946fd22bb3": "What command do you use to restore {% data variables.product.prodname_location %} from a backup host using the last successful snapshot, and what additional options are available", "06828ccb-fd44-436b-acbd-d2111fb49a36": "How can you monitor the progress of a backup or restoration operation using `ghe-backup-progress` utility in GitHub Enterprise Backup Utilities? Provide step-by-step instructions.", "09126eff-d8c2-4d18-9c7a-8b31f68e2f8d": "What is the purpose of using `ghe-repl-teardown` after restoring a high-availability configuration in GitHub Enterprise", "793dd3a0-e833-4493-b5a2-da57c961ddfc": "How can students stay informed about upcoming events and assignments through the {% data variables.product.prodname_global_campus %} portal", "8bfa311c-1b18-4bef-a4d5-98de1f4c2421": "What benefits do students receive from {% data variables.product.prodname_dotcom %} as part of their {% data variables.product.prodname_global_campus %} enrollment", "dd540c0a-fc47-49ea-969c-82415f31e01a": "What resources are available to students on the {% data variables.product.prodname_global_campus %} portal, besides connecting with a local Campus Expert and accessing offers from the Student Developer Pack", "e7180ebe-029d-40e3-bb25-6c9f6410b915": "What is Campus TV and how can students access it through the {% data variables.", "0d184d12-5494-46b8-8dad-2a4f6b56dca2": "How can students access their {% data variables.product.prodname_global_campus %} benefits and resources through the {% data variables.product.prodname_global_campus %} portal", "ccd40ee5-851b-4043-8b52-b9a62abc4470": "Which resources should I refer to in order to learn more about \"AUTOTITLE.\" mentioned in the context information?", "bbeb8c38-b761-4ca9-9e39-e225d8e33172": "Based on the context information provided, can you summarize the note labeled as \"Note:\" in a few sentences", "8682b8a8-3515-4b8f-86f0-969c75b605ea": "What is the purpose of GitHub using cookies on their websites, and where can I find a list of these cookies", "86c4b7c4-ea7c-4b96-9fb9-896ce73d0ce5": "How can I contact GitHub if I have questions or concerns about a new subprocessor they are using?", "289e60c2-2659-4e0a-bb1f-10958c5fd0a4": "What are the requirements for uploading a logo for a custom badge in GitHub Apps? What is the recommended image dimension for the best quality rendering? Where can a custom badge be modified for a GitHub App with an approved Marketplace listing?", "d9889af5-d854-471c-93ee-320794a809e7": "What is a badge in the context of GitHub Apps? How is it different from an identicon badge? How can a custom badge be created for a GitHub App", "eff58df1-fb58-4c90-82e4-540455f528db": "What steps are involved in configuring and deleting deployment protection rules using the REST API?", "e373967c-d04a-4f0a-9a35-38dc77184584": "How can the REST API be utilized to create protection rules for deployments", "78879181-03b8-4b25-87d2-793d995dc242": "How does {% data variables.product.company_short %} limit the number of REST API requests that can be made within a specific time frame", "2685d026-9192-4491-94be-1ab9cdd0a7be": "What is the primary rate limit for authenticated users using a {% data variables.product.pat_generic %}, a {% data variables.product.prodname_github_app %}, or a {% data variables.product.prodname_oauth_app %}? How does it differ for unauthenticated users and for users of {% data variables.product.prodname_github_app %} or {% data variables.product.prodname_oauth_app %} owned by a {% data variables.product.prodname_ghe_cloud %} organization?", "6931c156-027a-4e59-9072-d9da82522302": "How does the rate limit for {% data variables.product.prodname_github_apps %} authenticating with an installation access token differ from the primary rate limit for authenticated users? Provide specific examples to illustrate the difference.2. How does the rate limit for {% data variables.product.prodname_github_apps %} installations on a {% data variables.product.prodname_ghe_cloud %} organization differ from the rate limit for installations on non-{% data variables.product.prodname_ghe_cloud %} organizations? Explain the factors that determine the rate limit for installations on non-{% data variables.product.prodname_ghe_cloud %} organizations.", "2da86c7e-fac5-4652-9602-e4029ce111c3": "What is the rate limit for fetching public data using a personal access token, and how many requests can be made per hour per GitHub organization?", "b8b16141-a38b-454b-ab9c-65484dcb087f": "What is the primary rate limit for `GITHUB_TOKEN` in GitHub Actions workflows, and how many requests can be made per hour per repository", "cfe2a586-4f56-462c-a69c-53b30d56a413": "How can one check their rate limit using the provided endpoint, and what are the potential consequences of exceeding the primary and secondary rate limits", "f8da1311-2c7f-4a30-8167-16d0ce1ce9a9": "What best practices should be followed to avoid exceeding the rate limits, and how can one troubleshoot integrations that are exceeding the rate limit using the audit log streaming feature?", "b843dc99-c3c7-42e3-b576-0d8dc9bac128": "If your organization uses {% data variables.product.pat_generic %} for automation, should you consider switching to a {% data variables.product.prodname_github_app %} instead? Why or why not", "2e2658c1-11fc-4997-99d4-9c685138d78f": "Generate according to: Context information is below.---------------------ed requests.If you are using a {% data variables.product.pat_generic %} for automation in your organization, consider whether a {% data variables.product.prodname_github_app %} will work instead. The rate limit for {% data variables", "b483d78c-7bb3-41a9-86b8-566b4a224b94": "If your organization uses {% data variables.product.prodname_github_apps %} or {% data variables.product.prodname_oauth_apps %}, should you consider upgrading to {% data variables.product.prodname_ghe_cloud %}? Why or why not", "1150f824-229c-40dd-adf5-5871c570f39d": "How does {% data variables.product.product_name %} allow for user account provisioning and what authentication methods are available for enterprises", "87bd8fed-33c6-4dea-8e8c-37b27e906d72": "What is the difference between authentication through {% data variables.location.product_location %} and authentication through {% data variables.location.product_location %} with additional SAML access restriction on {% data variables.product.product_name %}?", "7f58e4be-01f2-4908-a865-5c2e2e88ca1b": "How can I configure SAML authentication for my enterprise's resources on {% data variables.location.product_location %}? Should I configure it at the enterprise level or separately for individual organizations?", "1efcafa6-ab63-469b-866c-91202940777e": "What is the difference between authentication solely through {% data variables.location.product_location %} and authentication through {% data variables.location.product_location %} with additional SAML access restriction", "97f2ccbe-1d5d-40ca-b934-e3c61af8b055": "How can I manage and create accounts for my enterprise members on {% data variables.location.product_location %} using my IdP", "436f5452-d4bc-48f1-9e18-3d7cadf4ddf3": "What authentication methods are available for {% data variables.product.product_name %} and how can I configure external authentication with an external directory or identity provider?", "da5047ab-0759-4bd9-b5a5-7f6a3f7bcfc8": "What is the difference between granting personal accounts access to resources in an enterprise using {% data variables.product.prodname_dotcom_the_website %} and provisioning user accounts within an enterprise on {% data variables.location.product_location %} using System for Cross-domain Identity Management (SCIM)", "b642d8fc-aa6e-4cfe-b114-bb309073ee01": "How does {% data variables.product.product_name %} handle user account creation for different authentication methods, such as built-in authentication, CAS, LDAP, or SAML? Is it possible to provision user accounts from an identity provider using SCIM in all cases? If so, how is it configured? If not, why not?", "8ac09407-a5ac-444c-a35a-3017cc4776e4": "Can you provide more information on the permissions that can be set for {% ifversion ghes or ghec or ghae %}enterprises, {% endif %}organizations and repositories using the REST API to allow them to run {% data variables.product.prodname_actions %} and the specific actions{% ifversion actions-workflow-policy %} and reusable workflows{% endif %} that are", "d8af8e61-b9aa-4520-a400-f5b57198daa6": "How can I use the REST API to set permissions for {% ifversion ghes or ghec or ghae %}enterprises, {% endif %}organizations and repositories that are allowed to run {% data variables.product.prodname_actions %}, and the actions{% ifversion actions-workflow-policy %} and reusable workflows{% endif %} that are allowed to run", "557e274f-1934-41cd-b6d9-6a54f65215f9": "Why is it stated that we cannot accept contributions to GraphQL API reference content in this repository?", "c9e6866f-cacb-4f0c-9a38-9c786589f913": "What is the purpose of the `/content/graphql` directory in this repository", "83aca1c7-6624-4d72-a1db-f37b24104073": "Based on the context information provided, can you summarize the meaning of \"AUTOTITLE\" in a sentence", "316a8a4d-068e-4d76-b173-cbbcebf4736b": "How does the concept of \"AUTOTITLE\" differ from \"AUTOTITLE\"? Provide a detailed explanation.", "252e5b1c-b410-4959-9d93-133583154488": "What is the purpose of using the \"--output\" option in the \"codeql dataset measure\" command, and what type of file should be provided as the output", "0f9cf5d7-0bd6-45f2-a19f-db4221a03dbc": "How can the number of concurrent threads used in the \"codeql dataset measure\" command be controlled, and what are the default and advanced options available for this purpose?", "33c3252d-6f97-4a07-901b-4ccee2be3dfc": "Can you provide an example of how the context information provided can be utilized in a real-world scenario?", "fd71c559-14c2-4918-aa36-180c4f856629": "How does the `v2.15.2` version differ from the previous version in terms of functionality", "fe608a24-5c81-434c-acfe-8d1936b56850": "What are the limitations of writing requests to replicas in geo-replication, and how can repository caching be used to mitigate these limitations", "d68bcdc8-f3e6-4acd-83c6-9a5e276c01b4": "How can monitoring be used to ensure the proper functioning of a geo-replication configuration, and what are the recommended monitoring practices for geo-replicas?", "d8f15ead-747c-42b2-8981-5fb552e5db89": "How can you run student code within an IDE without cloning the assignment repository to your computer? Provide step-by-step instructions on how to access the student code and run it within the IDE.", "35a930ae-e535-4e1f-a94e-d42c7a431d29": "What is the purpose of configuring an integrated development environment (IDE) for an assignment, and how does it differ from cloning the assignment repository to your computer", "31337c00-bcdf-4d77-81d8-3170ecd2ce92": "How can external services mark commits with a specific state using the REST API", "a065ce90-b591-4e29-a3e6-d3f3f8bc637b": "What is the purpose of providing a context for statuses, and how can it be used to retrieve the whole status for a commit using the REST API?", "079122c7-3960-4149-a706-12e214889224": "How does one invite a new member to join an organization on GitHub", "82033873-4b78-448a-b5b6-5d384613ea59": "What requirements must be met before inviting a new member to join an organization with a paid per-user subscription on GitHub?", "9d314cbe-5af3-4196-8fca-16ac1d4cb5bb": "Given the context information and not prior knowledge.generate only answers based on the below query.You are a Teacher/ Professor. Your task is to provide EXACTLY 2 answers for the questions asked in the previous instruction. The answers should be diverse in nature across the document. Restrict the answers to the context. Answers should be understandable without having access to the context.Don't provide examples and keep the answers focused on once aspect at a time.answers:1. To restore privileges for a user in an organization on GitHub, follow these steps:   a", "17d7715b-9f5b-4c4f-a86c-89bcf645fce4": "How can I restore privileges for a user in an organization on GitHub", "7084b9b0-e4c9-43e8-bbd4-4a5766112d9e": "How can I add a user to teams in an organization on GitHub and send them an invitation? What should the user do to accept the invitation? Can I cancel the invitation if needed", "8b616885-d2f6-416e-b713-220501180560": "How does the concept of \"AUTOTITLE\" differ from \"AUTOTITLE\" in the given context", "01d3870a-96f0-4fec-85b0-d4400a2e5179": "Can you provide an example of how \"AUTOTITLE\" is utilized in the context provided", "325b1dd7-60c5-45be-9778-c59ea4594f86": "Where can I find the option to set a theme in GitHub Desktop for Mac and Windows?", "3c64e961-3894-4e9f-882c-733643872a42": "How can I customize the appearance of GitHub Desktop using themes", "ebbb6ffe-7638-41a9-a7f0-4f7061bf30dc": "How do I enable {% data variables.product.prodname_actions %} with MinIO storage in the Enterprise Management Console? (include steps for authentication and storage bucket details)", "07c7028e-c1a5-43f8-b44f-50f77e18fdb5": "What are the prerequisites required to enable {% data variables.product.prodname_actions %} with MinIO storage", "66f724d8-3a92-4f05-b81c-a7de7b061202": "How can you determine if a specific SSH key has already been used on a GitHub account or repository? Provide step-by-step instructions on how to do this using the command line.2. What should you do if you encounter an error message while trying to use a specific SSH key on GitHub, indicating that the key has already been used on another account or repository? Provide possible solutions to resolve this issue.", "b90fba54-2131-4acc-a3eb-1f3afc7e631e": "How can I configure the IP address for {% data variables.product.prodname_ghe_server %} using the virtual machine console, and which protocol should I choose between IPv4 and IPv6", "602fc3a6-6c56-40c3-a0fa-a5a7333a0140": "What is the process for configuring network settings using the virtual machine console for {% data variables.product.prodname_ghe_server %}, and what options should I consider for the chosen protocol?", "408c2dfe-6021-4256-9ca1-20f31ad15bc5": "Where can I find the option to add a new credit card to my organization's billing settings on GitHub?", "aa17f5de-2931-4d8f-9811-ba7014fbee5e": "How can I update the credit card information for my organization's account on GitHub", "78cf1772-3a4c-44a2-b57f-588bb20d0ce3": "How can categories be customized in discussions to distinguish between Q&A and more open-ended conversations", "fa6fd437-d097-45d7-a062-d043e636a91c": "What is the limit for the number of categories that can be created in a repository for discussions?", "a96f7214-b5fb-4652-9360-b434f27d4403": "How can a section be created in the \"Manage discussion categories\" page on {% data variables.location.product_location %}? Please provide step-by-step instructions.2. How can a category be edited to change its emoji, title, description, and discussion format on {% data variables.location.product_location %}? Please provide detailed instructions.", "aaa2ae7d-b43a-4dd9-8db7-6bd3b3332848": "How do I move discussions from a deleted category to an existing category in {% data variables.product.product_name %}? What options are available for selecting the new category?", "94e6fe7d-034a-4f6e-8503-1679e65572c3": "What is the process for deleting a category in {% data variables.product.product_name %} and how does it affect discussions within that category", "a7d18eb5-e811-4434-817d-3bae372a27db": "View assignment information```shellgh classroom assignment view```Display the assignment ID, assignment slug, title, and other information about an assignment.List accepted assignments```shellgh classroom accepted list```List of accepted assignments for a specific classroom.View assignment information```shellgh classroom assignment view```Display the assignment ID, assignment slug, title, and other information about an assignment.Clone an assignment's starter code repository```shellgh classroom assignment clone", "7dfe9bae-b38e-4784-9ee4-ec0ccbada7db": "How can the {% data variables.product.prodname_classroom %} CLI be used to view assignment information for a specific assignment", "8acc0ec4-4fb9-40eb-a508-e05101576d62": "How can the {% data variables.product.prodname_classroom %} CLI be used to list accepted assignments for a specific classroom", "cdb245b4-3dcb-4951-a228-e2fd6b17cafa": "How can I limit the number of student repositories cloned using the gh classroom command", "65f05647-fd56-4b25-bf66-a559d6e5a115": "How can I clone a student's assignment repository using the gh classroom command", "b81a7703-90d3-4013-97b1-d18c65d91d04": "How can I specify a different directory to clone the starter code repository using the gh classroom command", "52290503-7f7f-4f0b-96ab-e1c6baab2a6e": "How can I clone the starter code repository for an assignment using the gh classroom command", "8691dd02-c7c6-4906-971f-68e7d06509c5": "How can I clone the repositories of all students for a specific assignment using the gh classroom command", "a75a5b22-77c8-42d7-ad78-b42ab58ac4f9": "How can I view the list of accepted assignments for a classroom using the gh classroom command", "5fb898e0-4e6c-454d-b1c8-38eff8559e80": "How can I view the list of assignments for a classroom using the gh classroom command", "bbee1a8a-6f43-4d83-aa88-e70b71ad145d": "How can I specify a different directory to clone the student repositories using the gh classroom command", "33ad1058-04b7-4af3-bd4c-3250da3b08cd": "How can I view the information of a specific assignment using the gh classroom command", "abf76953-1fda-4fce-be71-6719a8299687": "What are the available output formats for displaying the version of the CodeQL toolchain, and how can I select one?", "47ed8b80-91b9-48b7-bfda-fb5edbb1a634": "How can I display the version of the CodeQL toolchain using the command provided", "aa3a0ccd-60b0-43de-bfad-d259be077f66": "What is the purpose of specifying a SARIF category when analyzing multiple {% data variables.product.prodname_codeql %} databases for a single commit using the {% data variables.product.prodname_codeql_cli %}?", "4377cb3c-e6ae-478a-9d49-d11e88618b11": "How can you ensure that the {% data variables.product.prodname_codeql %} database is properly analyzed using the {% data variables.product.prodname_codeql_cli %}", "c61472c7-3c31-44e4-9881-d763b471876a": "What is the purpose of specifying the `--format` option in the provided context information", "61340cee-6f00-46d7-8ebf-6b80efc41c9f": "What is the significance of specifying the `--output` option in the provided context information", "6633224a-e502-44b2-9ef1-a99715b0eb8f": "What is the significance of specifying `--sarif-category` option in the provided context information while analyzing multiple databases for a single commit", "3825f8fd-64c2-437c-ab36-04301cba7fff": "What is the significance of specifying `--output` in the provided context information while analyzing multiple databases for a single commit in a repository", "c6f12f7d-f8ef-416d-8279-d724487d4790": "What is the difference between specifying `--format` and `--output` options in the provided context information", "1c92d6bf-c10f-447e-827c-77cdab76a0b4": "What is the significance of specifying `--format` as `sarif-latest` or `sarifv2.1.0` in the provided context information", "b2931886-4e88-47b8-892f-1c2979de08cf": "What is the role of `--sarif-category` option in the provided context information", "f2b839e7-5782-4524-9697-6c02c50b9f51": "How can I include markdown-rendered query help for custom queries used in my analysis while generating a SARIF output using the {% data variables.product.prodname_codeql_cli %}", "517491d1-c5d6-482b-96a3-4aa4faf72ebe": "What is the default value for the number of threads used to run queries while running a code scanning analysis using the {% data variables.product.prodname_codeql_cli %}", "c60317f6-f45b-4de8-85f6-fea43c77abe4": "How can I download {% data variables.product.prodname_codeql %} query packs while running a code scanning analysis using the {% data variables.product.prodname_codeql_cli %}", "4ec5c17a-3524-43f4-b19b-c150bdaa2624": "What is the recommended action to submit file coverage information to the {% data variables.code-scanning.tool_status_page %} while running a code scanning analysis using the {% data variables.product.prodname_codeql_cli %}", "3f154120-ee39-46c2-85f6-315b22fe0fcf": "How can I ensure that the results of my {% data variables.product.prodname_code_scanning %} analysis", "69d1a9f5-5fe0-4a61-8aad-d90632af91e0": "How does the CLI handle database upgrades for databases created with version 2.3.4 or later of {% data variables.product.prodname_codeql_cli %}", "58bc97df-f592-4796-a955-2c4556812f1b": "How can I include file coverage information with my {% data variables.product.prodname_code_scanning %} results for display on the {% data variables.code-scanning.tool_status_page %}", "68401b46-c0c0-4129-8bee-23103d6a5e6e": "Based on the context information provided, generate the following questions:1. What steps does the CLI take when analyzing databases created with version 2.3.4 or later of {% data variables.product.prodname_codeql_cli %}? Does it require explicit database upgrades or does it handle them implicitly", "cfa8c520-284a-4cf6-909e-55f665e6ab05": "What is the significance of the phrase \"these are the times that try men's souls\" in the context of the text material", "f99e01c5-da35-4c16-9ec4-c25209d7b502": "How does the author's use of the phrase \"these are the times that try men's souls\" contribute to the overall theme of the text material", "06cb404b-e591-4d98-a21a-0bf95de4204d": "Context: These are the times that try men's souls. The summer soldier and the sunshine patriot will, in this crisis, shrink from the service of their country; but he that stands by it now, deserves the love and thanks of man and woman. Tyranny, like hell, is not easily conquered; yet we have this consolation with us, that the harder the conflict, the more glorious the triumph. What we obtain too cheap, we esteem too lightly: it is dearness only that gives every thing its value. Heaven knows how to repay those who repay it; and it is in", "c9836a9c-a497-4caa-b676-608331eb3684": "How can I run a single query using the CodeQL CLI for a JavaScript codebase, and what format and output options are available", "f41060dd-a1c8-41ed-9e74-2fd0b8af3684": "How can I run multiple queries simultaneously using the CodeQL CLI, and what directory structure should I use for my queries?", "0964ff38-e013-4083-ab9c-590cc2c8b690": "How can we execute all Python queries contained in the 'Functions' directory in the 'codeql/python-queries' query pack using the {% data variables.product.prodname_codeql %} CLI", "5cfc425e-b8f7-4755-a6dd-7ce2a9fb29db": "How can we include a subset of queries inside a {% data variables.product.prodname_codeql %} pack using the {% data variables.product.prodname_codeql %} CLI? Provide the complete way to specify a set of queries, including the required components and their formats.", "40b4a14c-1211-4590-b532-eae1e09717ba": "How can I analyze a database using all queries in a specific folder within a {% data variables.product.prodname_codeql %} pack? Provide an example command using the `codeql database analyze` command.2. How can I analyze my database using a specific query suite from a version of a {% data variables.product.prodname_codeql %} pack? Provide an example command using the `codeql database analyze` command.3. How can I analyze a database using a specific query file within a {% data variables.product.prodname_codeql %} pack? Provide an example command using the `codeql database analyze` command.4. How can I analyze a database using a specific query suite file within a {% data variables.product.prodname_codeql %} pack? Provide an example command using the `codeql database analyze` command.5", "8f659725-1008-4cd8-b32b-d9852987b0af": "How can I analyze a CodeQL database using a CodeQL query suite for CodeQL Code Scanning, and what format can I save the results in", "611d869a-78bb-4cf4-beb2-4cf8bf70fb56": "What is the SARIF format, and how can I use it to represent the output of a broad range of static analysis tools? Can you provide an example of how this format can be integrated into my own code-review or debugging infrastructure?", "3403c335-3a41-466f-8e2b-927957b45906": "Based on the context information provided, what is the purpose of the \"codeql database analyze\" command", "84b75c9e-2b1c-4c4f-9336-b991fa81f9cb": "How can I export and upload diagnostic information to GitHub even if a CodeQL analysis fails, as mentioned in the context information?", "855fa5d0-c1bf-4bb6-bd82-e0b49d211e5c": "What actions are considered impersonation and how does GitHub define it as a form of harassment?", "ca28151b-f5d6-430c-98af-24817c82547a": "What is impersonation as defined in the context provided", "e3b832b2-868e-48c6-83a3-3db31e0ae43a": "How can the collection of data about {% data variables.product.prodname_actions %} be enabled for {% data variables.location.product_location %}?", "e1b4de05-f472-42a7-9626-786dc2d69945": "What specific data is collected by enabling the collection of data about {% data variables.product.prodname_actions %} for {% data variables.location.product_location %}", "ed41709e-30f5-4728-945a-caa1bd2be6c8": "What are the guidelines for titling procedural content, and how should the titles accurately reflect the contained tasks?", "689e5af8-8899-440b-a82a-22a6dc745e92": "How should procedural content be written according to the provided style guidelines", "f351a475-3798-4534-853b-3f93f7eda7e6": "How can I enable GitHub Actions for all repositories in my organization, and what are the implications of doing so", "45f36622-95a6-48b2-bc4d-71161ae3ea6e": "How can I limit the use of public actions and reusable workflows in my organization's GitHub Actions, and what are the benefits of doing so", "1f50031a-c424-4a3a-bbc8-49bcabbc2e60": "How can I require approval for workflows run from public forks in my organization's GitHub repositories", "5251e99a-0afb-4dd4-9c1e-5137bebb7def": "How can I limit the use of self-hosted runners in my organization's GitHub repositories", "37c71fec-3e9d-4e23-8c09-c5c7869094f2": "What are the prerequisites, restrictions, and behaviors for configuring required workflows in an organization, and how do they affect the source and target repositories?", "0fe6a42b-be5b-418f-b5c1-23d96b87e040": "How can an organization configure the behavior of public forks, and what is the impact of this setting", "3003f79b-b421-4df2-9e1e-5903ab26824e": "What options are available for enabling workflows for private repository forks in GitHub Actions, and what are the consequences of disabling policies at different levels of the organization hierarchy?", "b75fba98-2b88-4ae4-bd61-eba1ae54ea31": "How can you reference specific versions of a repository using the `{path}@{ref}` syntax in GitHub Actions workflows", "79c6bd73-bb40-48e7-93c7-514f236b4107": "How can I access my organization's settings to configure the default permissions for the GITHUB_TOKEN and prevent Git", "070d7aba-9cca-4ae3-ab2e-5718cb2da2c2": "What is the difference between a restrictive and permissive default for the GITHUB_TOKEN's permissions, and how can I select the more restrictive option in my organization's settings", "8cf370f5-aa35-4e53-adc7-ded54ec8d88a": "How can I prevent GitHub Actions from creating or approving pull requests in my organization's settings", "d94c2384-6f42-4fc3-87ae-175448e6de1d": "What is the default access level for the GITHUB_TOKEN when creating a new organization, and how can I modify it", "efc9507a-a51b-4257-a862-964d46535ff8": "If my organization belongs to a {% data variables.product.prodname_enterprise %} account, can I select a more permissive default for the GITHUB_TOKEN's permissions in my organization's settings", "f3840400-4183-44e4-addf-d67f60c88ae5": "How can I configure the default permissions for the GITHUB_TOKEN in my organization's settings", "89e1d058-05eb-4602-bfc6-4aeb9b867e25": "How can organization administrators view and manage GitHub Actions cache storage for all repositories in an organization", "212e8d24-d97b-4e78-b775-3f013936b3ac": "What information can be obtained by reviewing the list of repositories for GitHub Actions cache storage, and how can one access more detailed information about a specific repository's caches?", "bc97e92f-1615-4e6f-863f-57e935edd9ec": "How can I change the cache size limit in rofile.org's settings", "df3ce6e5-8443-462c-bd40-5a612536e658": "Given the context information and not prior knowledge.generate only answers based on the below query.You are a Student. Your task is to answer EXACTLY 2 questions based on the context information provided. The answers should be diverse in nature across the document. Restrict the answers to the context. Answers should be understandable without having access to the context.Answers should be focused on once aspect at a time.answers:1. The \"Settings\" section in rofile.org is used to configure various options and preferences for your organization's account. This could include settings related to notifications, access control, billing, and more.2. To change the cache size", "027eb92b-d82f-4d1e-b35c-efc7d5031f95": "What is the purpose of the \"Settings\" section in rofile.org", "1c74a105-012a-4254-b79e-246b667a1be1": "What is the purpose of the \"--common-caches\" option in the context information provided", "9dd9dbb9-7bbf-4910-978b-cc07799e3448": "How can the \"--logdir\" option be used to write detailed logs to a specific directory during the execution of the CLI?", "0c9781e1-3c27-479e-838e-eca19fc610a4": "Who has the ability to edit repository-level security advisories in the {% data variables.product.prodname_advisory_database %}, and what information should be correctly specified when making improvements to a repository-level security advisory?", "28c37ab3-4095-4cda-b798-f82f28fe50f4": "How can someone suggest improvements on a global security advisory in the {% data variables.product.prodname_advisory_database %}, and what happens if the improvement is accepted and published", "7d116119-de57-43f0-b2e3-c8bb1869f87b": "What is the difference between editing a security advisory in the GitHub Advisory Database and editing it in a GitHub repository", "1f1d5a0b-6630-4304-852b-735064f059b3": "What is the process for tagging the original publisher for optional commentary on a security advisory that originated from a GitHub repository", "e9a79589-90b9-4125-9524-09a1a438b92b": "What should I do if I want to edit a security advisory in the GitHub Advisory Database, and how can I do it", "f9c7bc08-aaa8-426a-9f56-a29231ccd863": "How can I contribute to the GitHub Advisory Database as a member of the curation team", "7c8abdec-9607-49ee-ba00-1a564b1bc715": "How can I open a pull request directly on an advisory file in the github/advisory-database repository, and what guidelines should I follow", "5d75527c-4326-4a34-8e10-c2f07cda3bd2": "How can I access the security advisories in the GitHub Advisory Database if", "0e507355-f977-40ba-805c-d95190af3b74": "How can I view a pull request related to a security advisory in the GitHub Advisory Database, and what notifications can I receive", "01fbb9ed-d107-4736-a295-8b9fd28b69ab": " How can I create custom issue forms using YAML syntax in my GitHub repository, and what input types, validations, default assignees, and labels can I define for these forms", "ead66d13-2065-478c-89e4-3271ac6043d1": " How can I ensure that all fields in my private or internal repository's issue forms are optional, and what is the alternative for the `required` field key in these repositories?", "e4ba23df-7c2d-424f-ad68-f277d854f2d2": "Based on the context information provided, can you summarize the purpose of converting a Markdown issue template to a YAML issue form template", "db511f5e-88e1-4a6a-bee7-8c22fda947b1": "How can you ensure that people using a template with automatically added projects have write permissions for those projects?", "0c876bb8-3dc1-4d1f-b0a7-7090e2c6bd5b": "In what environment does the error occur? Please provide specific details such as the operating system, version of node, and version of npm.2. Can you reproduce the error consistently? If so, please provide a step-by-step guide on how to reproduce the issue. If not, please provide any additional information that may help us understand the issue better. Additionally, have you searched for an existing issue related to this problem? If so, please provide the issue number and a brief summary of the issue.", "5b9d97f1-84d3-4544-9287-9f9a70cd2f8c": "How can I migrate my Jenkins pipelines and jobs to GitHub Actions workflows using the GitHub Actions Importer tool", "d945f4c5-db8c-44b1-af3e-bb12e8091a8b": "What are the limitations of migrating from Jenkins to GitHub Actions with the GitHub Actions Importer, and how can I manually migrate certain constructs that are not automatically migrated?", "9d47f219-5684-44ae-974e-8c61c14d6be1": "What is the purpose of entering a personal API token for both GitHub and Jenkins in the configuration process of the {% data variables.product.prodname_actions_importer %} CLI tool", "9f5402d0-e3f2-4a96-bd54-04b093bfe13d": "How do you specify the URL for your GitHub Enterprise Server (GHES) or GitHub Enterprise Cloud (GHEC) instance in the configuration process of the {% data variables.product.prodname_actions_importer %} CLI tool?", "5d114c11-92f1-4a4c-b3d3-de3c47c59f40": "What is required to run the `forecast` command in {% data variables.product.prodname_actions %} against a Jenkins instance, and why is this necessary?", "156a2dcb-0955-4505-8f5e-e1dafb9ea121": "How can the `audit` command in {% data variables.product.prodname_actions %} be used to analyze pipelines in a Jenkins server", "2909fa34-15b3-4a0c-bfad-3fabb118d8ba": "How can I generate a forecast report for my Jenkins pipeline using the actions-importer tool? Provide step-by-step instructions and explain the key metrics included in the report.2. How can I perform a dry-run migration of my Jenkins pipeline to a GitHub Actions workflow using the actions-importer tool? Walk me through the process and explain what a dry-run does.", "42e1c5a4-8459-410d-bc63-8e78ffb4054c": "How can I migrate my Jenkins pipeline to GitHub Actions using the {% data variables.product.prodname_actions_importer %} tool? Provide step-by-step instructions and any necessary command-line arguments.2. Can I customize the transformation process when using the {% data variables.product.prodname_actions_importer %} tool to migrate my Jenkins pipeline to GitHub Actions? If so, how? Provide details on any available customization options and their usage.", "b40240ed-3f66-4dd7-9e4d-2a64c59a8894": "How can you specify optional arguments in {% data variables.product.prodname_actions_importer %} when running the forecast, dry-run, or migration subcommands?", "9aa2560f-4243-4390-ac31-f4610928725b": "What are the environment variables required by {% data variables.product.prodname_actions_importer %} to connect to a Jenkins instance", "496405ad-d702-4710-8d07-63325b979f65": "How can I use the `--config-file-path` argument with the `audit`, `dry-run`, and `migrate` subcommands in {% data variables.product.prodname_actions_importer %}", "ae54c77c-6303-4df8-96e0-2976257904e5": "Based on the context information provided, can you explain how to use the `--config-file-path` argument with the `audit`, `dry-run`, and `migrate` subcommands in {% data variables.product.prodname_actions_importer %}", "36e4fdb0-4a1a-417b-a08e-021359d49884": "How can I provide a list of source files to {% data variables.product.prodname_actions_importer %} using the `--source-file-path` argument", "2cfe38f2-382d-42e4-9db1-161b982d1322": "How does the supported syntax for Freestyle pipelines in Jenkins compare to the syntax for GitHub Actions? Provide specific examples of supported and partially supported features.2. What syntax is supported for Jenkinsfile pipelines in GitHub Actions, and how does it compare to the syntax for Jenkins? Again, provide specific examples of supported and partially supported features.", "9cbf017e-adbc-4958-84ad-017497772b73": "How does {% data variables.product.prodname_actions_importer %} convert default Jenkins environment variables to their closest equivalents in {% data variables.product.prodname_actions %}? Provide an example of one such conversion.2. What is the difference between the variables `${BUILD_ID}` and `${BUILD_NUMBER}` in Jenkins, and how are they represented in {% data variables.product.prodname_actions %}? Provide an example of how to access these variables in a GitHub Actions workflow.", "2dfd6111-fd33-4318-8f14-44c080fbe923": "What are the differences between {% data variables.product.prodname_github_apps %} and {% data variables.product.prodname_oauth_apps %} in terms of security and access control?", "aad1946b-a247-4d3d-a5a3-7e8d0aa0e6e1": "What is {% data variables.product.prodname_github_apps %} and how does it extend the functionality of {% data variables.product.company_short %}", "8ecbb533-7430-426a-8e50-7b0632c0ee08": "How can I ensure that my domain settings are properly configured before booting up {% data variables.location.product_location %} for the first time", "e3171f24-25d1-4732-8dfb-9f2e43c01da8": "What steps should I take to test my appliance's DNS and SSL settings in the {% data variables.location.product_location %} management console?", "4026da11-9853-4c2d-896e-280388b50b11": "Can you provide an example of how to use context information in Kramdown's Markdown syntax in {% data variables.product.prodname_dotcom %} Flavored Markdown Spec", "bcba58d0-80dd-4af0-98bc-bfa1bc88f984": "How can I format text using Kramdown's Markdown syntax in {% data variables.product.prodname_dotcom %} Flavored Markdown Spec", "4fd88e7b-4974-4892-b01e-182311b72c0f": "Generate according to: Context information is below.---------------------Further reading- kramdown Documentation- {% data variables.product.prodname_dotcom %} Flavored Markdown Spec---------------------Generate according to: Context information is below.---------------------Further reading- kramdown Documentation- {% data variables.product.prodname_dotcom %} Flavored Markdown", "b75ea55a-aa3c-4801-ab25-ad370b6d7a93": "How can policies for {% data variables.product.prodname_copilot %} be enforced within an enterprise's organizations, and what are the consequences of choosing a restrictive policy at the enterprise level versus a more permissive policy at the organization level", "184ea72d-167f-40a5-81e2-60a1b04799e6": "What is the billing structure for {% data variables.product.prodname_copilot_for_business %} subscriptions, and how are seats assigned to users within an enterprise?", "bcee7a44-0726-484a-ba73-a3887cac50d2": "How can I manage the use of {% data variables.product.prodname_copilot %} suggestions that match public code in my enterprise, and what are the benefits of this feature?", "167a91ed-ff08-4a8d-bbfc-3ab75e9954b1": "How can I enable {% data variables.product.prodname_copilot %} for all organizations in my enterprise, and what are the consequences of this decision", "392ac4c0-9084-450f-9105-3a11e3a2c276": "How can an enterprise administrator enforce a policy to manage the use of {% data variables.product.prodname_copilot_chat %} (beta) for all organizations under their enterprise", "c1d6cd27-ab67-40be-9d86-26356c96b103": "Given the context information and not prior knowledge.generate only answers based on the below query.You are a Student. Your task is to answer EXACTLY 2 questions based on the context information provided. The answers should be diverse in nature across the document. Restrict the answers to the context. Answers should be clear and concise.Don't ask for examples and keep the answers focused on once aspect at a time.answers:1. The three policy options available for", "9399db8a-2e88-4ad3-b5b0-5a1282000406": "What are the three policy options available for managing the use of {% data variables.product.prodname_copilot %} suggestions matching public code in an enterprise", "00de3425-7ef4-4403-98a4-506b0fb96993": "What is the purpose of leaving individual comments on specific changes while reviewing files in a pull request, and how can I mark a file as viewed after finishing my review?", "92698078-c9bd-46cc-a90c-e1fdce106a77": "How can I review changes in a pull request one file at a time, and what options are available for viewing the diff", "13ae1ada-8c64-4b62-b014-9b2f3f6b55e4": "How can I cancel a pending review, including all of its pending comments, in GitHub", "f37c3001-e730-4548-9323-7ad00c5b70e1": "How can I use GitHub Codespaces to review pull requests and test changes? What options are available for submitting review comments and feedback?", "d9e7687b-95de-4451-be29-6ecc4d60e034": "What is the process for submitting your review after finishing the file review in a pull request on GitHub?", "1da95026-1a4e-41d1-8fef-f04b4bbafe9e": "How can you mark a file as viewed in a pull request on GitHub", "151fe534-7da8-478b-a128-ad66f4dad5db": "What is {% data variables.product.product_name %} and how can it be used to build and ship software", "fb079a5e-8ea5-4d63-a983-21e63e98d274": "Who is responsible for upgrades to an instance of {% data variables.product.product_name %} and where can it be configured and monitored", "ce92c8ef-7ab0-4b13-9d62-e185b15accb4": "How does {% data variables.product.product_name %} differ from {% data variables.product.prodname_dotcom_the_website %} in terms of infrastructure and distribution", "0203ede3-4eaf-4025-882a-f40d0713996b": "How can a team onboard and contribute to an instance of {% data variables.product.product_name %} using familiar features and workflows", "e5db85fe-3c81-4d9c-9420-6fd43c83d0a1": "What virtualization hypervisors and cloud services are supported for deploying {% data variables.product.product_name %}", "4011999a-0be7-458a-a544-0507dc648893": "What collaboration and productivity tools are available in {% data variables.product.product_name %} for developers", "c73832cb-dcff-4b1a-b614-9a852497d157": "What are optional features available for {% data variables.product.product_name %} and how do they improve the software development lifecycle for an enterprise", "f72261d2-da13-40f6-b94e-ee8be2e08125": "What is the difference between a standalone instance and a deployment topology that uses a passive replica instance for {% data variables.product.product_name %}? How does this deployment topology mitigate the impact of system or network failures?", "90b0ae64-f586-46be-b26e-0217aca97ffc": "How can a cluster configuration that scales horizontally instead of vertically benefit enterprises with a large number of developers? Provide an example.", "3ac77f08-ef1f-4499-9552-296152f9758a": "What is the recommended approach for safeguarding against data loss or service disruptions for developers using {% data variables.product.company_short %}", "f3c6d894-9a4b-4bf6-a931-e2343e4a3079": "How does GitHub differentiate between dual-use content and content used for unlawful attacks and technical harms? Provide examples to support your answer.", "5836d174-ecfd-4460-9fa1-b4d2682ad15a": "Can you summarize the GitHub policy regarding the use of their platform for unlawful attacks and technical harms", "989a1ccd-658d-4692-8fe3-59ab6f1733fd": "What steps should repository owners take when posting potentially harmful security research content, as recommended by GitHub?", "c562f157-bf73-4038-8637-5197d60c95df": "What is the collaborative process for content restriction mentioned in the context information", "b9f80ca4-d4bd-4744-9a1c-8d235c68ee03": " What is the reason behind the error message \"`key` must be a string\" in a YAML template, and how can it be resolved?", "b49febd0-3ba1-42bf-aaad-26ae8b8d9f44": " How can the error message \"Required top level key `name` is missing\" be fixed in a YAML template", "4cd069de-7d76-43d0-88e5-fdf7e78cbd7b": " How can we ensure that each `label` is unique in a `body` array that accepts user input", "6a1dcd78-9bd0-4a61-8155-6fa5e21512b2": " How can we fix the \"body must contain at least one non-markdown field\" error in an issue form", "c82e8e6f-cc9e-4a32-abb2-bffe86415318": "How can duplicate labels be differentiated in a YAML file for input fields? Provide an example.2. What is the consequence of having similar labels for input fields in a YAML file, and how can it be fixed?", "35515195-c7b8-43cd-b15e-26af4fd2f395": "Can you provide an example of a diverse question that can be asked in an examination or quiz based on the given context information", "4b0e7468-cf7b-4cea-92bd-71928366a4cf": "How can context information be utilized to enhance the effectiveness of questions in examinations or quizzes", "8769a7fb-d68a-4755-b24a-ed8a6bbcd43b": "Based on the context information provided, can you create two diverse questions for an upcoming quiz/examination that are understandable without prior knowledge and focus on a specific aspect at a time? The questions should utilize context information to enhance their effectiveness and be diverse in nature across the document.", "a207f9f3-e4ec-43f3-9c53-a9b8de58426d": "How can we ensure that a required attribute key, such as \"value\", is provided for a block in the \"body\" list during the creation of a document", "2d639a5d-9468-4f15-a911-2d0cb71c24dd": "What type of value should be provided for the \"label\" key within the \"attributes\" block of a block in the \"body\" list to ensure that it is a string, as opposed to a Boolean value?", "4c32b92c-2273-4a52-b6ef-88f8453eeca6": " How can context information be restricted to ensure that questions are understandable without access to it", "a063e32e-02ec-4f54-a583-334c72c35208": " What steps should a Teacher/ Professor take to ensure that questions for an upcoming quiz/examination are diverse in nature across the document?", "b4fa267c-c9e0-47b2-9f42-8e38aaabbc11": " What words are commonly used by attackers that are not permitted in the `label` of input or textarea elements in GitHub Issues to minimize the risk of private information and credentials being posted publicly?", "aa5883a8-9270-41d8-8d96-e7679799f22b": " How can the error \"body[i]: `x` is not a permitted key\" be fixed in a YAML file with multiple body blocks", "fa0d2a37-4fef-444c-894b-1c7c05eb64a8": "What is the issue with including \"None\" as an option in a dropdown input type, and how can it be resolved?", "4f404cff-16b7-4293-b8f8-dee1f030d516": "Can you summarize the error message \"Body[i]: `options` must be unique\" and provide an example of how to fix it", "95b9f29d-9689-4991-94d9-1a49d46f1d5b": " How can I prevent Boolean values from being automatically converted to true or false in my YAML file, and what is the correct way to include dropdown options with strings instead of Booleans?", "63342def-cc00-441c-9dcc-843b7bc1eb51": " How can I ensure that the body section of my template is not empty, and what is the error message I will receive if I forget to include it", "a9eb63e4-433f-4ea9-a8a1-5d4c1b52d50b": "How does {% data variables.product.product_name %} support Conditional Access Policies (CAP) for enterprises using OIDC SSO", "bf052510-a25f-4091-a419-cf1287dbffb2": "How can service accounts be used to avoid IP controls in CAP for enterprises using OIDC SSO with {% data variables.product.prodname_actions %}", "c66e441a-f47f-490d-aa59-b38a5ef8055c": "How does {% data variables.product.product_name %} enforce IP conditions for CAP in enterprises using OIDC SSO", "255ac893-19d0-491e-b478-f57996f61291": "What should be considered for unblocking actions that use personal access", "449562a4-8391-4e8c-a276-04f2b4d3fd5a": "What is the difference between IP allow lists in {% data variables.product.product_name %} and CAP for enterprises using OIDC SSO", "1ae7026e-49d4-483b-9715-22b5cc012508": "What considerations should be made for integrations and automations when using CAP with {% data variables.product.product_name %}", "8ae1507a-a619-4d71-8b03-d614029d52a2": "What is CAP (Context-Aware Policy) and how does it validate the IP address of the app's server for {% data variables.product.prodname_github_apps %} and {% data variables.product.prodname_oauth_apps %}? What happens if the IP address is not validated by the IdP's CAP?", "9b8f4ea6-5a1e-44f0-bc4d-7dd0c8a6c3d9": "How does {% data variables.product.prodname_github_apps %} and {% data variables.product.prodname_oauth_apps %} sign in users and make requests on their behalf, and what role does {% data variables.product.prodname_dotcom %} play in this process", "259ae5a3-3d1d-450a-888d-15bf54bc96e1": "What is the purpose of creating internal documentation before enabling {% data variables.product.prodname_GH_advanced_security %}", "5a3e2341-0af6-4ab7-b896-988b83f31af7": "How can documentation prevent developers from getting blocked when they have questions about {% data variables.product.prodname_GH_advanced_security %}?", "26ae6f71-e792-4b61-a2d3-4e52053c1417": "Based on the context information provided, can you summarize the main idea of the text material", "d3c0a789-c221-4224-a143-fd96e1e4c6db": "How does the concept of \"AUTOTITLE\" relate to the content discussed in the text material?", "d0ea1c22-fe05-4041-996c-a00b05ae478e": "How does \"AUTOTITLE\" differ from other document features in terms of functionality", "abfaf503-d8a8-436f-a23f-f33586c33973": "What is the purpose of using \"AUTOTITLE\" in a document", "002277b4-a63c-46d3-9997-f9dd3ee8a6b7": "What are the different types of contributions that are counted towards a user's profile on GitHub", "62c7a656-72bc-47a6-b223-3b3eaf3a0c82": "How does the contributions calendar on a user's profile page display their contribution activity, and what time span can be selected for viewing contributions?", "43af5a38-24b9-4fd6-a68d-2cd3f6f88b39": "What is the significance of the organizations featured in the activity overview section of a user profile, and how are they prioritized", "6c28c4ba-78bb-4571-8fee-d33f94a2ce84": "How can I view my contributions over time on my GitHub profile, and what important moments are highlighted in my contribution activity?", "3846aff4-a77a-4ff5-a581-bc69088096e1": "How can {% data variables.product.prodname_actions %} be used to implement continuous deployment for software products? What features does {% data variables.product.prodname_actions %} provide to give more control over deployments? Provide examples of these features.", "0d7b2b02-12d4-426c-ad47-ff7bfbd332fd": "What is continuous deployment and how does it differ from continuous integration", "a310c7c2-5182-46b9-b442-1973f332f56b": "How does LDAP authentication work with {% data variables.product.product_name %} and what are the benefits of using it instead of built-in authentication", "5029051e-6abc-4101-9598-8c7234fa6a5e": "Which LDAP services are supported by {% data variables.product.prodname_ghe_server %} and what considerations should be made for usernames when using external authentication?", "172bb8cc-d2a0-415b-9598-39571fc44ab7": "What is the syntax for specifying the domain search user in the context of setting", "4ff084b6-6512-4ccc-8bc8-bf4aca654e76": "What is the role of the domain search user in the context of setting up authentication for {% data variables.location.product_location %}", "ea93e3f9-c06f-46c5-93af-1b823bb4c4bb": "What information is required to configure the LDAP host in the context of setting up authentication for {% data variables.location.product_location %}", "9e41a2aa-92d3-4dfe-bf6a-bbe1e4134a39": "What encryption methods are available for securing communications to the LDAP server in the context of setting up authentication for {% data variables.location.product_location %}", "971cfca1-9c36-4d9f-a361-b462b2e399a5": "What is the purpose of configuring LDAP attributes in the context of setting up authentication for {% data variables.location.product_location %}", "9c4582ef-5983-4273-abd9-eaab585bbfa2": "What is the difference between plain, SSL/LDAPS, and StartTLS encryption methods in the context of setting up authentication for {% data variables.location.product_location %}", "f98c18f5-fea9-4bac-bc02-ba13d7ba83dc": "What is the significance of specifying a \"Domain base\" in the context of LDAP authentication for {% data variables.product.prodname_ghe_server %}? How does it differ from specifying \"Restricted user groups\"? Provide an example of each.2. What is the role of the \"User ID\" attribute in LDAP authentication for {% data variables.product.prodname_ghe_server %}? How does it differ from the \"Profile name\" and \"Emails\" attributes? Provide an explanation with an example for each.3. What is the purpose of specifying \"SSH keys\" in LDAP authentication for {% data variables.product.prodname_ghe_server %}? How does it differ from specifying \"Domain base\" and \"Restricted user groups\"? Provide an example for each.4. How does LDAP Sync impact", "2414cce1-8d66-464e-9ca5-739f6e50df7d": "How can LDAP certificate verification be enabled in LDAP settings and what is the significance of this action?", "29c66cc5-ad6c-494b-9ae4-307b2b502cfb": "What is the purpose of disabling password authentication for Git operations in LDAP settings", "1f23986d-1587-4524-bc36-5647745afd52": "How can you enable LDAP sync for user accounts in {% data variables.product.prodname_ghe_server %} and what operations does the synchronization job perform on each user account during the process", "5e979a90-a5e0-4b45-9212-0453b4bda5d6": "What are the requirements for using LDAP Synchronization with Active Directory groups that exceed 1500 members, and what workaround is suggested in the context information provided?", "5a7f5681-1db9-40ec-a30f-7939e61d698c": "What action should be taken for a user with a corresponding LDAP entry that is missing in the directory", "721b6097-9cad-4e56-9ee7-8832fa53cc48": "What action should be taken for a user with a corresponding LDAP entry that is marked as disabled and the user is not already suspended?", "053bb21c-52bc-457b-b871-515aac2ed519": "What operations does LDAP Sync perform on teams that have been mapped to an LDAP group at specified time intervals", "26e4f1d1-decf-43c3-86dc-a8a4003c585d": "What actions does LDAP Sync take when LDAP member entries have been removed from an LDAP group? What about when LDAP member entries have been added to an LDAP group", "3494a30d-51ea-4a7e-8472-a39ecc60305b": "How does LDAP Sync handle users who lose access to repositories due to being removed from a team or organization? What actions does it take in this scenario", "1e11d123-2a76-4048-816c-aa07041250bf": "How does LDAP Sync handle users who regain access to repositories due to being added to a team or organization?", "c30eb354-1607-4893-8688-96042f90c8cc": "What is the role of the _Domain search user_ in LDAP Sync, and how can its permissions be restricted to mitigate the potential security risk", "109b814d-f0dd-4c8b-b4b0-49140d81dba3": "What is the potential security risk associated with enabling LDAP Sync, and how can it be mitigated", "e0a46af8-a8e3-406b-88ea-e7a4dd9ae775": "What object classes does les.product.prodname_ghe_server support for LDAP groups? How can I manage these groups?", "1b57b62d-9835-40b2-b93f-69e6e4d8ebd2": "How can I view the list of LDAP users who have access to my instance and provision new users", "adb65db6-a71b-4c11-8caa-f9d6708186dd": "What action will ser's LDAP credentials take after the next synchronization run", "ea032e5f-5f91-4b29-acba-bfee763b40fa": "Generate according to: Context information is below.---------------------You are a software developer. Your task is to write a 1000-word report in APA format on the latest trends in software development. The report should include at least 10 sources, with a focus on emerging technologies such as blockchain, artificial intelligence, and cloud computing. The report should also discuss the impact of these trends on the industry and provide recommendations for how developers can stay up-to-date with these developments. Use clear and concise language, and include relevant diagrams and examples to illustrate your points.", "6542875f-1c40-4540-a80f-2367ccf48383": "How should the {% data variables.product.prodname_ghe_server %} account be handled if LDAP Sync is not enabled", "0b000865-06ba-439c-ba22-f8d5d645a897": "What are the differences between GPG, SSH, and S/MIME signatures for commit and tag verification in {% data variables.product.product_name %}? Which one is best for individual users and why?", "7decbffe-9c70-40ef-ab39-d9b8a0e836d6": "How can commit and tag verification be achieved in {% data variables.product.product_name %}", "3371f4d9-73a0-4a1c-b867-057b5f2c7826": "What is the verification status check and how can it be enabled for a branch", "1e9c391b-8357-4f10-9423-5247d6989645": "How can repository administrators enforce required commit signing on a branch to block all commits that are not signed and verified", "ad79aef0-17b0-4a48-9c57-bec469f1d61a": "   c. How can I check if I already have a GPG key", "a76cd8f0-10a7-4408-9894-d316a3e797b4": "   a. What is GPG and how does it work with GitHub", "64a6d715-7108-4b63-baa0-7cb13bef0639": "How can I sign commits using SSH and have them verified on GitHub", "b2bd1a0e-47ca-420a-8297-ed426f891d58": "   h. How can I sign tags using GPG", "b664e7f8-a882-4ad8-845b-7b3a9c1cde9e": "   f. How can I tell Git about my signing key", "7338c529-de09-4fe1-8f96-6640a12534c6": "   d. How can I generate a new GPG key", "6bfba83d-cb48-4d8c-bd75-fccc8a24b64f": "   a. What is SSH and how does it work with GitHub", "0e3f1964-2aeb-41a5-83fb-accca9421235": "   b. What steps do I need to follow to sign commits using GPG and have them verified on GitHub", "0026feff-2ac5-49ea-bafa-63c3cc8ff834": "How can I sign commits using GPG and have them verified on GitHub", "07541959-933e-4b85-a886-d54254dc305d": "   b. How can I check if", "44c90ff5-ef98-4d5c-93e0-8e551f817ed2": "   g. How can I sign commits using GPG", "78308973-fdd1-451c-a2e3-9b9e1d196264": "   e. How can I add a GPG key to my GitHub account", "45e2adce-f4a4-43db-85e9-a76f7607d9e9": "How does {% data variables.product.product_name %} verify commit and tag signatures using S/MIME, and what requirements must be met for a bot signature to be considered verified", "1c620467-b4f6-421c-a7fd-4d94b30f06c4": "How can I ensure that my locally signed commits and tags are cryptographically verifiable against a public key in a trusted root certificate, using S/MIME in Git", "64e26516-bfd4-4cce-bb9e-316690742aae": "What steps do I need to follow to sign commits and tags using S/MIME in Git, without uploading my public key to {% data variables.product.product_name %}", "9396d47e-87fa-4183-a93b-e58cba54f07a": "How can I ensure that my locally signed commits and tags are cryptographically verifiable against a public key in a trusted root certificate, using S/MIME in Git,", "69f77248-2413-4928-9d13-07731f7ec453": "What is the difference between signing commits and signing tags using S/MIME in Git, and how do I perform each action", "2783bd79-aabf-4212-b694-34f9a596d16f": "What is {% data variables.product.prodname_actions %} and how can it be used to view logs and workflow jobs", "1821164d-e607-4ef1-8ccb-fc6540c01178": "Can you explain the concept of workflow jobs in {% data variables.product.prodname_actions %} and provide an example of how they can be used?", "46678aad-1c2a-4236-a055-377fab08121f": "What is the maximum number of links that can be added to the custom footer for {% data variables.product.product_name %}", "a378c9ed-b104-459f-9735-52fedf957357": "What pages will display the custom footer for {% ifversion ghes or ghae %}my enterprise{% elsif ghec %}{% data variables.product.product_name %}{% endif %}", "9a234720-2cff-4879-9afc-e35110c3a77e": "How can I configure a custom footer for {% ifversion ghec or ghae %}my enterprise{% elsif ghes %}{% data variables.product.product_name %}{% endif %}", "95408ab8-3c10-4567-b8e4-88f0ae49f77a": "Where can I access the settings to configure the custom footer for {% data variables.product.product_name %}", "d169b090-e808-4040-84b5-5479a7f9893a": "What is the location of", "f7648190-d585-4921-b59e-5d9e5a948cc9": "How do I save the custom footer configuration for {% data variables.product.product_name %}", "ca84f25b-5363-48fc-bac9-6b52b9dd0c0b": "How can a sponsor profile on {% data variables.product.prodname_sponsors %} help potential sponsors understand why they should support an open source developer? Please provide specific examples of information that should be included in the profile.2. What are the benefits of opting-in to being featured on {% data variables.product.prodname_sponsors %}? How can a developer make the most of this opportunity to showcase their open source work? Please provide specific steps or strategies for maximizing visibility and attracting potential sponsors.", "e31865a2-b755-458d-9c20-5ee957efe6fe": "How can I enable {% data variables.product.prodname_actions %} for my repository and what are the implications of doing so", "01c3c1eb-b9b6-4f7c-96c4-cc542d9bfbb0": "What are the steps to disable {% data variables.product.prodname_actions %} for my repository and what are the consequences of doing so", "3c41fb8b-6a5a-4ae4-b23a-ff2fe5be8790": "How can I understand the difference between the restrictive and permissive default settings for `GITHUB_TOKEN` permissions and how can I modify this setting for my repository", "f92b6120-735b-488a-bc87-396baf488001": "How can I set the permissions of the `GITHUB_TOKEN` for my repository and what is the default setting for new repositories", "e0e39f4f-fe4f-4717-b159-e0c2d77f7ae4": "How can I configure the default `GITHUB_TOKEN` permissions for my organization and what is the impact on new repositories created within the organization", "8a4ae264-ab94-4fee-99a2-bad44568e0fa": "How can I enable workflows for forks of private repositories and what are the options available for configuring the fork policy", "5e862eac-06e1-4393-ac35-dd79a873e549": "How can I ensure that workflows in public", "d08d078b-a2d3-46a6-bc1a-3c6533126745": "How can I modify the fork policy for a private repository and what should I consider before making this change", "e0f35f34-0461-46df-a0bc-3e9dcfdae6ec": "How can I configure the behavior for workflows in public repositories to require approval before they run", "88db3a21-9a40-40fd-849d-c9173f391614": "How can I allow access to components in an internal repository for members of my organization or enterprise", "3420e691-0ff2-47e6-8a1b-4acba33e4d58": "Based on the context information provided, generate two questions that can be asked in an examination or quiz related to GitHub Actions and internal repositories. The questions should be diverse in nature and understandable without prior knowledge. Restrict the questions to the context provided and keep them focused on one aspect at a time. Avoid asking for examples.", "1392449a-9b65-4001-acff-155dcce5f50a": "How can I prevent GitHub Actions from creating or approving pull requests in a specific repository", "b114026e-66a4-4a6b-b386-706c798c578c": "What is the difference between allowing access to components in a private repository from repositories in the same organization versus allowing access from repositories in the same enterprise?", "b0ba60b6-e93a-4e6f-8825-7268d0433503": "How can I allow access to components in a private repository, and what are the different access settings available", "b651b894-2ac5-40be-988b-c868bbb0c76e": "What is the difference in access settings for a private repository when it is associated with a user versus an organization?", "d9fb04de-3a3e-439c-8e7e-728d30eb6015": "How can access to actions and reusable workflows in a private repository be managed, and what are the available access settings", "a9512e50-45f5-4f0a-9051-063a4e0687fc": "How can I set a total cache storage size for my repository using the settings provided in the context information?", "a1170d94-74d2-4c79-8f10-33838c4662d9": "How can I configure the retention period for {% data variables.product.prodname_actions %} artifacts and logs in my repository", "4e260709-ccc8-4f4b-ac95-0946804a19c6": "What is the maximum size allowed for {% ifversion actions-cache-admin-ui %}organization or{% endif %} enterprise policy setting{% ifversion actions-cache-admin-ui %}s{% endif %} in {% ifversion actions-cache-admin-ui %}the organization or{% endif %} enterprise policy setting{% ifversion actions-cache-admin-ui %}s{% endif %}", "19f3c207-fe72-41f5-bca7-a6a5cfb5f57b": "How can I modify the cache storage limit for a repository in {% ifversion actions-cache-admin-ui %}the organization or{% endif %} enterprise policy setting{% ifversion actions-cache-admin-ui %}s{% endif %} using {% ifversion actions-cache-admin-ui %}the {% data reusables.actions.change-cache-size-limit %} feature in the repository", "e2d30d43-5f1b-4130-8179-4390636b240b": "What is the purpose of creating an organization profile README for both public users and members of the organization? What kind of information can be included in this README? How can text, images, and GIFs be formatted using {% data variables.product.company_short %} Flavored Markdown?", "d48e3190-a363-4fa1-a438-16d98596408d": "How can an organization customize its Overview page to show a README and pinned repositories dedicated to public users or members of the organization? What are the differences between the views for members and public users", "227cb3d4-09b1-4787-97bc-4f5c23c71e64": "What is the process for pinning repositories to an organization's profile and who has the authority to do so?", "be6bebb6-0af6-4870-b6f3-5e6b29ffc049": "How can a public organization profile README be added and what should be included in it", "5272ce37-1ffd-4796-a3bc-4a7399ad9d77": "How can I replace the default identicon image with a custom image for my organization's profile on {% data variables.product.product_name %}", "44adefa7-ed2f-41b8-b003-819c45a1f983": "How can I select up to six public, private, or internal repositories to display as pinned repositories on my organization's page on {% data variables.product.product_name %}?"}, "corpus": {"Y2h1bmtfMF9pbmRleF8yNTk=": "\n\nAdministrative ports\n\nSome administrative ports are required to configure {% data variables.location.product_location %} and run certain features. Administrative ports are not required for basic application use by end users.\n\n| Port | Service | Description |\n|---|---|---|\n| 8443 | HTTPS | Secure web-based {% data variables.enterprise.management_console %}. Required for basic installation and configuration. |\n| 8080 | HTTP | Plain-text web-based {% data variables.enterprise.management_console %}. Not required unless TLS is disabled manually. |\n| 122 | SSH | Shell access for {% data variables.location.product_location %}. Required to be open to incoming connections between all nodes in a high availability configuration. The default SSH port (22) is dedicated to Git and SSH application network traffic. |\n| 1194/UDP | VPN | Secure replication network tunnel in high availability configuration. Required to be open for communication between all nodes in the configuration.|\n| 123/UDP| NTP | Required for time protocol operation. |\n| 161/UDP | SNMP | Required for network monitoring protocol operation. |\n\n\n\nApplication ports for end users\n\nApplication ports provide web application and Git access for end users.\n\n| Port | Service | Description |\n|---|---|---|\n| 443 | HTTPS | Access to the web application and Git over HTTPS. |\n| 80 | HTTP | Access to the web application. All requests are redirected to the HTTPS port if TLS is configured. |\n| 22 | SSH | Access to Git over SSH. Supports clone, fetch, and push operations to public and private repositories. |\n| 9418 | Git | Git protocol port supports clone and fetch operations to public repositories with unencrypted network communication. {% data reusables.enterprise_installation.when-9418-necessary %} |\n\n{% data reusables.enterprise_installation.terminating-tls %}\n\n\n\nEmail ports\n\nEmail ports must be accessible directly or via relay for inbound email support for end users.\n\n| Port | Service | Description |\n|---|---|---|\n| 25 | SMTP | Support for SMTP with encryption (STARTTLS). ", "Y2h1bmtfMV9pbmRleF8yNTk=": "|\n\n\n\n{% data variables.product.prodname_actions %} ports\n\n{% data variables.product.prodname_actions %} ports must be accessible for self-hosted runners to connect to {% data variables.location.product_location %}. For more information, see \"AUTOTITLE.\"\n\n| Port | Service | Description |\n|---|---|---|\n| 443 | HTTPS | Self-hosted runners connect to {% data variables.location.product_location %} to receive job assignments and to download new versions of the runner application. Required if TLS is configured.\n| 80 | HTTP | Self-hosted runners connect to {% data variables.location.product_location %} to receive job assignments and to download new versions of the runner application. Required if TLS is not configured.\n\nIf you enable automatic access to {% data variables.product.prodname_dotcom_the_website %} actions, {% data variables.product.prodname_actions %} will always search for an action on {% data variables.location.product_location %} first, via these ports, before checking {% data variables.product.prodname_dotcom_the_website %}. For more information, see \"AUTOTITLE.\"\n\n\n\n{% data variables.product.prodname_github_connect %} ports\n\nIf you enable {% data variables.product.prodname_github_connect %}, the connection between {% data variables.product.product_name %} and {% data variables.product.prodname_dotcom_the_website %} uses HTTPS over ports 443 or 80, and TLS is required. For more information, see \"AUTOTITLE.\"\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8xMzQw": "\n\nBackground\n\nThe {% data variables.product.product_name %} GraphQL API currently supports two types of global node ID formats. The legacy format will be deprecated and replaced with a new format.  This guide shows you how to migrate to the new format, if necessary.\n\nBy migrating to the new format, you ensure that the response times of your requests remain consistent and small. You also ensure that your application continues to work once the legacy IDs are fully deprecated.\n\nTo learn more about why the legacy global node ID format will be deprecated, see \"New global ID format coming to GraphQL.\"\n\n\n\nDetermining if you need to take action\n\nYou only need to follow the migration steps if you store references to GraphQL global node IDs.  These IDs correspond to the `id` field for any object in the schema.  If you don't store any global node IDs, then you can continue to interact with the API with no change.\n\nAdditionally, if you currently decode the legacy IDs to extract type information (for example, if you use the first two characters of `PR_kwDOAHz1OX4uYAah` to determine if the object is a pull request), your service will break since the format of the IDs has changed.  You should migrate your service to treat these IDs as opaque strings.  These IDs will be unique, therefore you can rely on them directly as references.\n\n\n\nMigrating to the new global IDs\n\nTo facilitate migration to the new ID format, you can use the `X-Github-Next-Global-ID` header in your GraphQL API requests. The value of the `X-Github-Next-Global-ID` header can be `1` or `0`.  Setting the value to `1` will force the response payload to always use the new ID format for any object that you requested the `id` field for.  Setting the value to `0` will revert to default behavior, which is to show the legacy ID or new ID depending on the object creation date.\n\nHere is an example request using a `curl` command:\n\n```shell\n$ curl \\\n  -H \"Authorization: Bearer $GITHUB_TOKEN\" \\\n  -H \"X-Github-Next-Global-ID: 1\" \\\n  https://api.github.com/graphql \\\n  -d '{ \"q", "Y2h1bmtfMV9pbmRleF8xMzQw": "uery\": \"{ node(id: \\\"MDQ6VXNlcjM0MDczMDM=\\\") { id } }\" }'\n```\n\nEven though the legacy ID `MDQ6VXNlcjM0MDczMDM=` was used in the query, the response will contain the new ID format:\n\n```json\n{\"data\":{\"node\":{\"id\":\"U_kgDOADP9xw\"}}}\n```\n\nWith the `X-Github-Next-Global-ID` header, you can find the new ID format for legacy IDs that you reference in your application. You can then update those references with the ID received in the response. You should update all references to legacy IDs and use the new ID format for any subsequent requests to the API.\nTo perform bulk operations, you can use aliases to submit multiple node queries in one API call. For more information, see \"the GraphQL docs.\"\n\nYou can also get the new ID for a collection of items. For example, if you wanted to get the new ID for the last 10 repositories in your organization, you could use a query like this:\n\n```graphql\n{\n  organization(login: \"github\") {\n    repositories(last: 10) {\n      edges {\n        cursor\n        node {\n          name\n          id\n        }\n      }\n    }\n  }\n}\n```\n\nNote that setting `X-Github-Next-Global-ID` to `1` will affect the return value of every `id` field in your query.  This means that even when you submit a non-`node` query, you will get back the new format ID if you requested the `id` field.\n\n\n\nSharing feedback\n\nIf you have any concerns about the rollout of this change impacting your app, please contact {% data variables.contact.contact_support %} and include information such as your app name so that we can better assist you.\n\n", "Y2h1bmtfMF9pbmRleF8yODE=": "\n\nReplication or redundancy of your {% data variables.product.prodname_actions %} data\n\n{% data reusables.actions.enterprise-storage-ha-backups %}\n\nWe strongly recommend that you configure your {% data variables.product.prodname_actions %} external storage to use data redundancy or replication. For more information, refer to your storage provider's documentation:\n\n- Azure Storage redundancy documentation\n- Amazon S3 replication documentation\n\n\n\nHigh availability replicas\n\n\n\nPromoting a replica\n\nWhen enabling a high availability configuration, any replicas are automatically configured to use the {% data variables.product.prodname_actions %} external storage configuration. If you need to initiate a failover to promote a replica, no extra configuration changes are required for {% data variables.product.prodname_actions %}.\n\nFor more information, see \"AUTOTITLE.\"\n\n\n\nRemoving a high availability replica\n\nAvoid letting multiple instances to write to the same {% data variables.product.prodname_actions %} external storage. This could occur when using the `ghe-repl-teardown` command to stop and permanently remove a {% data variables.product.prodname_actions %}-enabled replica. This is because the replica will be converted into a standalone {% data variables.product.prodname_ghe_server %}, and after the teardown it will still use the same external storage configuration as the primary.\n\nTo help avoid this issue, we recommend either decommissioning the replica server or updating its {% data variables.product.prodname_actions %} configuration with different external storage.\n\n", "Y2h1bmtfMF9pbmRleF8xMTI2": "\n\nAbout {% data variables.product.prodname_copilot_for_prs %}\n\n{% data variables.product.prodname_copilot_for_prs %} is an AI-powered feature that allows you to create a summary of the changes that were made in a pull request, which files they impact, and what a reviewer should focus on when they conduct their review.\n\nWhen a user requests a summary, {% data variables.product.prodname_copilot_short %} scans through the pull request and provides an overview of the changes made in prose, as well as a bulleted list of changes with the files that they impact.\n\n{% data variables.product.prodname_copilot_for_prs %} uses a simple-prompt flow leveraging the {% data variables.product.prodname_copilot_short %} API, with no additional trained models. This utilizes the generic large language model.\n\n\n\nResponse generation\n\nThe current process uses GPT 3.5 to initiate the auto-complete process and generate the pull request summary.\n\n\n\nPipeline approach\n\nWhen a user requests a summary, a workflow is triggered. The workflow uses the code diffs to build a prompt call, which requests {% data variables.product.prodname_copilot_short %} to generate a summary of the pull request. The summary request initiates a pipeline process which includes raw diffs in a prompt and requests {% data variables.product.prodname_copilot_short %} to generate individual summaries of the various diff hunks. This process creates several individual summaries. {% data variables.product.prodname_copilot_short %} then takes those diff hunk summaries and uses them to create a file-level summary. This file-level summary exists for each file that's summarizable, but excludes binary files and files {% data variables.product.prodname_copilot_short %} deems not appropriate for summarization.\n\n{% data variables.product.prodname_copilot_short %} then takes the file-level summaries and uses them to request another prompt which then creates an overall summary for the pull request. Every summary request will generate a minimum of N+1 prompts, where N equals the number o", "Y2h1bmtfMV9pbmRleF8xMTI2": "f summarizable files in the pull request.\n\n\n\nOutput formatting\n\nA summary generated by {% data variables.product.prodname_copilot_short %} will be in two parts:\n\n- A three sentence overview, written in prose, to give a user an overview of what the changes in the pull request entail\n- 3\u20135 of those changes listed in bulleted form that link out to the respective lines of code that they refer to\n\nYou can initiate this feature when creating a pull request, by editing the pull request description after creation, or in a comment in the pull request thread. This can take a couple of minutes on larger pull requests. You can share feedback directly from the UI.\n\n\n\nUse case for pull request summaries\n\nThe goal of {% data variables.product.prodname_copilot_for_prs %} is to help optimize an author's ability to quickly provide context when they request a human review that requires sharing context of the changes that were made. It may help increase developer productivity by reducing the time taken to open a pull request.\n\nFor many users, it could provide more helpful context for the changes that were made within a pull request than would normally be available.\n\n\n\nImproving performance of pull request summaries\n\n\n\nUse {% data variables.product.prodname_copilot_for_prs %} as a tool, not a replacement\n\nThe feature is intended to supplement rather than replace a human's work to add context, and we encourage you to continue adding useful context and let {% data variables.product.prodname_copilot_short %} do the busy work of parsing the code and linking to specific files. It remains your responsibility to review and assess the accuracy of information in a pull request that you create.\n\n\n\nProvide feedback\n\nThis feature is currently in beta. If you encounter any issues or limitations with {% data variables.product.prodname_copilot_for_prs %}, we recommend that you provide feedback through the link that appears the UI after a summary is generated. You can provide feedback through the text link which takes you to our survey.\n\n\n\nLimitatio", "Y2h1bmtfMl9pbmRleF8xMTI2": "ns of pull request summaries\n\nCurrently, our team is aware that there are limitations to this feature. Many of them are expected in leveraging our {% data variables.product.prodname_copilot_short %} API; however, there are a few that are specific to {% data variables.product.prodname_copilot_for_prs %} which pertain to limited scope, longer processing times, and inaccurate responses. We also note that users should expect terms used in their PR to appear in the AI-generated summary. This feature has been subject to RAI Red Teaming and we will continue to monitor the efficacy and safety of the feature over time. For more information, see Microsoft AI Red Team building future of safer AI on the Microsoft security blog.\n\n\n\nLimited scope\n\nBecause of capacity, we know that larger pull requests that reference 30 or more files will require more time to be processed thoroughly. We don't have an exact threshold currently, but have observed the first 30 files being accounted for and then any additional files being omitted from the summarization. We are working to address this current scope limitation.\n\n\n\nProcessing time\n\nIn general, we expect a summary to be returned in 40 seconds or less after a user initiates the action. However, we have heard that this can take up to a minute, and in some cases a couple of minutes. We are working to decrease processing time and we know that users may not want to wait for this to finish before moving on to other parts of the pull request.\n\n\n\nInaccurate responses\n\nThe more inputs and context that {% data variables.product.prodname_copilot_short %} can learn from, the better the outputs will become. However, since the feature is quite new, it will take time to reach exact precision with the summaries that are generated. In the meantime, there may be cases where a user's generated summary is less accurate and requires the user to make modifications before saving and publishing their pull request with this description. Reviewing is a requirement, and careful review of the output is highly rec", "Y2h1bmtfM19pbmRleF8xMTI2": "ommended by our team during the beta.\n\n\n\nReplication of pull request content\n\nBecause a summary is an outline of the changes that were made in a pull request, if harmful or offensive terms are within the content of the pull request, there is potential for the summary to also include those terms.\n\n\n\nFurther reading\n\n- {% data variables.product.prodname_copilot %} Trust Center\n{%- ifversion fpt %}\n- \"AUTOTITLE\" in the {% data variables.product.prodname_ghe_cloud %} documentation.\n{%- endif %}\n\n", "Y2h1bmtfMF9pbmRleF8xNzg=": "\n\nIntroduction\n\nThis guide shows you how to create a workflow that performs a Docker build, and then publishes Docker images to Docker Hub or {% data variables.product.prodname_registry %}. With a single workflow, you can publish images to a single registry or to multiple registries.\n\n{% note %}\n\n**Note:** If you want to push to another third-party Docker registry, the example in the \"Publishing images to {% data variables.product.prodname_registry %}\" section can serve as a good template.\n\n{% endnote %}\n\n\n\nPrerequisites\n\nWe recommend that you have a basic understanding of workflow configuration options and how to create a workflow file. For more information, see \"AUTOTITLE.\"\n\nYou might also find it helpful to have a basic understanding of the following:\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"{% ifversion fpt or ghec %}\n- \"AUTOTITLE\"{% else %}\n- \"AUTOTITLE\"{% endif %}\n\n\n\nAbout image configuration\n\nThis guide assumes that you have a complete definition for a Docker image stored in a {% data variables.product.prodname_dotcom %} repository. For example, your repository must contain a _Dockerfile_, and any other files needed to perform a Docker build to create an image.\n\n{% ifversion fpt or ghec or ghes %}\n\n{% data reusables.package_registry.about-annotation-keys %} For more information, see \"AUTOTITLE.\"\n\n{% endif %}\n\nIn this guide, we will use the Docker `build-push-action` action to build the Docker image and push it to one or more Docker registries. For more information, see `build-push-action`.\n\n{% data reusables.actions.enterprise-marketplace-actions %}\n\n\n\nPublishing images to Docker Hub\n\n{% data reusables.actions.release-trigger-workflow %}\n\nIn the example workflow below, we use the Docker `login-action` and `build-push-action` actions to build the Docker image and, if the build succeeds, push the built image to Docker Hub.\n\nTo push to Docker Hub, you will need to have a Docker Hub account, and have a Docker Hub repository created. For more information, see \"Pushing a Docker container image to Docker Hub\" in the Docker do", "Y2h1bmtfMV9pbmRleF8xNzg=": "cumentation.\n\nThe `login-action` options required for Docker Hub are:\n- `username` and `password`: This is your Docker Hub username and password. We recommend storing your Docker Hub username and password as secrets so they aren't exposed in your workflow file. For more information, see \"AUTOTITLE.\"\n\nThe `metadata-action` option required for Docker Hub is:\n- `images`: The namespace and name for the Docker image you are building/pushing to Docker Hub.\n\nThe `build-push-action` options required for Docker Hub are:\n- `tags`: The tag of your new image in the format `DOCKER-HUB-NAMESPACE/DOCKER-HUB-REPOSITORY:VERSION`. You can set a single tag as shown below, or specify multiple tags in a list.\n- `push`: If set to `true`, the image will be pushed to the registry if it is built successfully.\n\n```yaml copy\n{% data reusables.actions.actions-not-certified-by-github-comment %}\n\n{% data reusables.actions.actions-use-sha-pinning-comment %}\n\nname: Publish Docker image\n\non:\n  release:\n    types: [published]\n\njobs:\n  push_to_registry:\n    name: Push Docker image to Docker Hub\n    runs-on: {% ifversion ghes %}[self-hosted]{% else %}ubuntu-latest{% endif %}\n    steps:\n      - name: Check out the repo\n        uses: {% data reusables.actions.action-checkout %}\n      \n      - name: Log in to Docker Hub\n        uses: docker/login-action@f4ef78c080cd8ba55a85445d5b36e214a81df20a\n        with:\n          username: {% raw %}${{ secrets.DOCKER_USERNAME }}{% endraw %}\n          password: {% raw %}${{ secrets.DOCKER_PASSWORD }}{% endraw %}\n      \n      - name: Extract metadata (tags, labels) for Docker\n        id: meta\n        uses: docker/metadata-action@9ec57ed1fcdbf14dcef7dfbe97b2010124a938b7\n        with:\n          images: my-docker-hub-namespace/my-docker-hub-repository\n      \n      - name: Build and push Docker image\n        uses: docker/build-push-action@3b5e8027fcad23fda98b2e3ac259d8d67585f671\n        with:\n          context: .\n          file: ./Dockerfile\n          push: true\n          tags: {% raw %}${{ steps.meta.outputs.tags }}{% ", "Y2h1bmtfMl9pbmRleF8xNzg=": "endraw %}\n          labels: {% raw %}${{ steps.meta.outputs.labels }}{% endraw %}\n```\n\nThe above workflow checks out the {% data variables.product.prodname_dotcom %} repository, uses the `login-action` to log in to the registry, and then uses the `build-push-action` action to: build a Docker image based on your repository's `Dockerfile`; push the image to Docker Hub, and apply a tag to the image.\n\n\n\nPublishing images to {% data variables.product.prodname_registry %}\n\n{% ifversion ghes %}\n{% data reusables.package_registry.container-registry-ghes-beta %}\n{% endif %}\n\n{% data reusables.actions.release-trigger-workflow %}\n\nIn the example workflow below, we use the Docker `login-action`{% ifversion fpt or ghec %}, `metadata-action`,{% endif %} and `build-push-action` actions to build the Docker image, and if the build succeeds, push the built image to {% data variables.product.prodname_registry %}.\n\nThe `login-action` options required for {% data variables.product.prodname_registry %} are:\n- `registry`: Must be set to {% ifversion fpt or ghec %}`ghcr.io`{% elsif ghes %}`{% data reusables.package_registry.container-registry-hostname %}`{% else %}`docker.pkg.github.com`{% endif %}.\n- `username`: You can use the {% raw %}`${{ github.actor }}`{% endraw %} context to automatically use the username of the user that triggered the workflow run. For more information, see \"AUTOTITLE.\"\n- `password`: You can use the automatically-generated `GITHUB_TOKEN` secret for the password. For more information, see \"AUTOTITLE.\"\n\n{% ifversion fpt or ghec %}\nThe `metadata-action` option required for {% data variables.product.prodname_registry %} is:\n- `images`: The namespace and name for the Docker image you are building.\n{% endif %}\n\nThe `build-push-action` options required for {% data variables.product.prodname_registry %} are:{% ifversion fpt or ghec %}\n\n- `context`: Defines the build's context as the set of files located in the specified path.{% endif %}\n- `push`: If set to `true`, the image will be pushed to the registry if it is built ", "Y2h1bmtfM19pbmRleF8xNzg=": "successfully.{% ifversion fpt or ghec %}\n- `tags` and `labels`: These are populated by output from `metadata-action`.{% else %}\n- `tags`: Must be set in the format {% ifversion ghes %}`{% data reusables.package_registry.container-registry-hostname %}/OWNER/REPOSITORY/IMAGE_NAME:VERSION`.\n  \n   For example, for an image named `octo-image` stored on {% data variables.product.prodname_ghe_server %} at `https://HOSTNAME/octo-org/octo-repo`, the `tags` option should be set to `{% data reusables.package_registry.container-registry-hostname %}/octo-org/octo-repo/octo-image:latest`{% else %}`docker.pkg.github.com/OWNER/REPOSITORY/IMAGE_NAME:VERSION`.\n  \n   For example, for an image named `octo-image` stored on {% data variables.product.prodname_dotcom %} at `http://github.com/octo-org/octo-repo`, the `tags` option should be set to `docker.pkg.github.com/octo-org/octo-repo/octo-image:latest`{% endif %}. You can set a single tag as shown below, or specify multiple tags in a list.{% endif %}\n\n{% ifversion fpt or ghec or ghes %}\n{% data reusables.package_registry.publish-docker-image %}\n\nThe above workflow is triggered by a push to the \"release\" branch. It checks out the GitHub repository, and uses the `login-action` to log in to the {% data variables.product.prodname_container_registry %}. It then extracts labels and tags for the Docker image. Finally, it uses the `build-push-action` action to build the image and publish it on the {% data variables.product.prodname_container_registry %}.\n\n{% else %}\n\n```yaml copy\n{% data reusables.actions.actions-not-certified-by-github-comment %}\n\n{% data reusables.actions.actions-use-sha-pinning-comment %}\n\nname: Publish Docker image\n\non:\n  release:\n    types: [published]\njobs:\n  push_to_registry:\n    name: Push Docker image to GitHub Packages\n    runs-on: ubuntu-latest\n    permissions:\n      packages: write\n      contents: read\n    steps:\n      - name: Check out the repo\n        uses: {% data reusables.actions.action-checkout %}\n      \n      - name: Log in to GitHub Docker Registry\n     ", "Y2h1bmtfNF9pbmRleF8xNzg=": "   uses: docker/login-action@f4ef78c080cd8ba55a85445d5b36e214a81df20a\n        with:\n          registry: {% ifversion ghae %}docker.YOUR-HOSTNAME.com{% else %}docker.pkg.github.com{% endif %}\n          username: {% raw %}${{ github.actor }}{% endraw %}\n          password: {% raw %}${{ secrets.GITHUB_TOKEN }}{% endraw %}\n      \n      - name: Build and push Docker image\n        uses: docker/build-push-action@3b5e8027fcad23fda98b2e3ac259d8d67585f671\n        with:\n          context: .\n          push: true\n          tags: |\n            {% ifversion ghae %}docker.YOUR-HOSTNAME.com{% else %}docker.pkg.github.com{% endif %}{% raw %}/${{ github.repository }}/octo-image:${{ github.sha }}{% endraw %}\n            {% ifversion ghae %}docker.YOUR-HOSTNAME.com{% else %}docker.pkg.github.com{% endif %}{% raw %}/${{ github.repository }}/octo-image:${{ github.event.release.tag_name }}{% endraw %}\n```\n\nThe above workflow checks out the {% data variables.product.product_name %} repository, uses the `login-action` to log in to the registry, and then uses the `build-push-action` action to: build a Docker image based on your repository's `Dockerfile`; push the image to the Docker registry, and apply the commit SHA and release version as image tags.\n{% endif %}\n\n\n\nPublishing images to Docker Hub and {% data variables.product.prodname_registry %}\n\n{% ifversion ghes %}\n{% data reusables.package_registry.container-registry-ghes-beta %}\n{% endif %}\n\nIn a single workflow, you can publish your Docker image to multiple registries by using the `login-action` and `build-push-action` actions for each registry.\n\nThe following example workflow uses the steps from the previous sections (\"Publishing images to Docker Hub\" and \"Publishing images to {% data variables.product.prodname_registry %}\") to create a single workflow that pushes to both registries.\n\n```yaml copy\n{% data reusables.actions.actions-not-certified-by-github-comment %}\n\n{% data reusables.actions.actions-use-sha-pinning-comment %}\n\nname: Publish Docker image\n\non:\n  release:\n    types: [", "Y2h1bmtfNV9pbmRleF8xNzg=": "published]\n\njobs:\n  push_to_registries:\n    name: Push Docker image to multiple registries\n    runs-on: {% ifversion ghes %}[self-hosted]{% else %}ubuntu-latest{% endif %}\n    permissions:\n      packages: write\n      contents: read\n    steps:\n      - name: Check out the repo\n        uses: {% data reusables.actions.action-checkout %}\n      \n      - name: Log in to Docker Hub\n        uses: docker/login-action@f4ef78c080cd8ba55a85445d5b36e214a81df20a\n        with:\n          username: {% raw %}${{ secrets.DOCKER_USERNAME }}{% endraw %}\n          password: {% raw %}${{ secrets.DOCKER_PASSWORD }}{% endraw %}\n      \n      - name: Log in to the {% ifversion fpt or ghec or ghes %}Container{% else %}Docker{% endif %} registry\n        uses: docker/login-action@65b78e6e13532edd9afa3aa52ac7964289d1a9c1\n        with:\n          registry: {% ifversion fpt or ghec %}ghcr.io{% elsif ghae %}docker.YOUR-HOSTNAME.com{% elsif ghes %}{% data reusables.package_registry.container-registry-hostname %}{% else %}docker.pkg.github.com{% endif %}\n          username: {% raw %}${{ github.actor }}{% endraw %}\n          password: {% raw %}${{ secrets.GITHUB_TOKEN }}{% endraw %}\n      \n      - name: Extract metadata (tags, labels) for Docker\n        id: meta\n        uses: docker/metadata-action@9ec57ed1fcdbf14dcef7dfbe97b2010124a938b7\n        with:\n          images: |\n            my-docker-hub-namespace/my-docker-hub-repository\n            {% ifversion fpt or ghec or ghes %}{% data reusables.package_registry.container-registry-hostname %}/{% raw %}${{ github.repository }}{% endraw %}{% elsif ghae %}{% raw %}docker.YOUR-HOSTNAME.com/${{ github.repository }}/my-image{% endraw %}{% else %}{% raw %}docker.pkg.github.com/${{ github.repository }}/my-image{% endraw %}{% endif %}\n      \n      - name: Build and push Docker images\n        uses: docker/build-push-action@3b5e8027fcad23fda98b2e3ac259d8d67585f671\n        with:\n          context: .\n          push: true\n          tags: {% raw %}${{ steps.meta.outputs.tags }}{% endraw %}\n          labels: {% raw %", "Y2h1bmtfNl9pbmRleF8xNzg=": "}${{ steps.meta.outputs.labels }}{% endraw %}\n```\n\nThe above workflow checks out the {% data variables.product.product_name %} repository, uses the `login-action` twice to log in to both registries and generates tags and labels with the `metadata-action` action.\nThen the `build-push-action` action builds and pushes the Docker image to Docker Hub and the {% ifversion fpt or ghec or ghes %}{% data variables.product.prodname_container_registry %}{% else %}Docker registry{% endif %}.\n\n", "Y2h1bmtfMF9pbmRleF83MTE=": "\n\nRequirements\n\nBefore you start, make sure you know:\n- The {% data variables.product.prodname_dotcom %} username of the client who will become the owner of the organization you create\n- The name your client would like to use for the organization\n- The email address where you would like receipts to be sent\n- The product your client would like to purchase\n- The number of paid seats your client would like you to purchase for the organization\n\n\n\nStep 1: Create your personal {% data variables.product.prodname_dotcom %} account\n\nYou will use your personal account to set up the organization. You'll also need to sign in to this account to renew or make changes to your client's subscription in the future.\n\n{% data reusables.billing.create-personal-account %}\n\n\n\nStep 2: Create the organization\n\n{% data reusables.user-settings.access_settings %}\n{% data reusables.user-settings.organizations %}\n{% data reusables.organizations.new-organization %}\n1. Under \"Choose a plan\", click **Choose {% data variables.product.prodname_free_team %}**. You will upgrade the organization in the next step.\n{% data reusables.organizations.organization-name %}\n1. Under \"Contact email\", type a contact email address for your client.\n{% data reusables.dotcom_billing.owned_by_business %}\n1. Click **Next**.\n\n\n\nStep 3: Upgrade the organization to a yearly paid subscription\n\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n{% data reusables.organizations.billing_plans %}\n{% data reusables.dotcom_billing.upgrade_org %}\n{% data reusables.dotcom_billing.choose_org_plan %} (You can add more seats to the organization in the next step.)\n1. Under \"Upgrade summary\", select **Pay yearly** to pay for the organization yearly.\n{% data reusables.dotcom_billing.enter-payment-info %}\n{% data reusables.dotcom_billing.finish_upgrade %}\n\n\n\nStep 4: Upgrade the number of paid seats in the organization\n\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n{% data reusables.organizations.billing_plans %}\n{% data ", "Y2h1bmtfMV9pbmRleF83MTE=": "reusables.dotcom_billing.add-seats %}\n{% data reusables.dotcom_billing.number-of-seats %}\n{% data reusables.dotcom_billing.confirm-add-seats %}\n\n\n\nStep 5: Invite your client to join the organization\n\n{% data reusables.profile.access_org %}\n{% data reusables.user-settings.access_org %}\n{% data reusables.organizations.people %}\n{% data reusables.organizations.invite_member_from_people_tab %}\n1. In the search field, type your client's {% data variables.product.prodname_dotcom %} username and press **Enter**.\n1. Select **Owner**, then click **Send invitation**.\n1. Your client will receive an email inviting them to the organization. They will need to accept the invitation before you can move on to the next step.\n\n\n\nStep 6: Transfer organization ownership to your client\n\n{% data reusables.profile.access_org %}\n{% data reusables.user-settings.access_org %}\n{% data reusables.organizations.people %}\n1. Confirm that your client is listed among the members of the organization and is assigned the owner role.\n1. To the right of your username, select the {% octicon \"kebab-horizontal\" aria-label=\"Member settings\" %} dropdown menu, and click **Manage**.\n\n   !Screenshot of the member list for an organization. To the right of a member, a kebab icon is outlined in dark orange.\n1. In the left sidebar, click **Remove from organization**.\n1. Confirm your choice and click **Remove members**.\n\n\n\nNext steps\n\n1. Contact your client and ask them to add you to the organization as a billing manager. You'll need to be a billing manager for the organization so that you can renew or make changes to your client's subscription in the future.\n1. If you would like your organization's credit card to be removed from the organization so that it's not charged again, contact {% data variables.contact.contact_support %}.\n1. When it's time to renew your client's paid subscription, see \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF81NTQ=": "---\ntitle: Modifying an OAuth app\nintro: '{% data reusables.shortdesc.modifying_oauth_apps %}'\nredirect_from:\n  - /apps/building-integrations/managing-oauth-apps/modifying-an-oauth-app\n  - /apps/managing-oauth-apps/modifying-an-oauth-app\n  - /developers/apps/modifying-an-oauth-app\n  - /developers/apps/managing-oauth-apps/modifying-an-oauth-app\nversions:\n  fpt: '*'\n  ghes: '*'\n  ghae: '*'\n  ghec: '*'\ntopics:\n  - OAuth apps\n---\n{% data reusables.user-settings.access_settings %}\n{% data reusables.user-settings.developer_settings %}\n{% data reusables.user-settings.oauth_apps %}\n{% data reusables.user-settings.modify_oauth_app %}\n1. Modify the {% data variables.product.prodname_oauth_app %} information that you'd like to change.\n{% data reusables.user-settings.update_oauth_app %}\n\n", "Y2h1bmtfMF9pbmRleF8xMjU3": "\n\nAbout line endings\n\nEvery time you press return on your keyboard you insert an invisible character called a line ending. Different operating systems handle line endings differently.\n\nWhen you're collaborating on projects with Git and {% data variables.product.product_name %}, Git might produce unexpected results if, for example, you're working on a Windows machine, and your collaborator has made a change in macOS.\n\nYou can configure Git to handle line endings automatically so you can collaborate effectively with people who use different operating systems.\n\n\n\nGlobal settings for line endings\n\nThe `git config core.autocrlf` command is used to change how Git handles line endings. It takes a single argument.\n\n{% mac %}\n\nOn macOS, you simply pass `input` to the configuration. For example:\n\n```shell\n$ git config --global core.autocrlf input\n\n\nConfigure Git to ensure line endings in files you checkout are correct for macOS\n```\n\n{% endmac %}\n\n{% windows %}\n\nOn Windows, you simply pass `true` to the configuration. For example:\n\n```shell\n$ git config --global core.autocrlf true\n\n\nConfigure Git to ensure line endings in files you checkout are correct for Windows.\n```\n\n{% endwindows %}\n\n{% linux %}\n\nOn Linux, you simply pass `input` to the configuration. For example:\n\n```shell\n$ git config --global core.autocrlf input\n\n\nConfigure Git to ensure line endings in files you checkout are correct for Linux\n```\n\n{% endlinux %}\n\n\n\nPer-repository settings\n\nOptionally, you can configure a `.gitattributes` file to manage how Git reads line endings in a specific repository. When you commit this file to a repository, it overrides the `core.autocrlf` setting for all repository contributors. This ensures consistent behavior for all users, regardless of their Git settings and environment.\n\nThe `.gitattributes` file must be created in the root of the repository and committed like any other file.\n\nA `.gitattributes` file looks like a table with two columns:\n\n- On the left is the file name for Git to match.\n- On the right is the line ending c", "Y2h1bmtfMV9pbmRleF8xMjU3": "onfiguration that Git should use for those files.\n\n\n\nExample\n\nHere's an example `.gitattributes` file. You can use it as a template for your repositories:\n\n```text\n\n\nSet the default behavior, in case people don't have core.autocrlf set.\n* text=auto\n\n\n\nExplicitly declare text files you want to always be normalized and converted\n*.c text\n*.h text\n\n\n\nDeclare files that will always have CRLF line endings on checkout.\n*.sln text eol=crlf\n\n\n\nDenote all files that are truly binary and should not be modified.\n*.png binary\n*.jpg binary\n```\n\nYou'll notice that files are matched\u2014`*.c`, `*.sln`, `*.png`\u2014, separated by a space, then given a setting\u2014`text`, `text eol=crlf`, `binary`. We'll go over some possible settings below.\n\n- `text=auto` Git will handle the files in whatever way it thinks is best. This is a good default option.\n\n- `text eol=crlf` Git will always convert line endings to `CRLF` on checkout. You should use this for files that must keep `CRLF` endings, even on OSX or Linux.\n\n- `text eol=lf` Git will always convert line endings to `LF` on checkout. You should use this for files that must keep LF endings, even on Windows.\n\n- `binary` Git will understand that the files specified are not text, and it should not try to change them. The `binary` setting is also an alias for `-text -diff`.\n\n\n\nRefreshing a repository after changing line endings\n\nAfter you set the `core.autocrlf` option or commit a `.gitattributes` file, Git automatically changes line endings to match your new configuration. You may find that Git reports changes to files that you have not modified.\n\nTo ensure that all the line endings in your repository match your new configuration, back up your files with Git, then remove and restore all of the files to normalize the line endings.\n\n1. Before adding or committing any changes, verify that Git has applied the configuration correctly. For example, Git automatically determines whether files in a repository are text or binary files. To avoid corruption of binary files in your repository, we recommend that y", "Y2h1bmtfMl9pbmRleF8xMjU3": "ou explicitly mark files as binary in `.gitattributes`. For more information, see gitattributes - Defining attributes per path in the Git documentation.\n1. To avoid losing any local changes to files in the repository, add and commit any outstanding changes by running the following commands.\n\n   ```shell copy\n   git add . -u\n   git commit -m \"Saving files before refreshing line endings\"\n   ```\n\n1. To update all files on the current branch to reflect the new configuration, run the following commands.\n\n   ```shell copy\n   git rm -rf --cached .\n   git reset --hard HEAD\n   ```\n\n1. To display the rewritten, normalized files, run the following command.\n\n   ```shell copy\n   git status\n   ```\n\n1. Optionally, to commit any outstanding changes in your repository, run the following command.\n\n   ```shell copy\n   git commit -m \"Normalize all the line endings\"\n   ```\n\n\n\nFurther reading\n\n- Customizing Git - Git Attributes in the Pro Git book\n- git-config in the man pages for Git\n- Getting Started - First-Time Git Setup in the Pro Git book\n- Mind the End of Your Line by Tim Clem\n\n", "Y2h1bmtfMF9pbmRleF8xMTEx": "\n\nAbout tool switchers\n\nIn some articles, we write content tailored to different tools (the {% data variables.product.prodname_dotcom %} UI, {% data variables.product.prodname_cli %}, {% data variables.product.prodname_desktop %}, cURL, {% data variables.product.prodname_codespaces %}, {% data variables.product.prodname_vscode_shortname %}, GraphQL API, etc.) The tool switcher lets people select a tool to see only the content that is relevant to that tool since tools may have different conceptual or procedural information. People can use the tool switcher in two ways when reading the docs.\n\n**Exploring**\nFor tasks that can be completed with different tools, the tool switcher signals to people that there are multiple ways a task can be done. For example, using the {% data variables.product.prodname_cli %} or {% data variables.product.prodname_desktop %}, instead of the {% data variables.product.prodname_dotcom %} UI.\n\n**Getting to the point**\nWhen someone knows how they want to do a task and doesn\u2019t need to see additional options, the tool switcher removes less relevant content, so they can find exactly what they need.\n\n\n\nUsing tool tags\n\nWe use tool tags to divide information for each tool. On rare occasions, we will add new tools.\n\nTool tags are a key value pair. The key is the tag you use to refer to the tool in the article and the value is how the tool will be identified on the tool picker at the top of the article. The existing tools are in `lib/all-tools.js` in the {% data variables.product.prodname_docs %} repository.\n\n\n\nWhen to use tool tags\n\nWe only use tool tags if an article must have tool-specific information to help people accomplish their tasks. If the conceptual information or procedural steps for a task are significantly different depending on what tool someone uses, and we want people to be able to accomplish the task with different tools, we use tool tags to present the relevant information in an article.\n\nDo not use the tool switcher just to show examples in different languages. Only use the too", "Y2h1bmtfMV9pbmRleF8xMTEx": "l switcher if the tasks or concepts described in an article change based on what tool someone uses.\n\n\n\nHow to use tool tags\n\nTool tags are Liquid tags that wrap content specific to a tool. \n\nPut tools in alphabetical order. By default, the first tool tag will be selected for an article. You can define a different default tool for an article by specifying a `defaultTool:` property in the article's frontmatter. For more information, see the content README.\n\nYou can also link to an article with a specific tool selected by adding `?tool=TOOLNAME` to the end of the link. For more information, see \"AUTOTITLE.\"\n\nOnly include a maximum of eight different tools in an article. Including more tools causes the tool switcher tabs to overflow with an article's table of contents, which prevents people from using either the tool switcher or table of contents. It is unlikely that you will ever need to include eight separate tools in an article. In general, plan to use as few separate tools as possible in an article.\n\n\n\nAdding new tools\n\n{% data variables.product.prodname_docs %} documents and maintains tool tags for {% data variables.product.prodname_dotcom %} products, {% data variables.product.prodname_dotcom %}-developed tools, and select third-party extensions developed in collaboration with {% data variables.product.company_short %} .\n\nNew tools are only added when they are the only way to accurately document something for a specific user need. If a writer determines that adding a new tool is the only way to accurately document something, they need to propose the new tool in a content design plan. Whoever reviews the content design plan should consider any alternative ways to address the documentation needs without adding a new tool. If a new tool is the only way to create accurate documentation, the new tool should be added. If there is an alternative content solution that does not add a new tool, that option should be used.\n\nTo add a new tool, add an entry to the `allTools` object in the `lib/all-tools.js` file as a key-va", "Y2h1bmtfMl9pbmRleF8xMTEx": "lue pair. Add new tools in alphabetical order.\n\n", "Y2h1bmtfMF9pbmRleF8yMTEz": "\n\nAbout {% data variables.contact.premium_support %}\n\n{% data reusables.support.premium-support-features %}\n\n\n\n{% data variables.contact.premium_support %} plans\n\nThere are two {% data variables.contact.premium_support %} plans: Premium and Premium Plus / {% data variables.product.microsoft_premium_plus_support_plan %}.\n\n{% rowheaders %}\n\n| | {% data variables.product.premium_support_plan %} | {% data variables.product.premium_plus_support_plan %} |\n|---|---|------|\n| Hours of operation | 24 x 7 | 24 x 7 |\n| Initial response time | 30 minutes for {% data variables.product.support_ticket_priority_urgent %} (including initial troubleshooting)4 hours for {% data variables.product.support_ticket_priority_high %} | 30 minutes for {% data variables.product.support_ticket_priority_urgent %} (including initial troubleshooting)4 hours for {% data variables.product.support_ticket_priority_high %} |\n| Support channels | Online ticket submissionPhone support in English via callback request (when required for ticket resolution)Screen share request for critical issues | Online ticket submissionPhone support in English via callback request (when required for ticket resolution)Screen share request for critical issues |\n| Training | Access to premium content  | Access to premium content1 virtual training class per year |\n| Members with support entitlements | 20 | 20 |\n| Resources | Priority ticket handling | Priority ticket handlingNamed Customer Reliability Engineer   |\nEscalation management | For high and urgent priority tickets | For High and Urgent priority tickets\nIncident management | None | For urgent priority tickets, as needed\n| Health checks | {% ifversion not ghes %}None{% else %}Unlimited automated health check reports (see \"Generating a health check for your enterprise\"){% endif %} | {% ifversion ghes %}Unlimited automated health check reports. For more information, see \"AUTOTITLE\"){% endif %}Quarterly enhanced health checks, with findings, interpretations, and recommendations from your CRE (by request)    |\n{%- ifve", "Y2h1bmtfMV9pbmRleF8yMTEz": "rsion ghes %}\n| Crisis prevention | None | Yearly participation in guided incident simulations to help you be prepared |\n{%- endif %}\n| Technical advisory hours| None | 12 hours per quarter |\n| Application upgrade assistance | None | By request |\n| Cloud planning | None | By request |\n\n{% endrowheaders %}\n\n  {% note %}\n\n  **Note:** Enterprise owners and billing managers automatically have a support entitlement. Enterprise owners can add support entitlements to members of organizations owned by their enterprise account. For more information, see \"AUTOTITLE.\"\n\n  {% endnote %}\n\n\n\nSigning up for {% data variables.contact.premium_support %}\n\nTo sign up for {% data variables.contact.premium_support %} or upgrade your plan, contact our account management team.\n\n\n\nScope of support\n\n{% data reusables.support.scope-of-support %}\n\n\n\nContacting {% data variables.contact.premium_support %}\n\n{% data variables.contact.premium_support %} customers can use the {% data variables.contact.contact_landing_page_portal %} to report issues in writing, in English.\n\n\n\nHours of operation\n\n{% data variables.contact.premium_support %} is available 24 hours a day, 7 days per week. If you purchased {% data variables.contact.premium_support %} prior to September 17, 2018, support is limited during holidays. For more information on holidays {% data variables.contact.premium_support %} observes, see the holiday schedule at \"AUTOTITLE.\"\n\n\n\nService Level Agreement response times\n\nFor tickets you submit, support is available 24 hours a day, 7 days per week. The initial response time guaranteed by the SLA is dependent on the priority level of the ticket. Response time begins when {% data variables.contact.premium_support %} sets the priority level of the ticket. A response does not mean the issue has been resolved.\n\n| Ticket priority level | Initial response time |\n| --- | ---|\n| {% data variables.product.support_ticket_priority_urgent %} | 30 minutes |\n| {% data variables.product.support_ticket_priority_high %} | 4 hours |\n\nDuring the initial respon", "Y2h1bmtfMl9pbmRleF8yMTEz": "se time for Urgent priority tickets, you can expect us to do the following:\n\n- The paged Support Engineer or CRE assigns and carefully reviews your ticket. The goal is to understand the issue, start troubleshooting, and identify next steps.\n- In the initial response, the assigned Support Engineer or CRE will acknowledge ticket receipt and assignment as well as provide next steps to clarify and troubleshoot the situation. To assist with resolving your issue, the Support Engineer or CRE may ask for additional information such as screenshots, error messages, log files, diagnostics files, support bundles, or the output of specific console commands.\n- Depending on the issue, the assigned Support Engineer or CRE may collaborate with others in Support, Engineering, or the regional incident commander.\n- If a callback was requested upon opening the Urgent ticket, the assigned Support Engineer or CRE will determine if, at the current time, screen sharing is the most efficient way of driving the ticket towards resolution. If so, they will extend an offer to you to join a screen sharing session.\n\n{% data reusables.enterprise_enterprise_support.installing-releases %}\n\n{% ifversion ghes %}\nYou must install the minimum supported version of {% data variables.product.prodname_ghe_server %} pursuant to the Supported Releases section of your applicable license agreement within 90 days of placing an order for {% data variables.contact.premium_support %}.\n{% endif %}\n\n\n\nAssigning a priority to a support ticket\n\nWhen you contact {% data variables.contact.premium_support %}, you can choose one of four priorities for the ticket: {% data variables.product.support_ticket_priority_urgent %}, {% data variables.product.support_ticket_priority_high %}, {% data variables.product.support_ticket_priority_normal %}, or {% data variables.product.support_ticket_priority_low %}. For more information, see \"AUTOTITLE.\"\n\n\n\nResolving and closing support tickets\n\n{% data variables.contact.premium_support %} may consider a ticket solved after providing an", "Y2h1bmtfM19pbmRleF8yMTEz": " explanation, recommendation, usage instructions, workaround instructions, or by advising you of an available {% data variables.product.prodname_ghe_server %} release that addresses the issue.\n\nIf you use a custom or unsupported plug-in, module, or custom code, {% data variables.contact.premium_support %} may ask you to remove the unsupported plug-in, module, or code while attempting to resolve the issue. If the problem is fixed when the unsupported plug-in, module, or custom code is removed, {% data variables.contact.premium_support %} may consider the ticket solved.\n\n{% data variables.contact.premium_support %} may close a ticket if the ticket is outside the scope of support or if multiple attempts to contact you have gone unanswered. If {% data variables.contact.premium_support %} closes a ticket due to lack of response, you can request that {% data variables.contact.premium_support %} reopen the ticket.\n\n\n\nReceiving credits for missed responses to support tickets\n\nIf you don't receive an initial response within the guaranteed response time to more than four tickets in a given quarter based on {% data variables.product.company_short %}'s fiscal year, you're eligible for a credit. To honor the SLA, {% data variables.product.company_short %} will refund 20% of the quarterly {% data variables.contact.premium_support %} fee. To receive the refund, you must submit a credit request.\n\nThe credit request must be made within 30 days of the end of the quarter during which {% data variables.contact.premium_support %} did not respond to your tickets within the designated response time. Credit requests will not be honored if the respective deadline has passed. Once the respective deadline passes, you have waived the ability to claim a refund for the qualified credit. Credit requests may take the form of a refund or credit to your account, cannot be exchanged into a cash amount, require you to have paid any outstanding invoices, and expire upon termination of your agreement with {% data variables.product.company_short %}.\n\n", "Y2h1bmtfNF9pbmRleF8yMTEz": "To receive a refund, you must submit a completed credit request to . To be eligible, the credit request must:\n- Be sent from an email address associated with your account on {% ifversion ghae %}{% data variables.product.product_name %}{% else %}{% data variables.location.product_location %}{% endif %}\n- Be received by {% data variables.product.company_short %} by the end of the 30th day after the quarter in which the four qualifying credits occurred\n- Include \"Credit Request\" in the subject line\n\nThe following information **must be included** in your credit request:\n- **Date** (The date must be within 30 days after the quarter based on {% data variables.product.company_short %}\u2019s fiscal year end in which the claims occurred [January 31, April 30, July 31, or October 31].)\n- **Customer contact** (You must specify both name and email address.)\n- **Customer address**\n- **Qualifying credits** (You must provide the date of each qualifying credit and the associated ticket number.){% ifversion fpt or ghec %}\n- **Name of {% data variables.product.prodname_ghe_cloud %} organization**{% endif %}\n- **Ticket numbers**\n\n\n\nAccessing premium content\n\nYou can access premium content by signing into the {% data variables.contact.contact_landing_page_portal %}, then clicking **Premium**.\n\n", "Y2h1bmtfMF9pbmRleF85NDY=": "\n\nWhat is the end-to-end supply chain?\n\nAt its core, end-to-end software supply chain security is about making sure the code you distribute hasn't been tampered with. Previously, attackers focused on targeting dependencies you use, for example libraries and frameworks. Attackers have now expanded their focus to include targeting user accounts and build processes, and so those systems must be defended as well.\n\nFor information about features in {% data variables.product.prodname_dotcom %} that can help you secure dependencies, see \"AUTOTITLE.\"\n\n\n\nAbout these guides\n\nThis series of guides explains how to think about securing your end-to-end supply chain: personal account, code, and build processes. Each guide explains the risk to that area, and introduces the {% data variables.product.product_name %} features that can help you address that risk.\n\nEveryone's needs are different, so each guide starts with the highest impact change, and continues from there with additional improvements you should consider. You should feel free to skip around and focus on improvements you think will have the biggest benefit. The goal isn't to do everything at once but to continuously improve security in your systems over time.\n\n- \"AUTOTITLE\"\n\n- \"AUTOTITLE\"\n\n- \"AUTOTITLE\"\n\n\n\nFurther reading\n\n- Safeguarding artifact integrity across any software supply chain\n- Microsoft Supply Chain Integrity Model\n- Software Supply Chain Security Paper - CNCF Security Technical Advisory Group\n\n", "Y2h1bmtfMF9pbmRleF81MTk=": "\n\nGitHub Actions\n\n{% data reusables.actions.actions-not-verified %}\n\nTo learn about publishing {% data variables.product.prodname_actions %} in {% data variables.product.prodname_marketplace %}, see \"AUTOTITLE.\"\n\n\n\nApps\n\nAnyone can share their apps with other users for free on {% data variables.product.prodname_marketplace %} but only apps owned by organizations can sell their app.\n\nTo publish paid plans for your app and display a marketplace badge, you must complete the publisher verification process. For more information, see \"AUTOTITLE\" or \"AUTOTITLE.\"\n\nOnce the organization meets the requirements, someone with owner permissions in the organization can publish paid plans for any of their apps. Each app with a paid plan also goes through a financial onboarding process to enable payments.\n\nTo publish apps with free plans, you only need to meet the general requirements for listing any app. For more information, see \"AUTOTITLE.\"\n\n\n\nNew to apps?\n\nIf you're interested in creating an app for {% data variables.product.prodname_marketplace %}, but you're new to {% data variables.product.prodname_github_apps %} or {% data variables.product.prodname_oauth_apps %}, see \"AUTOTITLE\" or \"AUTOTITLE.\"\n\n\n\n{% data variables.product.prodname_github_apps %} vs. {% data variables.product.prodname_oauth_apps %}\n\n{% data reusables.marketplace.github_apps_preferred %}, although you can list both OAuth and {% data variables.product.prodname_github_apps %} in {% data variables.product.prodname_marketplace %}. For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n\n\n\nPublishing an app to {% data variables.product.prodname_marketplace %} overview\n\nWhen you have finished creating your app, you can share it with other users by publishing it to {% data variables.product.prodname_marketplace %}. In summary, the process is:\n\n1. Review your app carefully to ensure that it will behave as expected in other repositories and that it follows best practice guidelines. For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n\n1. Add webhook events to th", "Y2h1bmtfMV9pbmRleF81MTk=": "e app to track user billing requests. For more information about the {% data variables.product.prodname_marketplace %} API, webhook events, and billing requests, see \"AUTOTITLE.\"\n\n1. Create a draft {% data variables.product.prodname_marketplace %} listing. For more information, see \"AUTOTITLE.\"\n\n1. Add a pricing plan. For more information, see \"AUTOTITLE.\"\n\n1. Read and accept the terms of the \"AUTOTITLE.\"\n\n1. Submit your listing for publication in {% data variables.product.prodname_marketplace %}. For more information, see \"AUTOTITLE.\"\n\n\n\nSeeing how your app is performing\n\nYou can access metrics and transactions for your listing. For more information, see:\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n\n\nContacting Support\n\nIf you have questions about {% data variables.product.prodname_marketplace %}, please contact {% data variables.contact.contact_support %}.\n\n", "Y2h1bmtfMF9pbmRleF8yMDY5": "\n\nThe short version\n\nWe use your personal information as this Privacy Statement describes. No matter where you are, where you live, or what your citizenship is, you have the same high standard of privacy protection when using GitHub's products as all our users around the world, regardless of their country of origin or location.\n\nTo see our Privacy Notice for U.S. Residents, please go to GitHub's Notice about U.S. State Data Privacy or scroll down.\n\n\n\nSummary\n\n| Section | What can you find there? |\n|---|---|\n| Who is responsible for the processing of your information | Subject to limited exceptions, GitHub is the controller and entity responsible for the processing of your personal data in connection with the Website or Service if you are in North America. For individuals outside North America the data controller is GitHub B.V. |\n| What information GitHub collects | GitHub collects information directly from you for your registration, payment, transactions, and user profile. We also automatically collect from you your usage information, cookies, and device information, subject, where necessary, to your consent. GitHub may also collect personal data from third parties. We only collect the minimum amount of personal data necessary to provide innovative services and personalized experiences, unless you choose to provide more.|\n| How GitHub uses your information | In this section, we describe the ways in which we use your information, including to provide you the Service, to communicate with you, for security and compliance purposes, and to improve our Website or Service or develop new features and functionality of our Website or Service. We also describe the legal basis upon which we process your information, where legally required. |\n| How we share the information we collect | We may share your information with third parties under one of the following circumstances: with your consent, with our service providers, for security purposes, to comply with our legal obligations, or when there is a change of control or sale ", "Y2h1bmtfMV9pbmRleF8yMDY5": "of corporate entities or business units. We do not sell your personal information and we do not display advertising on GitHub. |\n| Your choices regarding our processing of your personal data | We provide ways for you to access, alter, or delete your personal information. |\n| Cookies and tracking technologies | Except for some of the cookies used on our Enterprise Marketing Pages, we only use strictly necessary cookies to provide, secure, and improve our Website or Service or develop new features and functionality of our Website or Service.As described below, we may use non-essential cookies on certain pages of our website to support our enterprise marketing efforts and market our products and services to enterprise customers, for example on resources.github.com (collectively \u201cEnterprise Marketing Pages\u201d).For more information about cookies, see the list of cookies used by GitHub. |\n| How GitHub secures your information | We take all measures reasonably necessary to protect the confidentiality, integrity, and availability of your personal data on GitHub and to protect the resilience of our servers. |\n| Communication preferences | We communicate with you by email. You can control the way we contact you in your account settings, or by contacting us. |\n| Resolving complaints | In the unlikely event that we are unable to resolve a privacy concern quickly and thoroughly, we provide a path of dispute resolution. |\n| Changes to our Privacy Statement | We notify you of material changes to this Privacy Statement 30 days before any such changes become effective. You may also track changes in our Site Policy repository. |\n| License | This Privacy Statement is licensed under the Creative Commons Zero license. |\n| Contacting GitHub | Please feel free to contact us if you have questions about our Privacy Statement. |\n| Translations | We provide links to some translations of the Privacy Statement. |\n\n\n\nGitHub Privacy Statement\n\n\n\nWho is responsible for the processing of your information?\n\nThe data controller of your personal data", "Y2h1bmtfMl9pbmRleF8yMDY5": " is GitHub, Inc. For individuals outside North America, the data controller is GitHub B.V.\n\nThis privacy statement does not apply to personal data we process as a service provider or data processor on behalf of our enterprise customers. Our data processing activities as service provider or data processor is governed by our Data Protection Agreement. If you are an end-user of one of those organizations, such as an employee or student, you should read that organization\u2019s privacy statement and direct any privacy inquiries to that organization.\n\n\n\nGitHub acting on your behalf\n\nIn some cases, GitHub is acting only on your behalf for the personal data we collect and process in connection with our Service (for example, for the personal data added to a repository by the contributors to such repository). In such cases, GitHub will only process the data in order to provide, protect, and improve Service. Please note that subject to our Private Information Removal Policy contributors\u2019 requests to remove personal data generally require notice to and action from the repository owner.\n\n\n\nWhat information GitHub collects\n\nThe personal data we collect depends on how you interact with us, the services you use, and the choices you make. We collect information about you from different sources and in various ways when you use our Service, including information you provide directly, information collected automatically, third-party data sources, and data we infer or generate from other data.\n\n\n\nInformation users provide directly to GitHub\n\nWe collect personal data you provide to us. For example:\n\n\n\nRegistration information\n\nWe collect information such as your name and contact data, including username and email address, and credentials such as your password, during account creation.\n\n\n\nDemographic information\n\nIn some cases, we request that you provide age, gender, and similar demographic details.\n\n\n\nPayment and billing information\n\nIf you make a purchase or other financial transaction, we collect credit card numbers, financial account ", "Y2h1bmtfM19pbmRleF8yMDY5": "information, and other payment details.\n\n\n\nContent and files\n\nWe collect any code, text, photographs, documents, or other files, including videos or recordings, you upload to our Service; and if you send us email messages or other communications, we collect and retain those communications. For example, you may choose to give us more information for your Account profile, such as your full name, an avatar which may include a photograph, your biography, your location, your company, and a URL to a third-party website. Please note that your profile information may be visible to other Users of our Service.\n\n\n\nFeedback and ratings\n\nWe collect any feedback or ratings you provide, including through written communications and via surveys.\n\n\n\nInformation GitHub automatically collects\n\nWhen you visit or use our Service, we collect some information automatically. For example:\n\n\n\nTransaction information, Subscription and licensing data\n\nIf you have a paid Account or subscription with us, or make a purchase or sale using our Service, we automatically collect certain information about your transactions on the Service, such as your full name, address, region, state, country, zip code, the date, time, and amount charged.\n\n\n\nUsage information and Interactions\n\nIf you're accessing or using our Service, we may automatically collect information about how you use and how your device interacts with the Service, such as the pages you view, the referring site, your IP address and information about your device, session information, the date and time of each request, device type and ID, operation system and application version, information contained in or relating to your contributions to individual repositories, and telemetry data (i.e., information about how a specific feature or service is performing) regarding your use of other features and functionality of the Service. As further described below, we automatically collect usage information and interaction data using cookies (which may use  a cookie ID), depending on your settings or pre", "Y2h1bmtfNF9pbmRleF8yMDY5": "ferences, in connection with our Service.\n\n\n\nGeolocation information\n\nIn connection with certain features and depending on the functionality of the Service, we collect geolocation information such as through IP addresses or the location information you choose to provide in your Account profile.\n\n\n\nInformation we create or generate\n\nWe infer new information from other data we collect, including using automated means to generate information about your likely preferences or other characteristics (\u201cinferences\u201d). For example, we infer your general geographic location (such as city, state, and country) based on your IP address.\n\n\n\nInformation we collect from third parties\n\nOther companies with whom you choose to engage. GitHub may collect personal data about you from third parties. For example, this may happen if you sign up for training or to receive information about GitHub from one of our vendors, partners, or affiliates. GitHub does not purchase personal data from third-party data brokers.\n\nService Providers. We may also receive information from processors or service providers who process the data on our behalf, such as our payment processor who process payment and billing information in connection with our Service.\n\nContent you post on our Service. Information you store in, or contribute to, a public repository, provide for use in connection with a Community Feature or make otherwise publicly available through the Service will be collected by GitHub as described in this Privacy Statement. Such information may also be available to the GitHub user community as well as the general public. For more information about repositories and community features, see \"AUTOTITLE.\"\n\nCo-branding/marketing partners. We may receive information from partners with which we offer co-branded services or engage in joint marketing activities.\n\nPublicly available sources. We may also obtain information from publicly available sources as GitHub repositories.\n\nWhen you are asked to provide personal data, you may decline. And you may use web b", "Y2h1bmtfNV9pbmRleF8yMDY5": "rowser or operating system controls to prevent certain types of automatic data collection. But if you choose not to provide or allow information that is necessary for certain services or features, those services or features may not be available or fully functional.\n\n\n\nHow GitHub uses your information\n\nWe may use your information to provide, administer, analyze, manage, and operate our Service. For example, we use your information for the following purposes:\n- Provide our products and deliver our services including troubleshooting, improving, and personalizing the features on the Service.\n- Business operations such as billing, accounting, improving our internal operations, securing our systems, detecting fraudulent or illegal activity, and meeting our legal obligations.\n- Improve and develop our products and services including to develop new services or features, and conduct research.\n- Personalization of our Service by understanding you and your preferences to enhance your experience and enjoyment using our Service.\n- Provide customer support and respond to your questions.\n- Deliver promotional communications with you about new services, features, offers, promotions, and other information about our Service.\n- Personalize and measure the effectiveness of enterprise business ads, including those you see off of the Services, promotional communications or marketing you receive related to the Enterprise Marketing Pages.\n- Send you information, including confirmations, invoices, technical notices, updates, security alerts, support and administrative messages.\n\nWe combine data we collect from different sources for these purposes and to give you a more seamless, consistent, and personalized experience.\n\n\n\nHow we share the information we collect\n\nWe share personal data as described below, including with your consent or as necessary to complete your transactions or provide the services you have requested or authorized. In addition, we may share each of the categories of your personal data described above with the types of ", "Y2h1bmtfNl9pbmRleF8yMDY5": "third parties described below for the following business purposes:\n\n\n\nPublic information\n\nYou may select options available through our Service to publicly display and share your name and/or username and certain other information, such as your profile, demographic data, content and files, or geolocation data. For example, if you would like your email address to remain private, even when you\u2019re commenting on public repositories, you can adjust your setting for your email address to be private in your user profile. You can also update your local Git configuration to use your private email address.\n\nPlease note that if you would like to compile GitHub data, you must comply with our Terms of Service regarding information usage and privacy, and you may only use any public-facing information you gather for the purpose for which our user authorized it. For example, where a GitHub user has made an email address public-facing for the purpose of identification and attribution, do not use that email address for the purposes of sending unsolicited emails to users or selling personal information, such as to recruiters, headhunters, and job boards, or for commercial advertising. We expect you to reasonably secure information you have gathered from GitHub, and to respond promptly to complaints, removal requests, and \"do not contact\" requests from GitHub or GitHub users.\n\n\n\nThird-party applications\n\nWe share your personal data with third party applications when you tell us to do so. For example, if you purchase an application listed on our Marketplace, we share your username to allow the application developer to provide you with services. You can enable or add third-party applications, known as \"Developer Products,\" to your Account. These Developer Products are not necessary for your use of GitHub. We will share your personal data with such third-party applications when you ask us to; however, you are responsible for your use of the third-party Developer Products and for the amount of personal data you choose to share with it. Yo", "Y2h1bmtfN19pbmRleF8yMDY5": "u can check our API documentation to see what information is provided when you authenticate into a Developer Product using your GitHub profile.\n\n\n\nOrganizations with which you engage\n\nYou may indicate, through your actions on GitHub, that you are willing to share your personal data with Organizations, as defined in GitHub\u2019s Terms of Service, who also use the Services. If you collaborate on or become a member of an Organization, then its Account owners may receive your personal data, for example by having the ability to view your activity in the Organization\u2019s access log.\n\nWhen you accept an invitation to an Organization, you will be notified of the types of information owners may be able to see (for more information, see About Organization Membership). Please contact the Account owners for more information about how they might process your personal data in their Organization and the ways for you to access, update, alter, or delete your personal data stored in the Account.\n\n\n\nService providers\n\nWe share your personal data with service providers who process the information on our behalf to provide or improve our Service. For example, our service providers may perform payment processing, customer support ticketing, network data transmission, web analytics, marketing operations, security, online advertising, and other similar services. Our service providers may process data in your region, in the United States, or in any other country where they operate facilities.\n\nSuch processing by service providers and any related cross border data transfers will be in compliance with applicable law.\n\n\n\nAffiliates\n\nWe enable access to personal data across our subsidiaries, affiliates, and related companies, for example, where we share common data systems, when affiliates provide services on our behalf, or where access is needed to operate and provide the Service.\n\nGitHub has the responsibility for the processing of personal information it receives under the Data Privacy Framework (DPF) Principles and subsequently transfers to a t", "Y2h1bmtfOF9pbmRleF8yMDY5": "hird party acting as an agent on GitHub\u2019s behalf. GitHub shall remain liable under the DPF Principles if its agent processes such personal information in a manner inconsistent with the DPF Principles, unless the organization proves that it is not responsible for the event giving rise to the damage.\n\n\n\nFor security purposes\n\nWe will disclose personal data if we believe it is necessary to:\n- protect our customers and others, for example to prevent spam or attempts to commit fraud, or to help prevent the loss of life or serious injury of anyone;\n- operate and maintain the security of the Service, including to prevent or stop an attack on our systems or networks; or\n- protect the rights or property or ourselves or others, including enforcing our agreements, terms, and policies.\n\n\n\nFor legal disclosure\n\nGitHub may disclose personal data or other information we collect about you to law enforcement or other governmental agencies if required in response to a valid legal process. For more information about our disclosure in response to legal requests, see our Guidelines for Legal Requests of User Data.\n\n\n\nChange in control or sale\n\nWe may share your personal data if we are involved in a merger, sale, or acquisition of corporate entities or business units as described in this Privacy Statement.\n\nPlease note that some of the features on our Service include integrations, references, or links to services provided by third parties whose privacy practices differ from ours. If you provide personal data to any of those third parties, or allow us to share personal data with them, that data is governed by their privacy statements.\n\nFinally, we may share de-identified information in accordance with applicable law.\n\n\n\nYour choices regarding our processing of your personal data\n\nWe provide choices about the personal data we collect about you. The choices you make will not apply to any personal data associated with an Organization under your Account.\n\nAccess, correction, and deletion. If you're a GitHub user, you may access, update, al", "Y2h1bmtfOV9pbmRleF8yMDY5": "ter, or delete your basic user profile information by editing your user profile or contacting us through the GitHub Support portal or GitHub Premium Support. You can control the information we collect about you by limiting what information is in your profile, by keeping your information current, by changing your cookie preferences, or by contacting us through the GitHub Support portal or GitHub Premium Support.\n\nWe retain and use your information as described in this Privacy Statement, but barring legal requirements, we will delete your full profile within 90 days of your request. After an account has been deleted, certain data, such as contributions to other Users' repositories and comments in others' issues, will remain. However, we will delete or de-identify your personal data, including your username and email address, from the author field of issues, pull requests, and comments by associating them with a ghost user. That said, the email address you have provided via your Git commit settings will always be associated with your commits in the Git system. If you choose to make your email address private, you should also update your Git commit settings. We are unable to change or delete data in the Git commit history \u2014 the Git software is designed to maintain a record \u2014 but we do enable you to control what information you put in that record.\n\nIf GitHub processes personal data other than your profile information, such as information about you GitHub receives from third parties, then you may, subject to applicable law, access, update, alter, delete, object to or restrict the processing of your personal data by contacting us through the GitHub Support portal or GitHub Premium Support.\n\nYou can adjust the settings on your Account regarding the display of your personal data in private or public repositories or personal data processed in connection with Community Features (such as GitHub Feed, GitHub Sponsors, and GitHub Explore) through profile settings.\n\nAdditionally, if you are unable to access certain personal dat", "Y2h1bmtfMTBfaW5kZXhfMjA2OQ==": "a we have via the means described above, you can request access by contacting us as described at the bottom of this privacy statement.\n\n\n\nData portability\n\nAs a GitHub User, you can always take your data with you. You can clone your repositories to your desktop, for example, or you can use our Data Portability tools to download information we have about you.\n\n\n\nCommunication preferences\n\nWe use your email address to communicate with you, if you've said that's okay, and only for the reasons you\u2019ve said that\u2019s okay. For example, if you contact our Support team with a request, we respond to you via email. You have control over how your email address is used and shared with other Users on and through our Service. You may manage your communication preferences in your profile's email settings.\n\nBy design, the Git version control system associates many actions with a user's email address, such as commit messages. See more details regarding setting your commit email address.\n\nDepending on your email settings, GitHub may occasionally send notification emails, for example, about changes in a repository you\u2019re watching, new features, requests for feedback, important policy changes, or to offer customer support. We may also send marketing emails, based on your choices and in accordance with applicable laws and regulations. There's an \u201cunsubscribe\u201d link located at the bottom of each of the marketing emails we send you.\n\nPlease note that you cannot opt out of receiving important communications from us, such as emails from our Support team or system emails, but you can configure your notifications settings in your profile to opt out of other communications.\n\n\n\nOur use of cookies and tracking technologies\n\n\n\nCookies and tracking technologies\n\nGitHub uses cookies to provide, secure and improve our Service or to develop new features and functionality of our Service. For example, we use them to (i) keep you logged in, (ii) remember your preferences, (iii) identify your device for security and fraud purposes, including as needed to ", "Y2h1bmtfMTFfaW5kZXhfMjA2OQ==": "maintain the integrity of our Service, (iv) compile statistical reports, and (v) provide information and insight for future development of GitHub. We provide more information about cookies on GitHub that describes the cookies we set, the needs we have for those cookies, and the expiration of such cookies.\n\nFor Enterprise Marketing Pages, we may also use non-essential cookies to  (i) gather information about enterprise users\u2019 interests and online activities to personalize their experiences, including by making the ads, content, recommendations, and marketing seen or received more relevant and (ii) serve and measure the effectiveness of targeted advertising and other marketing efforts. If you disable the non-essential cookies on the Enterprise Marketing Pages, the ads, content, and marketing you see may be less relevant.\n\nOur emails to users may contain a pixel tag, which is a small, clear image that can tell us whether or not you have opened an email and what your IP address is. We use this pixel tag to make our email communications more effective and to make sure we are not sending you unwanted email.\n\nThe length of time a cookie will stay on your browser or device depends on whether it is a \u201cpersistent\u201d or \u201csession\u201d cookie. Session cookies will only stay on your device until you stop browsing. Persistent cookies stay until they expire or are deleted. The expiration time or retention period applicable to persistent cookies depends on the purpose of the cookie collection and tool used. You may be able to delete cookie data. For more information, see \"AUTOTITLE.\"\n\n\n\nWhat are cookies and similar technologies?\n\nWe use cookies and similar technologies, such as web beacons, local storage, and mobile analytics, to operate and provide our Services. When visiting Enterprise Marketing Pages, like resources.github.com, these and additional cookies, like advertising IDs, may be used for sales and marketing purposes.\n\nCookies are small text files stored by your browser on your device. A cookie can later be read when your brow", "Y2h1bmtfMTJfaW5kZXhfMjA2OQ==": "ser connects to a web server in the same domain that placed the cookie. The text in a cookie contains a string of numbers and letters that may uniquely identify your device and can contain other information as well. This allows the web server to recognize your browser over time, each time it connects to that web server.\n\nWeb beacons are electronic images (also called \u201csingle-pixel\u201d or \u201cclear GIFs\u201d) that are contained within a website or email. When your browser opens a webpage or email that contains a web beacon, it automatically connects to the web server that hosts the image (typically operated by a third party). This allows that web server to log information about your device and to set and read its own cookies. In the same way, third-party content on our websites (such as embedded videos, plug-ins, or ads) results in your browser connecting to the third-party web server that hosts that content.\n\nMobile identifiers for analytics can be accessed and used by apps on mobile devices in much the same way that websites access and use cookies. When visiting Enterprise Marketing pages, like resources.github.com, on a mobile device these may allow us and our third-party analytics and advertising partners to collect data for sales and marketing purposes.\n\nWe may also use so-called \u201cflash cookies\u201d (also known as \u201cLocal Shared Objects\u201d or \u201cLSOs\u201d) to collect and store information about your use of our Services. Flash cookies are commonly used for advertisements and videos.\n\n\n\nHow do we and our partners use cookies and similar technologies?\n\nThe GitHub Services use cookies and similar technologies for a variety of purposes, including to store your preferences and settings, enable you to sign-in, analyze how our Services perform, track your interaction with the Services, develop inferences, combat fraud, and fulfill other legitimate purposes. Some of these cookies and technologies may be provided by third parties, including service providers and advertising partners. For example, our analytics and advertising partners may us", "Y2h1bmtfMTNfaW5kZXhfMjA2OQ==": "e these technologies in our Services to collect personal information (such as the pages you visit, the links you click on, and similar usage information, identifiers, and device information) related to your online activities over time and across Services for various purposes, including targeted advertising. GitHub will place non-essential cookies on pages where we market products and services to enterprise customers, for example, on resources.github.com.\n\nWe and/or our partners also share the information we collect or infer with third parties for these purposes.\n\nThe table below provides additional information about how we use different types of cookies:\n\n| Purpose | Description |\n|:---|:---|\n| Required Cookies | GitHub uses required cookies to perform essential website functions and to provide the services. For example, cookies are used to log you in, save your language preferences, provide a shopping cart experience, improve performance, route traffic between web servers, detect the size of your screen, determine page load times, improve user experience, and for audience measurement. These cookies are necessary for our websites to work. |\n| Analytics | We allow third parties to use analytics cookies to understand how you use our websites so we can make them better. For example, cookies are used to gather information about the pages you visit and how many clicks you need to accomplish a task. We also use some analytics cookies to provide personalized advertising. |\n| Social Media | GitHub and third parties use social media cookies to show you ads and content based on your social media profiles and activity on GitHub\u2019s  websites. This ensures that the ads and content you see on our websites and on social media will better reflect your interests. This also enables third parties to develop and improve their products, which they may use on websites that are not owned or operated by GitHub. |\n| Advertising | In addition, GitHub and third parties use advertising cookies to show you new ads based on ads you've already ", "Y2h1bmtfMTRfaW5kZXhfMjA2OQ==": "seen. Cookies also track which ads you click or purchases you make after clicking an ad. This is done both for payment purposes and to show you ads that are more relevant to you. For example, cookies are used to detect when you click an ad and to show you ads based on your social media interests and website browsing history. |\n\n\n\nWhat are your cookie choices and controls?\n\n  You have several options to disable non-essential cookies:\n\n  1. **Specifically on GitHub Enterprise Marketing Pages**\n\n     Any GitHub page that serves non-essential cookies will have a link in the page\u2019s footer to cookie settings. You can express your preferences at any time by clicking on that linking and updating your settings.\n\n     Some users will also be able to manage non-essential cookies via a cookie consent banner, including the options to accept, manage, and reject all non-essential cookies.\n  1. **Generally for all websites**\n  You can control the cookies you encounter on the web using a variety of widely-available tools. For example:\n  - If your browser sends a Do Not Track (DNT) signal, GitHub will not set non-essential cookies and will not load third party resources which set non-essential cookies.\n  - Many browsers provide cookie controls which may limit the types of cookies you encounter online. Check out the documentation for your browser to learn more.\n  - If you enable a browser extension designed to block tracking, such as Privacy Badger, non-essential cookies set by a website or third parties may be disabled.\n  - If you enable a browser extension designed to block unwanted content, such as uBlock Origin, non-essential cookies will be disabled to the extent that content that sets non-essential cookies will be blocked.\n  - You may use the Global Privacy Control (GPC) to communicate your privacy preferences. If GitHub detects the GPC signal from your device, GitHub will not share your data (we do not sell your data). To learn more, visit Global Privacy Control \u2014 Take Control Of Your Privacy\n  - Advertising controls. Our ad", "Y2h1bmtfMTVfaW5kZXhfMjA2OQ==": "vertising partners may participate in associations that provide simple ways to opt out of ad targeting, which you can access at:\n  - United States: NAI and DAA\n  - Canada: Digital Advertising Alliance of Canada\n  - Europe: European Digital Advertising Alliance\n\nThese choices are specific to the browser you are using. If you access our Services from other devices or browsers, take these actions from those systems to ensure your choices apply to the data collected when you use those systems.\n\n\n\nRetention of personal data\n\nWe retain personal data for as long as necessary to provide the services and fulfill the transactions you have requested, comply with our legal obligations, resolve disputes, enforce our agreements, and other legitimate and lawful business purposes. Because these needs can vary for different data types in the context of different services, actual retention periods can vary significantly based on criteria such as user expectations or consent, the sensitivity of the data, the availability of automated controls that enable users to delete data, and our legal or contractual obligations. For example, we may retain your personal data for longer periods, where necessary, subject to applicable law, for security purposes.\n\n\n\nHow GitHub secures your information\n\nGitHub takes reasonable measures necessary to protect your personal data from unauthorized access, alteration, or destruction; maintain data accuracy; and help ensure the appropriate use of your personal data. To help us protect personal data, we request that you use a strong password and never share your password with anyone or use the same password with other sites or accounts.\n\nIn addition, if your account has private repositories, you control the access to that Content. GitHub personnel does not access private repository content except for\n- security purposes,\n- automated scanning for known vulnerabilities, active malware, or other content known to violate our Terms of Service\n- to assist the repository owner with a support matter\n- to maintain ", "Y2h1bmtfMTZfaW5kZXhfMjA2OQ==": "the integrity of the Service\n- to comply with our legal obligations if we have reason to believe the contents are in violation of the law,\n- or with your consent.\n\nGitHub will provide notice regarding private repository access where not prohibited by law or if in response to a security threat or other risk to security.\n\n\n\nCross-border data transfers\n\n\n\nData Privacy Framework (DPF)\n\nGitHub complies with the EU-U.S. Data Privacy Framework (EU-U.S. DPF), the UK Extension to the EU-U.S. DPF, and the Swiss-U.S. Data Privacy Framework (Swiss-U.S. DPF) as set forth by the U.S. Department of Commerce. GitHub has certified to the U.S. Department of Commerce that it adheres to the EU-U.S. Data Privacy Framework Principles (EU-U.S. DPF Principles) with regard to the processing of personal data received from the European Union in reliance on the EU-U.S. DPF and from the United Kingdom (and Gibraltar) in reliance on the UK Extension to the EU-U.S. DPF. GitHub has certified to the U.S. Department of Commerce that it adheres to the Swiss-U.S. Data Privacy Framework Principles (Swiss-U.S. DPF Principles) with regard to the processing of personal data received from Switzerland in reliance on the Swiss-U.S. DPF.  If there is any conflict between the terms in this privacy policy and the EU-U.S. DPF Principles and/or the Swiss-U.S. DPF Principles, the Principles shall govern. To learn more about the Data Privacy Framework (DPF) program, and to view our certification, please visit https://www.dataprivacyframework.gov/.\n\nGitHub may store and process your personal data in your region, in the United States, and in any other country where GitHub or its affiliates, subsidiaries, or service providers operate facilities.\n\nWe transfer personal data from the European Union, the United Kingdom, and Switzerland to other countries, some of which have not yet been determined by the European Commission to have an adequate level of data protection. For example, their laws may not guarantee you the same rights, or there may not be a privacy supervis", "Y2h1bmtfMTdfaW5kZXhfMjA2OQ==": "ory authority there that is capable of addressing your complaints. When we engage in such transfers, we use a variety of legal mechanisms, including contracts, such as the standard contractual clauses published by the European Commission under Commission Implementing Decision 2021/914, to help protect your rights and enable these protections to travel with your data. To learn more about the European Commission\u2019s decisions on the adequacy of the protection of personal data in the countries where Microsoft processes personal data, see this article on the European Commission website. You may view a copy of the Standard Contractual Clauses on the GitHub Customer Agreements website under the GitHub Data Protection Agreement.\n\n\n\nHow to Contact Us\n\nIf you have a privacy inquiry or concerns about the way GitHub is handling your personal data, please let us know immediately. We want to help. You may contact us by filling out the Privacy contact form. We will respond promptly.\n\nOur address is:\n\n**GitHub Privacy Team**\n\nGitHub, Inc. \n88 Colin P. Kelly Jr. St. \nSan Francisco, CA 94107 \nUnited States\n\nPrivacy contact form\n\n\n\nDispute resolution process\n\nIn the unlikely event that a dispute arises between you and GitHub regarding our handling of your personal data, please email us directly at (privacy [at] github [dot] com) with the subject line \"Privacy Concerns\". We will respond promptly and do our best to resolve the dispute.\n\nAdditionally, you may have the right to file a complaint with your local data protection or privacy agency or supervisory authority.\n\nIn compliance with the EU-U.S. DPF and the UK Extension to the EU-U.S. DPF and the Swiss-U.S. DPF, GitHub commits to refer unresolved complaints concerning our handling of personal data received in reliance on the EU-U.S. DPF and the UK Extension to the EU-U.S. DPF and the Swiss-U.S. DPF to the International Centre for Dispute Resolution, an alternative dispute resolution provider based in the United States, the European Union, the United Kingdom, and/or Switzerland (as ", "Y2h1bmtfMThfaW5kZXhfMjA2OQ==": "applicable). If you do not receive timely acknowledgment of your DPF Principles-related complaint from us, or if we have not addressed your DPF Principles-related complaint to your satisfaction, please visit https://go.adr.org/dpf_irm.html for more information or to file a complaint. The services of the International Centre for Dispute Resolution are provided at no cost to you.\n\nAn individual has the possibility, under certain conditions, to invoke binding arbitration for complaints regarding DPF compliance not resolved by any of the other DPF mechanisms. For additional information visit the Data Privacy Framework website.\n\n\n\nGovernment Enforcement\n\nGitHub is subject to the investigatory and enforcement powers of the Federal Trade Commission (FTC). Under Section 5 of the Federal Trade Commission Act (15 U.S.C. \u00a7 45), an organization's failure to abide by commitments to implement the DPF Principles may be challenged as deceptive by the FTC. The FTC has the power to prohibit such misrepresentations through administrative orders or by seeking court orders.\n\n\n\nChanges to our Privacy Statement\n\nGitHub may change this Privacy Statement from time to time for a variety of reasons, including to comply with new laws and regulations, to cover new features and functionality, and to increase transparency. We will provide notice of material changes to this Privacy Statement through our Website at least 30 days prior to the change taking effect by posting a notice on our home page or sending email to the primary email address specified in your GitHub account. We will also update our Site Policy repository, which tracks all changes to this policy. For other changes to this Privacy Statement, we encourage Users to watch or to check our Site Policy repository frequently. To learn how to watch a repository, see \"AUTOTITLE.\"\n\n\n\nLicense\n\nThis Privacy Statement is licensed under this Creative Commons Zero license. For details, see our site-policy repository.\n\n\n\nContacting GitHub\n\nQuestions regarding GitHub's Privacy Statement or infor", "Y2h1bmtfMTlfaW5kZXhfMjA2OQ==": "mation practices should be directed to our Privacy contact form.\n\n\n\nTranslations\n\nBelow are translations of this document into other languages. In the event of any conflict, uncertainty, or apparent inconsistency between any of those versions and the English version, this English version is the controlling version.\n\n\n\nFrench\n\nCliquez ici pour obtenir la version fran\u00e7aise: D\u00e9claration de confidentialit\u00e9 de GitHub (PDF)(fr).pdf)\n\n\n\nOther translations\n\nFor translations of this statement into other languages, please visit https://docs.github.com/ and select a language from the drop-down menu under \u201cEnglish.\u201d\n\n\n\nEuropean Data Protection Rights Notice\n\nIf you are in the European Economic Area, we process your personal data in accordance with applicable laws, and the processing of personal data about you is subject to European Union data protection law, you have certain rights with respect to that data:\n\nYou can request access to, and rectification or erasure of, personal data; If any automated processing of personal data is based on your consent or a contract with you, you have a right to transfer or receive a copy of the personal data in a usable and portable format; If the processing of personal data is based on your consent, you can withdraw consent at any time for future processing; You can to object to, or obtain a restriction of, the processing of personal data under certain circumstances; and for residents of France, you can send us specific instructions regarding the use of your data after your death.\n\nTo make such requests, please use the contact information at the bottom of this statement. When we are processing data on behalf of another party (i.e., where GitHub is acting as a data processor) you should direct your request to that party. You also have the right to lodge a complaint with a supervisory authority, but we encourage you to first contact us with any questions or concerns.\n\nWe rely on different lawful bases for collecting and processing personal data about you, for example, with your consent and/or", "Y2h1bmtfMjBfaW5kZXhfMjA2OQ==": " as necessary to provide the services you use, operate our business, meet our contractual and legal obligations, protect the security of our systems and our customers, or fulfill other legitimate interests.\n\n\n\nU.S. State Data Privacy\n\nIf you are a U.S. resident, we process your personal data in accordance with applicable U.S. state data privacy laws, including the California Consumer Privacy Act (CCPA). This section of our Privacy Statement contains information required by the CCPA and other U.S. state data privacy laws and supplements our Privacy Statement.\n\n**Sale**. We do not sell your personal data. So, we do not offer an opt-out to the sale of personal data.\n\n**Share**. We may \u201cshare\u201d your personal data for targeted advertising purposes. You may opt out of sharing data for cross-contextual advertising purposes, and make additional privacy choices on GitHub\u2019s Enterprise Marketing pages by selecting Managing Your Cookie Preferences. Here are the categories of personal data shared over the past 12 months with additional details.\n\n| Categories of Personal Data Shared | Categories of Recipients | Business or commercial purpose for sharing |\n|:---                                |:---                      |:---                                        |\n| Usage information and Interactions | Advertisers | To support GitHub\u2019s enterprise marketing efforts |\n\n**Rights**. You have the right to request that we (i) disclose what personal data we collect, use, disclose, share, and sell, (ii) delete your personal data, (iii) correct your personal data, and (iv) restrict the use and disclosure of your sensitive data, and (v) opt-out of future \u201csharing\u201d of personal data for targeted advertising purposes. You may make these requests yourself or through an authorized agent. If you use an authorized agent, we provide your agent with detailed guidance on how to exercise your privacy rights.\n\nPlease see Your choices regarding our processing of your personal data section of the GitHub Privacy Statement for additional information on ", "Y2h1bmtfMjFfaW5kZXhfMjA2OQ==": "how to exercise these rights. You can use GitHub\u2019s User Migration API to access and download your data. For more information, see \"AUTOTITLE.\"\n\nIf you have a GitHub account, you must exercise your rights through the tools provided, which requires you to log in to your GitHub account. If you have an additional request or questions after logging in, you may contact GitHub at the address in the How to contact us section, including through our web form.\n\nIf you do not have an account, you may exercise your rights by contacting us as described above. We may ask for additional information to validate your request before honoring the request. To submit a request based on these rights, you can also contact us through the GitHub Support portal.\n\nYou may opt-out of \u201csharing\u201d information for cross-contextual behavioral advertising purposes, and make additional privacy choices related to GitHub\u2019s Enterprise Marketing pages by selecting Managing Your Cookie Preferences. You have a right not to receive discriminatory treatment if you exercise your privacy rights. We will not discriminate against you if you exercise your privacy rights.\n\nAdditionally, under California Civil Code section 1798.83, also known as the \u201cShine the Light\u201d law, California residents who have provided personal information to a business with which the individual has established a business relationship for personal, family, or household purposes (\u201cCalifornia Customers\u201d) may request information about whether the business has disclosed personal information to any third parties for the third parties\u2019 direct marketing purposes. Please be aware that we do not disclose personal information to any third parties for their direct marketing purposes as defined by this law. California Customers may request further information about our compliance with this law by emailing (privacy [at] github [dot] com). Please note that businesses are required to respond to one request per California Customer each year and may not be required to respond to requests made by means othe", "Y2h1bmtfMjJfaW5kZXhfMjA2OQ==": "r than through the designated email address.\n\nCalifornia residents under the age of 18 who are registered users of online sites, services, or applications have a right under California Business and Professions Code Section 22581 to remove, or request and obtain removal of, content or information they have publicly posted. To remove content or information you have publicly posted, please submit a Private Information Removal request. Alternatively, to request that we remove such content or information, please send a detailed description of the specific content or information you wish to have removed to GitHub support. Please be aware that your request does not guarantee complete or comprehensive removal of content or information posted online and that the law may not permit or require removal in certain circumstances. If you have any questions about our privacy practices with respect to California residents, please contact us through the GitHub Support portal.\n\n\n\nOur handling of personal information\n\nThe table below contains information about the categories of personal information we collect, our purposes of processing, and the categories of third-party recipients with whom we share the personal information. Please see the GitHub Privacy Statement for full details, including a description of the data included in each category.\n\n|Category of Personal Data   |Sources of Personal Data    |Purposes of Processing    |Recipients    |\n|:----                       |:----                       |:----                     |:----         |\n|Registration information|Users and customers who use create an account|Provide and personalize our Services; authenticate and provide account access; respond to user and customer questions; help, secure, and troubleshoot; honor users rights; and marketing| Service providers and user-directed entities|\n|Demographic information|Users and customers, third-party data brokers|Provide and personalize our Services; product improvement and development; help, secure, and troubleshoot; and marketing|", "Y2h1bmtfMjNfaW5kZXhfMjA2OQ==": "Service providers and user-directed entities|\n|Payment and billing information|Users and customers, financial institutions|Transact commerce; provide our Services; process transactions; fulfill orders; help, secure, and troubleshoot; and detect and prevent fraud|Service providers and user-directed entities|\n|Content and files|Users and customers|Provide our Services; safety; compliance; and help, secure, and troubleshoot; honor user rights|Service providers and user-directed entities|\n|Feedback and ratings|Users and customers|Provide our Services; product improvement; product improvement and development; marketing; customer support; and help, secure, and troubleshoot|Service providers and user-directed entities|\n|Transaction information, subscription and licensing data|Users and customers|Provide, personalize, and activate our Services; customer support; help, secure, and troubleshoot; and marketing|Service providers and user-directed entities|\n|Usage information and Interactions|Users, customers, website visitors|Provide and personalize our Services; product improvement and development; marketing; and help, secure and troubleshoot|Service providers and user-directed entities|\n|Geolocation information|Users, customers, website visitors|Provide and personalize our Services; product improvement and development; marketing; and help, secure and troubleshoot|Service providers and user-directed entities|\n\n**Categories of Sensitive Data**.  We may collect, process, or disclose certain personal data that qualifies as \u201csensitive data\u201d under applicable U.S. state data privacy laws. For example, this data may be collected if you participate in a survey, share it in your account profile, or are engaged in certain community-focused repositories. Sensitive data is a subset of personal data. In the list below, we outline the categories of sensitive data we collect, the sources of the sensitive data, our purposes of processing, and the categories of third-party recipients with whom we share the sensitive data. Please see the \"Wh", "Y2h1bmtfMjRfaW5kZXhfMjA2OQ==": "at information GitHub collects\" section for more information about the sensitive data we may collect.\n\n|Sensitive Data Type    |Purposes of Processing    |Recipients    |\n|:----                  |:----                     |:----         |\n|Account log-in, financial account, debit or credit card number, and the means to access the account (security or access code, password, credentials, etc.)|Transact commerce; process transactions; fulfill orders; provide our Services; help, secure, and troubleshoot; and detect and prevent fraud|Service providers and user-directed entities|\n|Racial or ethnic origin, religious or philosophical beliefs, or union membership|Provide and personalize our products; product development; help, secure, and troubleshoot; and marketing|Service providers and user-directed entities|\n|Medical or mental health, sex life, or sexual orientation|Provide and personalize our products; product development; help, secure, and troubleshoot; and marketing|Service providers and user-directed entities|\n|Contents of your mail, email, or text messages (where GitHub is not the intended recipient of the communication)|Provide our products; safety; compliance; and help, secure, and troubleshoot|Service providers and user-directed entities|\n\nGitHub asks your consent to collect and process your sensitive data or does so at your direction. We do not use or disclose your sensitive data for purposes other than the following:\n- To perform the services, fulfill the transactions, or provide the goods or Services you reasonably expect;\n- To help ensure the security and integrity of our Services, to combat malicious deceptive, fraudulent or illegal acts, and to protect the physical safety of individuals, to the extent the processing is reasonably necessary and proportionate;\n- for transient use (including non-personalized advertising), so long as the personal data is not used for profiling, and is not used to alter an individual\u2019s experience outside the current interaction with GitHub;\n- To perform services to operate our", "Y2h1bmtfMjVfaW5kZXhfMjA2OQ==": " business, such as maintaining accounts, providing customer service, processing, or fulfilling orders/transactions, verifying customer information, processing payments, provide financing, providing analytics, providing storage, and similar services;\n- To undertake activities to verify or maintain the quality or safety of, or improve, upgrade, or enhance a service or device owned or controlled by GitHub; and\n- To conduct any other activities in accordance with applicable law.\n\nThe charts above contain the primary sources, purposes of processing, and recipients for each category of personal data. We use the categories of personal information described above for the purposes listed in the \"How GitHub uses your information\" section of our Privacy Statement, such as meeting our legal obligations, improving our internal operations, and doing research. We also disclose the categories of personal information listed above for business or compliance purposes. Please see the \"How we share information we collect\" section of our Privacy Statement for additional details.\n\n**Not in a Position to Identify Data**. In some situations GitHub may process data in a state called Not in a Position to Identify Data (NPI) or de-identified data. Data is in this state when we are not able to link data to an individual to whom such data may relate without taking additional steps. In those instances, and unless allowed under applicable law, we will maintain such information in an NPI state, and will not try to re-identify the individual to whom NPI data relates.\n\n**Disclosures of personal data for business or commercial purposes**. As indicated in the How We share the information we collect section, we share personal data with third parties for various business and commercial purposes. The primary business and commercial purposes for which we share personal data are the purposes of processing listed in the table above. We also disclose the categories of personal information listed above for business purposes. Please see the \"How we share the", "Y2h1bmtfMjZfaW5kZXhfMjA2OQ==": " information we collect\" section of our Privacy Statement for additional details.\n\n**Parties that control collection of personal data**. In certain situations, we may allow a third party to control the collection of your personal data. For example, on our Enterprise Marketing Pages, advertisers may be the controllers of information they collect through their cookies.\n\n", "Y2h1bmtfMF9pbmRleF8xNTI5": "---\ntitle: Creating an announcement banner for your organization\nshortTitle: Create an announcement banner\nintro: Organization owners can create announcement banners for the organization.\nversions:\n  feature: custom-banner-messages\ntype: how_to\ntopics:\n  - Maintenance\n---\n\n{% ifversion ghec %}\n{% note %}\n\n**Note:** To create an announcement banner, your organization must use {% data variables.product.prodname_ghe_cloud %}. {% data reusables.enterprise.link-to-ghec-trial %}\n\n{% endnote %}\n{% endif %}\n\nYou can create an announcement banner that will be displayed to all organization members at the top of every page in the organization.\n\n{% data reusables.enterprise.user-messages-markdown %}\n\nYou can also set announcement banners at the enterprise level. For more information, see \"AUTOTITLE.\"\n\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n1. In the \"Messages\" section of the sidebar, click **{% octicon \"megaphone\" aria-hidden=\"true\" %} Announcement**.\n1. Under \"Announcement\", in the text field, type the announcement you want displayed in a banner.\n1. Optionally, under \"Expires on\", select the calendar drop-down menu and click an expiration date.\n\n   {% note %}\n\n   **Note:** Announcements must either have an expiration date, be user dismissible, or both.\n\n   {% endnote %}\n1. Optionally, to allow each user to dismiss the announcement, select **Allow users to dismiss the announcement**.\n{% data reusables.enterprise_site_admin_settings.message-preview-save %}\n\n", "Y2h1bmtfMF9pbmRleF8zODI=": "\n\nPromoting a user from the enterprise settings\n\n{% data reusables.enterprise-accounts.access-enterprise %}\n{% data reusables.enterprise-accounts.people-tab %}\n{% data reusables.enterprise-accounts.administrators-tab %}\n1. In the upper-right corner of the page, click **Add owner**.\n1. In the search field, type the name of the user, then click **Add**.\n\n\n\nDemoting a site administrator from the enterprise settings\n\n{% data reusables.enterprise-accounts.access-enterprise %}\n{% data reusables.enterprise-accounts.people-tab %}\n{% data reusables.enterprise-accounts.administrators-tab %}\n1. In the upper-left corner of the page, in the \"Find an administrator\" search field, type the username of the person you want to demote.\n{%- ifversion ghes %}\n1. In the search results, find the username of the person you want to demote, then select the {% octicon \"kebab-horizontal\" aria-label=\"Administrator settings\" %} dropdown menu and click **Convert to member**.\n\n   !Screenshot of a user in the enterprise administrators list. A dropdown menu, labeled with a kebab icon, is highlighted with an orange outline.\n{%- else %}\n1. In the search results, find the username of the person you want to demote, then use the {% octicon \"gear\" %} drop-down menu, and select **Remove owner**.\n{%- endif %}\n\n\n\nPromoting a user from the command line\n\n1. SSH into your appliance.\n1. Run ghe-user-promote with the username to promote.\n\n   ```shell\n   ghe-user-promote USERNAME\n   ```\n\n\n\nDemoting a site administrator from the command line\n\n1. SSH into your appliance.\n1. Run ghe-user-demote with the username to demote.\n\n   ```shell\n   ghe-user-demote USERNAME\n   ```\n\n", "Y2h1bmtfMF9pbmRleF8xNTM5": "\n\nCreating a default label\n\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n{% data reusables.organizations.repository-defaults %}\n1. Under \"Repository labels\", click **New label**.\n{% data reusables.project-management.name-label %}\n{% data reusables.project-management.label-description %}\n{% data reusables.project-management.label-color-randomizer %}\n{% data reusables.project-management.create-label %}\n\n\n\nEditing a default label\n\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n{% data reusables.organizations.repository-defaults %}\n\n{% data reusables.project-management.edit-label %}\n{% data reusables.project-management.name-label %}\n{% data reusables.project-management.label-description %}\n{% data reusables.project-management.label-color-randomizer %}\n{% data reusables.project-management.save-label %}\n\n\n\nDeleting a default label\n\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n{% data reusables.organizations.repository-defaults %}\n\n{% data reusables.project-management.delete-label %}\n{% data reusables.project-management.confirm-label-deletion %}\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF85OTE=": "\n\nOverview\n\nYour organization is billed according to its compute and storage usage for {% data variables.product.prodname_github_codespaces %}. This article explains the ways in which you, as an organization owner, can manage these costs.\n\nTo learn about pricing for {% data variables.product.prodname_github_codespaces %}, see \"AUTOTITLE.\"\n\n\n\nSpending limits\n\nYou can set a spending limit for {% data variables.product.prodname_github_codespaces %} for your organization. This limit is applied to the total compute and storage cost for {% data variables.product.prodname_github_codespaces %}. For more information, see \"AUTOTITLE.\"\n\n- **Compute usage:** This is the total time during which all {% data variables.product.prodname_github_codespaces %} instances (\"codespaces\") were active in a billing month.\n\n- **Storage usage:** For {% data variables.product.prodname_github_codespaces %} billing purposes, this includes all files used by all codespaces and prebuilds in your account. This includes resources such as cloned repositories, configuration files, and extensions, among others.\n\nYou can check the compute and storage usage for {% data variables.product.prodname_github_codespaces %} for the current billing month. For information, see \"AUTOTITLE.\"\n\n{% note %}\n\n**Note**: Prebuilds for {% data variables.product.prodname_github_codespaces %} are created and updated using {% data variables.product.prodname_actions %}. This may incur billable costs for {% data variables.product.prodname_actions %}. You can set a spending limit for {% data variables.product.prodname_actions %}. For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\" Storage of the generated prebuilds is charged at the same rate as your codespaces, and is included in your {% data variables.product.prodname_github_codespaces %} spending limit.\n\n{% endnote %}\n\n\n\nDisabling or limiting billing for {% data variables.product.prodname_codespaces %}\n\nYou can choose for all usage of {% data variables.product.prodname_codespaces %} in your organization to be billed to the", "Y2h1bmtfMV9pbmRleF85OTE=": " user who creates the codespace. Alternatively, you can specify which organization members or collaborators can use {% data variables.product.prodname_codespaces %} at your organization's expense. For more information, see \"AUTOTITLE.\"\n\nYou can limit the number of codespaces that people can create, where the organization will be billed for the codespace. This can help to reduce codespace storage charges for your organization. For more information, see \"AUTOTITLE.\"\n\nYou can configure which repositories can be accessed from codespaces created for a particular repository. For more information, see \"AUTOTITLE.\"\n\nYou can limit the choice of types of machine that are available for codespaces created from repositories owned by your organization. This allows you to prevent people using overly resourced machines for their codespaces, and incurring unnecessary charges. For more information, see \"AUTOTITLE.\"\n\nYou can set a maximum idle timeout constraint to limit the maximum timeout that people can set for codespaces that are billable to your organization. This can reduce the compute usage charges generated by codespaces that are left running in an idle state, by stopping active codespace after a shorter timeout period. For more information, see \"AUTOTITLE.\"\n\nYou can also restrict how long stopped codespaces can remain unused before they are automatically deleted. This can help to reduce storage costs for {% data variables.product.prodname_codespaces %}. For more information, see \"AUTOTITLE.\"\n\nRepository owners who set up prebuilds for their repository can reduce the storage costs of prebuilds by configuring these to be created only in selected regions. For more information, see \"AUTOTITLE.\"\n\n\n\nDeleting unused codespaces\n\nYour users can delete their own codespaces in https://github.com/codespaces and from within {% data variables.product.prodname_vscode %}. To reduce the size of a codespace, users can manually delete files using the terminal or from within {% data variables.product.prodname_vscode_shortname %}.\n\nAs an organ", "Y2h1bmtfMl9pbmRleF85OTE=": "ization owner, you can delete any codespace in your organization. For more information, see \"AUTOTITLE.\"\n\n{% note %}\n\n**Note:** Codespaces are automatically deleted after they have been stopped and have remained inactive for a user-definable number of days. For more information, see \"AUTOTITLE.\" As an organization owner, you can set the maximum retention period for codespaces owned by your organization. This will override a user's personal retention setting. For more information, see \"AUTOTITLE.\"\n\n{% endnote %}\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF84NjI=": "\n\nAbout creating {% data variables.product.prodname_codeql %} query suites\n\n{% data reusables.code-scanning.codeql-cli-version-ghes %}\n\n{% data variables.product.prodname_codeql %} query suites provide a way of selecting queries, based on their\nfilename, location on disk{% ifversion codeql-packs %} or in a {% data variables.product.prodname_codeql %} pack{% endif %}, or metadata properties.\nCreate query suites for the queries that you want to frequently use in\nyour {% data variables.product.prodname_codeql %} analyses.\n\nQuery suites allow you to pass multiple queries to {% data variables.product.prodname_codeql %} without having to specify the path to each query file individually. Query suite definitions are stored in YAML files with the extension `.qls`. A suite definition is a sequence of instructions, where each instruction is a YAML\nmapping with (usually) a single key. The instructions are executed in the order\nthey appear in the query suite definition. After all the instructions in the\nsuite definition have been executed, the result is a set of selected queries.\n\n{% ifversion codeql-packs %}\n{% note %}\n\n**Note:** Any custom queries that you want to add to a query suite must be in a {% data variables.product.prodname_codeql %} pack\" and contain the correct query metadata. For more information, see \"Using custom queries with the {% data variables.product.prodname_codeql_cli %}.\"\n\n{% endnote %}\n{% endif %}\n\n\n\nLocating queries to add to a query suite\n\nWhen creating a query suite, you first need to specify the locations of the\nqueries that you want to select. You can define the location of one or more\nqueries using:\n\n- A `query` instruction\u2014tells {% data variables.product.prodname_codeql %} to look for one or more specified `.ql`\nfiles:\n\n  ```yaml\n  - query: \n  ```\n\n  The argument must be one or more file paths, relative to the {% data variables.product.prodname_codeql %} pack containing\n  the suite definition.\n\n- A `queries` instruction\u2014tells {% data variables.product.prodname_codeql %} to recursively scan a dir", "Y2h1bmtfMV9pbmRleF84NjI=": "ectory\nfor `.ql` files:\n\n  ```yaml\n  - queries: \n  ```\n\n  The path of the directory must be relative to the root of the {% data variables.product.prodname_codeql %} pack that\n  contains the suite definition file. To find the queries relative to a\n  different {% data variables.product.prodname_codeql %} pack, add a `from` field:\n\n  ```yaml\n  - queries: \n    from: \n    version: ^x.y.z\n  ```\n\n  The `version` field is optional and specifies a range of compatible versions of this {% data variables.product.prodname_codeql %} pack.\n  If you don\u2019t specify a version, then the most recent version of the pack is used.\n\n- A `qlpack` instruction\u2014tells {% data variables.product.prodname_codeql %} to resolve queries in the default suite of the\nnamed {% data variables.product.prodname_codeql %} pack:\n\n  ```yaml\n  - qlpack: \n    version: ^x.y.z\n  ```\n\n  The default suite of a query pack includes a recommended set of queries\n  inside of that query pack. Not all query packs have a default suite. If the given query pack does not define a default suite, the qlpack instruction will resolve to all of the queries within the pack.\n\n  The `version` field is optional and specifies a range of compatible versions of this {% data variables.product.prodname_codeql %} pack.\n  If you don\u2019t specify a version, then the most recent version of the pack is used.\n\n{% note %}\n\n**Note:** When pathnames appear in query suite definitions, they must always be given with a forward slash, `/`, as a directory separator. This ensures that query suite definitions work on all operating systems.\n\n{% endnote %}\n\nYou must add at least one `query`, `queries`, or `qlpack` instruction to\nyour suite definition, otherwise no queries will be selected. If the suite\ncontains no further instructions, all the queries found from the list of files,\nin the given directory, or in the named {% data variables.product.prodname_codeql %} pack are selected. If there are further\nfiltering instructions, only queries that match the constraints imposed by those\ninstructions will be selec", "Y2h1bmtfMl9pbmRleF84NjI=": "ted.\n\n\n\nFiltering the queries in a query suite\n\nAfter you have defined the initial set of queries to add to your suite by\nspecifying `query`, `queries`, or `qlpack` instructions, you can add\n`include` and `exclude` instructions. These instructions define selection\ncriteria based on specific properties:\n\n- When you execute an `include` instruction on a set of queries, any\nqueries that match your conditions are retained in the selection, and queries\nthat don\u2019t match are removed.\n- When you execute an `exclude` instructions on a set of queries,\nany queries that match your conditions are removed from the selection, and queries\nthat don\u2019t match are retained.\n\nThe order of your filter instructions is important. The first filter instruction\nthat appears after the locating instructions determines whether the queries are\nincluded or excluded by default. If the first filter is an `include`, the\ninitially located queries will only be part of the suite if they match an\nexplicit `include` filter. If the first filter is an `exclude`, the initially\nlocated queries are part of the suite unless they are explicitly excluded.\n\nSubsequent instructions are executed in order and the instructions that appear\nlater in the file take precedence over the earlier instructions. So, `include`\ninstructions can be overridden by a later `exclude` instructions that match\nthe same query. Similarly, `exclude`s can be overridden by a later\n`include`.\n\nFor both instructions, the argument is a constraint block\u2014that is, a YAML map\nrepresenting the constraints. Each constraint is a map entry, where the key is\ntypically a query metadata property. The value can be:\n\n- A single string.\n- A `/`-enclosed regular expression.\n- A list containing strings, regular expressions, or both.\n\nTo match a constraint, a metadata value must match one of the strings or\nregular expressions. When there is more than one metadata key, each key must be matched.\nThe standard metadata keys available to match on are: `description`, `id`, `kind`,\n`name`, `tags`, `precision`, and `p", "Y2h1bmtfM19pbmRleF84NjI=": "roblem.severity`.\nFor more information about query metadata properties, see\n\"Metadata for {% data variables.product.prodname_codeql %} queries.\"\n\nIn addition to metadata tags, the keys in the constraint block can also be:\n\n- `query filename`\u2014matches on the last path component of the query file name.\n- `query path`\u2014matches on the path to the query file relative to its\nenclosing {% data variables.product.prodname_codeql %} pack.\n- `tags contain`\u2014one of the given match strings must match\none of the space-separated components of the value of the `@tags` metadata property.\n- `tags contain all`\u2014each of the given match strings must match one of the\ncomponents of the `@tags` metadata property.\n\n\n\nExamples of filtering which queries are run\n\nA common use case is to create a query suite that runs all queries in a {% data variables.product.prodname_codeql %} pack,\nexcept for a few specific queries that the user does not want to run. In general, we\nrecommend filtering on the query `id`, which is a unique and stable identifier for\neach query. The following three query suite definitions are semantically identical and\nfilter by the query `id`:\n\nThis filter matches all the queries in the default suite of `codeql/cpp-queries`, except for the two queries with the excluded identifiers:\n\n```yaml\n- qlpack: codeql/cpp-queries\n- exclude:\n    id:\n      - cpp/cleartext-transmission\n      - cpp/cleartext-storage-file\n```\n\nIn this example, a separate `exclude` instruction is used for each query:\n\n```yaml\n- qlpack: codeql/cpp-queries\n- exclude:\n    id: cpp/cleartext-transmission\n- exclude:\n    id: cpp/cleartext-storage-file\n```\n\nIn this example, a regular expression excludes the same two queries. It would also exclude any future queries added to the suite with identifiers that begin: `cpp/cleartext-`:\n\n```yaml\n- qlpack: codeql/cpp-queries\n- exclude:\n    id:\n      - /^cpp\\/cleartext-.*/\n```\n\nTo define a suite that selects all queries in the default suite of the\n`codeql/cpp-queries` {% data variables.product.prodname_codeql %} pack, and then ", "Y2h1bmtfNF9pbmRleF84NjI=": "refines them to only include\nsecurity queries, use:\n\n```yaml\n- qlpack: codeql/cpp-queries\n- include:\n    tags contain: security\n```\n\nTo define a suite that selects all queries with `@kind problem`\nand `@precision high` from the `my-custom-queries` directory, use:\n\n```yaml\n- queries: my-custom-queries\n- include:\n    kind: problem\n    precision: very-high\n```\n\nNote that the following query suite definition behaves differently from the definition above. This definition selects queries that are `@kind problem` _or_\nare `@precision very-high`:\n\n```yaml\n- queries: my-custom-queries\n- include:\n    kind: problem\n- include:\n    precision: very-high\n```\n\nTo create a suite that selects all queries with `@kind problem` from the\n`my-custom-queries` directory except those with `@problem.severity\nrecommendation`, use:\n\n```yaml\n- queries: my-custom-queries\n- include:\n    kind: problem\n- exclude:\n    problem.severity: recommendation\n```\n\nTo create a suite that selects all queries with `@tag security` and\n`@precision high` or `very-high` from the `codeql/cpp-queries` {% data variables.product.prodname_codeql %} pack,\nuse:\n\n```yaml\n- queries: .\n  from: codeql/cpp-queries\n- include:\n    tags contain: security\n    precision:\n    - high\n    - very-high\n```\n\n\n{% note %}\n\n**Note:** You can use the `codeql resolve queries /path/to/suite.qls` command to see which queries are selected by a query suite definition. For more information, see \"AUTOTITLE.\"\n\n{% endnote %}\n\n\n\nReusing existing query suite definitions\n\nExisting query suite definitions can be reused by specifying:\n\n- An `import` instruction\u2014adds the queries selected by a\npreviously defined `.qls` file to the current suite:\n\n  ```yaml\n  - import: \n  ```\n\n  The path to the imported suite must be relative to the {% data variables.product.prodname_codeql %} pack containing the\n  current suite definition. If the imported query suite is in a different QL\n  pack you can use:\n\n  ```yaml\n  - import: \n    from: \n    version: ^x.y.z\n  ```\n\n  The `version` field is optional and specifies a rang", "Y2h1bmtfNV9pbmRleF84NjI=": "e of compatible versions of this {% data variables.product.prodname_codeql %} pack.\n  If you don\u2019t specify a version, then the most recent version of the pack is used.\n\n  Queries added using an `import` instruction can be filtered using subsequent\n  `exclude` instructions.\n\n- An `apply` instruction\u2014adds all of the instructions from a\npreviously defined `.qls` file to the current suite. The instructions in the\napplied `.qls` file are executed as if they appear in place of `apply`.\nAny `include` and `exclude` instructions from the applied suite also act on\nqueries added by any earlier instructions:\n\n  ```yaml\n  - apply: \n  ```\n\n  The `apply` instruction can also be used to apply a set of reusable\n  conditions, saved in a `.yml` file, to multiple query definitions. For more\n  information, see the examples below.\n\n\n\nReusability Examples\n\nTo use the same conditions in multiple query suite definitions, create a\nseparate `.yml` file containing your instructions. For example, save the\nfollowing in a file called `reusable-instructions.yml`:\n\n```yaml\n- include:\n    kind:\n    - problem\n    - path-problem\n    tags contain: security\n    precision:\n    - high\n    - very-high\n```\n\nAdd `reusable-instructions.yml` to the same {% data variables.product.prodname_codeql %} pack as your current query\nsuite. Then, in one or more query suites, use the `apply` instruction to apply\nthe reusable instructions to the current suite. For example:\n\n```yaml\n- queries: queries/cpp/custom\n- apply: reusable-instructions.yml\n```\n\nThis will filter the queries in `queries/cpp/custom` to only include those that match the reusable conditions.\n\nYou can also create a suite definition using `reusable-instructions.yml` on\nqueries in a different {% data variables.product.prodname_codeql %} pack. If the `.qls` file is in the same {% data variables.product.prodname_codeql %} pack as\nthe queries, you can add a `from` field immediately after the `apply`\ninstruction:\n\n```yaml\n\n\nload queries from the default suite of my-org/my-other-custom-queries\n- qlpack: my-or", "Y2h1bmtfNl9pbmRleF84NjI=": "g/my-other-custom-queries\n\n\n\napply the reusable instructions from the my-org/my-custom-instructions {% data variables.product.prodname_codeql %} pack\n- apply: reusable-instructions.yml\n  from: my-org/my-custom-instructions\n  version: ^1.2.3 # optional\n```\n\nA common use case for an `import` instruction is to apply a further filter to queries from another\nquery suite. For example, this suite will further filter the `cpp-security-and-quality` suite\nand exclude `low` and `medium` precision queries:\n\n```yaml\n- import: codeql-suites/cpp-security-and-quality.qls\n  from: codeql/cpp-queries\n- exclude:\n    precision:\n      - low\n      - medium\n```\n\nIf you want to `include` queries imported from another suite, the syntax is a little different:\n\n```yaml\n- import: codeql-suites/cpp-security-and-quality.qls\n  from: codeql/cpp-queries\n- exclude: {}\n- include:\n    precision:\n      - very-high\n      - high\n```\n\nNotice the empty `exclude` instruction. This is required to ensure that the subsequent `include`\ninstruction is able to filter queries from the imported suite.\n\n\n\nNaming a query suite\n\nYou can provide a name for your query suite by specifying a `description`\ninstruction:\n\n```yaml\n- description: \n```\n\nThis value is displayed when you run AUTOTITLE, if the suite is added to a \"well-known\"\ndirectory. For more information, see \"Specifying well-known query suites.\"\n\n{% ifversion codeql-packs %}\n\n\n\nSaving a query suite\n\nSave your query suite in a file with a `.qls` extension and add it to a {% data variables.product.prodname_codeql %}\npack. For more information, see \"AUTOTITLE.\"\n\n\n\nSpecifying well-known query suites\n\nYou can use {% data variables.product.prodname_codeql %} packs to declare directories that contain \"well-known\" query\nsuites. You can use \"well-known\" query suites on the command line by referring\nto their file name,\nwithout providing their full path. This gives you a simple way of specifying a\nset of queries, without needing to search inside {% data variables.product.prodname_codeql %} packs and distributions.\nTo d", "Y2h1bmtfN19pbmRleF84NjI=": "eclare a directory that contains \"well-known\" query suites, add the directory\nto the `suites` property in the `qlpack.yml` file at the root of your {% data variables.product.prodname_codeql %} pack.\nFor more information, see \"AUTOTITLE.\"\n{% endif %}\n\n\n\nUsing query suites with {% data variables.product.prodname_codeql %}\n\nYou can specify query suites on the command line for any command that accepts\n`.qls` files. For example, you can compile the queries selected by a suite\ndefinition using `query compile`, or use the queries in an analysis using\n`database analyze`. For more information about analyzing {% data variables.product.prodname_codeql %} databases, see\n\"AUTOTITLE.\"\n\n\n\nFurther reading\n\n- \"{% data variables.product.prodname_codeql %} queries\"\n\n", "Y2h1bmtfMF9pbmRleF8xNDg=": "---\ntitle: Deleting a workflow run\nshortTitle: Delete a workflow run\nintro: 'You can delete a workflow run that has been completed, or is more than two weeks old.'\nversions:\n  fpt: '*'\n  ghes: '*'\n  ghae: '*'\n  ghec: '*'\n---\n \n{% data reusables.actions.enterprise-github-hosted-runners %}\n\n{% data reusables.repositories.permissions-statement-write %}\n\n{% data reusables.repositories.navigate-to-repo %}\n{% data reusables.repositories.actions-tab %}\n{% data reusables.repositories.navigate-to-workflow %}\n1. To delete a workflow run, select {% octicon \"kebab-horizontal\" aria-label=\"Show options\" %}, then click **Delete workflow run**.\n\n   !Screenshot of a list of workflow runs. To the right of a run, an icon of three horizontal dots is highlighted with an orange outline.\n\n1. Review the confirmation prompt and click **Yes, permanently delete this workflow run**.\n\n", "Y2h1bmtfMF9pbmRleF80ODA=": "\n\nAbout email restrictions for your enterprise\n\nWhen you restrict email notifications, enterprise members can only use an email address in a verified or approved domain to receive email notifications about activity in organizations owned by your enterprise.\n\n{% data reusables.enterprise-accounts.approved-domains-beta-note %}\n\nThe domains can be inherited from the enterprise or configured for the specific organization. For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n\n{% data reusables.notifications.email-restrictions-verification %}\n\nIf email restrictions are enabled for an enterprise, organization owners cannot disable email restrictions for any organization owned by the enterprise. If changes occur that result in an organization having no verified or approved domains, either inherited from an enterprise that owns the organization or for the specific organization, email restrictions will be disabled for the organization.\n\n\n\nRestricting email notifications for your enterprise\n\nBefore you can restrict email notifications for your enterprise, you must verify or approve at least one domain for the enterprise. {% ifversion ghec %} For more information, see \"AUTOTITLE.\"{% endif %}\n\nUsers will not be notified when you enable email restrictions. It is your responsibility to inform users that, in the future, they will only receive email notifications related to your enterprise if they've added an email address belonging to a verified or approved domain to their account settings.\n\n{% data reusables.enterprise-accounts.access-enterprise %}\n{% data reusables.enterprise-accounts.settings-tab %}\n{% data reusables.enterprise-accounts.verified-domains-tab %}\n{% data reusables.organizations.restrict-email-notifications %}\n1. Click **Save**.\n\n", "Y2h1bmtfMF9pbmRleF81NjQ=": "\n\nAbout developing {% data variables.product.prodname_github_apps %} for {% data variables.product.prodname_ghe_server %}\n\nIf you want your {% data variables.product.prodname_github_app %} to be available to organizations in a {% data variables.product.prodname_ghe_server %} instance that you are not part of, you must take the following steps.\n\n{% ifversion ghes %}\nThese steps are not required if your {% data variables.product.prodname_github_app %} will only be used by organizations in a {% data variables.product.prodname_ghe_server %} instance that you are part of. For more information, see \"AUTOTITLE.\"\n{% endif %}\n\nIf {% data variables.product.prodname_ghe_server %} access is important, consider whether a custom action for {% data variables.product.prodname_actions %} will suit your needs instead. Public actions are available on {% data variables.product.prodname_ghe_server %} instances with {% data variables.product.prodname_github_connect %}. For more information, see {% ifversion ghes %}\"AUTOTITLE.\"{% else %}\"AUTOTITLE\" in the  {% data variables.product.prodname_ghe_server %} documentation.{% endif %}\n\n\n\nEach {% data variables.product.prodname_ghe_server %} instance must register their own {% data variables.product.prodname_github_app %}\n\nOrganizations owned by a {% data variables.product.prodname_ghe_server %} instance cannot install {% data variables.product.prodname_github_apps %} registered on {% data variables.product.prodname_dotcom_the_website %} or on another {% data variables.product.prodname_ghe_server %} instance. Instead, they must register and install their own {% data variables.product.prodname_github_app %} for use on that instance.\n\n1. The app developer creates a manifest or URL parameters. For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n1. The app developer shares the manifest or URL parameters with the {% data variables.product.prodname_ghe_server %} administrator that wants to use the app. The same manifest or URL parameters can be shared with multiple {% data variables.product.pro", "Y2h1bmtfMV9pbmRleF81NjQ=": "dname_ghe_server %} instances.\n1. An organization owner in the instance uses the manifest or URL parameters to register a {% data variables.product.prodname_github_app %}.\n1. The organization installs the {% data variables.product.prodname_github_app %} that they registered.\n\n   Optionally, if the organization made the {% data variables.product.prodname_github_app %} public, other organizations within the instance can install the {% data variables.product.prodname_github_app %} as well. There is not a way to install a {% data variables.product.prodname_github_app %} on an entire instance, only on organizations within an instance.\n\n\n\nThe app code must be able to access the {% data variables.product.prodname_github_app %} credentials for the instance\n\nYou app's code will need the credentials of the {% data variables.product.prodname_github_app %} that the {% data variables.product.prodname_ghe_server %} instance registered. It will also need the hostname of the instance. You have two options: get the credentials and hostname from the instance, or have the {% data variables.product.prodname_ghe_server %} customer host and manage a self-hostable version of the app.\n\n\n\nGet the credentials from the {% data variables.product.prodname_ghe_server %} instance\n\nThe instance can share their {% data variables.product.prodname_github_app %} credentials and hostname with the app developer. The site administrator should only do this if they trust the app developer. Then, the app code can use the appropriate credentials depending on what actions it is taking. The app developer must take precautions to use the appropriate set of credentials and to not leak data.\n\nAdvantages:\n\n- The app developer controls the infrastructure that the app runs on.\n- The app developer has more control over app updates.\n- The app developer may have more insight into app performance.\n\nDisadvantages:\n\n- The app developer must take precautions to avoid leaking data from the instance.\n- The site administrator may need to open firewall exceptions for your a", "Y2h1bmtfMl9pbmRleF81NjQ=": "pplication to reach the instance, and they may be reluctant to do so.\n\n\n\nHave the {% data variables.product.prodname_ghe_server %} customer host and manage a self-hostable version of the app\n\nThe app developer can provide a self-hostable version of their app. Then, the site administrator can host the app according to app developer's setup and installation instructions.\n\nThe method by which the self-hostable version of the app is created and shared is up to the app developer and depends on technology that the app uses.\n\nAdvantages:\n\n- The instance remains more secure because they aren't sharing their app credentials.\n- The app developer doesn't need to worry about leaking data from the instance.\n\nDisadvantages:\n\n- The app developer relies on the site administrator to provide infrastructure for the app and set things up correctly.\n- Releasing updates to the app code may be more complex.\n- The app developer may lose visibility about app performance.\n\n\n\nThe app code must use the correct URLs\n\n{% data variables.product.prodname_ghe_server %} uses different URLs than {% data variables.product.prodname_free_user %}, {% data variables.product.prodname_pro %}, {% data variables.product.prodname_team %}, and {% data variables.product.prodname_ghe_cloud %}. You should update your app code to use the appropriate URL depending on whether it is working with a {% data variables.product.prodname_ghe_server %} instance. Replace `HOSTNAME` with the hostname of the {% data variables.product.prodname_ghe_server %} instance.\n\n{% data variables.product.prodname_free_user %}{% data variables.product.prodname_pro %}{% data variables.product.prodname_team %}{% data variables.product.prodname_ghe_cloud %} | {% data variables.product.prodname_ghe_server %}\n--- | ---\n`https://api.github.com` | `https://HOSTNAME/api/v3`\n`https://api.github.com/graphql` | `https://HOSTNAME/api/v3/graphql`\n`https://github.com/login/oauth/authorize` | `https://HOSTNAME/login/oauth/authorize`\n`https://github.com/login/oauth/access_token` | `https://HOSTNAME/logi", "Y2h1bmtfM19pbmRleF81NjQ=": "n/oauth/access_token`\n\n\n\nThe app code must be aware of feature differences\n\nNew REST API endpoints, GraphQL objects, and webhooks are released to {% data variables.product.prodname_ghe_server %} at a later date than {% data variables.product.prodname_free_user %}, {% data variables.product.prodname_pro %}, {% data variables.product.prodname_team %}, and {% data variables.product.prodname_ghe_cloud %}. Additionally, there are multiple versions of {% data variables.product.prodname_ghe_server %}, and older versions may have different REST API endpoints, GraphQL objects, and webhooks.\n\nTherefore, the app code needs to be aware of these differences. API responses and webhook payloads include a `x-github-enterprise-version` header for {% data variables.product.prodname_ghe_server %} payloads to help you determine what version you are handling.\n\n\n\nEach {% data variables.product.prodname_ghe_server %} instance can configure rate limits\n\nEach {% data variables.product.prodname_ghe_server %} instance can configure its own rate limits. If your app is hitting a rate limit and is already taking precautions to stay under the rate limit, you should talk to the admin of the {% data variables.product.prodname_ghe_server %} instance.\n\n", "Y2h1bmtfMF9pbmRleF8yMDg3": "\n\nJoining {% data variables.product.prodname_sponsors %}\n\n{% data reusables.sponsors.you-can-be-a-sponsored-developer %} For more information, see \"AUTOTITLE.\"\n\n{% data reusables.sponsors.you-can-be-a-sponsored-organization %} For more information, see \"AUTOTITLE.\"\n\nAfter you join {% data variables.product.prodname_sponsors %}, you can add a sponsor button to the open source repository you contribute to, to increase the visibility of your {% data variables.product.prodname_sponsors %} profile and other funding platforms. For more information, see \"AUTOTITLE.\"\n\nYou can set a goal for your sponsorships. For more information, see \"AUTOTITLE.\"\n\n{% data reusables.sponsors.github-contact-applicants %}\n\n\n\nSponsorship tiers\n\n{% data reusables.sponsors.tier-details %} For more information, see \"AUTOTITLE,\" \"AUTOTITLE, and \"AUTOTITLE.\"\n\nIt's best to set up a range of different sponsorship options, including monthly and one-time tiers, to make it easy for anyone to support your work. In particular, one-time payments allow people to reward your efforts without worrying about whether their finances will support a regular payment schedule.\n\n\n\nSponsorship payouts\n\n{% data reusables.sponsors.no-fees %}\n\n{% data reusables.sponsors.payout-info %}\n\nFor more information, see \"AUTOTITLE.\"\n\n\n\nSharing feedback about {% data variables.product.prodname_sponsors %}\n\n{% data reusables.sponsors.feedback %}\n\n\n\nFurther reading\n\n- \"FAQ with the {% data variables.product.prodname_sponsors %} team\" on {% data variables.product.prodname_blog %}\n\n", "Y2h1bmtfMF9pbmRleF8yMTk=": "---\ntitle: Using GitHub CLI in workflows\nshortTitle: GitHub CLI in workflows\nintro: 'You can script with {% data variables.product.prodname_cli %} in {% data variables.product.prodname_actions %} workflows.'\nredirect_from:\n  - /actions/guides/using-github-cli-in-workflows\n  - /actions/advanced-guides/using-github-cli-in-workflows\nversions:\n  fpt: '*'\n  ghes: '*'\n  ghae: '*'\n  ghec: '*'\ntopics:\n  - CLI\n  - Workflows\ntype: how_to\n---\n\n\n{% data reusables.cli.cli-learn-more %}\n\n{% data variables.product.prodname_cli %} is preinstalled on all {% data variables.product.prodname_dotcom %}-hosted runners. For each step that uses {% data variables.product.prodname_cli %}, you must set an environment variable called `GITHUB_TOKEN` to a token with the required scopes.\n\nYou can execute any {% data variables.product.prodname_cli %} command. For example, this workflow uses the `gh issue comment` subcommand to add a comment when an issue is opened.\n\n```yaml copy\nname: Comment when opened\non:\n  issues:\n    types:\n      - opened\njobs:\n  comment:\n    runs-on: ubuntu-latest\n    steps:\n      - run: gh issue comment $ISSUE --body \"Thank you for opening this issue!\"\n        env:\n          GITHUB_TOKEN: {% raw %}${{ secrets.GITHUB_TOKEN }}{% endraw %}\n          ISSUE: {% raw %}${{ github.event.issue.html_url }}{% endraw %}\n```\n\nYou can also execute API calls through {% data variables.product.prodname_cli %}. For example, this workflow first uses the `gh api` subcommand to query the GraphQL API and parse the result. Then it stores the result in an environment variable that it can access in a later step. In the second step, it uses the `gh issue create` subcommand to create an issue containing the information from the first step.\n\n```yaml copy\nname: Report remaining open issues\non: \n  schedule: \n    # Daily at 8:20 UTC\n    - cron: '20 8 * * *'\njobs:\n  track_pr:\n    runs-on: ubuntu-latest\n    steps:\n      - run: |\n          numOpenIssues=\"$(gh api graphql -F owner=$OWNER -F name=$REPO -f query='\n            query($name: String!, $owner: S", "Y2h1bmtfMV9pbmRleF8yMTk=": "tring!) {\n              repository(owner: $owner, name: $name) {\n                issues(states:OPEN){\n                  totalCount\n                }\n              }\n            }\n          ' --jq '.data.repository.issues.totalCount')\"\n\n          echo 'NUM_OPEN_ISSUES='$numOpenIssues >> $GITHUB_ENV\n        env:\n          GITHUB_TOKEN: {% raw %}${{ secrets.GITHUB_TOKEN }}{% endraw %}\n          OWNER: {% raw %}${{ github.repository_owner }}{% endraw %}\n          REPO: {% raw %}${{ github.event.repository.name }}{% endraw %}\n      - run: |\n          gh issue create --title \"Issue report\" --body \"$NUM_OPEN_ISSUES issues remaining\" --repo $GITHUB_REPOSITORY\n        env:\n          GITHUB_TOKEN: {% raw %}${{ secrets.GITHUB_TOKEN }}{% endraw %}\n```\n\n", "Y2h1bmtfMF9pbmRleF8xMjk4": "\n\nAbout access to {% data variables.product.product_name %} from a restricted network\n\nIn rare cases, an institution's network access policy may restrict access to specific domain names for end users. For example, the policy may use DNS filtering to deny access to sites like {% data variables.location.product_location %}. If your institution requires this level of control, but you still want to permit access to services on {% data variables.location.product_location %}, you can create exceptions in your policy to allow access to the necessary domains.\n\n\n\nRetrieving {% data variables.product.company_short %}'s domain names using the REST API\n\nYou can use the REST API to retrieve a list of {% data variables.product.company_short %}'s domain names.\n\n{% warning %}\n\n**Warning**: The list of domains from the REST API is not intended to be comprehensive. If you block access to services using DNS, but selectively allow access to {% data variables.product.company_short %}'s domain names, any or all of {% data variables.location.product_location %} and related services may not function properly or at all for your end users.\n\n{% endwarning %}\n\nFor more information, see \"AUTOTITLE\" in the REST API documentation.\n\n", "Y2h1bmtfMF9pbmRleF8xNTM1": "\n\nAbout organization discussions\n\n{% data reusables.discussions.about-organization-discussions %}\n\nYou can also manage repository discussions. For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n\n\n\nEnabling or disabling {% data variables.product.prodname_discussions %} for your organization\n\n{% data reusables.discussions.enabling-or-disabling-github-discussions-for-your-organization %}\n1. To disable discussions, under \"Discussions\", unselect **Enable discussions for this organization**.\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8zNTU=": "---\ntitle: Configuring visibility for organization membership\nintro: You can set visibility for new organization members across your enterprise to public or private. You can also prevent members from changing their visibility from the default.\nredirect_from:\n  - /enterprise/admin/user-management/configuring-visibility-for-organization-membership\n  - /admin/user-management/configuring-visibility-for-organization-membership\n  - /admin/user-management/managing-organizations-in-your-enterprise/configuring-visibility-for-organization-membership\nversions:\n  ghes: '*'\n  ghae: '*'\ntype: how_to\ntopics:\n  - Enterprise\n  - Organizations\n  - User account\nshortTitle: Set membership visibility\n---\n{% ifversion ghes %}\nYou can also enforce your default setting on all current organization members in your instance using a command-line utility. For example, if you'd like to require every organization member's visibility to be public, you can set the default to public and enforce the default for all new members in the admin settings, and then use the command-line utility to enforce the public setting on existing members.\n{% endif %}\n\n{% data reusables.enterprise-accounts.access-enterprise %}\n{% ifversion ghes or ghae %}\n{% data reusables.enterprise-accounts.policies-tab %}\n{% else %}\n{% data reusables.enterprise-accounts.settings-tab %}\n{% endif %}\n{% data reusables.enterprise-accounts.options-tab %}\n1. Under \"Default organization membership visibility\", select the drop-down menu, and click **Private** or **Public**.\n1. Optionally, to prevent members from changing their membership visibility from the default, select **Enforce for all enterprise members**.\n   !Screenshot of the \"Default organization membership visibility\" section on the enterprise's policies page. The \"Enforce for all enterprise members\" checkbox is highlighted with an orange outline.{% ifversion ghes %}\n1. If you'd like to enforce your new visibility setting on all existing members, use the `ghe-org-membership-update` command-line utility. For more information, see", "Y2h1bmtfMV9pbmRleF8zNTU=": " \"AUTOTITLE.\"{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF8xMTI3": "\n\nAbout {% data variables.product.prodname_copilot_for_prs %}\n\nYou can use {% data variables.product.prodname_copilot %} to generate a summary of a pull request on {% data variables.product.prodname_dotcom_the_website %}. You can use the summary to help reviewers understand your changes, or to quickly understand the changes in a pull request you're reviewing.\n\n{% data variables.product.prodname_copilot %} will scan through the pull request and provide an overview of the changes made in prose, as well as a bulleted list of changes with the files that they impact. You can generate a summary in the following places.\n\n- In the description of a new pull request you're creating\n- In the description of an existing pull request, by editing the opening comment\n- In a comment on the main timeline of a pull request\n\nTo learn more about {% data variables.product.prodname_copilot_for_prs %} and how to use the feature most effectively, see \"AUTOTITLE.\"\n\n\n\nCreating a summary for a pull request\n\n1. On {% data variables.product.prodname_dotcom_the_website %}, create a pull request or navigate to an existing pull request.\n\n   {% note %}\n\n   **Note:** {% data variables.product.prodname_copilot %} does not take into account any existing content in the pull request description, so it is best to start with a blank description.\n\n   {% endnote %}\n\n1. Navigate to the text field where you want to add the pull request summary.\n\n   - If you're creating a new pull request, use the \"Add a description\" field.\n   - If you're adding a description to an existing pull request, edit the opening comment.\n   - If you're adding a summary as a comment, navigate to the \"Add a comment\" section at the bottom of the pull request page.\n\n1. In the header of the text field, select {% octicon \"copilot\" aria-label=\"Copilot actions\" %}, then click **Summary**.\n\n   !Screenshot of the form for creating a pull request. In the header of the \"Description\" field, a Copilot icon is highlighted in orange, and a box appears with the \"Summary\" command.\n\n1. Wait for {% dat", "Y2h1bmtfMV9pbmRleF8xMTI3": "a variables.product.prodname_copilot %} to produce the summary, then check over the results carefully.\n1. Add any additional context that will help people viewing your pull request.\n1. When you're happy with the description, click **Create pull request** on a new pull request, or **Update comment** if you're editing an existing description.\n\n", "Y2h1bmtfMF9pbmRleF8yMDEx": "\n\nAbout searching for discussions\n\nYou can search for discussions globally across all of {% data variables.product.product_name %}, or search for discussions within a particular organization or repository. For more information, see \"AUTOTITLE.\"\n\n{% data reusables.search.syntax_tips %}\n\n\n\nSearch by the title, body, or comments\n\nWith the `in` qualifier you can restrict your search for discussions to the title, body, or comments. You can also combine qualifiers to search a combination of title, body, or comments. When you omit the `in` qualifier, {% data variables.product.product_name %} searches the title, body, and comments.\n\n| Qualifier | Example |\n| :- | :- |\n| `in:title` | **welcome in:title** matches discussions with \"welcome\" in the title. |\n| `in:body` | **onboard in:title,body** matches discussions with \"onboard\" in the title or body. |\n| `in:comments` | **thanks in:comments** matches discussions with \"thanks\" in the comments for the discussion. |\n\n\n\nSearch within a user's or organization's repositories\n\nTo search discussions in all repositories owned by a certain user or organization, you can use the  `user` or `org` qualifier. To search discussions in a specific repository, you can use the `repo` qualifier.\n\n| Qualifier | Example |\n| :- | :- |\n| user:USERNAME | **user:octocat feedback** matches discussions with the word \"feedback\" from repositories owned by @octocat. |\n| org:ORGNAME | **org:github** matches discussions in repositories owned by the GitHub organization. |\n| repo:USERNAME/REPOSITORY | **repo:nodejs/node created:<2021-01-01** matches discussions from @nodejs' Node.js runtime project that were created before January 2021. |\n\n\n\nSearch by open or closed state\n\nYou can filter discussions based on whether they're open or closed using the `is` qualifier.\n\n| Qualifier        | Example\n| ------------- | -------------\n| `is:open` | **performance is:open is:discussion** matches open discussions with the word \"performance.\"\n| `is:closed` | **android is:closed** matches closed discussions with the word \"", "Y2h1bmtfMV9pbmRleF8yMDEx": "android.\"\n\n\n\nSearch based on whether a discussion was answered\n\nYou can search for a discussion that has been answered using the `is` qualifier.\n\n| Qualifier        | Example\n| ------------- | -------------\n| `is:answered` | **performance is:answered is:discussion** matches answered discussions with the word \"performance.\"\n| `is:unanswered` | **android is:unanswered** matches unanswered discussions with the word \"android.\"\n\n\n\nSearch based on whether a discussion is locked\n\nYou can search for a discussion that has been locked using the `is` qualifier. For more information, see \"AUTOTITLE.\"\n\n| Qualifier        | Example\n| ------------- | -------------\n| `is:locked` | **\"code of conduct\" is:locked is:discussion** matches discussions with the words \"code of conduct\" that have been locked.\n| `is:unlocked` | **code of conduct is:unlocked is:discussion** matches discussions with the words \"code of conduct\" that are unlocked.\n\n\n\nFilter by repository visibility\n\nYou can filter by the visibility of the repository containing the discussions using the `is` qualifier. For more information, see \"AUTOTITLE.\"\n\n| Qualifier  | Example\n| :- | :- |{% ifversion fpt or ghes or ghec %}\n| `is:public` | **is:public** matches discussions in public repositories.{% endif %}{% ifversion ghec %}\n| `is:internal` | **is:internal** matches discussions in internal repositories.{% endif %}\n| `is:private` | **is:private tiramisu** matches discussions that contain the word \"tiramisu\" in private repositories you can access.\n\n\n\nSearch by author\n\nThe `author` qualifier finds discussions created by a certain user.\n\n| Qualifier | Example |\n| :- | :- |\n| author:USERNAME | **cool author:octocat** matches discussions with the word \"cool\" that were created by @octocat. |\n| `in:body` author:USERNAME | **bootstrap in:body author:octocat** matches discussions created by @octocat that contain the word \"bootstrap\" in the body. |\n\n\n\nSearch by commenter\n\nThe `commenter` qualifier finds discussions that contain a comment from a certain user.\n\n| Qualifier | Example |", "Y2h1bmtfMl9pbmRleF8yMDEx": "\n| :- | :- |\n| commenter:USERNAME | **github commenter:becca org:github** matches discussions in repositories owned by GitHub, that contain the word \"github,\" and have a comment by @becca.\n\n\n\nSearch by user who has answered a discussion\n\nThe `answered-by` qualifier finds discussions where a certain user's comment was marked as an answer.\n\n| Qualifier | Example |\n| :- | :- |\n| answered-by:USERNAME | **cool answered-by:octocat** matches discussions with the word \"cool\" that were answered by @octocat. |\n\n\n\nSearch by a user that's involved in a discussion\n\nYou can use the `involves` qualifier to find discussions that involve a certain user. The qualifier returns discussions that were either created by a certain user, mention the user, or contain comments by the user. The `involves` qualifier is a logical OR between the `author`, `mentions`, and `commenter` qualifiers for a single user.\n\n| Qualifier | Example |\n| :- | :- |\n| involves:USERNAME | **involves:becca involves:octocat** matches discussions either @becca or @octocat are involved in.\n| `in:body` involves:USERNAME | **NOT beta in:body involves:becca** matches discussions @becca is involved in that do not contain the word \"beta\" in the body.\n\n\n\nSearch by number of comments\n\nYou can use the `comments` qualifier along with greater than, less than, and range qualifiers to search by the number of comments. For more information, see \"AUTOTITLE.\"\n\n| Qualifier | Example |\n| :- | :- |\n| comments:n | **comments:&gt;100** matches discussions with more than 100 comments.\n| comments:n | **comments:500..1000** matches discussions with comments ranging from 500 to 1,000.\n\n\n\nSearch by when a discussion was created or last updated\n\nYou can filter discussions based on times of creation, or when the discussion was last updated. For discussion creation, you can use the `created` qualifier; to find out when an discussion was last updated, use the `updated` qualifier.\n\nBoth qualifiers take a date as a parameter. {% data reusables.time_date.date_format %} {% data reusables.time_date.", "Y2h1bmtfM19pbmRleF8yMDEx": "time_format %}\n\n{% data reusables.search.date_gt_lt %}\n\n| Qualifier | Example |\n| :- | :- |\n| created:YYYY-MM-DD | **created:>2020-11-15** matches discussions that were created after November 15, 2020.\n| updated:YYYY-MM-DD | **weird in:body updated:>=2020-02-01** matches discussions with the word \"weird\" in the body that were updated after December 2020.\n\n\n\nSearch by category\n\nYou can filter discussions by specific discussions categories.  \n\n| Qualifier | Example |\n| :- | :- |\n| category:CATEGORYNAME | **category:Ideas** matches discussions categories that match the name \"Ideas\".\n\n\n\nSearch by label\n\nYou can filter discussions by specific labels that are applied to discussions.  \n\n| Qualifier | Example |\n| :- | :- |\n| label: \"LABEL NAME\" | **label:\"Product Feedback\"** matches discussions that match the label \"Product Feedback\".\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF82Njg=": "\n\nDowngrading an app for your personal account\n\n{% data reusables.user-settings.access_settings %}\n{% data reusables.user-settings.billing_plans %}\n{% data reusables.marketplace.downgrade-app-billing-settings %}\n{% data reusables.marketplace.choose-new-plan %}\n{% data reusables.marketplace.choose-new-quantity %}\n{% data reusables.marketplace.issue-plan-changes %}\n\n\n\nDowngrading an app for your organization\n\n{% data reusables.marketplace.marketplace-org-perms %}\n\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n{% data reusables.organizations.billing_plans %}\n{% data reusables.marketplace.downgrade-app-billing-settings %}\n{% data reusables.marketplace.choose-new-plan %}\n{% data reusables.marketplace.choose-new-quantity %}\n{% data reusables.marketplace.issue-plan-changes %}\n\n\n\nDowngrading an app in your enterprise\n\n{% data reusables.marketplace.marketplace-enterprise-account %}\n\n{% data reusables.enterprise-accounts.access-enterprise %}\n{% data reusables.enterprise-accounts.billing-tab %}\n1. In the \"Marketplace apps\" tab, find the app you want to downgrade.\n1. Next to the organization where you want to downgrade the app, select **{% octicon \"kebab-horizontal\" aria-label=\"More\" %}** and then click **Change plan**.\n1. Select the **Edit your plan** dropdown and click an account's plan to edit.\n{% data reusables.marketplace.choose-new-plan %}\n{% data reusables.marketplace.choose-new-quantity %}\n{% data reusables.marketplace.issue-plan-changes %}\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF82MDE=": "---\ntitle: Preventing unauthorized access\nintro: 'You may be alerted to a security incident in the media, such as the discovery of the Heartbleed bug, or your computer could be stolen while you''re signed in to {% data variables.location.product_location %}. In such cases, changing your password prevents any unintended future access to your account and projects.'\nredirect_from:\n  - /articles/preventing-unauthorized-access\n  - /github/authenticating-to-github/preventing-unauthorized-access\n  - /github/authenticating-to-github/keeping-your-account-and-data-secure/preventing-unauthorized-access\nversions:\n  fpt: '*'\n  ghes: '*'\n  ghec: '*'\ntopics:\n  - Identity\n  - Access management\nshortTitle: Unauthorized access\n---\n{% data variables.product.product_name %} requires a password to perform sensitive actions, such as adding new SSH keys, authorizing applications, or modifying team members.\n\nAfter changing your password, you should perform these actions to make sure that your account is secure:\n\n- Enable two-factor authentication on your account so that access requires more than just a password. For more information, see \"AUTOTITLE.\"\n{%- ifversion passkeys %}\n- Add a passkey to your account to enable a secure, passwordless login. Passkeys are phishing-resistant, and they don't require memorization or active management. For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"{% endif %}\n- Review your SSH keys, deploy keys, and authorized integrations and revoke unauthorized or unfamiliar access in your SSH and Applications settings. For more information, see \"AUTOTITLE,\" \"AUTOTITLE,\" and \"AUTOTITLE.\"\n{% ifversion fpt or ghec %}\n- Verify all your email addresses. If an attacker added their email address to your account, it could allow them to force an unintended password reset. For more information, see \"AUTOTITLE.\"\n{% endif %}\n- Review your account's security log. This provides an overview on various configurations made to your repositories. For example, you can ensure that no private repositories were turned public, or th", "Y2h1bmtfMV9pbmRleF82MDE=": "at no repositories were transferred. For more information, see \"AUTOTITLE.\"\n- Review the webhooks on your repositories. Webhooks could allow an attacker to intercept pushes made to your repository. For more information, see \"AUTOTITLE.\"\n- Make sure that no new deploy keys were created. This could enable outside servers access to your projects. For more information, see \"AUTOTITLE.\"\n- Review recent commits made to your repositories.\n- Review the list of collaborators for each repository.\n\n", "Y2h1bmtfMF9pbmRleF85MDU=": "\n\nAbout generic secret detection for {% data variables.product.prodname_secret_scanning %}\n\nGeneric secret detection is an AI-powered expansion of {% data variables.product.prodname_secret_scanning %} that identifies unstructured secrets (passwords) in your source code and then generates an alert.\n\n{% data variables.product.prodname_GH_advanced_security %} users can already receive {% data variables.secret-scanning.alerts %} for partner or custom patterns found in their source code, but unstructured secrets are not easily discoverable. AI-powered generic secret detection uses large language models (LLMs) to identify this type of secret.\n\nWhen a password is detected, an alert is displayed in the list of {% data variables.product.prodname_secret_scanning %} alerts (under the **Security** tab of the repository, organization, or enterprise), so that maintainers and security managers can review the alert and, where necessary, remove the credential or implement a fix.\n\nIn order to use generic secret detection, the enterprise owner sets a policy at the enterprise level. The feature must then be enabled for repositories. For more information, see \"AUTOTITLE.\"\n\n\n\nInput processing\n\nInput is limited to text (typically code) that a user has checked into a repository. The system provides this text to the LLM along with a meta prompt asking the LLM to find passwords within the scope of the input. The user does not interact with the LLM directly.\n\nThe system scans for passwords using the LLM. No additional data is collected by the system, other than what is already collected by the existing {% data variables.product.prodname_secret_scanning %} feature.\n\n\n\nOutput and display\n\nThe LLM scans for strings that resemble passwords and verifies that the identified strings included in the response actually exist in the input.\n\nThese detected strings are surfaced as alerts on the {% data variables.product.prodname_secret_scanning %} alerts page, but they are displayed in an additional list that is separate from regular {% data variables.", "Y2h1bmtfMV9pbmRleF85MDU=": "secret-scanning.alerts %}. The intent is that this separate list is triaged with more scrutiny to verify the validity of the findings. Each alert notes that it was detected using AI. {% ifversion secret-scanning-ai-generic-secret-detection %}For information on how to view alerts for generic secrets, see \"AUTOTITLE.\"{% endif %}\n\n\n\nImproving the performance of generic secret detection\n\nTo improve the performance of generic secret detection, we recommend closing false positive alerts appropriately and providing feedback when you encounter issues.\n\n\n\nVerify the accuracy of alerts and close as appropriate\n\nSince AI-powered generic secret detection may generate more false positives than the existing {% data variables.product.prodname_secret_scanning %} feature for partner patterns, it's important that you review the accuracy of these alerts. When you verify an alert to be a false positive, be sure to close the alert and mark the reason as \"False positive\" in the {% data variables.product.prodname_dotcom %} UI. The {% data variables.product.prodname_dotcom %} development team will use this information to improve the model.\n\n\n\nProvide feedback\n\nGeneric secret detection is currently in beta. If you encounter any issues or limitations with the feature, we recommend that you provide feedback through the **Give feedback** button listed under each detected secret in the list of alerts for the repository, organization, or enterprise. This can help the developers improve the tool and address any concerns or limitations.\n\n\n\nLimitations of generic secret detection\n\nWhen using generic secret detection for {% data variables.product.prodname_secret_scanning %}, you should consider the following limitations.\n\n\n\nLimited scope\n\nAI-powered generic secret detection currently only looks for instances of passwords in git content. The feature does not look for other types of generic secrets, and it does not look for secrets in non-git content, such as {% data variables.product.prodname_github_issues %}.\n\n\n\nPotential for false positive alert", "Y2h1bmtfMl9pbmRleF85MDU=": "s\n\nAI-powered generic secret detection may generate more false positive alerts when compared to the existing {% data variables.product.prodname_secret_scanning %} feature (which detects partner patterns, and which has a very low false positive rate). To mitigate this excess noise, alerts are grouped in a separate list from partner pattern alerts, and security managers and maintainers should triage each alert to verify its accuracy.\n\n\n\nPotential for incomplete reporting\n\nAI-powered generic secret detection may miss instances of credentials checked into a repository. The LLM will improve over time. You retain ultimate responsibility for ensuring the security of your code.\n\n\n\nEvaluation of generic secret detection\n\nGeneric secret detection has been subject to Responsible AI Red Teaming and {% data variables.product.prodname_dotcom %} will continue to monitor the efficacy and safety of the feature over time.\n\n{% ifversion secret-scanning-ai-generic-secret-detection %}\n\n\n\nNext steps\n\n- AUTOTITLE\n- AUTOTITLE\n\n{% endif %}\n\n\n\nFurther reading\n\n- AUTOTITLE\n\n", "Y2h1bmtfMF9pbmRleF8xMzY2": "\n\nAutomation options\n\n| Column preset | Configuration options |\n| --- | --- |\n| To do | Move all newly added issues hereMove all newly added pull requests hereMove all reopened issues hereMove all reopened pull requests here |\n| In progress | Move all newly opened pull requests hereMove all reopened issues hereMove all reopened pull requests hereMove all pull requests that meet the base branch's minimum number of required reviews hereMove all pull requests that no longer meet the base branch's minimum number of required reviews here |\n| Done | Move all closed issues hereMove all merged pull requests hereMove all closed, unmerged pull requests here |\n\n\n\nProject progress tracking\n\nYou can track the progress on your {% data variables.projects.projects_v1_board %}. Cards in the \"To do\", \"In progress\", or \"Done\" columns count toward the overall project progress. {% data reusables.project-management.project-progress-locations %}\n\nFor more information, see \"AUTOTITLE.\"\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"{% ifversion fpt or ghec %}\n- \"AUTOTITLE\"{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF8xMzUw": "\n\nNode limit\n\nTo pass schema validation, all GraphQL API calls must meet these standards:\n\n- Clients must supply a `first` or `last` argument on any connection.\n- Values of `first` and `last` must be within 1-100.\n- Individual calls cannot request more than 500,000 total nodes.\n\n\n\nCalculating nodes in a call\n\nThese two examples show how to calculate the total nodes in a call.\n\n1. Simple query:\n\n   query {\n     viewer {\n       repositories(first: 50) {\n         edges {\n           repository:node {\n             name\n\n             issues(first: 10) {\n               totalCount\n               edges {\n                 node {\n                   title\n                   bodyHTML\n                 }\n               }\n             }\n           }\n         }\n       }\n     }\n   }\n\n   Calculation:\n\n   50         = 50 repositories\n    +\n   50 x 10  = 500 repository issues\n\n               = 550 total nodes\n\n1. Complex query:\n\n   query {\n     viewer {\n       repositories(first: 50) {\n         edges {\n           repository:node {\n             name\n\n             pullRequests(first: 20) {\n               edges {\n                 pullRequest:node {\n                   title\n\n                   comments(first: 10) {\n                     edges {\n                       comment:node {\n                         bodyHTML\n                       }\n                     }\n                   }\n                 }\n               }\n             }\n\n             issues(first: 20) {\n               totalCount\n               edges {\n                 issue:node {\n                   title\n                   bodyHTML\n\n                   comments(first: 10) {\n                     edges {\n                       comment:node {\n                         bodyHTML\n                       }\n                     }\n                   }\n                 }\n               }\n             }\n           }\n         }\n       }\n\n       followers(first: 10) {\n         edges {\n           follower:node {\n             login\n           }\n         }\n       }\n     }\n   }\n\n   Calculation:", "Y2h1bmtfMV9pbmRleF8xMzUw": "\n\n   50              = 50 repositories\n    +\n   50 x 20       = 1,000 pullRequests\n    +\n   50 x 20 x 10 = 10,000 pullRequest comments\n    +\n   50 x 20       = 1,000 issues\n    +\n   50 x 20 x 10 = 10,000 issue comments\n    +\n   10              = 10 followers\n\n                    = 22,060 total nodes\n\n\n\nPrimary rate limit\n\n{% ifversion ghes %}\n\nRate limits are disabled by default for {% data variables.product.product_name %}. Contact your site administrator to confirm the rate limits for your instance.\n\nIf you are a site administrator, you can set rate limits for your instance. For more information, see \"AUTOTITLE.\"\n\nIf you are developing an app for users or organizations outside of your instance, the standard {% data variables.product.prodname_dotcom_the_website %} rate limits apply. For more information, see \"AUTOTITLE\" in the {% data variables.product.prodname_free_user %} documentation.\n\n{% else %}\n\nThe GraphQL API assigns points to each query and limits the points that you can use within a specific amount of time. This limit helps prevent abuse and denial-of-service attacks, and ensures that the API remains available for all users.\n\nThe REST API also has a separate primary rate limit. For more information, see \"AUTOTITLE.\"\n\nIn general, you can calculate your primary rate limit for the GraphQL API based on your method of authentication:\n\n- _For users_: 5,000 points per hour per user. This includes requests made with a {% data variables.product.pat_generic %} as well as requests made by a {% data variables.product.prodname_github_app %} or {% data variables.product.prodname_oauth_app %} on behalf of a user that authorized the app. Requests made on a user's behalf by a {% data variables.product.prodname_github_app %} that is owned by a {% data variables.product.prodname_ghe_cloud %} organization have a higher rate limit of 10,000 points per hour. Similarly, requests made on your behalf by an {% data variables.product.prodname_oauth_app %} that is owned or approved by a {% data variables.product.prodname_ghe_clou", "Y2h1bmtfMl9pbmRleF8xMzUw": "d %} organization have a higher rate limit of 10,000 points per hour if you are a member of the {% data variables.product.prodname_ghe_cloud %} organization.\n- _For {% data variables.product.prodname_github_app %} installations not on a {% data variables.product.prodname_ghe_cloud %} organization_: 5,000 points per hour per installation. Installations that have more than 20 repositories receive another 50 points per hour for each repository. Installations that are on an organization that have more than 20 users receive another 50 points per hour for each user. The rate limit cannot increase beyond 12,500 points per hour. The rate limit for user access tokens (as opposed to installation access tokens) are dictated by the primary rate limit for users.\n- _For {% data variables.product.prodname_github_app %} installations on a {% data variables.product.prodname_ghe_cloud %} organization_: 10,000 points per hour per installation. The rate limit for user access tokens (as opposed to installation access tokens) are dictated by the primary rate limit for users.\n- _For {% data variables.product.prodname_oauth_apps %}_: 5,000 points per hour, or 10,000 points per hour if the app is owned by a {% data variables.product.prodname_ghe_cloud %} organization. This only applies when the app uses their client ID and client secret to request public data. The rate limit for OAuth access tokens generated by a {% data variables.product.prodname_oauth_app %} are dictated by the primary rate limit for users.\n- _For `GITHUB_TOKEN` in {% data variables.product.prodname_actions %} workflows_: 1,000 points per hour per repository. For requests to resources that belong to an enterprise account on GitHub.com, the limit is 15,000 points per hour per repository.\n\nYou can check the point value of a query or calculate the expected point value as described in the following sections. The formula for calculating points and the rate limit are subject to change.\n\n\n\nChecking the status of your primary rate limit\n\nYou can use the headers that are sent w", "Y2h1bmtfM19pbmRleF8xMzUw": "ith each response to determine the current status of your primary rate limit.\n\nHeader name | Description\n-----------|-----------|\n`x-ratelimit-limit` | The maximum number of points that you can use per hour\n`x-ratelimit-remaining` | The number of points remaining in the current rate limit window\n`x-ratelimit-used` | The number of points you have used in the current rate limit window\n`x-ratelimit-reset` | The time at which the current rate limit window resets, in UTC epoch seconds\n`x-ratelimit-resource` | The rate limit resource that the request counted against. For GraphQL requests, this will always be `graphql`.\n\nYou can also query the `rateLimit` object to check your rate limit. When possible, you should use the rate limit response headers instead of querying the API to check your rate limit.\n\n```graphql\nquery {\n  viewer {\n    login\n  }\n  rateLimit {\n    limit\n    remaining\n    used\n    resetAt\n  }\n}\n```\n\nField | Description\n-----------|-----------|\n`limit` | The maximum number of points that you can use per hour\n`remaining` | The number of points remaining in the current rate limit window\n`used` | The number of points you have used in the current rate limit window\n`resetAt` | The time at which the current rate limit window resets, in UTC epoch seconds\n\n\n\nReturning the point value of a query\n\nYou can return the point value of a query by querying the `cost` field on the `rateLimit` object:\n\n```graphql\nquery {\n  viewer {\n    login\n  }\n  rateLimit {\n    cost\n  }\n}\n```\n\n\n\nPredicting the point value of a query\n\nYou can also roughly calculate the point value of a query before you make the query.\n\n1. Add up the number of requests needed to fulfill each unique connection in the call. Assume every request will reach the `first` or `last` argument limits.\n1. Divide the number by **100** and round the result to the nearest whole number to get the final aggregate point value. This step normalizes large numbers.\n\n{% note %}\n\n**Note**: The minimum point value of a call to the GraphQL API is **1**.\n\n{% endnote %}\n\nHere's an e", "Y2h1bmtfNF9pbmRleF8xMzUw": "xample query and score calculation:\n\n```graphql\nquery {\n  viewer {\n    login\n    repositories(first: 100) {\n      edges {\n        node {\n          id\n\n          issues(first: 50) {\n            edges {\n              node {\n                id\n\n                labels(first: 60) {\n                  edges {\n                    node {\n                      id\n                      name\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\nThis query requires 5,101 requests to fulfill:\n\n- Although we're returning 100 repositories, the API has to connect to the viewer's account **once** to get the list of repositories. So, requests for repositories = **1**\n- Although we're returning 50 issues, the API has to connect to each of the **100** repositories to get the list of issues. So, requests for issues = **100**\n- Although we're returning 60 labels, the API has to connect to each of the **5,000** potential total issues to get the list of labels. So, requests for labels = **5,000**\n- Total = **5,101**\n\nDividing by 100 and rounding gives us the final score of the query: **51**\n\n\n\nSecondary rate limits\n\n{% data reusables.rest-api.secondary-rate-limit-rest-graphql %}\n\n\n\nExceeding the rate limit\n\nIf you exceed your primary rate limit, the response status will still be `200`, but you will receive an error message, and the value of the `x-ratelimit-remaining` header will be `0`. You should not retry your request until after the time specified by the `x-ratelimit-reset` header.\n\nIf you exceed a secondary rate limit, the response status will be `200` or `403`, and you will receive an error message that indicates that you hit a secondary rate limit. If the `retry-after` response header is present, you should not retry your request until after that many seconds has elapsed. If the `x-ratelimit-remaining` header is `0`, you should not retry your request until after the time, in UTC epoch seconds, specified by the `x-ratelimit-reset` header. Otherwise, ", "Y2h1bmtfNV9pbmRleF8xMzUw": "wait for at least one minute before retrying. If your request continues to fail due to a secondary rate limit, wait for an exponentially increasing amount of time between retries, and throw an error after a specific number of retries.\n\nContinuing to make requests while you are rate limited may result in the banning of your integration.\n\n\n\nStaying under the rate limit\n\nTo avoid exceeding a rate limit, you should pause at least 1 second between mutative requests and avoid concurrent requests.\n\nYou should also subscribe to webhook events instead of polling the API for data. For more information, see \"AUTOTITLE.\"\n\n{% ifversion audit-log-streaming %}\n\nYou can also stream the audit log in order to view API requests. This can help you troubleshoot integrations that are exceeding the rate limit. For more information, see \"AUTOTITLE.\"\n\n{% endif %}\n\n{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF8xMzY4": "---\ntitle: 'Changing {% data variables.product.prodname_project_v1 %} visibility'\nintro: 'As an organization owner or {% data variables.projects.projects_v1_board %} admin, you can make a {% data variables.projects.projects_v1_board %} {% ifversion ghae %}internal{% else %}public{% endif %} or private.'\nredirect_from:\n  - /github/managing-your-work-on-github/managing-project-boards/changing-project-board-visibility\n  - /articles/changing-project-board-visibility\n  - /github/managing-your-work-on-github/changing-project-board-visibility\nversions:\n  feature: projects-v1\ntopics:\n  - Pull requests\nshortTitle: Change visibility\nallowTitleToDifferFromFilename: true\n---\n{% data reusables.projects.project_boards_old %}\n\n{% data reusables.project-management.project-board-visibility %}\n\n{% note %}\n\n**{% ifversion classic-project-visibility-permissions %}Notes{% else %}Note{% endif %}:** {% ifversion classic-project-visibility-permissions %}\n\n- {% data reusables.projects.owners-can-limit-visibility-permissions %}\n- {% endif %}When you make your {% data variables.projects.projects_v1_board %} {% ifversion ghae %}internal{% else %}public{% endif %}, organization members are given read access by default. You can give specific organization members write or admin permissions by giving access to teams they're on or by adding them to the {% data variables.projects.projects_v1_board %} as a collaborator. For more information, see \"AUTOTITLE.\"\n\n{% endnote %}\n\n1. Navigate to the project board you want to make {% ifversion ghae %}internal{% else %}public{% endif %} or private.\n{% data reusables.project-management.click-menu %}\n{% data reusables.project-management.access-collaboration-settings %}\n{% data reusables.project-management.choose-visibility %}\n1. Click **Save**.\n\n", "Y2h1bmtfMF9pbmRleF8xMTg=": "\n\nUsing repository-level self-hosted runners\n\nYou may not be able to create a self-hosted runner for an organization-owned repository.\n\n{% data reusables.actions.disable-selfhosted-runners-crossrefs %}\n\n{% endif %}\n\n\n\nChecking the status of a self-hosted runner\n\n{% data reusables.actions.self-hosted-runner-management-permissions-required %}\n\n{% data reusables.actions.self-hosted-runner-navigate-repo-and-org %}\n{% data reusables.organizations.settings-sidebar-actions-runners %}\n1. Under \"Runners\", you can view a list of registered runners, including the runner's name, labels, and status.\n\n    The status can be one of the following:\n\n    - **Idle**: The runner is connected to {% data variables.product.product_name %} and is ready to execute jobs.\n    - **Active**: The runner is currently executing a job.\n    - **Offline**: The runner is not connected to {% data variables.product.product_name %}. This could be because the machine is offline, the self-hosted runner application is not running on the machine, or the self-hosted runner application cannot communicate with {% data variables.product.product_name %}.\n\n\n\nTroubleshooting network connectivity\n\n\n\nChecking self-hosted runner network connectivity\n\nYou can use the self-hosted runner application's `run` script with the `--check` parameter to check that a self-hosted runner can access all required network services on {% data variables.location.product_location %}.\n\nIn addition to `--check`, you must provide two arguments to the script:\n\n- `--url` with the URL to your {% data variables.product.company_short %} repository, organization, or enterprise. For example, `--url https://github.com/octo-org/octo-repo`.\n- `--pat` with the value of a {% data variables.product.pat_v1 %}, which must have the `workflow` scope{% ifversion pat-v2%}, or a {% data variables.product.pat_v2 %} with workflows read and write access {% endif %}. For example, `--pat ghp_abcd1234`. For more information, see \"AUTOTITLE.\"\n\nFor example:\n\n{% mac %}\n\n{% data reusables.actions.self-hosted-runner-ch", "Y2h1bmtfMV9pbmRleF8xMTg=": "eck-mac-linux %}\n\n{% endmac %}\n{% linux %}\n\n{% data reusables.actions.self-hosted-runner-check-mac-linux %}\n\n{% endlinux %}\n{% windows %}\n\n```shell\nrun.cmd --check --url https://github.com/YOUR-ORG/YOUR-REPO --pat GHP_ABCD1234\n```\n\n{% endwindows %}\n\nThe script tests each service, and outputs either a `PASS` or `FAIL` for each one. If you have any failing checks, you can see more details on the problem in the log file for the check. The log files are located in the `_diag` directory where you installed the runner application, and the path of the log file for each check is shown in the console output of the script.\n\nIf you have any failing checks, you should also verify that your self-hosted runner machine meets all the communication requirements. For more information, see \"AUTOTITLE.\"\n\n\n\nDisabling TLS certificate verification\n\n{% ifversion ghes %}\nBy default, the self-hosted runner application verifies the TLS certificate for {% data variables.product.product_name %}.  If your {% data variables.product.product_name %} has a self-signed or internally-issued certificate, you may wish to disable TLS certificate verification for testing purposes.\n{% else %}\nBy default, the self-hosted runner application verifies the TLS certificate for {% data variables.product.product_name %}.  If you encounter network problems, you may wish to disable TLS certificate verification for testing purposes.\n{% endif %}\n\nTo disable TLS certification verification in the self-hosted runner application, set the `GITHUB_ACTIONS_RUNNER_TLS_NO_VERIFY` environment variable to `1` before configuring and running the self-hosted runner application.\n\n{% linux %}\n\n```shell\nexport GITHUB_ACTIONS_RUNNER_TLS_NO_VERIFY=1\n./config.sh --url https://github.com/YOUR-ORG/YOUR-REPO --token\n./run.sh\n```\n\n{% endlinux %}\n{% mac %}\n\n```shell\nexport GITHUB_ACTIONS_RUNNER_TLS_NO_VERIFY=1\n./config.sh --url https://github.com/YOUR-ORG/YOUR-REPO --token\n./run.sh\n```\n\n{% endmac %}\n{% windows %}\n\n```powershell\n[Environment]::SetEnvironmentVariable('GITHUB_ACTIONS_RUNNER_T", "Y2h1bmtfMl9pbmRleF8xMTg=": "LS_NO_VERIFY', '1')\n./config.cmd --url https://github.com/YOUR-ORG/YOUR-REPO --token\n./run.sh\n```\n\n{% endwindows %}\n\n{% warning %}\n\n**Warning**: Disabling TLS verification is not recommended since TLS provides privacy and data integrity between the self-hosted runner application and {% data variables.product.product_name %}. We recommend that you install the {% data variables.product.product_name %} certificate in the operating system certificate store for your self-hosted runner. For guidance on how to install the {% data variables.product.product_name %} certificate, check with your operating system vendor.\n\n{% endwarning %}\n\n\n\nReviewing the self-hosted runner application log files\n\nYou can monitor the status of the self-hosted runner application and its activities. Log files are kept in the `_diag` directory where you installed the runner application, and a new log is generated each time the application is started. The filename begins with `Runner_`, and is followed by a UTC timestamp of when the application was started.\n\nFor detailed logs on workflow job executions, see the next section describing the `Worker_` files.\n\n\n\nReviewing a job's log file\n\nThe self-hosted runner application creates a detailed log file for each job that it processes. These files are stored in the `_diag` directory where you installed the runner application, and the filename begins with `Worker_`.\n\n{% linux %}\n\n\n\nUsing journalctl to check the self-hosted runner application service\n\nFor Linux-based self-hosted runners running the application using a service, you can use `journalctl` to monitor their real-time activity. The default systemd-based service uses the following naming convention: `actions.runner.-..service`. This name is truncated if it exceeds 80 characters, so the preferred way of finding the service's name is by checking the _.service_ file. For example:\n\n```shell\n$ cat ~/actions-runner/.service\nactions.runner.octo-org-octo-repo.runner01.service\n```\n\nIf this fails due to the service being installed elsewhere, you can find t", "Y2h1bmtfM19pbmRleF8xMTg=": "he service name in the list of running services. For example, on most Linux systems you can use the `systemctl` command:\n\n```shell\n$ systemctl --type=service | grep actions.runner\nactions.runner.octo-org-octo-repo.hostname.service loaded active running GitHub Actions Runner (octo-org-octo-repo.hostname)\n```\n\nYou can use `journalctl` to monitor the real-time activity of the self-hosted runner:\n\n```shell\nsudo journalctl -u actions.runner.octo-org-octo-repo.runner01.service -f\n```\n\nIn this example output, you can see `runner01` start, receive a job named `testAction`, and then display the resulting status:\n\n```shell\nFeb 11 14:57:07 runner01 runsvc.sh[962]: Starting Runner listener with startup type: service\nFeb 11 14:57:07 runner01 runsvc.sh[962]: Started listener process\nFeb 11 14:57:07 runner01 runsvc.sh[962]: Started running service\nFeb 11 14:57:16 runner01 runsvc.sh[962]: \u221a Connected to GitHub\nFeb 11 14:57:17 runner01 runsvc.sh[962]: 2020-02-11 14:57:17Z: Listening for Jobs\nFeb 11 16:06:54 runner01 runsvc.sh[962]: 2020-02-11 16:06:54Z: Running job: testAction\nFeb 11 16:07:10 runner01 runsvc.sh[962]: 2020-02-11 16:07:10Z: Job testAction completed with result: Succeeded\n```\n\nTo view the `systemd` configuration, you can locate the service file here: `/etc/systemd/system/actions.runner.-..service`.\nIf you want to customize the self-hosted runner application service, do not directly modify this file. Follow the instructions described in \"AUTOTITLE.\"\n\n{% endlinux %}\n\n{% mac %}\n\n\n\nUsing `launchd` to check the self-hosted runner application service\n\nFor macOS-based self-hosted runners running the application as a service, you can use `launchctl` to monitor their real-time activity. The default launchd-based service uses the following naming convention: `actions.runner.-.`. This name is truncated if it exceeds 80 characters, so the preferred way of finding the service's name is by checking the _.service_ file in the runner directory:\n\n```shell\n% cat ~/actions-runner/.service\n/Users/exampleUsername/Library/LaunchAgents/ac", "Y2h1bmtfNF9pbmRleF8xMTg=": "tions.runner.octo-org-octo-repo.runner01.plist\n```\n\nThe `svc.sh` script uses `launchctl` to check whether the application is running. For example:\n\n```shell\n$ ./svc.sh status\nstatus actions.runner.example.runner01:\n/Users/exampleUsername/Library/LaunchAgents/actions.runner.example.runner01.plist\nStarted:\n379 0 actions.runner.example.runner01\n```\n\nThe resulting output includes the process ID and the name of the application\u2019s `launchd` service.\n\nTo view the `launchd` configuration, you can locate the service file here: `/Users/exampleUsername/Library/LaunchAgents/actions.runner...service`.\nIf you want to customize the self-hosted runner application service, do not directly modify this file. Follow the instructions described in \"AUTOTITLE.\"\n\n{% endmac %}\n\n{% windows %}\n\n\n\nUsing PowerShell to check the self-hosted runner application service\n\nFor Windows-based self-hosted runners running the application as a service, you can use PowerShell to monitor their real-time activity. The service uses the naming convention `GitHub Actions Runner (-.)`. You can also find the service's name by checking the _.service_ file in the runner directory:\n\n```shell\nPS C:\\actions-runner> Get-Content .service\nactions.runner.octo-org-octo-repo.runner01.service\n```\n\nYou can view the status of the runner in the Windows _Services_ application (`services.msc`). You can also use PowerShell to check whether the service is running:\n\n```shell\nPS C:\\actions-runner> Get-Service \"actions.runner.octo-org-octo-repo.runner01.service\" | Select-Object Name, Status\nName                                                  Status\n----                                                  ------\nactions.runner.octo-org-octo-repo.runner01.service    Running\n```\n\nYou can use PowerShell to check the recent activity of the self-hosted runner. In this example output, you can see the application start, receive a job named `testAction`, and then display the resulting status:\n\n```shell\nPS C:\\actions-runner> Get-EventLog -LogName Application -Source ActionsRunnerService\n\n   In", "Y2h1bmtfNV9pbmRleF8xMTg=": "dex Time          EntryType   Source                 InstanceID Message\n   ----- ----          ---------   ------                 ---------- -------\n     136 Mar 17 13:45  Information ActionsRunnerService          100 2020-03-17 13:45:48Z: Job Greeting completed with result: Succeeded\n     135 Mar 17 13:45  Information ActionsRunnerService          100 2020-03-17 13:45:34Z: Running job: testAction\n     134 Mar 17 13:41  Information ActionsRunnerService          100 2020-03-17 13:41:54Z: Listening for Jobs\n     133 Mar 17 13:41  Information ActionsRunnerService          100 \u00fb Connected to GitHub\n     132 Mar 17 13:41  Information ActionsRunnerService            0 Service started successfully.\n     131 Mar 17 13:41  Information ActionsRunnerService          100 Starting Actions Runner listener\n     130 Mar 17 13:41  Information ActionsRunnerService          100 Starting Actions Runner Service\n     129 Mar 17 13:41  Information ActionsRunnerService          100 create event log trace source for actions-runner service\n```\n\n{% endwindows %}\n\n\n\nMonitoring the automatic update process\n\nWe recommend that you regularly check the automatic update process, as the self-hosted runner will not be able to process jobs if it falls below a certain version threshold. The self-hosted runner application automatically updates itself, but note that this process does not include any updates to the operating system or other software; you will need to separately manage these updates.\n\nYou can view the update activities in the `Runner_` log files. For example:\n\n```shell\n[Feb 12 12:37:07 INFO SelfUpdater] An update is available.\n```\n\nIn addition, you can find more information in the _SelfUpdate_ log files located in the `_diag` directory where you installed the runner application.\n\n{% linux %}\n\n\n\nTroubleshooting containers in self-hosted runners\n\n\n\nChecking that Docker is installed\n\nIf your jobs require containers, then the self-hosted runner must be Linux-based and needs to have Docker installed. Check that your self-hosted runner has Doc", "Y2h1bmtfNl9pbmRleF8xMTg=": "ker installed and that the service is running.\n\nYou can use `systemctl` to check the service status:\n\n```shell\n$ sudo systemctl is-active docker.service\nactive\n```\n\nIf Docker is not installed, then dependent actions will fail with the following errors:\n\n```shell\n[2020-02-13 16:56:10Z INFO DockerCommandManager] Which: 'docker'\n[2020-02-13 16:56:10Z INFO DockerCommandManager] Not found.\n[2020-02-13 16:56:10Z ERR  StepsRunner] Caught exception from step: System.IO.FileNotFoundException: File not found: 'docker'\n```\n\n\n\nChecking the Docker permissions\n\nIf your job fails with the following error:\n\n```shell\ndial unix /var/run/docker.sock: connect: permission denied\n```\n\nCheck that the self-hosted runner's service account has permission to use the Docker service. You can identify this account by checking the configuration of the self-hosted runner in `systemd`. For example:\n\n```shell\n$ sudo systemctl show -p User actions.runner.octo-org-octo-repo.runner01.service\nUser=runner-user\n```\n\n{% endlinux %}\n\n{% ifversion ghes %}\n\n\n\nResolving runners that are offline after an upgrade of {% data variables.location.product_location %}\n\n{% data reusables.actions.upgrade-runners-before-upgrade-ghes %}\n\nIf your runners are offline for this reason, manually update the runners. For more information, see the installation instructions for the latest release in the actions/runner repository.\n{% endif %}\n\n\n\nChecking which Docker engine is installed on the runner\n\nIf your build fails with the following error:\n\n```shell\nError: Input required and not supplied: java-version\n```\n\nCheck which Docker engine is installed on your self-hosted runner. To pass the inputs of an action into the Docker container, the runner uses environment variables that might contain dashes as part of their names. The action may not able to get the inputs if the Docker engine is not a binary executable, but is instead a shell wrapper or a link (for example, a Docker engine installed on Linux using `snap`). To address this error, configure your self-hosted runner to use ", "Y2h1bmtfN19pbmRleF8xMTg=": "a different Docker engine.\n\nTo check if your Docker engine was installed using `snap`, use the `which` command. In the following example, the Docker engine was installed using `snap`:\n\n```shell\n$ which docker\n/snap/bin/docker\n```\n\n", "Y2h1bmtfMF9pbmRleF81NzI=": "\n\nAbout {% data variables.product.prodname_marketplace %}\n\nThis article applies to installing and purchasing {% data variables.product.prodname_github_apps %} from {% data variables.product.prodname_marketplace %}. For more information on installing {% data variables.product.prodname_github_apps %} from a source other than {% data variables.product.prodname_marketplace %}, see \"AUTOTITLE.\"\n\nIf you install a {% data variables.product.prodname_github_app %} on your organization account and you choose a paid plan, you will pay for your app subscription on your organization's current billing date using your organization's existing payment method.\n\n{% data reusables.marketplace.free-trials %}\n\nFor more information about installing an {% data variables.product.prodname_oauth_app %} instead of a {% data variables.product.prodname_github_app %} from {% data variables.product.prodname_marketplace %}, see \"AUTOTITLE.\"\n\n\n\nAbout installing {% data variables.product.prodname_github_apps %}\n\n{% data reusables.apps.about-installation %}\n\n\n\nDifference between installation and authorization\n\nAfter you install a {% data variables.product.prodname_github_app %}, you may also be asked to authorize the app.\n\n{% data reusables.apps.install-vs-authorize %}\n\nFor more information about authorizing {% data variables.product.prodname_github_apps %}, see \"AUTOTITLE.\"\n\n\n\nRequirements to install a {% data variables.product.prodname_github_app %} on an organization\n\nOrganization owners can install {% data variables.product.prodname_github_apps %} on their organization.\n\nFor enterprises that pay by credit card, enterprise owners who are also organization owners can install {% data variables.product.prodname_github_apps %} on organizations within their enterprise.\n\nAdmins of repositories that are owned by an organization can also install {% data variables.product.prodname_github_apps %} on the organization if they only grant the app access to repositories that they are an admin of and if the app does not request any organization resources. Organ", "Y2h1bmtfMV9pbmRleF81NzI=": "ization owners can prevent outside collaborators who are repository admins from installing {% data variables.product.prodname_github_apps %}.\n\nThe \"app manager\" role in an organization does not give a person the ability to install a {% data variables.product.prodname_github_app %} in the organization. For more information, see \"AUTOTITLE.\"\n\n\n\nInstalling a {% data variables.product.prodname_github_app %} in your organization\n\n{% data reusables.marketplace.visit-marketplace %}\n{% data reusables.marketplace.browse-to-app %}\n{% data reusables.marketplace.choose-plan %}\n{% data reusables.marketplace.install-buy %}\n{% data reusables.marketplace.confirm-install-account-org %}\n{% data reusables.marketplace.add-payment-method-org %}\n{% data reusables.marketplace.complete-order-begin-installation %}\n1. If the app requires access to repositories, select **All repositories** or **Only select repositories**.\n\n   If the app creates any repositories, the app will automatically be granted access to those repositories as well.\n{% data reusables.marketplace.select-installation-repos %}\n{% data reusables.marketplace.review-app-perms-install %}\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8xNjky": "\n\nAbout pull request comments\n\nYou can comment on a pull request's **Conversation** tab to leave general comments, questions, or props. You can also suggest changes that the author of the pull request can apply directly from your comment.\n\nYou can also comment on specific {% ifversion pull-request-comment-on-file %}files or {% endif %}sections of a file in a pull request's **Files changed** tab in the form of individual line {% ifversion pull-request-comment-on-file %}or file {% endif %}comments, or as part of a pull request review. Adding line {% ifversion pull-request-comment-on-file %}or file {% endif %}comments is a great way to discuss questions about implementation or provide feedback to the author. For more information about pull request reviews, see \"AUTOTITLE.\"\n\nFor more information on adding line {% ifversion pull-request-comment-on-file %}or file {% endif %}comments to a pull request review, see \"AUTOTITLE.\"\n\n{% note %}\n\n**Note:** If you reply to a pull request via email, your comment will be added on the **Conversation** tab and will not be part of a pull request review.\n\n{% endnote %}\n\nTo reply to an existing line {% ifversion pull-request-comment-on-file %}or file {% endif %}comment, you'll need to navigate to the comment on either the **Conversation** tab or **Files changed** tab and add an additional comment below it.\n\n{% tip %}\n\n**Tips:**\n- Pull request comments support the same formatting as regular comments on {% data variables.product.product_name %}, such as @mentions, emoji, and references.\n- You can add reactions to comments in pull requests in the **Files changed** tab.\n\n{% endtip %}\n\n\n\nAdding comments to a pull request\n\n{% data reusables.repositories.sidebar-pr %}\n1. In the list of pull requests, click the pull request where you'd like to leave line comments.\n{% data reusables.repositories.changed-files %}\n{% data reusables.repositories.start-line-comment %}\n{% data reusables.repositories.type-line-comment %}\n{% data reusables.repositories.suggest-changes %}\n{% ifversion pull-request-comm", "Y2h1bmtfMV9pbmRleF8xNjky": "ent-on-file %}\n{% data reusables.repositories.start-file-comment %}{% endif %}\n1. When you're done, click **Add single comment**.\n\nAnyone watching the pull request or repository will receive a notification of your comment.\n\n{% data reusables.pull_requests.resolving-conversations %}\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n{% ifversion fpt or ghec %}- \"AUTOTITLE\"\n{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF8xNDU=": "\n\nAbout workflow runs from private forks\n\n{% data reusables.actions.private-repository-forks-overview %} For more information, see \"AUTOTITLE.\"\n\n\n\nApproving workflow runs on a pull request from a private fork\n\n{% data reusables.actions.workflows.approve-workflow-runs %}\n\n", "Y2h1bmtfMF9pbmRleF8xMzY0": "\n\nIntroduction\n\nThis guide demonstrates how to use tasklists to split up a larger piece of work into multiple tasklists and multiple subtasks. You will learn how to create a tasklist using the UI, how to create a tasklist using Markdown, how to make changes to a tasklist, and how to integrate your new tasklists with a project.\n\nTo help demonstrate how tasklists can be used to divide work into smaller subtasks, this guide will follow a scenario where we need to create a landing page for a new feature. Feel free to follow this guide but incorporate your own scenario.\n\n\n\nPrerequisites\n\nAs you follow this guide, you will create several issues in a repository. You will need a repository that you are able to create issues in.\n\n\n\nCreating an issue to track the work of adding a new landing page\n\nIn this step, we will create the parent issue to track the subtasks required to publish the new landing page.\n\n1. Navigate to the repository where you want to track the work.\n1. Create a new blank issue with the title \"Tracking issue for landing page.\" For more information, see \"AUTOTITLE.\"\n\n\n\nCreating the first tasklist\n\nTasklists are added to the opening comment of an issue (the issue description). Issues can contain multiple tasklists with different titles. This is a great way to categorize your subtasks.\n\n1. Go to the issue you just created. If you have not already done so, press **Submit new issue**.\n1. At the bottom of the issue description, click {% octicon \"plus\" aria-hidden=\"true\" %} **Add tasklist**.\n  \n  !Screenshot an issue. The \"Add tasklist\" button is highlighted with an orange outline.\n  \nThis will insert an empty tasklist into your issue.\n\n\n\nAdding draft tasks\n\nDraft tasks are text items that are added to your tasklist. Draft tasks appear in your tasklist with a checkbox. You can use draft tasks to quickly sketch out the requirements and subtasks for your project and, optionally, later convert them into issues.\n\n1. If the text field is not already focused, click **Add item to Tasks**.\n  \n   !Screenshot of a taskli", "Y2h1bmtfMV9pbmRleF8xMzY0": "st. The \"Add item to Tasks\" field is highlighted with an orange rectangle.\n  \n1. Add some draft tasks to sketch out this work. Type your draft task and then press Enter after each one.\n\n   For our example landing page scenario, you can add:\n   - \"Design new landing page\"\n   - \"Create content for landing page\"\n   - \"Translate content into supported languages\"\n\n\n\nConverting a draft task into an issue\n\nYou can convert your draft tasks into issues. You can convert draft tasks when you're ready to start work on a particular task. The issues are created in the same repository you have used for your tracking issue.\n\n1. Next to the \"Design new landing page\" draft task, click {% octicon \"kebab-horizontal\" aria-label=\"tracking block item menu\" %}.\n  \n   !Screenshot of a tasklist. To the right of a draft task, the tracking block item menu is outlined in orange.\n  \n1. In the menu, click **Convert to issue**.\n\n\n\nAssigning yourself to the new issue\n\nYou can now assign yourself to the new issue without leaving your tasklist.\n\n1. Next to the \"Design new landing page\" issue in your tasklist, click {% octicon \"kebab-horizontal\" aria-label=\"tracking block item menu\" %}.\n\n   !Screenshot of a tasklist. To the right of a task, the tracking block item menu, which is labeled with a horizontal kebab icon, is outlined in dark orange.\n  \n1. In the context menu, click **Set assignees**.\n1. In the list of people, select yourself.\n\nYou can also use this context menu to set labels and add an issue to a project.\n\n\n\nRenaming a tasklist\n\nYou can change the title of a tasklist to better represent the tasks it is tracking. This is particularly useful when you have multiple tasklists in the same issue and want to segment your tasks.\n\n1. In the top-right of your tasklist, click {% octicon \"kebab-horizontal\" aria-label=\"tracking block item menu\" %}.\n\n   !Screenshot of a tasklist. The tracking block item menu, which is labeled with a horizontal kebab icon, is outlined in dark orange.\n\n1. In the menu, click **Rename**.\n1. Type a new title for your taskl", "Y2h1bmtfMl9pbmRleF8xMzY0": "ist and press Enter.\n\n    For our example landing page scenario, you could rename this tasklist to \"Landing page content.\"\n\n\n\nCreating a second tasklist using Markdown\n\nYou can create multiple tasklists in a single issue. Each tasklist has its own tasks and title. You can add tasklists using the **Add tasklist** button or by entering Markdown when you edit the issue.\n\n1. At the top of the issue description (the opening comment), click {% octicon \"kebab-horizontal\" aria-label=\"Show options\" %}.\n  \n   !Screenshot of an issue containing a tasklist. The \"Show options\" button is highlighted with an orange rectangle.\n  \n1. In the menu, click **Edit**.\n1. In the issue description, below your first tasklist, add the Markdown below:\n  \n   ````markdown copy\n   ```[tasklist]\n   ### Tasks\n   - [ ] Draft task\n   ```\n   ````\n\n1. To change the title of this tasklist, type a new title after `### `. For example, change `### Tasks` to `### Backend changes`.\n\nIn the next two sections, we will make further changes to the Markdown before saving the comment.\n\n\n\nAdding draft tasks using Markdown\n\nYou can quickly add new draft tasks by just typing them directly into your tasklist using Markdown.\n\n1. Add new draft tasks by create a new line after the last task, typing `- [ ] ` and your new task. For example, `- [ ] Sign-up form`.\n1. Edit an existing draft task by modifying the text after `- [ ]`. For example, change `- [ ] Draft task` to `- [ ] Database schema`.\n\n\n\nAdding existing issues using Markdown\n\nYou can also track existing issues by adding them to your tasklist. You can add existing issues using Markdown or in the UI by pasting the issue URL. You can add issues and pull requests from any repository you have access to.\n\n1. Start typing `- [ ] ` on a new line and then paste the full URL of an issue. For example, `- [ ] https://github.com/octo-org/octo-repo/issues/45`\n1. Click **Update comment**.\n  \n  !Screenshot of an issue being edited. There are two tasklists present and the \"Update comment\" button is highlighted with an orange r", "Y2h1bmtfM19pbmRleF8xMzY0": "ectangle.\n  \nYou will see your new second tasklist displayed beneath your first tasklist.\n\n\n\nTracking progress\n\nTasklists help you quickly see the status and progress of the tasks you have chosen to track.\n\n1. To the left of one of your draft tasks, select the checkbox to mark that task as done.\n1. Click on the issue that you previously converted from a draft.\n1. In the converted issue, at the bottom of the page, click **Close issue**.\n\nWhen you return to your tasklist and refresh the page, you can see that the issue you just closed now has an icon indicating that is closed. At the top of the issue, below the title, the progress is indicated as \"2 of 6 tasks.\"\n\n  !Screenshot of an issue containing two tasklists. One issue is closed and one draft task is marked as completed. The progress information is highlighted with an orange rectangle.\n\n\n\nIntegrate with a project\n\nThe relationships you build in your tasklists are available in your projects. You can quickly see the progress made in each issue, browse through the subtasks, and setup views that use your tasklists.\n\n1. Navigate to a project that's owned by the same user or organization account that you have used for your tasklist and issues. If you don't have a project available, you can create one. For more information, see \"AUTOTITLE.\"\n1. Create a new view in your project using the table layout. For more information on views, see \"AUTOTITLE.\"\n1. Add one of the issues from your tasklists to your project. For more information on adding items to projects, see \"AUTOTITLE.\"\n{% data reusables.projects.open-view-menu %}\n1. In the menu, click **Group by** and then select **Tracked by**. This creates a view where your issues are grouped by the issue that is tracking them.\n\nIssues and pull requests are not automatically added to a project when they are added to a tasklist. When you group a view by the \"Tracked by\" field, {% data variables.product.product_name %} will prompt you add other issues associated with the tasklist.\n\n1. If there are issues in your tasklists that a", "Y2h1bmtfNF9pbmRleF8xMzY0": "re not part of your project, you can click **1 item not in this project** below the group.\n  \n  !Screenshot of a project in the table layout. At the bottom of a group, \"1 item not in this project\" is highlighted with an orange rectangle.\n  \n1. In the list of issues, click on the issue you want to add. If you have multiple issues, you can choose to add all of them.\n\n\n\nConclusion\n\nAfter following this guide, you have created a tracking issue with two tasklists, made changes to those tasklists in the UI and directly with Markdown, converted a draft task into an issue, and integrated your tasklist data with a project.\n\nTo learn more about managing the items in your tasklist, see \"AUTOTITLE.\" For more information on integrating tasklists with your projects, see \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF8xMzI=": "\n\nAbout expressions\n\nYou can use expressions to programmatically set environment variables in workflow files and access contexts. An expression can be any combination of literal values, references to a context, or functions. You can combine literals, context references, and functions using operators. For more information about contexts, see \"AUTOTITLE.\"\n\nExpressions are commonly used with the conditional `if` keyword in a workflow file to determine whether a step should run. When an `if` conditional is `true`, the step will run.\n\n{% data reusables.actions.expressions-syntax-evaluation %}\n\n{% raw %}\n`${{  }}`\n{% endraw %}\n\n{% note %}\n\n**Note**: The exception to this rule is when you are using expressions in an `if` clause, where, optionally, you can usually omit {% raw %}`${{`{% endraw %} and {% raw %}`}}`{% endraw %}. For more information about `if` conditionals, see \"AUTOTITLE.\"\n\n{% endnote %}\n\n{% data reusables.actions.context-injection-warning %}\n\n\n\nExample setting an environment variable\n\n{% raw %}\n\n```yaml\nenv:\n  MY_ENV_VAR: ${{  }}\n```\n\n{% endraw %}\n\n\n\nLiterals\n\nAs part of an expression, you can use `boolean`, `null`, `number`, or `string` data types.\n\n| Data type | Literal value |\n|-----------|---------------|\n| `boolean` | `true` or `false` |\n| `null`    | `null` |\n| `number`  | Any number format supported by JSON. |\n| `string`  | You don't need to enclose strings in `{% raw %}${{{% endraw %}` and `{% raw %}}}{% endraw %}`. However, if you do, you must use single quotes (`'`) around the string. To use a literal single quote, escape the literal single quote using an additional single quote (`''`). Wrapping with double quotes (`\"`) will throw an error. |\n\n\n\nExample of literals\n\n{% raw %}\n\n```yaml\nenv:\n  myNull: ${{ null }}\n  myBoolean: ${{ false }}\n  myIntegerNumber: ${{ 711 }}\n  myFloatNumber: ${{ -9.2 }}\n  myHexNumber: ${{ 0xff }}\n  myExponentialNumber: ${{ -2.99e-2 }}\n  myString: Mona the Octocat\n  myStringInBraces: ${{ 'It''s open source!' }}\n```\n\n{% endraw %}\n\n\n\nOperators\n\n| Operator    | Description |", "Y2h1bmtfMV9pbmRleF8xMzI=": "\n| ---         | ---         |\n| `( )`       | Logical grouping |\n| `[ ]`       | Index |\n| `.`         | Property de-reference |\n| `!`         | Not |\n| `<`         | Less than |\n| `<=`        | Less than or equal |\n| `>`         | Greater than |\n| `>=`        | Greater than or equal |\n| `==`        | Equal |\n| `!=`        | Not equal |\n| `&&`        | And |\n|  \\|\\| | Or |\n\n  {% note %}\n\n  **Notes:**\n  - {% data variables.product.company_short %} ignores case when comparing strings.\n  - `steps..outputs.` evaluates as a string. {% data reusables.actions.expressions-syntax-evaluation %} For more information, see \"AUTOTITLE.\"\n  - For numerical comparison, the `fromJSON()` function can be used to convert a string to a number. For more information on the `fromJSON()` function, see \"fromJSON.\"\n\n  {% endnote %}\n\n{% data variables.product.prodname_dotcom %} performs loose equality comparisons.\n\n- If the types do not match, {% data variables.product.prodname_dotcom %} coerces the type to a number. {% data variables.product.prodname_dotcom %} casts data types to a number using these conversions:\n\n  | Type    | Result |\n  | ---     | ---    |\n  | Null    | `0` |\n  | Boolean | `true` returns `1`  `false` returns `0` |\n  | String  | Parsed from any legal JSON number format, otherwise `NaN`.  Note: empty string returns `0`. |\n  | Array   | `NaN` |\n  | Object  | `NaN` |\n- A comparison of one `NaN` to another `NaN` does not result in `true`. For more information, see the \"NaN Mozilla docs.\"\n- {% data variables.product.prodname_dotcom %} ignores case when comparing strings.\n- Objects and arrays are only considered equal when they are the same instance.\n\n{% data variables.product.prodname_dotcom %} offers ternary operator like behaviour that you can use in expressions. By using a ternary operator in this way, you can dynamically set the value of an environment variable based on a condition, without having to write separate if-else blocks for each possible option.\n\n\n\nExample\n\n{% raw %}\n\n```yaml\nenv:\n  MY_ENV_VAR: ${{ github.ref ==", "Y2h1bmtfMl9pbmRleF8xMzI=": " 'refs/heads/main' && 'value_for_main_branch' || 'value_for_other_branches' }}\n```\n\n{% endraw %}\n\nIn this example, we're using a ternary operator to set the value of the `MY_ENV_VAR` environment variable based on whether the {% data variables.product.prodname_dotcom %} reference is set to `refs/heads/main` or not. If it is, the variable is set to `value_for_main_branch`. Otherwise, it is set to `value_for_other_branches`.\nIt is important to note that the first value after the `&&` condition must be `truthy` otherwise the value after the `||` will always be returned.\n\n\n\nFunctions\n\n{% data variables.product.prodname_dotcom %} offers a set of built-in functions that you can use in expressions. Some functions cast values to a string to perform comparisons. {% data variables.product.prodname_dotcom %} casts data types to a string using these conversions:\n\n| Type    | Result |\n| ---     | ---    |\n| Null    | `''` |\n| Boolean | `'true'` or `'false'` |\n| Number  | Decimal format, exponential for large numbers |\n| Array   | Arrays are not converted to a string |\n| Object  | Objects are not converted to a string |\n\n\n\ncontains\n\n`contains( search, item )`\n\nReturns `true` if `search` contains `item`. If `search` is an array, this function returns `true` if the `item` is an element in the array. If `search` is a string, this function returns `true` if the `item` is a substring of `search`. This function is not case sensitive. Casts values to a string.\n\n\n\nExample using a string\n\n`contains('Hello world', 'llo')` returns `true`.\n\n\n\nExample using an object filter\n\n`contains(github.event.issue.labels.*.name, 'bug')` returns `true` if the issue related to the event has a label \"bug\".\n\nFor more information, see \"Object filters.\"\n\n\n\nExample matching an array of strings\n\nInstead of writing `github.event_name == \"push\" || github.event_name == \"pull_request\"`, you can use `contains()` with `fromJSON()` to check if an array of strings contains an `item`.\n\nFor example, `contains(fromJSON('[\"push\", \"pull_request\"]'), github.event_name)` re", "Y2h1bmtfM19pbmRleF8xMzI=": "turns `true` if `github.event_name` is \"push\" or \"pull_request\".\n\n\n\nstartsWith\n\n`startsWith( searchString, searchValue )`\n\nReturns `true` when `searchString` starts with `searchValue`. This function is not case sensitive. Casts values to a string.\n\n\n\nExample of `startsWith`\n\n`startsWith('Hello world', 'He')` returns `true`.\n\n\n\nendsWith\n\n`endsWith( searchString, searchValue )`\n\nReturns `true` if `searchString` ends with `searchValue`. This function is not case sensitive. Casts values to a string.\n\n\n\nExample of `endsWith`\n\n`endsWith('Hello world', 'ld')` returns `true`.\n\n\n\nformat\n\n`format( string, replaceValue0, replaceValue1, ..., replaceValueN)`\n\nReplaces values in the `string`, with the variable `replaceValueN`. Variables in the `string` are specified using the `{N}` syntax, where `N` is an integer. You must specify at least one `replaceValue` and `string`. There is no maximum for the number of variables (`replaceValueN`) you can use. Escape curly braces using double braces.\n\n\n\nExample of `format`\n\n{% raw %}\n\n```javascript\nformat('Hello {0} {1} {2}', 'Mona', 'the', 'Octocat')\n```\n\n{% endraw %}\n\nReturns 'Hello Mona the Octocat'.\n\n\n\nExample escaping braces\n\n{% raw %}\n\n```javascript\nformat('{{Hello {0} {1} {2}!}}', 'Mona', 'the', 'Octocat')\n```\n\n{% endraw %}\n\nReturns '{Hello Mona the Octocat!}'.\n\n\n\njoin\n\n`join( array, optionalSeparator )`\n\nThe value for `array` can be an array or a string. All values in `array` are concatenated into a string. If you provide `optionalSeparator`, it is inserted between the concatenated values. Otherwise, the default separator `,` is used. Casts values to a string.\n\n\n\nExample of `join`\n\n`join(github.event.issue.labels.*.name, ', ')` may return 'bug, help wanted'\n\n\n\ntoJSON\n\n`toJSON(value)`\n\nReturns a pretty-print JSON representation of `value`. You can use this function to debug the information provided in contexts.\n\n\n\nExample of `toJSON`\n\n`toJSON(job)` might return `{ \"status\": \"success\" }`\n\n\n\nfromJSON\n\n`fromJSON(value)`\n\nReturns a JSON object or JSON data type for `value`. You can us", "Y2h1bmtfNF9pbmRleF8xMzI=": "e this function to provide a JSON object as an evaluated expression or to convert environment variables from a string.\n\n\n\nExample returning a JSON object\n\nThis workflow sets a JSON matrix in one job, and passes it to the next job using an output and `fromJSON`.\n\n{% raw %}\n\n```yaml\nname: build\non: push\njobs:\n  job1:\n    runs-on: ubuntu-latest\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n    steps:\n      - id: set-matrix{% endraw %}\n{%- ifversion actions-save-state-set-output-envs %}\n        run: echo \"matrix={\\\"include\\\":[{\\\"project\\\":\\\"foo\\\",\\\"config\\\":\\\"Debug\\\"},{\\\"project\\\":\\\"bar\\\",\\\"config\\\":\\\"Release\\\"}]}\" >> $GITHUB_OUTPUT\n{%- else %}\n        run: echo \"::set-output name=matrix::{\\\"include\\\":[{\\\"project\\\":\\\"foo\\\",\\\"config\\\":\\\"Debug\\\"},{\\\"project\\\":\\\"bar\\\",\\\"config\\\":\\\"Release\\\"}]}\"\n{%- endif %}{% raw %}\n  job2:\n    needs: job1\n    runs-on: ubuntu-latest\n    strategy:\n      matrix: ${{ fromJSON(needs.job1.outputs.matrix) }}\n    steps:\n      - run: build\n```\n\n{% endraw %}\n\n\n\nExample returning a JSON data type\n\nThis workflow uses `fromJSON` to convert environment variables from a string to a Boolean or integer.\n\n{% raw %}\n\n```yaml\nname: print\non: push\nenv:\n  continue: true\n  time: 3\njobs:\n  job1:\n    runs-on: ubuntu-latest\n    steps:\n      - continue-on-error: ${{ fromJSON(env.continue) }}\n        timeout-minutes: ${{ fromJSON(env.time) }}\n        run: echo ...\n```\n\n{% endraw %}\n\n\n\nhashFiles\n\n`hashFiles(path)`\n\nReturns a single hash for the set of files that matches the `path` pattern. You can provide a single `path` pattern or multiple `path` patterns separated by commas. The `path` is relative to the `GITHUB_WORKSPACE` directory and can only include files inside of the `GITHUB_WORKSPACE`. This function calculates an individual SHA-256 hash for each matched file, and then uses those hashes to calculate a final SHA-256 hash for the set of files. If the `path` pattern does not match any files, this returns an empty string. For more information about SHA-256, see \"SHA-2.\"\n\nYou can use pattern", "Y2h1bmtfNV9pbmRleF8xMzI=": " matching characters to match file names. Pattern matching for `hashFiles` follows glob pattern matching and is case-insensitive on Windows. For more information about supported pattern matching characters, see the Patterns section in the `@actions/glob` documentation.\n\n\n\nExample with a single pattern\n\nMatches any `package-lock.json` file in the repository.\n\n`hashFiles('**/package-lock.json')`\n\n\n\nExample with multiple patterns\n\nCreates a hash for any `package-lock.json` and `Gemfile.lock` files in the repository.\n\n`hashFiles('**/package-lock.json', '**/Gemfile.lock')`\n\n\n\nStatus check functions\n\nYou can use the following status check functions as expressions in `if` conditionals. A default status check of `success()` is applied unless you include one of these functions. For more information about `if` conditionals, see \"AUTOTITLE\" and \"AUTOTITLE\".\n\n\n\nsuccess\n\nReturns `true` when all previous steps have succeeded.\n\n\n\nExample of `success`\n\n```yaml\nsteps:\n  ...\n  - name: The job has succeeded\n    if: {% raw %}${{ success() }}{% endraw %}\n```\n\n\n\nalways\n\nCauses the step to always execute, and returns `true`, even when canceled. The `always` expression is best used at the step level or on tasks that you expect to run even when a job is canceled. For example, you can use `always` to send logs even when a job is canceled.\n\n{% warning %}\n\n**Warning:** Avoid using `always` for any task that could suffer from a critical failure, for example: getting sources, otherwise the workflow may hang until it times out. If you want to run a job or step regardless of its success or failure, use the recommended alternative: `if: {% raw %}${{ !cancelled() }}{% endraw %}`\n\n{% endwarning %}\n\n\n\nExample of `always`\n\n```yaml\nif: {% raw %}${{ always() }}{% endraw %}\n```\n\n\n\ncancelled\n\nReturns `true` if the workflow was canceled.\n\n\n\nExample of `cancelled`\n\n```yaml\nif: {% raw %}${{ cancelled() }}{% endraw %}\n```\n\n\n\nfailure\n\nReturns `true` when any previous step of a job fails. If you have a chain of dependent jobs, `failure()` returns `true` if an", "Y2h1bmtfNl9pbmRleF8xMzI=": "y ancestor job fails.\n\n\n\nExample of `failure`\n\n```yaml\nsteps:\n  ...\n  - name: The job has failed\n    if: {% raw %}${{ failure() }}{% endraw %}\n```\n\n\n\nfailure with conditions\n\nYou can include extra conditions for a step to run after a failure, but you must still include `failure()` to override the default status check of `success()` that is automatically applied to `if` conditions that don't contain a status check function.\n\n\n\nExample of `failure` with conditions\n\n```yaml\nsteps:\n  ...\n  - name: Failing step\n    id: demo\n    run: exit 1\n  - name: The demo step has failed\n    if: {% raw %}${{ failure() && steps.demo.conclusion == 'failure' }}{% endraw %}\n```\n\n\n\nObject filters\n\nYou can use the `*` syntax to apply a filter and select matching items in a collection.\n\nFor example, consider an array of objects named `fruits`.\n\n```json\n[\n  { \"name\": \"apple\", \"quantity\": 1 },\n  { \"name\": \"orange\", \"quantity\": 2 },\n  { \"name\": \"pear\", \"quantity\": 1 }\n]\n```\n\nThe filter `fruits.*.name` returns the array `[ \"apple\", \"orange\", \"pear\" ]`.\n\nYou may also use the `*` syntax on an object. For example, suppose you have an object named `vegetables`.\n\n```json\n\n{\n  \"scallions\":\n  {\n    \"colors\": [\"green\", \"white\", \"red\"],\n    \"ediblePortions\": [\"roots\", \"stalks\"],\n  },\n  \"beets\":\n  {\n    \"colors\": [\"purple\", \"red\", \"gold\", \"white\", \"pink\"],\n    \"ediblePortions\": [\"roots\", \"stems\", \"leaves\"],\n  },\n  \"artichokes\":\n  {\n    \"colors\": [\"green\", \"purple\", \"red\", \"black\"],\n    \"ediblePortions\": [\"hearts\", \"stems\", \"leaves\"],\n  },\n}\n```\n\nThe filter `vegetables.*.ediblePortions` could evaluate to:\n\n```json\n\n[\n  [\"roots\", \"stalks\"],\n  [\"hearts\", \"stems\", \"leaves\"],\n  [\"roots\", \"stems\", \"leaves\"],\n]\n```\n\nSince objects don't preserve order, the order of the output cannot be guaranteed.\n\n", "Y2h1bmtfMF9pbmRleF8xMDk1": "\n\nAbout the structure of an article\n\nWithin an article, there is a standard order of content sections. Every article contains required elements. Articles will also contain conditional elements and optional elements outlined in content design or creation. See the guidelines below for more details.\n\n!Screenshot of article with title, intro, permissions, product callout, conceptual section, procedural section, and table of contents labeled.\n\n\n\nTitles\n\nTitles fully describe what a page is about, and what someone will learn by reading it.\n\nTitles can be challenging. Use these general guidelines to help create clear, helpful, and descriptive titles. The guidelines for each content type in this article provide more specific title rules.\n\n\n\nTitles for all content types\n\n- Titles clearly describe what a page is about. They are descriptive and specific.\n  - Use: \"Browsing actions in the workflow editor\"\n  - Use: \"Example of configuring a codespace\"\n  - Avoid: \"Using the workflow editor sidebar\"\n  - Avoid: \"Example\"\n- Titles have hard limits for length to keep them easy to understand (and easier to render on the site):\n  - Category titles: 67 characters and `shortTitle` 26 characters\n  - Map topic titles: 63 characters and `shortTitle` 29 characters\n  - Article titles: 80 characters, 60 if possible, and `shortTitle` 30 characters, ideally 20-25 characters\n- Titles use sentence case.\n  - Use: \"Changing a commit message\"\n  - Avoid: \"Changing A Commit Message\"\n- Titles are consistent across a content type. See specific guidelines for each content type.\n- Titles are general enough to scale with product changes, reflect all of the content within the article, or include content on multiple products.\n  - Use: \"{% data variables.product.company_short %}'s billing plans\"\n  - Avoid: \"Billing plans for user and organization accounts\"\n- Titles use consistent terminology.\n  - Develop and follow patterns within a category or on similar subjects.\n- Titles use terminology from the product itself.\n- Write the title and the intro at the same", "Y2h1bmtfMV9pbmRleF8xMDk1": " time.\n  - Use the intro to develop the ideas presented in the title.\n  - See guidance on intros for more information.\n- If it's hard to come up with a title, consider the content type. Sometimes trouble choosing a title indicates that another content type would fit better.\n- Think about how the title will appear in search results for multiple products.\n  - What specific words do we need to include in the title or intro so that folks don\u2019t mistake it for content about a different product?\n- Think about how the title will look in production.\n\n\n\nProduct callout\n\nUse the product callout when a feature is available in specific products only and that availability cannot be conveyed by versioning alone. For example, if a feature is available for GHEC and GHES, you can version content about the feature for GHEC and GHES only. If a feature is available for Pro, Team, GHEC, and GHES (but not Free), use a product callout to convey that availability.\n\nAll product callouts are stored as reusables in `gated-features` and added in YAML frontmatter for relevant articles.\n\n\n\nHow to write a product callout\n\n- Product callouts follow a strict format, clearly identifying the feature and which products it\u2019s available in.\n- Product callouts also include a link to \"GitHub\u2019s products\u201d and occasionally to another relevant article.\n- Examples:\n  - [Feature name] is available in [product(s)]. For more information, see \"GitHub\u2019s products.\u201d\n  - [Feature name] is available in public repositories with [free product(s)], and in public and private repositories with [paid products]. For more information, see \"GitHub\u2019s products.\u201d\n\n\n\nExamples of articles with product callouts\n\nCheck the source files and `gated-features` to see how source content is written.\n- AUTOTITLE\n\n\n\nIntro\n\nThe top of every page has an intro that provides context and sets expectations, allowing readers to quickly decide if the page is relevant to them. Intros also are displayed in search results to provide contextual information to help readers choose a result.\n\n\n\nHow to writ", "Y2h1bmtfMl9pbmRleF8xMDk1": "e an intro\n\n- Article intros are one to two sentences long.\n- Map topic and category intros are one sentence long.\n- API reference intros are one sentence long.\n  - The intro for an API page should define the feature so that someone knows whether the feature meets their needs without reading the entire article.\n- Intros contain a high-level summary of the page\u2019s content, developing the idea presented in a title with more detail.\n  - Use approachable synonyms of words in the page\u2019s title to help readers understand the article\u2019s purpose differently. Avoid repeating words from the title when possible.\n- Intros are relatively evergreen and high-level, so they can scale with future changes to the content on the page without needing to be frequently updated.\n- For searchability, include keywords on the page's subject in the intro.\n- When a term in the intro has an acronym we\u2019ll use elsewhere in the article, indicate the acronym.\n- Intros generally don't contain permissions for any tasks contained within the article.\n\n\n\nPermissions statements\n\nEvery procedure includes a permissions statement explaining the role required to take the action described in the procedure, which helps people understand whether they'll be able to complete the task.\n\nOccasionally, it's relevant to mention required permissions in conceptual content, especially in standalone conceptual articles. Make sure to also include a permissions statement in related procedures (or write a longer article combining all of the content).\n\n\n\nHow to write a permissions statement\n\n- When a single set of permissions applies to all procedures in an article, use the permissions frontmatter.\n- When an article contains multiple procedures and different permissions apply, include a separate permissions statement under each relevant header, before each procedure.\n- Don't include permissions in an article\u2019s intro.\n- Roles exist at different levels. Refer only to the role at the same level as the action. For example, you need admin access to a repository (repository-level r", "Y2h1bmtfM19pbmRleF8xMDk1": "ole) to configure protected branches. You can get admin access to a repository by being an organization owner (organization-level role), but the repository-level role is what actually governs your ability to take the action, so that is the only role that should be mentioned in the permissions statement.\n- Language to use in a permissions statement:\n  - [ACCOUNT ROLE] can [ACTION].\n  - People with [FEATURE ROLE] access for a [FEATURE] can [ACTION].\n  - AVOID: [ACCOUNT ROLE] and people with [FEATURE ROLE] access for a [FEATURE] can [ACTION].\n\n\n\nExamples of permissions statements\n\n- Article with single permissions statement for multiple procedures: AUTOTITLE\n\n\n\nTool switcher\n\nSome articles have content that varies depending on what tool someone uses to complete a task, such as the {% data variables.product.prodname_cli %} or {% data variables.product.prodname_desktop %}. For most content, the same conceptual or procedural information will be accurate for multiple tools. However, if the only way to make information clear and accurate is by distinguishing content by tool, use the tool switcher. Do not use the tool switcher just to show examples in different languages. Only use the tool switcher if the tasks or concepts change based on what tool someone uses. For more information, see \"AUTOTITLE\".\n\n\n\nTable of contents\n\nTables of contents are automatically generated. For more information see \"Autogenerated mini-TOCs.\"\n\n\n\nConceptual content\n\nConceptual content helps people understand or learn about a topic. For more information, see \"AUTOTITLE\" in the content model.\n\n\n\nReferential content\n\nReferential content provides structured information related to actively using a product or feature. For more information, see \"AUTOTITLE\" in the content model.\n\n\n\nPrerequisites\n\nPrerequisites are information that people need to know before proceeding with a procedure, so that they can prepare everything they need before starting the task.\n\n\n\nHow to write prerequisites\n\n- Write prerequisites immediately before a procedure's numbered ste", "Y2h1bmtfNF9pbmRleF8xMDk1": "ps.\n- You can use a list, a sentence, or a paragraph to explain prerequisites.\n- You can also use a separate prerequisites section when:\n  - The prerequisite information is very important and should not be missed.\n  - There's more than one prerequisite.\n- To repeat or highlight important information about data loss or destructive actions, you may also use a warning or danger callout to share a prerequisite.\n\n\n\nTitle guidelines for prerequisites\n\n- When using a separate section, use a header called `Prerequisites`\n\n\n\nExamples of articles with prerequisites sections\n\n- AUTOTITLE\n- AUTOTITLE\n\n\n\nProcedural content\n\nProcedural content helps people complete tasks. For more information, see \"AUTOTITLE\" in the content model.\n\n\n\nTroubleshooting content\n\nTroubleshooting content helps people avoid or work through errors. For more information, see \"AUTOTITLE\" in the content model.\n\n\n\nFurther reading\n\nFurther reading sections highlight additional targeted articles that aren\u2019t already included within the article\u2019s content or sidebar. Use further reading sections sparingly when they provide real value.\n\n\n\nHow to write a further reading section\n\n- Use a bulleted list.\n- Use further reading sections sparingly and when they provide high value - see style guide for guidelines on linking.\n\n\n\nTitle and format for further reading sections\n\n```markdown\n\n\nFurther reading\n- \"Article title\"\n- External resource title in External Resource Name\n```\n\n", "Y2h1bmtfMF9pbmRleF8xMTc3": "\n\nSite wide shortcuts\n\n| Keyboard shortcut | Description\n|-----------|------------\n|Command+, | Go to Preferences\n|Command+H | Hide the {% data variables.product.prodname_desktop %} application\n|Option+Command+H | Hide all other applications\n|Command+Q | Quit {% data variables.product.prodname_desktop %}\n|Control+Command+F | Toggle full screen view\n|Command+0 | Reset zoom to default text size\n|Command+= | Zoom in for larger text and graphics\n|Command+- | Zoom out for smaller text and graphics\n|Command+8 | Decrease active pane width\n|Command+9 | Increase active pane width\n|Option+Command+I | Toggle Developer Tools\n\n\n\nRepositories\n\n| Keyboard shortcut | Description\n|-----------|------------\n|Command+N | Add a new repository\n|Command+O | Add a local repository\n|Shift+Command+O | Clone a repository from {% data variables.product.prodname_dotcom %}\n|Command+T | Show a list of your repositories\n|Command+P | Push the latest commits to {% data variables.product.prodname_dotcom %}\n|Shift+Command+P | Pull down the latest changes from {% data variables.product.prodname_dotcom %}\n|Command+Delete | Remove an existing repository\n|Shift+Command+G | View the repository on {% data variables.product.prodname_dotcom %}\n|Control+&grave; | Open repository in your preferred terminal tool\n|Shift+Command+F | Show the repository in Finder\n|Shift+Command+A | Open the repository in your preferred editor tool\n|Command+I | Create an issue on {% data variables.product.prodname_dotcom %}\n\n\n\nBranches\n\n| Keyboard shortcut | Description\n|-----------|------------\n|Command+1 | Show all your changes before committing\n|Command+2 | Show your commit history\n|Command+B | Show all your branches\n|Command+G | Go to the commit summary field\n|Command+Enter | Commit changes when summary or description field is active\n|Space| Select or deselect all highlighted files\n|Shift+Command+N | Create a new branch\n|Shift+Command+R | Rename the current branch\n|Shift+Command+D | Delete the current branch\n|Shift+Command+U | Update from default branch\n|Shift+Command+B | Com", "Y2h1bmtfMV9pbmRleF8xMTc3": "pare to an existing branch\n|Shift+Command+M | Merge into current branch\n|Control+H | Show or hide stashed changes\n|Shift+Command+C | Compare branches on {% data variables.product.prodname_dotcom %}\n|Command+R | Show the current pull request on {% data variables.product.prodname_dotcom %}\n\n{% endmac %}\n\n{% windows %}\n\nGitHub Desktop keyboard shortcuts on Windows\n\n\n\nSite wide shortcuts\n\n| Keyboard shortcut | Description\n|-----------|------------\n|Ctrl+, | Go to Options\n|F11 | Toggle full screen view\n|Ctrl+0 | Reset zoom to default text size\n|Ctrl+= | Zoom in for larger text and graphics\n|Ctrl+- | Zoom out for smaller text and graphics\n|Ctrl+8 | Decrease active pane width\n|Ctrl+9 | Increase active pane width\n|Ctrl+Shift+I | Toggle Developer Tools\n\n\n\nRepositories\n\n| Keyboard Shortcut | Description\n|-----------|------------\n|Ctrl+N | Add a new repository\n|Ctrl+O | Add a local repository\n|Ctrl+Shift+O | Clone a repository from {% data variables.product.prodname_dotcom %}\n|Ctrl+T | Show a list of your repositories\n|Ctrl+P | Push the latest commits to {% data variables.product.prodname_dotcom %}\n|Ctrl+Shift+P | Pull down the latest changes from {% data variables.product.prodname_dotcom %}\n|Ctrl+Delete | Remove an existing repository\n|Ctrl+Shift+G | View the repository on {% data variables.product.prodname_dotcom %}\n|Ctrl+&grave; | Open repository in your preferred command line tool\n|Ctrl+Shift+F | Show the repository in Explorer\n|Ctrl+Shift+A | Open the repository in your preferred editor tool\n|Ctrl+I | Create an issue on {% data variables.product.prodname_dotcom %}\n\n\n\nBranches\n\n| Keyboard shortcut | Description\n|-----------|------------\n|Ctrl+1 | Show all your changes before committing\n|Ctrl+2 | Show your commit history\n|Ctrl+B | Show all your branches\n|Ctrl+G | Go to the commit summary field\n|Ctrl+Enter | Commit changes when summary or description field is active\n|Space| Select or deselect all highlighted files\n|Ctrl+Shift+N | Create a new branch\n|Ctrl+Shift+R | Rename the current branch\n|Ctrl+Shift+D | Delete the curr", "Y2h1bmtfMl9pbmRleF8xMTc3": "ent branch\n|Ctrl+Shift+U | Update from default branch\n|Ctrl+Shift+B | Compare to an existing branch\n|Ctrl+Shift+M | Merge into current branch\n|Ctrl+H | Show or hide stashed changes\n|Ctrl+Shift+C | Compare branches on {% data variables.product.prodname_dotcom %}\n|Ctrl+R | Show the current pull request on {% data variables.product.prodname_dotcom %}\n\n{% endwindows %}\n\n", "Y2h1bmtfMF9pbmRleF8xODc4": "---\ntitle: Deployment statuses\nintro: Use the REST API to manage deployment statuses.\nversions: # DO NOT MANUALLY EDIT. CHANGES WILL BE OVERWRITTEN BY A \ud83e\udd16\n  fpt: '*'\n  ghae: '*'\n  ghec: '*'\n  ghes: '*'\ntopics:\n  - API\nallowTitleToDifferFromFilename: true\nautogenerated: rest\n---\n\n\n\n\n\n", "Y2h1bmtfMF9pbmRleF8xMjM1": "\n\nAbout the assignment overview page\n\nEach assignment you create on {% data variables.product.prodname_classroom %} has an assignment overview page. The assignment overview page provides an overview of your assignment acceptances and student progress. You may see different summary information on an assignment overview page based on the configurations of your assignments.\n\nFor individual assignments, you can view the following information at the top of the assignment overview page:\n\n- **Rostered students**: The number of students on the classroom's roster.\n- **Added students**: The number of {% data variables.product.prodname_dotcom %} accounts that have accepted the assignment and are not associated with a roster identifier.\n- **Accepted students**: The number of accounts that have accepted this assignment.\n- **Assignment submissions**: The number of students that have submitted the assignment. Submission is triggered at the assignment deadline.\n- **Passing students**: The number of students currently passing the autograding tests for this assignment.\n\nFor group assignments, you can view the following information at the top of the assignment overview page:\n\n- **Total teams**: The number of teams that have been created.\n- **Rostered students**: The number of students on the classroom's roster.\n- **Students not on a team**: The number of students on the classroom roster who have not yet joined a team.\n- **Accepted teams**: The number of teams who have accepted this assignment.\n- **Assignment submissions**: The number of teams that have submitted the assignment. Submission is triggered at the assignment deadline.\n- **Passing teams**: The number of teams that are currently passing the autograding tests for this assignment.\n\n\n\nViewing the assignment overview page for an assignment\n\nThe assignment overview page displays information for a specific assignment. You can view general information at a glance, or apply searches, sorts, and filters to find students or teams that meet specific criteria.\n\n{% data reusables.class", "Y2h1bmtfMV9pbmRleF8xMjM1": "room.sign-into-github-classroom %}\n1. Navigate to a classroom.\n1. To open the assignment overview page for an assignment, in the \"Assignments\" section, click the name of that assignment.\n\n\n\nSearching and sorting the assignment overview page\n\nYou can search and sort the assignment overview page to find specific students or teams.\n\n1. To find a specific student or team on the assignment overview page, in the search bar, type the student's {% data variables.product.prodname_dotcom %} handle, the student's identifier, or the team's name, then press Enter or Return.\n\n   If the search term you enter matches multiple students or teams, each student or team will be shown in the search results. For example, if you have two students with the {% data variables.product.prodname_dotcom %} handles \"@octocat\" and \"@monacat\", and you search for \"cat\", both \"@octocat\" and \"@monacat\" will appear in the search results.\n1. To sort the students or teams displayed on an assignment overview page, select **Sort by:** {% octicon \"triangle-down\" aria-hidden=\"true\" %}, then click **Alphabetical A-Z**, **Alphabetical Z-A**, **Newest**, or **Oldest**.\n\n   The **Newest** sort orders the results from the most recently updated assignment to the least recently updated assignment, while the **Oldest** sort does the opposite.\n{% data reusables.classroom.clear-all-assignment-overview %}\n\n\n\nFiltering the assignment overview page\n\nUsing a series of dropdown menus, you can apply multiple filters to the assignment overview page to search for students or teams based on specific criteria. You can even apply multiple filters from a single dropdown menu to include all students or teams that match the criteria.\n\n1. To filter for students with unlinked accounts, select the **Unlinked accounts** {% octicon \"triangle-down\" aria-hidden=\"true\" %} dropdown menu, then click **Student identifiers** or **{% data variables.product.prodname_dotcom %} accounts**.\n1. To filter by which students have or haven't accepted the assignment, select the **Accepted** {% octicon ", "Y2h1bmtfMl9pbmRleF8xMjM1": "\"triangle-down\" aria-hidden=\"true\" %} dropdown menu, then click **Accepted** or **Unaccepted**.\n1. To filter by the submission status for each student's assignment repository, select the **Submitted** {% octicon \"triangle-down\" aria-hidden=\"true\" %} dropdown menu, then click **Submitted**, **On-time**, **Late**, or **Not submitted**.\n1. To filter for students by passing or failing grades, select the **Passing** {% octicon \"triangle-down\" aria-hidden=\"true\" %} dropdown menu, then click **Passing** or **Failing**.\n1. To unapply a filter, select the associated dropdown menu, then click the filter once more. A {% octicon \"check\" aria-hidden=\"true\" %} is displayed alongside the name of an applied filter, while unapplied filters only display their names.\n{% data reusables.classroom.clear-all-assignment-overview %}\n\n", "Y2h1bmtfMF9pbmRleF8xNTg=": "\n\nAbout migrating from Bitbucket Pipelines with GitHub Actions Importer\n\nThe instructions below will guide you through configuring your environment to use {% data variables.product.prodname_actions_importer %} to migrate Bitbucket Pipelines to {% data variables.product.prodname_actions %}.\n\n\n\nPrerequisites\n\n{% data reusables.actions.actions-importer-prerequisites %}\n\n\n\nLimitations\n\nThere are some limitations when migrating from Bitbucket Pipelines to {% data variables.product.prodname_actions %} with {% data variables.product.prodname_actions_importer %}.\n\n- Images in a private AWS ECR are not supported.\n- The Bitbucket Pipelines option `size` is not supported. {% ifversion fpt or ghec %}If additional runner resources are required in {% data variables.product.prodname_actions %}, consider using {% data variables.actions.hosted_runner %}s. For more information, see \"AUTOTITLE.\"{% endif %}\n- Metrics detailing the queue time of jobs is not supported by the `forecast` command.\n- Bitbucket after-scripts are supported using {% data variables.product.prodname_actions %} `always()` in combination with checking the `steps..conclusion` of the previous step. For more information, see \"AUTOTITLE.\"\n\n  The following is an example of using the `always()` with `steps..conclusion`.\n\n  ```yaml\n    - name: After Script 1\n      run: |-\n        echo \"I'm after the script ran!\"\n        echo \"We should be grouped!\"\n      id: after-script-1\n      if: \"{% raw %}${{ always() }}{% endraw %}\"\n    - name: After Script 2\n      run: |-\n        echo \"this is really the end\"\n        echo \"goodbye, for now!\"\n      id: after-script-2\n      if: \"{% raw %}${{ steps.after-script-1.conclusion == 'success' && always() }}{% endraw %}\"\n  ```\n\n\n\nManual tasks\n\nCertain Bitbucket Pipelines constructs must be migrated manually. These include:\n\n- Secured repository, workspace, and deployment variables\n- SSH keys\n\n\n\nInstalling the {% data variables.product.prodname_actions_importer %} CLI extension\n\n{% data reusables.actions.installing-actions-importer %}\n\n\n\nCo", "Y2h1bmtfMV9pbmRleF8xNTg=": "nfiguring credentials\n\nThe `configure` CLI command is used to set required credentials and options for {% data variables.product.prodname_actions_importer %} when working with Bitbucket Pipelines and {% data variables.product.prodname_dotcom %}.\n\n1. Create a {% data variables.product.prodname_dotcom %} {% data variables.product.pat_v1 %}. For more information, see \"AUTOTITLE.\"\n\n   Your token must have the `workflow` scope.\n\n   After creating the token, copy it and save it in a safe location for later use.\n1. Create a Workspace Access Token for Bitbucket Pipelines. For more information, see Workspace Access Token permissions in the Bitbucket documentation. Your token must have the `read` scope for pipelines, projects, and repositories.\n\n1. In your terminal, run the {% data variables.product.prodname_actions_importer %} `configure` CLI command:\n\n   ```shell\n   gh actions-importer configure\n   ```\n\n   The `configure` command will prompt you for the following information:\n\n   - For \"Which CI providers are you configuring?\", use the arrow keys to select `Bitbucket`, press Space to select it, then press Enter.\n   - For \"{% data variables.product.pat_generic_caps %} for GitHub\", enter the value of the {% data variables.product.pat_v1 %} that you created earlier, and press Enter.\n   - For \"Base url of the GitHub instance\", {% ifversion ghes or ghae %}enter the URL for your {% data variables.product.product_name %} instance, and press Enter.{% else %}press Enter to accept the default value (`https://github.com`).{% endif %}\n   - For \"{% data variables.product.pat_generic_caps %} for Bitbucket\", enter the Workspace Access Token that you created earlier, and press Enter.\n   - For \"Base url of the Bitbucket instance\", enter the URL for your Bitbucket instance, and press Enter.\n\n   An example of the `configure` command is shown below:\n\n   ```shell\n   $ gh actions-importer configure\n   \u2714 Which CI providers are you configuring?: Bitbucket\n   Enter the following values (leave empty to omit):\n   \u2714 {% data variables.product.pat_ge", "Y2h1bmtfMl9pbmRleF8xNTg=": "neric_caps %} for GitHub: ***************\n   \u2714 Base url of the GitHub instance: https://github.com\n   \u2714 {% data variables.product.pat_generic_caps %} for Bitbucket: ********************\n   \u2714 Base url of the Bitbucket instance: https://bitbucket.example.com\n   Environment variables successfully updated.\n   ```\n\n1. In your terminal, run the {% data variables.product.prodname_actions_importer %} `update` CLI command to connect to {% data variables.product.prodname_registry %} {% data variables.product.prodname_container_registry %} and ensure that the container image is updated to the latest version:\n\n   ```shell\n   gh actions-importer update\n   ```\n\n   The output of the command should be similar to below:\n\n   ```shell\n   Updating ghcr.io/actions-importer/cli:latest...\n   ghcr.io/actions-importer/cli:latest up-to-date\n   ```\n\n\n\nPerform an audit of the Bitbucket instance\n\nYou can use the audit command to get a high-level view of pipelines in a Bitbucket instance.\n\nThe audit command performs the following steps.\n1. Fetches all of the pipelines for a workspace.\n1. Converts pipeline to its equivalent GitHub Actions workflow.\n1. Generates a report that summarizes how complete and complex of a migration is possible with {% data variables.product.prodname_actions_importer %}.\n\n\n\nRunning the audit command\n\nTo perform an audit run the following command in your terminal, replacing `:workspace` with the name of the Bitbucket workspace to audit.\n\n```bash\ngh actions-importer audit bitbucket --workspace :workspace--output-dir tmp/audit\n```\n\nOptionally, a `--project-key` option can be provided to the audit command to limit the results to only pipelines associated with a project.\n\nIn the below example command `:project_key` should be replaced with the key of the project that should be audited. Project keys can be found in Bitbucket on the workspace projects page.\n\n```bash\ngh actions-importer audit bitbucket --workspace :workspace --project-key :project_key --output-dir tmp/audit\n```\n\n\n\nInspecting the audit results\n\n{% data reusable", "Y2h1bmtfM19pbmRleF8xNTg=": "s.actions.gai-inspect-audit %}\n\n\n\nForecasting usage\n\nYou can use the `forecast` command to forecast potential {% data variables.product.prodname_actions %} usage by computing metrics from completed pipeline runs in your Bitbucket instance.\n\n\n\nRunning the forecast command\n\nTo perform a forecast of potential GitHub Actions usage, run the following command in your terminal, replacing `:workspace` with the name of the Bitbucket workspace to forecast. By default, GitHub Actions Importer includes the previous seven days in the forecast report.\n\n```shell\ngh actions-importer forecast bitbucket --workspace :workspace --output-dir tmp/forecast_reports\n```\n\n\n\nForecasting a project\n\nTo limit the forecast to a project, you can use the `--project-key` option. Replace the value for the `:project_key` with the project key for the project to forecast.\n\n```shell\ngh actions-importer forecast bitbucket --workspace :workspace --project-key :project_key --output-dir tmp/forecast_reports\n```\n\n\n\nInspecting the forecast report\n\nThe `forecast_report.md` file in the specified output directory contains the results of the forecast.\n\nListed below are some key terms that can appear in the forecast report:\n\n- The **job count** is the total number of completed jobs.\n- The **pipeline count** is the number of unique pipelines used.\n- **Execution time** describes the amount of time a runner spent on a job. This metric can be used to help plan for the cost of {% data variables.product.prodname_dotcom %}-hosted runners.\n  - This metric is correlated to how much you should expect to spend in {% data variables.product.prodname_actions %}. This will vary depending on the hardware used for these minutes. You can use the {% data variables.product.prodname_actions %} pricing calculator to estimate the costs.\n- **Concurrent jobs** metrics describe the amount of jobs running at any given time.\n\n\n\nPerforming a dry-run migration\n\nYou can use the dry-run command to convert a Bitbucket pipeline to an equivalent {% data variables.product.prodname_actions %} workf", "Y2h1bmtfNF9pbmRleF8xNTg=": "low(s). A dry-run creates the output files in a specified directory, but does not open a pull request to migrate the pipeline.\n\n\n\nRunning the dry-run command\n\nTo perform a dry run of migrating a Bitbucket pipeline to {% data variables.product.prodname_actions %}, run the following command in your terminal, replacing `:workspace` with the name of the workspace and `:repo` with the name of the repository in Bitbucket.\n\n```bash\ngh actions-importer dry-run bitbucket --workspace :workspace --repository :repo --output-dir tmp/dry-run\n```\n\n\n\nInspecting the converted workflows\n\nYou can view the logs of the dry run and the converted workflow files in the specified output directory.\n\n{% data reusables.actions.gai-custom-transformers-rec %}\n\n\n\nPerforming a production migration\n\nYou can use the migrate command to convert a Bitbucket pipeline and open a pull request with the equivalent {% data variables.product.prodname_actions %} workflow(s).\n\n\n\nRunning the migrate command\n\nTo migrate a Bitbucket pipeline to {% data variables.product.prodname_actions %}, run the following command in your terminal, replacing the following values.\n\n- Replace `target-url` value with the URL for your {% data variables.product.company_short %} repository.\n- Replace `:repo` with the name of the repository in Bitbucket.\n- Replace `:workspace` with the name of the workspace.\n\n```bash\ngh actions-importer migrate bitbucket --workspace :workspace --repository :repo --target-url https://github.com/:owner/:repo --output-dir tmp/dry-run\n```\n\nThe command's output includes the URL of the pull request that adds the converted workflow to your repository. An example of a successful output is similar to the following:\n\n```bash\ngh actions-importer migrate bitbucket --workspace actions-importer --repository custom-trigger --target-url https://github.com/valet-dev-testing/demo-private --output-dir tmp/bitbucket\n[2023-07-18 09:56:06] Logs: 'tmp/bitbucket/log/valet-20230718-165606.log'\n[2023-07-18 09:56:24] Pull request: 'https://github.com/valet-dev-testing/demo-pr", "Y2h1bmtfNV9pbmRleF8xNTg=": "ivate/pull/55'\n```\n\n{% data reusables.actions.gai-inspect-pull-request %}\n\n\n\nReference\n\nThis section contains reference information on environment variables, optional arguments, and supported syntax when using {% data variables.product.prodname_actions_importer %} to migrate from Bitbucket Pipelines.\n\n\n\nUsing environment variables\n\n{% data reusables.actions.gai-config-environment-variables %}\n\n{% data variables.product.prodname_actions_importer %} uses the following environment variables to connect to your Bitbucket instance.\n\n- `GITHUB_ACCESS_TOKEN`: The {% data variables.product.pat_v1 %} used to create pull requests with a transformed workflow (requires `repo` and `workflow` scopes).\n- `GITHUB_INSTANCE_URL`: The url to the target GitHub instance. (e.g. `https://github.com`)\n- `BITBUCKET_ACCESS_TOKEN`: The workspace access token with read scopes for pipeline, project, and repository.\n\nThese environment variables can be specified in a `.env.local` file that will be loaded by {% data variables.product.prodname_actions_importer %} at run time. The distribution archive contains a `.env.local.template` file that can be used to create these files.\n\n\n\nOptional arguments\n\n{% data reusables.actions.gai-optional-arguments-intro %}\n\n\n\n`--source-file-path`\n\nYou can use the `--source-file-path` argument with the  `dry-run` or `migrate` subcommands.\n\nBy default, {% data variables.product.prodname_actions_importer %} fetches pipeline contents from the Bitbucket instance. The `--source-file-path` argument tells {% data variables.product.prodname_actions_importer %} to use the specified source file path instead.\n\nFor example:\n\n```bash\ngh actions-importer dry-run bitbucket --workspace :workspace --repository :repo --output-dir tmp/dry-run --source-file-path path/to/my/pipeline/file.yml\n```\n\n\n\n`--config-file-path`\n\nYou can use the `--config-file-path` argument with the `audit`, `dry-run`, and `migrate` subcommands.\n\nBy default, {% data variables.product.prodname_actions_importer %} fetches pipeline contents from the Bitbucket ins", "Y2h1bmtfNl9pbmRleF8xNTg=": "tance. The `--config-file-path` argument tells {% data variables.product.prodname_actions_importer %} to use the specified source files instead.\n\n\n\nAudit example\n\nIn this example, {% data variables.product.prodname_actions_importer %} uses the specified YAML configuration file to perform an audit.\n\n```bash\ngh actions-importer audit bitbucket --workspace :workspace --output-dir tmp/audit --config-file-path \"path/to/my/bitbucket/config.yml\"\n```\n\nTo audit a Bitbucket instance using a config file, the config file must be in the following format, and each `repository_slug` must be unique:\n\n```yaml\nsource_files:\n  - repository_slug: repo_name\n    path: path/to/one/source/file.yml\n  - repository_slug: another_repo_name\n    path: path/to/another/source/file.yml\n```\n\n\n\nSupported syntax for Bitbucket Pipelines\n\nThe following table shows the type of properties that {% data variables.product.prodname_actions_importer %} is currently able to convert.\n\n| Bitbucket                 | GitHub Actions                                  |  Status      |\n| :-------------------      | :-------------------------------------------    | -----------: |\n| `after-script`            | `jobs..steps[*]`                        | Supported    |\n| `artifacts`               | `actions/upload-artifact` & `download-artifact` | Supported    |\n| `caches`                  | `actions/cache`                                 | Supported    |\n| `clone`                   | `actions/checkout`                              | Supported    |\n| `condition`               | `job..steps[*].run`                     | Supported    |\n| `deployment`              | `jobs..environmen`                      | Supported    |\n| `image`                   | `jobs..container`                       | Supported    |\n| `max-time`                | `jobs..steps[*].timeout-minutes`        | Supported    |\n| `options.docker`          | None                                            | Supported    |\n| `options.max-time`        | `jobs..steps[*].timeout-minutes`        | Supported    |\n| `", "Y2h1bmtfN19pbmRleF8xNTg=": "parallel`                | `jobs.`                                 | Supported    |\n| `pipelines.branches`      | `on.push`                                       | Supported    |\n| `pipelines.custom`        | `on.workflow_dispatch`                          | Supported    |\n| `pipelines.default`       | `on.push`                                       | Supported    |\n| `pipelines.pull-requests` | `on.pull_requests`                              | Supported    |\n| `pipelines.tags`          | `on.tags`                                       | Supported    |\n| `runs-on`                 | `jobs..runs-on`                         | Supported    |\n| `script`                  | `job..steps[*].run`                     | Supported    |\n| `services`                | `jobs..service`                         | Supported    |\n| `stage`                   | `jobs.`                                 | Supported    |\n| `step`                    | `jobs..steps[*]`                        | Supported    |\n| `trigger`                 | `on.workflow_dispatch`                          | Supported    |\n| `fail-fast`               | None                                            | Unsupported  |\n| `oidc`                    | None                                            | Unsupported  |\n| `options.size`            | None                                            | Unsupported  |\n| `size`                    | None                                            | Unsupported  |\n\n\n\nEnvironment variable mapping\n\n{% data variables.product.prodname_actions_importer %} uses the mapping in the table below to convert default Bitbucket environment variables to the closest equivalent in {% data variables.product.prodname_actions %}.\n\n| Bitbucket                                | GitHub Actions                                                                 |\n| :-------------------------------------   | :------------------------------------------------------                        |\n|  `CI`                                    | {% raw %}`true`{% endraw %}   ", "Y2h1bmtfOF9pbmRleF8xNTg=": "                                                 |\n|  `BITBUCKET_BUILD_NUMBER`                | {% raw %}`${{ github.run_number }}`{% endraw %}                                |\n|  `BITBUCKET_CLONE_DIR`                   | {% raw %}`${{ github.workspace  }}`{% endraw %}                                |\n|  `BITBUCKET_COMMIT`                      | {% raw %}`${{ github.sha }}`{% endraw %}                                       |\n|  `BITBUCKET_WORKSPACE`                   | {% raw %}`${{ github.repository_owner }}`{% endraw %}                          |\n|  `BITBUCKET_REPO_SLUG`                   | {% raw %}`${{ github.repository }}`{% endraw %}                                |\n|  `BITBUCKET_REPO_UUID`                   | {% raw %}`${{ github.repository_id }}`{% endraw %}                             |\n|  `BITBUCKET_REPO_FULL_NAME`              | {% raw %}`${{ github.repository_owner }}`{% endraw %}/{% raw %}`${{ github.repository }}`{% endraw %} |\n|  `BITBUCKET_BRANCH`                      | {% raw %}`${{ github.ref }}`{% endraw %}                                       |\n|  `BITBUCKET_TAG`                         | {% raw %}`${{ github.ref }}`{% endraw %}                                       |\n|  `BITBUCKET_PR_ID`                       | {% raw %}`${{ github.event.pull_request.number }}`{% endraw %}                 |\n|  `BITBUCKET_PR_DESTINATION_BRANCH`       | {% raw %}`${{ github.event.pull_request.base.ref }}`{% endraw %}               |\n|  `BITBUCKET_GIT_HTTP_ORIGIN`             | {% raw %}`${{ github.event.repository.clone_url }}`{% endraw %}                |\n|  `BITBUCKET_GIT_SSH_ORIGIN`              | {% raw %}`${{ github.event.repository.ssh_url }}`{% endraw %}                  |\n|  `BITBUCKET_EXIT_CODE`                   | {% raw %}`${{ job.status }}`{% endraw %}                                       |\n|  `BITBUCKET_STEP_UUID`                   | {% raw %}`${{ job.github_job }}`{% endraw %}                                   |\n|  `BITBUCKET_PIPELINE_UUID`               | {% raw %}`${{ github.workflow }}`{% end", "Y2h1bmtfOV9pbmRleF8xNTg=": "raw %}                                  |\n|  `BITBUCKET_PROJECT_KEY`                 | {% raw %}`${{ github.repository_owner }}`{% endraw %}                          |\n|  `BITBUCKET_PROJECT_UUID`                | {% raw %}`${{ github.repository_owner }}`{% endraw %}                          |\n|  `BITBUCKET_STEP_TRIGGERER_UUID`         | {% raw %}`${{ github.actor_id }}`{% endraw %}                                  |\n|  `BITBUCKET_SSH_KEY_FILE`                | {% raw %}`${{ github.workspace }}/.ssh/id_rsa`{% endraw %}                     |\n|  `BITBUCKET_STEP_OIDC_TOKEN`             | No Mapping                                           |\n|  `BITBUCKET_DEPLOYMENT_ENVIRONMENT`      | No Mapping                                           |\n|  `BITBUCKET_DEPLOYMENT_ENVIRONMENT_UUID` | No Mapping                                           |\n|  `BITBUCKET_BOOKMARK`                    | No Mapping                                           |\n|  `BITBUCKET_PARALLEL_STEP`               | No Mapping                                           |\n|  `BITBUCKET_PARALLEL_STEP_COUNT`         | No Mapping                                           |\n\n\n\nSystem Variables\n\nSystem variables used in tasks are transformed to the equivalent bash shell variable and are assumed to be available. For example, `${system.}` will be transformed to `$variable_name`. We recommend you verify this to ensure proper operation of the workflow.\n\n\n\nLegal notice\n\n{% data reusables.actions.actions-importer-legal-notice %}\n\n", "Y2h1bmtfMF9pbmRleF8xNjc2": "\n\nAbout reverting a pull request\n\nReverting a pull request on {% data variables.product.product_name %} creates a new pull request that contains one revert of the merge commit from the original merged pull request. To revert pull requests, you must have write permissions in the repository.\n\n\n\nReverting a pull request\n\n{% note %}\n\n**Note:** You may need to revert the individual commits in your pull request if either of the following is true.\n\n- Reverting the pull request causes merge conflicts\n- The original pull request was not originally merged on {% data variables.product.product_name %}. For example, someone could have merged the pull request using a fast-forward merge on the command line.\n\nFor more information about using Git to manually revert individual commits, see Git revert in the Git documentation.\n\n{% endnote %}\n\n{% data reusables.repositories.sidebar-pr %}\n1. In the \"Pull Requests\" list, click the pull request you'd like to revert.\n1. Near the bottom of the pull request, click **Revert**. If the **Revert** option isn't displayed, you'll need to ask the repository administrator for write permissions.\n\n   !Screenshot of a pull request's timeline. The \"Revert\" button is outlined in dark orange.\n\n1. Merge the resulting pull request. For more information, see \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF8xMTQ=": "\n\nAbout autoscaling\n\nYou can automatically increase or decrease the number of self-hosted runners in your environment in response to the webhook events you receive with a particular label. For example, you can create automation that adds a new self-hosted runner each time you receive a `workflow_job` webhook event with the  `queued` activity, which notifies you that a new job is ready for processing. The webhook payload includes label data, so you can identify the type of runner the job is requesting. Once the job has finished, you can then create automation that removes the runner in response to the `workflow_job` `completed` activity.\n\n\n\nSupported autoscaling solutions\n\n{% data variables.product.prodname_dotcom %} recommends using actions/actions-runner-controller for autoscaling your runners.\n\n{%- ifversion fpt or ghec or ghes > 3.8 %}\nFor more information, see \"AUTOTITLE.\"\n{% endif %}\n\n\n\nUsing ephemeral runners for autoscaling\n\n{% data variables.product.prodname_dotcom %} recommends implementing autoscaling with ephemeral self-hosted runners; autoscaling with persistent self-hosted runners is not recommended. In certain cases, {% data variables.product.prodname_dotcom %} cannot guarantee that jobs are not assigned to persistent runners while they are shut down. With ephemeral runners, this can be guaranteed because {% data variables.product.prodname_dotcom %} only assigns one job to a runner.\n\nThis approach allows you to manage your runners as ephemeral systems, since you can use automation to provide a clean environment for each job. This helps limit the exposure of any sensitive resources from previous jobs, and also helps mitigate the risk of a compromised runner receiving new jobs.\n\nTo add an ephemeral runner to your environment, include the `--ephemeral` parameter when registering your runner using `config.sh`. For example:\n\n```shell\n./config.sh --url https://github.com/octo-org --token example-token --ephemeral\n```\n\nThe {% data variables.product.prodname_actions %} service will then automatically de-reg", "Y2h1bmtfMV9pbmRleF8xMTQ=": "ister the runner after it has processed one job. You can then create your own automation that wipes the runner after it has been de-registered.\n\n{% note %}\n\n**Note:**  If a job is labeled for a certain type of runner, but none matching that type are available, the job does not immediately fail at the time of queueing. Instead, the job will remain queued until the 24 hour timeout period expires.\n\n{% endnote %}\n\n{% ifversion actions-single-use-tokens %}\n\nAlternatively, you can create ephemeral, just-in-time runners using the REST API. For more information, see \"AUTOTITLE.\"\n\n{% endif %}\n\n\n\nControlling runner software updates on self-hosted runners\n\nBy default, self-hosted runners will automatically perform a software update whenever a new version of the runner software is available.  If you use ephemeral runners in containers then this can lead to repeated software updates when a new runner version is released.  Turning off automatic updates allows you to update the runner version on the container image directly on your own schedule.\n\nTo turn off automatic software updates and install software updates yourself, specify the `--disableupdate` flag when registering your runner using `config.sh`. For example:\n\n```shell\n./config.sh --url https://github.com/YOUR-ORGANIZATION --token EXAMPLE-TOKEN --disableupdate\n```\n\nIf you disable automatic updates, you must still update your runner version regularly.  New functionality in {% data variables.product.prodname_actions %} requires changes in both the {% data variables.product.prodname_actions %} service _and_ the runner software.  The runner may not be able to correctly process jobs that take advantage of new features in {% data variables.product.prodname_actions %} without a software update.\n\nIf you disable automatic updates, you will be required to update your runner version within 30 days of a new version being made available.  You may want to subscribe to notifications for releases in the `actions/runner` repository. For more information, see \"AUTOTITLE.\"\n\nFor instructio", "Y2h1bmtfMl9pbmRleF8xMTQ=": "ns on how to install the latest runner version, see the installation instructions for the latest release.\n\n{% note %}\n\n**Note:** If you do not perform a software update within 30 days, the {% data variables.product.prodname_actions %} service will not queue jobs to your runner.  In addition, if a critical security update is required, the {% data variables.product.prodname_actions %} service will not queue jobs to your runner until it has been updated.\n\n{% endnote %}\n\n\n\nUsing webhooks for autoscaling\n\nYou can create your own autoscaling environment by using payloads received from the `workflow_job` webhook. This webhook is available at the repository, organization, and enterprise levels, and the payload for this event contains an `action` key that corresponds to the stages of a workflow job's life-cycle; for example when jobs are `queued`, `in_progress`, and `completed`. You must then create your own scaling automation in response to these webhook payloads.\n\n- For more information about the `workflow_job` webhook, see \"AUTOTITLE.\"\n- To learn how to work with webhooks, see \"AUTOTITLE.\"\n\n\n\nAuthentication requirements\n\nYou can register and delete repository and organization self-hosted runners using the API. To authenticate to the API, your autoscaling implementation can use an access token or a {% data variables.product.prodname_dotcom %} app.\n\nYour access token will require the following scope:\n\n- For private repositories, use an access token with the `repo` scope.\n- For public repositories, use an access token with the `public_repo` scope.\n- For organizations, use an access token with the `admin:org` scope.\n\nTo  authenticate using a {% data variables.product.prodname_dotcom %} App, it must be assigned the following permissions:\n- For repositories, assign the `administration` permission.\n- For organizations, assign the `organization_self_hosted_runners` permission.\n\nYou can register and delete enterprise self-hosted runners using the API. To authenticate to the API, your autoscaling implementation can use an access", "Y2h1bmtfM19pbmRleF8xMTQ=": " token.\n\nYour access token will require the `manage_runners:enterprise` scope.\n\n", "Y2h1bmtfMF9pbmRleF81ODM=": "\n\nAbout authentication with SAML SSO\n\n{% ifversion ghae %}\n\nSAML SSO allows an enterprise owner to centrally control and secure access to {% data variables.product.product_name %} from a SAML IdP. When you visit {% data variables.location.product_location %} in a browser, {% data variables.product.product_name %} will redirect you to your IdP to authenticate. After you successfully authenticate with an account on the IdP, the IdP redirects you back to {% data variables.location.product_location %}. {% data variables.product.product_name %} validates the response from your IdP, then grants access.\n\n{% data reusables.saml.you-must-periodically-authenticate %}\n\nIf you can't access {% data variables.product.product_name %}, contact your local enterprise owner or administrator for {% data variables.product.product_name %}. You may be able to locate contact information for your enterprise by clicking **Support** at the bottom of any page on {% data variables.product.product_name %}. {% data variables.product.company_short %} and {% data variables.contact.github_support %} do not have access to your IdP, and cannot troubleshoot authentication problems.\n\n{% endif %}\n\n{% ifversion ghec %}\n\n{% data reusables.saml.dotcom-saml-explanation %} Organization owners can invite your personal account on {% data variables.product.prodname_dotcom %} to join their organization that uses SAML SSO, which allows you to contribute to the organization and retain your existing identity and contributions on {% data variables.product.prodname_dotcom %}.\n\nIf you're a member of an {% data variables.enterprise.prodname_emu_enterprise %}, you will instead use a new account that is provisioned for you and controlled by your enterprise. {% data reusables.enterprise-accounts.emu-more-info-account %}\n\nWhen you attempt to access most resources within an organization that uses SAML SSO, {% data variables.product.prodname_dotcom %} will redirect you to the organization's SAML IdP to authenticate. After you successfully authenticate with your account on ", "Y2h1bmtfMV9pbmRleF81ODM=": "the IdP, the IdP redirects you back to {% data variables.product.prodname_dotcom %}, where you can access the organization's resources.\n\n{% data reusables.saml.resources-without-sso %}\n\n{% data reusables.saml.outside-collaborators-exemption %}\n\nIf you have recently authenticated with your organization's SAML IdP in your browser, you are automatically authorized when you access a {% data variables.product.prodname_dotcom %} organization that uses SAML SSO. If you haven't recently authenticated with your organization's SAML IdP in your browser, you must authenticate at the SAML IdP before you can access the organization.\n\n{% data reusables.saml.you-must-periodically-authenticate %}\n\n\n\nLinked SAML identities\n\nWhen you authenticate with your IdP account and return to {% data variables.product.prodname_dotcom %}, {% data variables.product.prodname_dotcom %} will record a link in the organization or enterprise between your {% data variables.product.prodname_dotcom %} personal account and the SAML identity you signed into.  This linked identity is used to validate your membership in that organization, and depending on your organization or enterprise setup, is also used to determine which organizations and teams you're a member of as well. Each {% data variables.product.prodname_dotcom %} account can be linked to exactly one SAML identity per organization. Likewise, each SAML identity can be linked to exactly one {% data variables.product.prodname_dotcom %} account in an organization.\n\nIf you sign in with a SAML identity that is already linked to another {% data variables.product.prodname_dotcom %} account, you will receive an error message indicating that you cannot sign in with that SAML identity. This situation can occur if you are attempting to use a new {% data variables.product.prodname_dotcom %} account to work inside of your organization. If you didn't intend to use that SAML identity with that {% data variables.product.prodname_dotcom %} account, then you'll need to sign out of that SAML identity and then repeat", "Y2h1bmtfMl9pbmRleF81ODM=": " the SAML login. If you do want to use that SAML identity with your {% data variables.product.prodname_dotcom %} account, you'll need to ask your admin to unlink your SAML identity from your old account, so that you can link it to your new account.  Depending on the setup of your organization or enterprise, your admin may also need to reassign your identity within your SAML provider.  For more information, see \"AUTOTITLE.\"\n\nIf the SAML identity you sign in with does not match the SAML identity that is currently linked to your {% data variables.product.prodname_dotcom %} account, you'll receive a warning that you are about to relink your account. Because your SAML identity is used to govern access and team membership, continuing with the new SAML identity can cause you to lose access to teams and organizations inside of {% data variables.product.prodname_dotcom %}. Only continue if you know that you're supposed to use that new SAML identity for authentication in the future.\n\n\n\nAuthorizing {% data variables.product.pat_generic %}s and SSH keys with SAML SSO\n\nTo use the API or Git on the command line to access protected content in an organization that uses SAML SSO, you will need to use an authorized {% data variables.product.pat_generic %} over HTTPS or an authorized SSH key.\n\nIf you don't have a {% data variables.product.pat_generic %} or an SSH key, you can create a {% data variables.product.pat_generic %} for the command line or generate a new SSH key. For more information, see \"AUTOTITLE\" or \"AUTOTITLE.\"\n\nTo use a new or existing {% data variables.product.pat_generic %} or SSH key with an organization that uses or enforces SAML SSO, you will need to authorize the token or authorize the SSH key for use with a SAML SSO organization. For more information, see \"AUTOTITLE\" or \"AUTOTITLE.\"\n\n\n\nAbout {% data variables.product.prodname_oauth_apps %}, {% data variables.product.prodname_github_apps %}, and SAML SSO\n\nYou must have an active SAML session each time you authorize an {% data variables.product.prodname_oauth_ap", "Y2h1bmtfM19pbmRleF81ODM=": "p %} or {% data variables.product.prodname_github_app %} to access an organization that uses or enforces SAML SSO. You can create an active SAML session by navigating to `https://github.com/orgs/ORGANIZATION-NAME/sso` in your browser.\n\nAfter an enterprise or organization owner enables or enforces SAML SSO for an organization, and after you authenticate via SAML for the first time, you must reauthorize any {% data variables.product.prodname_oauth_apps %} or {% data variables.product.prodname_github_apps %} that you previously authorized to access the organization.\n\nTo see the {% data variables.product.prodname_oauth_apps %} you've authorized, visit your {% data variables.product.prodname_oauth_apps %} page. To see the {% data variables.product.prodname_github_apps %} you've authorized, visit your {% data variables.product.prodname_github_apps %} page.\n\nFor more information, see \"AUTOTITLE.\"\n\n{% endif %}\n\n\n\nFurther reading\n\n{% ifversion ghec %}- \"AUTOTITLE\"{% endif %}\n{% ifversion ghae %}- \"AUTOTITLE\"{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF8xNTgz": "\n\nAbout team synchronization\n\nYou can enable team synchronization between your IdP and {% data variables.product.product_name %} to allow organization owners and team maintainers to connect teams in your organization with IdP groups.\n\n{% data reusables.identity-and-permissions.about-team-sync %}\n\n{% data reusables.identity-and-permissions.team-and-idp-group %}\n\n{% data reusables.saml.ghec-only %}\n\n{% data reusables.identity-and-permissions.supported-idps-team-sync %}\n\n{% ifversion team-sync-manage-org-invites %}\n{% data reusables.identity-and-permissions.team-sync-org-invites %}\n{% endif %}\n\n{% data reusables.identity-and-permissions.sync-team-with-idp-group %}\n\nYou can also enable team synchronization for all organizations owned by an enterprise account. If SAML is configured at the enterprise level, you cannot enable team synchronization on an individual organization. Instead, you must configure team synchronization for the entire enterprise. For more information, see \"AUTOTITLE.\"\n\n{% data reusables.enterprise-accounts.team-sync-override %}\n\n{% data reusables.identity-and-permissions.team-sync-usage-limits %}\n\n\n\nEnabling team synchronization\n\nThe steps to enable team synchronization depend on the IdP you want to use. There are prerequisites to enable team synchronization that apply to every IdP. Each individual IdP has additional prerequisites.\n\n\n\nPrerequisites\n\n{% data reusables.identity-and-permissions.team-sync-required-permissions %}\n\nYou must enable SAML single sign-on for your organization and your supported IdP. For more information, see \"AUTOTITLE.\"\n\nYou must have a linked SAML identity. To create a linked identity, you must authenticate to your organization using SAML SSO and the supported IdP at least once. For more information, see \"AUTOTITLE.\"\n\n{% note %}\n\n**Note**: For team synchronization to work, your SAML settings must contain a valid IdP URL for the \"Issuer\" field. For more information, see \"Enabling and testing SAML single sign-on for your organization.\"\n\n{% endnote %}\n\n\n\nEnabling team synchro", "Y2h1bmtfMV9pbmRleF8xNTgz": "nization for Azure AD\n\n{% data reusables.identity-and-permissions.team-sync-azure-permissions %}\n\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n{% data reusables.organizations.security %}\n{% data reusables.identity-and-permissions.team-sync-confirm-saml %}\n{% data reusables.identity-and-permissions.enable-team-sync-azure %}\n{% data reusables.identity-and-permissions.team-sync-confirm %}\n1. Review the identity provider tenant information you want to connect to your organization, then click **Approve**.\n\n\n\nEnabling team synchronization for Okta\n\nOkta team synchronization requires that SAML and SCIM with Okta have already been set up for your organization.\n\nTo avoid potential team synchronization errors with Okta, we recommend that you confirm that SCIM linked identities are correctly set up for all organization members who are members of your chosen Okta groups, before enabling team synchronization on {% data variables.product.prodname_dotcom %}.\n\nIf an organization member does not have a linked SCIM identity, then team synchronization will not work as expected and the user may not be added or removed from teams as expected. If any of these users are missing a SCIM linked identity, you will need to re-provision them.\n\nFor help on provisioning users that have missing a missing SCIM linked identity, see \"AUTOTITLE.\"\n\n{% data reusables.identity-and-permissions.team-sync-okta-requirements %}\n\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n{% data reusables.organizations.security %}\n{% data reusables.identity-and-permissions.team-sync-confirm-saml %}\n{% data reusables.identity-and-permissions.team-sync-confirm-scim %}\n1. Consider enforcing SAML in your organization to ensure that organization members link their SAML and SCIM identities. For more information, see \"AUTOTITLE.\"\n{% data reusables.identity-and-permissions.enable-team-sync-okta %}\n1. Under your organization's name, in the \"SSWS Token\" field, type a valid SSWS token.\n1. In the \"URL\" field, ", "Y2h1bmtfMl9pbmRleF8xNTgz": "type the URL for your Okta instance.\n1. Review the identity provider tenant information you want to connect to your organization, then click **Create**.\n\n{% ifversion team-sync-manage-org-invites %}\n\n\n\nManaging whether team sync can re-invite non-members to your organization\n\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n{% data reusables.organizations.security %}\n1. Under \"Team synchronization\", select or deselect **Do not allow Team Sync to re-invite past members to this organization that were removed by an organization owner.**\n{% endif %}\n\n\n\nDisabling team synchronization\n\n{% data reusables.identity-and-permissions.team-sync-disable %}\n\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n{% data reusables.organizations.security %}\n1. Under \"Team synchronization\", click **Disable team synchronization**.\n\n", "Y2h1bmtfMF9pbmRleF82OQ==": "\n\nIntroduction\n\nThis guide shows you how to build and test a Swift package.\n\n{% ifversion ghae %} To build and test your Swift project on {% data variables.product.prodname_ghe_managed %}, the necessary Swift dependencies are required. {% data reusables.actions.self-hosted-runners-software %}\n{% else %}{% data variables.product.prodname_dotcom %}-hosted runners have a tools cache with preinstalled software, and the Ubuntu and macOS runners include the dependencies for building Swift packages. For a full list of up-to-date software and the preinstalled versions of Swift and Xcode, see \"AUTOTITLE.\"{% endif %}\n\n\n\nPrerequisites\n\nYou should already be familiar with YAML syntax and how it's used with {% data variables.product.prodname_actions %}. For more information, see \"AUTOTITLE.\"\n\nWe recommend that you have a basic understanding of Swift packages. For more information, see \"Swift Packages\" in the Apple developer documentation.\n\n\n\nUsing a Swift starter workflow\n\n{% data reusables.actions.starter-workflow-get-started %}\n\n{% data variables.product.prodname_dotcom %} provides a starter workflow for Swift that should work for most Swift projects. The subsequent sections of this guide give examples of how you can customize this starter workflow.\n\n{% data reusables.repositories.navigate-to-repo %}\n{% data reusables.repositories.actions-tab %}\n{% data reusables.actions.new-starter-workflow %}\n1. The \"{% ifversion actions-starter-template-ui %}Choose a workflow{% else %}Choose a workflow template{% endif %}\" page shows a selection of recommended starter workflows. Search for \"swift\".\n1. Filter the selection of workflows by clicking **Continuous integration**.\n1. On the \"Swift\" workflow, click {% ifversion actions-starter-template-ui %}**Configure**{% else %}**Set up this workflow**{% endif %}.\n\n{%- ifversion ghes or ghae %}\n\n   If you don't find the \"Swift\" starter workflow, copy the following workflow code to a new file called `swift.yml` in the `.github/workflows` directory of your repository.\n\n   ```yaml copy\n   name: S", "Y2h1bmtfMV9pbmRleF82OQ==": "wift\n\n   on:\n     push:\n       branches: [ \"main\" ]\n     pull_request:\n       branches: [ \"main\" ]\n\n   jobs:\n     build:\n       runs-on: macos-latest\n\n       steps:\n       - uses: {% data reusables.actions.action-checkout %}\n       - name: Build\n         run: swift build -v\n       - name: Run tests\n         run: swift test -v\n   ```\n\n{%- endif %}\n\n1. Edit the workflow as required. For example, change the branch on which the workflow will run.\n1. Click **Commit changes**.\n\n{% ifversion fpt or ghec %}\n   The `swift.yml` workflow file is added to the `.github/workflows` directory of your repository.\n{% endif %}\n\n\n\nSpecifying a Swift version\n\nTo use a specific preinstalled version of Swift on a {% data variables.product.prodname_dotcom %}-hosted runner, use the `swift-actions/setup-swift` action. This action finds a specific version of Swift from the tools cache on the runner and adds the necessary binaries to `PATH`. These changes will persist for the remainder of a job. For more information, see the `swift-actions/setup-swift` action.\n\nIf you are using a self-hosted runner, you must install your desired Swift versions and add them to `PATH`.\n\nThe examples below demonstrate using the `swift-actions/setup-swift` action.\n\n\n\nUsing multiple Swift versions\n\nYou can configure your job to use multiple versions of Swift in a matrix.\n\n```yaml copy\n\n{% data reusables.actions.actions-not-certified-by-github-comment %}\n\n{% data reusables.actions.actions-use-sha-pinning-comment %}\n\n\nname: Swift\n\non: [push]\n\njobs:\n  build:\n    name: {% raw %}Swift ${{ matrix.swift }} on ${{ matrix.os }}{% endraw %}\n    strategy:\n      matrix:\n        os: [ubuntu-latest, macos-latest]\n        swift: [\"5.2\", \"5.3\"]\n    runs-on: {% raw %}${{ matrix.os }}{% endraw %}\n    steps:\n      - uses: swift-actions/setup-swift@65540b95f51493d65f5e59e97dcef9629ddf11bf\n        with:\n          swift-version: {% raw %}${{ matrix.swift }}{% endraw %}\n      - uses: {% data reusables.actions.action-checkout %}\n      - name: Build\n        run: swift build\n      - name", "Y2h1bmtfMl9pbmRleF82OQ==": ": Run tests\n        run: swift test\n```\n\n\n\nUsing a single specific Swift version\n\nYou can configure your job to use a single specific version of Swift, such as `5.3.3`.\n\n{% raw %}\n\n```yaml copy\nsteps:\n  - uses: swift-actions/setup-swift@65540b95f51493d65f5e59e97dcef9629ddf11bf\n    with:\n      swift-version: \"5.3.3\"\n  - name: Get swift version\n    run: swift --version # Swift 5.3.3\n```\n\n{% endraw %}\n\n\n\nBuilding and testing your code\n\nYou can use the same commands that you use locally to build and test your code using Swift. This example demonstrates how to use `swift build` and `swift test` in a job:\n\n```yaml copy\nsteps:\n  - uses: {% data reusables.actions.action-checkout %}\n  - uses: swift-actions/setup-swift@65540b95f51493d65f5e59e97dcef9629ddf11bf\n    with:\n      swift-version: \"5.3.3\"\n  - name: Build\n    run: swift build\n  - name: Run tests\n    run: swift test\n```\n\n", "Y2h1bmtfMF9pbmRleF8xMTc0": "\n\nAbout {% data variables.product.prodname_desktop %}\n\n{% data variables.product.prodname_desktop %} is a free, open source application that helps you to work with files hosted on {% data variables.product.prodname_dotcom %} or other Git hosting services.\n\n\n\nBenefits of {% data variables.product.prodname_desktop %}\n\n{% data variables.product.prodname_desktop %} is useful for beginning and advanced users. Benefits include:\n\n- **Get started easily.** If you're new to Git and {% data variables.product.prodname_dotcom %}, you may find it easier to use {% data variables.product.prodname_desktop %} than to use Git on the command line. {% data variables.product.prodname_desktop %} has a graphical user interface that simplifies commands and helps you visualize changes.\n- **Find commands.** Because {% data variables.product.prodname_desktop %} has a visual interface, you can easily access less-common Git commands, such as choosing which changed lines to include in a commit or adding a co-author to a commit, without needing to memorize or look up syntax.\n- **Follow best practices.** {% data variables.product.prodname_desktop %} encourages best practices. For example, it helps you to create an accurate and easy-to-follow commit history so other collaborators on a project can easily review your work.\n- **Integrate with {% data variables.product.prodname_dotcom %}.** {% data variables.product.prodname_desktop %} is specifically designed for use with {% data variables.product.prodname_dotcom %}. For example, you can authenticate to {% data variables.product.prodname_dotcom_the_website %} or {% data variables.product.prodname_ghe_server %} quickly, without needing to use a separate credential manager. You can also check out a pull request to run checks without needing to open your browser.\n\n\n\n{% data variables.product.prodname_desktop %} workflow\n\nYou can use {% data variables.product.prodname_desktop %} alongside any tools you need to contribute to a project. For example, a typical workflow is:\n\n- Use {% data variables.product", "Y2h1bmtfMV9pbmRleF8xMTc0": ".prodname_desktop %} to download a {% data variables.product.prodname_dotcom %} repository to your computer and create a new branch\n- Use an editor such as {% data variables.product.prodname_vscode %} to make changes to the code\n- Return to {% data variables.product.prodname_desktop %} to commit and push the changes to {% data variables.product.prodname_dotcom %}\n\n\n\nGetting started\n\n{% data variables.product.prodname_desktop %} is available for Windows and macOS. For information about installing and getting started with {% data variables.product.prodname_desktop %}, see \"AUTOTITLE.\"\n\nIf you're interested in the open source {% data variables.product.prodname_desktop %} project, you can see the roadmap, contribute to the project, or open an issue to provide feedback in the `desktop/desktop` repository.\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF80MTg=": "\n\nAbout initialization of a {% data variables.product.product_name %} cluster\n\nTo deploy a {% data variables.product.product_name %} cluster in your environment, you must install {% data variables.product.prodname_ghe_server %}, upload a cluster-enabled license, configure the first node, and initialize the node with a configuration file.\n\n{% data reusables.enterprise_clustering.clustering-requires-https %}\n\n\n\nInstalling {% data variables.product.prodname_ghe_server %}\n\nTo start setting up the cluster, install the {% data variables.product.prodname_ghe_server %} appliance on each node's virtual machine (VM), then configure an IP address.\n\n1. On each cluster node, provision and install {% data variables.product.prodname_ghe_server %}. For more information, see \"AUTOTITLE.\"\n1. Using the administrative shell or DHCP, **only** configure the IP address of each node. Don't configure any other settings.\n\n\n\nConfiguring the first node\n\nOn the node that will function as your primary MySQL node, install your {% data variables.product.product_name %} license.\n\n1. Connect to the node that will be designated as MySQL primary in `cluster.conf`. For more information, see \"AUTOTITLE.\"\n1. In your web browser, visit `https://:8443/setup/`.\n{% data reusables.enterprise_installation.upload-a-license-file %}\n{% data reusables.enterprise_installation.save-settings-in-web-based-mgmt-console %}\n{% data reusables.enterprise_installation.instance-will-restart-automatically %}\n\n\n\nInitializing the cluster\n\nTo initialize the cluster, you need a cluster configuration file (`cluster.conf`). For more information, see \"AUTOTITLE\".\n\n1. From the first node that was configured, run `ghe-cluster-config-init`.  This will initialize the cluster if there are nodes in the cluster configuration file that are not configured.\n1. Run `ghe-cluster-config-apply`. This will validate the `cluster.conf` file, apply the configuration to each node file and bring up the configured services on each node.\n\nTo check the status of a running cluster use the `ghe-cluster-s", "Y2h1bmtfMV9pbmRleF80MTg=": "tatus` command.\n\n\n\nAbout the cluster configuration file\n\nThe cluster configuration file (`cluster.conf`) defines the nodes in the cluster, and what services they run.\nFor more information, see \"AUTOTITLE.\"\n\nThis example `cluster.conf` defines a cluster with 11 nodes.\n\n- Two nodes called `ghes-front-end-node-\\*` run services responsible for responding to client requests.\n- Three nodes called `ghes-database-node-\\*` run services responsible for storage, retrieval, and replication of database data.\n- Three nodes called `ghes-search-node-\\*` run services responsible for search functionality.\n- Three nodes called `ghes-storage-node-\\*` run services responsible for storage, retrieval, and replication of data.\n\nThe names of the nodes can be any valid hostname you choose. The names are set as the hostname of each node, and will also be added to `/etc/hosts` on each node, so that the nodes are locally resolvable to each other.\n\nSpecify the first cluster node you configured as the MySQL primary via `mysql-server` and `mysql-master`.\n\n```shell\n[cluster]\n  mysql-master = ghes-database-node-1\n  redis-master = ghes-database-node-1\n  primary-datacenter = primary\n[cluster \"ghes-front-end-node-1\"]\n  hostname = ghes-front-end-node-1\n  ipv4 = 192.168.0.2\n  # ipv6 = fd12:3456:789a:1::2\n  consul-datacenter = primary\n  datacenter = primary\n  web-server = true\n  job-server = true\n  memcache-server = true\n[cluster \"ghes-front-end-node-2\"]\n  hostname = ghes-front-end-node-2\n  ipv4 = 192.168.0.3\n  # ipv6 = fd12:3456:789a:1::3\n  consul-datacenter = primary\n  datacenter = primary\n  web-server = true\n  job-server = true\n  memcache-server = true\n[cluster \"ghes-database-node-1\"]\n  hostname = ghes-database-node-1\n  ipv4 = 192.168.0.4\n  # ipv6 = fd12:3456:789a:1::4\n  consul-datacenter = primary\n  datacenter = primary\n  consul-server = true\n  mysql-server = true\n  redis-server = true\n[cluster \"ghes-database-node-2\"]\n  hostname = ghes-database-node-2\n  ipv4 = 192.168.0.5\n  # ipv6 = fd12:3456:789a:1::5\n  consul-datacenter = primary\n  datacenter = p", "Y2h1bmtfMl9pbmRleF80MTg=": "rimary\n  consul-server = true\n  mysql-server = true\n  redis-server = true\n[cluster \"ghes-database-node-3\"]\n  hostname = ghes-database-node-3\n  ipv4 = 192.168.0.6\n  # ipv6 = fd12:3456:789a:1::6\n  consul-datacenter = primary\n  datacenter = primary\n  consul-server = true\n  mysql-server = true\n  redis-server = true\n[cluster \"ghes-search-node-1\"]\n  hostname = ghes-search-node-1\n  ipv4 = 192.168.0.7\n  # ipv6 = fd12:3456:789a:1::7\n  consul-datacenter = primary\n  datacenter = primary\n  elasticsearch-server = true\n[cluster \"ghes-search-node-2\"]\n  hostname = ghes-search-node-2\n  ipv4 = 192.168.0.8\n  # ipv6 = fd12:3456:789a:1::8\n  consul-datacenter = primary\n  datacenter = primary\n  elasticsearch-server = true\n[cluster \"ghes-search-node-3\"]\n  hostname = ghes-search-node-3\n  ipv4 = 192.168.0.9\n  # ipv6 = fd12:3456:789a:1::9\n  consul-datacenter = primary\n  datacenter = primary\n  elasticsearch-server = true\n[cluster \"ghes-storage-node-1\"]\n  hostname = ghes-storage-node-1\n  ipv4 = 192.168.0.10\n  # ipv6 = fd12:3456:789a:1::10\n  consul-datacenter = primary\n  datacenter = primary\n  git-server = true\n  pages-server = true\n  storage-server = true\n  metrics-server = true\n[cluster \"ghes-storage-node-2\"]\n  hostname = ghes-storage-node-2\n  ipv4 = 192.168.0.11\n  # ipv6 = fd12:3456:789a:1::11\n  consul-datacenter = primary\n  datacenter = primary\n  git-server = true\n  pages-server = true\n  storage-server = true\n  metrics-server = true\n[cluster \"ghes-storage-node-3\"]\n  hostname = ghes-storage-node-3\n  ipv4 = 192.168.0.12\n  # ipv6 = fd12:3456:789a:1::12\n  consul-datacenter = primary\n  datacenter = primary\n  git-server = true\n  pages-server = true\n  storage-server = true\n  metrics-server = true\n```\n\nCreate the file `/data/user/common/cluster.conf` on the configured first node. For example, using `vim`:\n\n   ```shell\n   ghe-data-node-1:~$ sudo vim /data/user/common/cluster.conf\n   ```\n\n", "Y2h1bmtfMF9pbmRleF8xNTg4": "\n\nAbout conversion of organization members to outside collaborators\n\nYou can convert a member of an organization to an outside collaborator. For more information about outside collaborators, see \"AUTOTITLE.\"\n\n{% ifversion fpt or ghec %}If the organization is owned by an enterprise, converting{% elsif ghes or ghae %}Converting{% endif %} an organization member to an outside collaborator may be restricted. For more information, see \"Enforcing repository management policies in your enterprise{% ifversion ghec or ghes or ghae %}.\"{% elsif fpt %}\" in the {% data variables.product.prodname_ghe_cloud %} documentation.{% endif %}\n\n{% data reusables.organizations.outside-collaborators-use-seats %} {% data reusables.organizations.outside_collaborator_forks %}\n\nAfter converting an organization member to an outside collaborator, they'll only have access to the repositories that their current team membership allows. The person will no longer be an explicit member of the organization, and will no longer be able to:\n\n- Create teams\n- See all organization members and teams\n- @mention any visible team\n- Be a team maintainer\n\nFor more information, see \"AUTOTITLE.\"\n\nWe recommend reviewing the organization member's access to repositories to ensure their access is as you expect. For more information, see \"AUTOTITLE.\"\n\nWhen you convert an organization member to an outside collaborator, their privileges as organization members are saved for three months so that you can restore their membership privileges if you{% ifversion fpt or ghec %} invite them to rejoin{% else %} add them back to{% endif %} your organization within that time frame. For more information, see \"AUTOTITLE.\"\n\n\n\nConverting an organization member to an outside collaborator\n\n{% note %}\n\n**Note:** You may not be able to convert an organization member to an outside collaborator, if an organization owner{% ifversion not fpt %} or enterprise owner{% endif %} has restricted your ability to add outside collaborators.\n\n{% endnote %}\n\n{% data reusables.profile.access_org %}\n{% d", "Y2h1bmtfMV9pbmRleF8xNTg4": "ata reusables.user-settings.access_org %}\n{% data reusables.organizations.people %}\n1. Select the person or people you'd like to convert to outside collaborators.\n\n   !Screenshot of the first two users in a list of organization members. To the left of each member, a checkbox is checked and outlined in dark orange.\n1. Above the list of members, select the **X members selected...** dropdown menu and click **Convert to outside collaborator**.\n\n   !Screenshot of the list of organization members. Above the list, a dropdown menu, labeled \"2 members selected...\" is outlined in dark orange.\n1. Read the information about converting members to outside collaborators, then click **Convert to outside collaborator**.\n\n", "Y2h1bmtfMF9pbmRleF8xNjI2": "\n\nAbout published packages\n\nYou can help people understand and use your package by providing a description and other details like installation and usage instructions on the package page. {% data variables.product.product_name %} provides metadata for each version, such as the publication date, download activity, and recent versions. For an example package page, see @Codertocat/hello-world-npm.\n\n{% data reusables.package_registry.public-or-private-packages %} A repository can be connected to more than one package. To prevent confusion, make sure the README and description clearly provide information about each package.\n\n{% ifversion fpt or ghec %}\nIf a new version of a package fixes a security vulnerability, you should publish a security advisory in your repository. {% data variables.product.prodname_dotcom %} reviews each published security advisory and may use it to send {% data variables.product.prodname_dependabot_alerts %} to affected repositories. For more information, see \"AUTOTITLE.\"\n{% endif %}\n\n\n\nPublishing a package\n\n{% data reusables.package_registry.packages-classic-pat-only %}\n\nYou can publish a package to {% data variables.product.prodname_registry %} using any {% ifversion fpt or ghae or ghec %}supported package client{% else %}package type enabled for your instance{% endif %} by following the same general guidelines.\n\n1. Create or use an existing {% data variables.product.pat_v1 %} with the appropriate scopes for the task you want to accomplish. For more information, see \"AUTOTITLE.\"\n1. Authenticate to {% data variables.product.prodname_registry %} using your {% data variables.product.pat_v1 %} and the instructions for your package client.\n1. Publish the package using the instructions for your package client.\n\nFor instructions specific to your package client, see \"AUTOTITLE.\"\n\nAfter you publish a package, you can view the package on {% data variables.product.prodname_dotcom %}. For more information, see \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF85ODA=": "\n\nAbout {% data variables.product.prodname_cli %}\n\n{% data reusables.cli.about-cli %} For more information, see \"AUTOTITLE.\"\n\nYou can work with {% data variables.product.prodname_github_codespaces %} in the  {% data variables.product.prodname_cli %} to:\n- List all of your codespaces\n- Create a new codespace\n- View details of a codespace\n- Stop a codespace\n- Delete a codespace\n- Rename a codespace\n- Rebuild a codespace\n- SSH into a codespace\n- Open a codespace in {% data variables.product.prodname_vscode %}\n- Open a codespace in JupyterLab\n- Copy a file to/from a codespace\n- Modify ports in a codespace\n- Access codespace logs\n- Access remote resources\n- Change the machine type of a codespace\n\n\n\nInstalling {% data variables.product.prodname_cli %}\n\n{% data reusables.cli.cli-installation %}\n\n\n\nUsing {% data variables.product.prodname_cli %}\n\nIf you have not already done so, run `gh auth login` to authenticate with your {% data variables.product.prodname_dotcom %} account.\n\nTo use `gh` to work with {% data variables.product.prodname_github_codespaces %}, type `gh codespace SUBCOMMAND` or its alias `gh cs SUBCOMMAND`.\n\nAs an example of a series of commands you might use to work with {% data variables.product.prodname_github_codespaces %}, you could:\n\n- List your current codespaces, to check whether you have a codespace for a particular repository:\n  `gh codespace list`\n- Create a new codespace for the required repository branch:\n  `gh codespace create -r github/docs -b main`\n- SSH into the new codespace:\n  `gh codespace ssh -c octocat-literate-space-parakeet-7gwrqp9q9jcx4vq`\n- Forward a port to your local machine:\n  `gh codespace ports forward 8000:8000 -c octocat-literate-space-parakeet-7gwrqp9q9jcx4vq`\n\n\n\n`gh` commands for {% data variables.product.prodname_github_codespaces %}\n\nThe sections below give example commands for each of the available operations.\n\nFor a complete reference of `gh` commands for {% data variables.product.prodname_github_codespaces %}, including details of all available options for each comman", "Y2h1bmtfMV9pbmRleF85ODA=": "d, see the {% data variables.product.prodname_cli %} online help for \"gh codespace.\" Alternatively, on the command line, use `gh codespace --help` for general help or `gh codespace SUBCOMMAND --help` for help with a specific subcommand.\n\n{% note %}\n\n**Note**: The `-c CODESPACE_NAME` flag, used with many commands, is optional. If you omit it a list of codespaces is displayed for you to choose from.\n\n{% endnote %}\n\n\n\nList all of your codespaces\n\n```shell\ngh codespace list\n```\n\nThe list includes the unique name of each codespace, which you can use in other `gh codespace` commands.\n\nAn asterisk at the end of the branch name for a codespace indicates that there are uncommitted or unpushed changes in that codespace.\n\n\n\nCreate a new codespace\n\n```shell\ngh codespace create -r OWNER/REPO_NAME [-b BRANCH]\n```\n\nFor more information, see \"AUTOTITLE.\"\n\n\n\nView details of a codespace\n\n```shell\ngh codespace view\n```\n\nAfter running this command you are prompted to choose one of your existing codespaces. The following information is then displayed:\n- Name of the codespace\n- State (for example, \"Available\" or \"Shutdown\")\n- Repository\n- Git status\n- Path to the dev container configuration file used to create the codespace\n- Machine type\n- Idle timeout\n- Date and time the codespace was created\n- Retention period\n\nFor more information, see the {% data variables.product.prodname_dotcom %} CLI reference.\n\n\n\nStop a codespace\n\n```shell\ngh codespace stop -c CODESPACE-NAME\n```\n\nFor more information, see \"AUTOTITLE.\"\n\n\n\nDelete a codespace\n\n```shell\ngh codespace delete -c CODESPACE-NAME\n```\n\nFor more information, see \"AUTOTITLE.\"\n\n\n\nRename a codespace\n\n```shell\ngh codespace edit -c CODESPACE-NAME -d 'DISPLAY-NAME'\n```\n\nFor more information, see \"AUTOTITLE.\"\n\n\n\nRebuild a codespace\n\n```shell\ngh codespace rebuild\n```\n\nTo perform a full rebuild, add `--full` at the end of this command. For more information, see \"AUTOTITLE.\"\n\nWhen you use this command to rebuild a codespace, it uses the `devcontainer.json` file that is currently saved in the codes", "Y2h1bmtfMl9pbmRleF85ODA=": "pace's system. This happens regardless of whether or not the current state of the file has been saved in source control. For more information, see \"AUTOTITLE.\"\n\n\n\nSSH into a codespace\n\nTo run commands on the remote codespace machine, from your terminal, you can SSH into the codespace.\n\n```shell\ngh codespace ssh -c CODESPACE-NAME\n```\n\n{% note %}\n\n**Note**: {% data reusables.codespaces.ssh-server-installed %}\n\nFor more information about the `devcontainer.json` file and the default container image, see \"AUTOTITLE.\"\n\n{% endnote %}\n\n{% data variables.product.prodname_github_codespaces %} creates a local SSH key automatically to provide a seamless authentication experience. For more information on connecting with SSH, see `gh codespace ssh`.\n\n\n\nOpen a codespace in {% data variables.product.prodname_vscode %}\n\n```shell\ngh codespace code -c CODESPACE-NAME\n```\n\nYou must have {% data variables.product.prodname_vscode_shortname %} installed on your local machine. For more information, see \"AUTOTITLE.\"\n\n\n\nOpen a codespace in JupyterLab\n\n```shell\ngh codespace jupyter -c CODESPACE-NAME\n```\n\n{% data reusables.codespaces.jupyterlab-installed-in-codespace %}\n\n\n\nCopy a file to/from a codespace\n\n```shell\ngh codespace cp [-r] SOURCE(S) DESTINATION\n```\n\nUse the prefix `remote:` on a file or directory name to indicate that it's on the codespace. As with the UNIX `cp` command, the first argument specifies the source and the last specifies the destination. If the destination is a directory, you can specify multiple sources. Use the `-r` (recursive) flag if any of the sources is a directory.\n\nThe location of files and directories on the codespace is relative to the home directory of the remote user.\n\n\n\nExamples\n\n- Copy a file from the local machine to the `$HOME` directory of a codespace:\n\n   `gh codespace cp myfile.txt remote:`\n\n- Copy a file to the directory in which a repository is checked out in a codespace:\n\n   `gh codespace cp myfile.txt remote:/workspaces/REPOSITORY-NAME`\n\n- Copy a file from a codespace to the current directory on", "Y2h1bmtfM19pbmRleF85ODA=": " the local machine:\n\n   `gh codespace cp remote:myfile.txt .`\n\n- Copy three local files to the `$HOME/temp` directory of a codespace:\n\n   `gh codespace cp a1.txt a2.txt a3.txt remote:temp`\n\n- Copy three files from a codespace to the current working directory on the local machine:\n\n   `gh codespace cp remote:a1.txt remote:a2.txt remote:a3.txt .`\n\n- Copy a local directory into the `$HOME` directory of a codespace:\n\n   `gh codespace cp -r mydir remote:`\n\n- Copy a directory from a codespace to the local machine, changing the directory name:\n\n   `gh codespace cp -r remote:mydir mydir-localcopy`\n\nFor more information about the `gh codespace cp` command, including additional flags you can use, see the {% data variables.product.prodname_cli %} manual.\n\n\n\nModify ports in a codespace\n\nYou can forward a port on a codespace to a local port. The port remains forwarded as long as the process is running. To stop forwarding the port, press Control+C.\n\n```shell\ngh codespace ports forward CODESPACE-PORT_NAME:LOCAL-PORT-NAME -c CODESPACE-NAME\n```\n\nTo see details of forwarded ports enter `gh codespace ports` and then choose a codespace.\n\nYou can set the visibility of a forwarded port. {% data reusables.codespaces.port-visibility-settings %}\n\n```shell\ngh codespace ports visibility CODESPACE-PORT:private|org|public -c CODESPACE-NAME\n```\n\nYou can set the visibility for multiple ports with one command. For example:\n\n```shell\ngh codespace ports visibility 80:private 3000:public 3306:org -c CODESPACE-NAME\n```\n\nFor more information, see \"AUTOTITLE.\"\n\n\n\nAccess codespace logs\n\nYou can see the creation log for a codespace. After entering this command you will be asked to enter the passphrase for your SSH key.\n\n```shell\ngh codespace logs -c CODESPACE-NAME\n```\n\nFor more information about the creation log, see \"AUTOTITLE.\"\n\n\n\nAccess remote resources\n\nYou can use the {% data variables.product.prodname_cli %} extension to create a bridge between a codespace and your local machine, so that the codespace can access any remote resource that is access", "Y2h1bmtfNF9pbmRleF85ODA=": "ible from your machine. For more information on using the extension, see \"Using {% data variables.product.prodname_cli %} to access remote resources.\"\n\n{% note %}\n\n**Note**: The {% data variables.product.prodname_cli %} extension is currently in beta and subject to change.\n\n{% endnote %}\n\n\n\nChange the machine type of a codespace\n\n```shell\ngh codespace edit -m MACHINE-TYPE-NAME\n```\n\nFor more information, see the \"{% data variables.product.prodname_cli %}\" tab of \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF82ODM=": "\n\nAbout downgrades\n\nWhen you downgrade your personal account, organization, or enterprise account's subscription, pricing and account feature changes take effect on your next billing date. Downgrading your plan does not affect other subscriptions or usage-based billing for your account. For more information, see \"AUTOTITLE.\"\n\n\n\nDowngrading your personal account's plan\n\nIf you downgrade your personal account from {% data variables.product.prodname_pro %} to {% data variables.product.prodname_free_user %}, the account will lose access to advanced code review tools on private repositories. {% data reusables.gated-features.more-info %}\n\n{% data reusables.user-settings.access_settings %}\n{% data reusables.user-settings.billing_plans %}\n1. Under \"Current plan\", use the **Edit** drop-down and click **Downgrade to Free**.\n   !Screenshot of the \"Current plan\" section of the billing settings page. The \"Edit\" dropdown menu is expanded and highlighted with an orange outline.\n1. Read the information about the features your personal account will no longer have access to on your next billing date, then click **I understand. Continue with downgrade**.\n\nIf you published a {% data variables.product.prodname_pages %} site in a private repository and added a custom domain, remove or update your DNS records before downgrading from {% data variables.product.prodname_pro %} to {% data variables.product.prodname_free_user %}, to avoid the risk of a domain takeover. For more information, see \"AUTOTITLE.\"\n\n\n\nDowngrading your organization's plan\n\n{% data reusables.dotcom_billing.org-billing-perms %}\n\nAfter an organization's plan is downgraded, the organization will lose access to any functionality that is not included in the new plan. If an advanced feature, such as {% data variables.product.prodname_pages %}, is not available for private repositories in your new plan, consider whether you'd like to retain access to the feature by making affected repositories public. For more information, see \"Setting repository visibility.\"\n\nDowngrading f", "Y2h1bmtfMV9pbmRleF82ODM=": "rom {% data variables.product.prodname_ghe_cloud %} disables any SAML settings. If you later purchase {% data variables.product.prodname_enterprise %}, you will need to reconfigure SAML.\n\n{% note %}\n\n**Note:** If your organization is owned by an enterprise account, billing cannot be managed at the organization level. To downgrade, you must remove the organization from the enterprise account first. For more information, see \"AUTOTITLE.\"\n\n{% endnote %}\n\n{% data reusables.organizations.billing-settings %}\n1. Under \"Current plan\", use the **Edit** drop-down and click the downgrade option you want.\n   !Screenshot of the \"Current plan\" section of the billing settings page. The \"Edit\" dropdown menu is expanded and highlighted with an orange outline.\n{% data reusables.dotcom_billing.confirm_cancel_org_plan %}\n\n\n\nDowngrading an organization's plan with legacy per-repository pricing\n\n{% data reusables.dotcom_billing.org-billing-perms %}\n\n{% data reusables.dotcom_billing.switch-legacy-billing %} For more information, see \"AUTOTITLE.\"\n\n{% data reusables.organizations.billing-settings %}\n5. Under \"Subscriptions\", next to your current plan, select the **Edit** dropdown menu and click **Edit plan**.\n1. Under \"Billing/Plans\", next to the plan you want to change, click **Downgrade**.\n1. Enter the reason you're downgrading your account, then click **Downgrade plan**.\n\n\n\nRemoving paid seats from your organization\n\nTo reduce the number of paid seats your organization uses, you can remove members from your organization or convert members to outside collaborators and give them access to only public repositories. For more information, see:\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n{% data reusables.organizations.billing-settings %}\n1. Under \"Current plan\", next to your current plan, select the **Edit** dropdown menu, then click **Remove seats**.\n1. Under \"Remove seats\", select the number of seats you'd like to downgrade to.\n1. Review the information about your new payment on your next billing date, then click **Remove seats**.\n\n{% ifv", "Y2h1bmtfMl9pbmRleF82ODM=": "ersion ghec %}\n\n\n\nDowngrading your enterprise account's plan\n\nEnterprise accounts are only available with {% data variables.product.prodname_enterprise %}, so it's not possible to downgrade an enterprise account to another plan.\n\nTo downgrade the plan of an individual organization within the enterprise account, you must remove the organization from the enterprise account. Removing an organization from an enterprise automatically downgrades the organization to {% data variables.product.prodname_free_team %}. For more information, see \"AUTOTITLE.\"\n\nIf you want to stop paying for {% data variables.product.prodname_enterprise %} altogether and your company pays via invoice, contact {% data variables.contact.contact_enterprise_sales %}. If your company pays for {% data variables.product.prodname_enterprise %} by credit card or PayPal, an enterprise owner can delete the enterprise account. For more information, see \"AUTOTITLE.\"\n\n\n\nRemoving paid seats for your enterprise account\n\n{% data reusables.enterprise-accounts.billing-perms %}\n\n{% note %}\n\n**Note:** If your enterprise account is invoiced, you cannot remove seats on {% data variables.product.prodname_dotcom %}. Instead, contact {% data variables.contact.contact_enterprise_sales %}.\n\n{% endnote %}\n\n{% data reusables.enterprise-accounts.access-enterprise %}\n{% data reusables.enterprise-accounts.settings-tab %}\n{% data reusables.enterprise-accounts.billing-tab %}\n{% data reusables.enterprise-accounts.manage-seats %}\n{% endif %}\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE.\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8xODUw": "---\ntitle: Branches\nintro: Use the REST API to modify branches and their protection settings.\nversions: # DO NOT MANUALLY EDIT. CHANGES WILL BE OVERWRITTEN BY A \ud83e\udd16\n  fpt: '*'\n  ghae: '*'\n  ghec: '*'\n  ghes: '*'\ntopics:\n  - API\nautogenerated: rest\n---\n\n\n\n\n\n", "Y2h1bmtfMF9pbmRleF81NTc=": "\n\nIncorrect client credentials\n\nIf the client\\_id and or client\\_secret you pass are incorrect you will\nreceive this error response.\n\n```json\n{\n  \"error\": \"incorrect_client_credentials\",\n  \"error_description\": \"The client_id and/or client_secret passed are incorrect.\",\n  \"error_uri\": \"/apps/managing-oauth-apps/troubleshooting-oauth-app-access-token-request-errors/#incorrect-client-credentials\"\n}\n```\n\nTo solve this error, make sure you have the correct credentials for your {% data variables.product.prodname_oauth_app %}. Double check the `client_id` and `client_secret` to make sure they are correct and being passed correctly\nto {% data variables.product.product_name %}.\n\n\n\nRedirect URI mismatch\n\nIf you provide a `redirect_uri` that doesn't match what you've registered with your {% data variables.product.prodname_oauth_app %}, you'll receive this error message:\n\n```json\n{\n  \"error\": \"redirect_uri_mismatch\",\n  \"error_description\": \"The redirect_uri MUST match the registered callback URL for this application.\",\n  \"error_uri\": \"/apps/managing-oauth-apps/troubleshooting-authorization-request-errors/#redirect-uri-mismatch2\"\n}\n```\n\nTo correct this error, either provide a `redirect_uri` that matches what\nyou registered or leave out this parameter to use the default one\nregistered with your application.\n\n\n\nBad verification code\n\nIf the verification code you pass is incorrect, expired, or doesn't\nmatch what you received in the first request for authorization you will\nreceive this error.\n\n```json\n{\n  \"error\": \"bad_verification_code\",\n  \"error_description\": \"The code passed is incorrect or expired.\",\n  \"error_uri\": \"/apps/managing-oauth-apps/troubleshooting-oauth-app-access-token-request-errors/#bad-verification-code\"\n}\n```\n\nTo solve this error, start the OAuth authorization process again\nand get a new code.\n\n\n\nUnverified user email\n\nIf the user for whom you are trying to generate a user access token has not verified their primary email address with {% data variables.product.company_short %}, you will receive this error.\n\n```", "Y2h1bmtfMV9pbmRleF81NTc=": "json\n{\n  \"error\": \"unverified_user_email\",\n  \"error_description\": \"The user must have a verified primary email.\",\n  \"error_uri\": \"/apps/managing-oauth-apps/troubleshooting-oauth-app-access-token-request-errors/#unverified_user_email\"\n}\n```\n\nTo resolve this error, prompt the user to verify the primary email address on their {% data variables.product.company_short %} account. For more information, see {% ifversion fpt or ghec %}\"AUTOTITLE.\"{% else %}\"AUTOTITLE\" in the  {% data variables.product.prodname_free_user %} documentation.{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF8xNDE1": "---\ntitle: Deleting custom fields\nintro: 'Learn how to delete a custom field from your {% data variables.projects.project_v2 %}.'\nversions:\n  feature: projects-v2\ntype: tutorial\ntopics:\n  - Projects\nredirect_from:\n  - /issues/planning-and-tracking-with-projects/understanding-field-types/deleting-fields\n---\n\n{% data reusables.projects.project-settings %}\n1. Click the name of the custom field you want to delete.\n1. Click **Delete field**.\n\n   !Screenshot showing the settings for a note field. The \"Delete field\" button is highlighted with an orange outline.\n\n", "Y2h1bmtfMF9pbmRleF82MjQ=": "\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8xOTEx": "\n\nAbout Octokit.rb\n\nIf you want to write a script using Ruby to interact with the {% data variables.product.company_short %} REST API, {% data variables.product.company_short %} recommends that you use the Octokit.rb SDK. Octokit.rb is maintained by {% data variables.product.company_short %}. The SDK implements best practices and makes it easier for you to interact with the REST API via Ruby. Octokit.rb works with all modern browsers, Node.rb, and Deno. For more information about Octokit.rb, see the Octokit.rb README.\n\n\n\nPrerequisites\n\nThis guide assumes that you are familiar with Ruby and the {% data variables.product.company_short %} REST API. For more information about the REST API, see \"AUTOTITLE.\"\n\nYou must install and import the `octokit` gem in order to use the Octokit.rb library. This guide uses import statements in accordance with Ruby's conventions. For more information about different installation methods, see the Octokit.rb README's Installation section.\n\n\n\nInstantiating and authenticating\n\n{% warning %}\n\n**Warning**: Treat your authentication credentials like a password.\n\nTo keep your credentials secure, you can store your credentials as a secret and run your script through  {% data variables.product.prodname_actions %}. For more information, see \"AUTOTITLE.\"\n\n{% ifversion ghec or fpt %}You can also store your credentials as a {% data variables.product.prodname_codespaces %} secret and run your script in {% data variables.product.prodname_codespaces %}. For more information, see \"AUTOTITLE.\"{% endif %}\n\nIf {% ifversion ghec or fpt %}these options are not possible{% else %}this is not possible{% endif %}, consider using another CLI service to store your credentials securely.\n\n{% endwarning %}\n\n\n\nAuthenticating with a {% data variables.product.pat_generic %}\n\nIf you want to use the {% data variables.product.company_short %} REST API for personal use, you can create a {% data variables.product.pat_generic %}. For more information about creating a {% data variables.product.pat_generic %}, see \"AUTOTITLE.", "Y2h1bmtfMV9pbmRleF8xOTEx": "\"\n\nFirst, require the `octokit` library. Then, create an instance of `Octokit` by passing your {% data variables.product.pat_generic %} as the `access_token` option. In the following example, replace `YOUR-TOKEN` with your {% data variables.product.pat_generic %}.\n\n```ruby copy\nrequire 'octokit'\n\noctokit = Octokit::Client.new(access_token: 'YOUR-TOKEN')\n```\n\n\n\nAuthenticating with a {% data variables.product.prodname_github_app %}\n\nIf you want to use the API on behalf of an organization or another user, {% data variables.product.company_short %} recommends that you use a {% data variables.product.prodname_github_app %}. If an endpoint is available to {% data variables.product.prodname_github_apps %}, the REST reference documentation for that endpoint will say \"Works with {% data variables.product.prodname_github_app %}.\" For more information, see \"AUTOTITLE,\" \"AUTOTITLE,\" and \"AUTOTITLE.\"\n\nInstead of requiring `octokit`, create an instance of `Octokit::Client` by passing your {% data variables.product.prodname_github_app %}'s information as options. In the following example, replace `APP_ID` with your app's ID, `PRIVATE_KEY` with your app's private key, and `INSTALLATION_ID` with the ID of the installation of your app that you want to authenticate on behalf of. You can find your app's ID and generate a private key on the settings page for your app. For more information, see \"AUTOTITLE.\" You can get an installation ID with the `GET /users/{username}/installation`, `GET /repos/{owner}/{repo}/installation`, or `GET /orgs/{org}/installation` endpoints. For more information, see \"AUTOTITLE\" in the REST reference documentation.{% ifversion ghes or ghae %} Replace `HOSTNAME` with the name of {% data variables.location.product_location %}.{% endif %}\n\n```ruby copy\nrequire 'octokit'\n\napp = Octokit::Client.new(\n  client_id: APP_ID,\n  client_secret: PRIVATE_KEY,\n  installation_id: INSTALLATION_ID\n)\n\noctokit = Octokit::Client.new(bearer_token: app.create_app_installation.access_token)\n```\n\n\n\nAuthenticating in {% data variable", "Y2h1bmtfMl9pbmRleF8xOTEx": "s.product.prodname_actions %}\n\nIf you want to use the API in a {% data variables.product.prodname_actions %} workflow, {% data variables.product.company_short %} recommends that you authenticate with the built-in `GITHUB_TOKEN` instead of creating a token. You can grant permissions to the `GITHUB_TOKEN` with the `permissions` key. For more information about `GITHUB_TOKEN`, see \"AUTOTITLE.\"\n\nIf your workflow needs to access resources outside of the workflow's repository, then you will not be able to use `GITHUB_TOKEN`. In that case, store your credentials as a secret and replace `GITHUB_TOKEN` in the examples below with the name of your secret. For more information about secrets, see \"AUTOTITLE.\"\n\nIf you use the `run` keyword to execute your Ruby script in your {% data variables.product.prodname_actions %} workflows, you can store the value of `GITHUB_TOKEN` as an environment variable. Your script can access the environment variable as `ENV['VARIABLE_NAME']`.\n\nFor example, this workflow step stores `GITHUB_TOKEN` in an environment variable called `TOKEN`:\n\n```yaml\n- name: Run script\n  env:\n    TOKEN: {% raw %}${{ secrets.GITHUB_TOKEN }}{% endraw %}\n  run: |\n    ruby .github/actions-scripts/use-the-api.rb\n```\n\nThe script that the workflow runs uses `ENV['TOKEN']` to authenticate:\n\n```ruby copy\nrequire 'octokit'\n\noctokit = Octokit::Client.new(access_token: ENV['TOKEN'])\n```\n\n\n\nInstantiating without authentication\n\nYou can use the REST API without authentication, although you will have a lower rate limit and will not be able to use some endpoints. To create an instance of `Octokit` without authenticating, do not pass the `access_token` option.\n\n```ruby copy\nrequire 'octokit'\n\noctokit = Octokit::Client.new\n```\n\n\n\nMaking requests\n\nOctokit supports multiple ways of making requests. You can use the `request` method to make requests if you know the HTTP verb and path for the endpoint. You can use the `rest` method if you want to take advantage of autocompletion in your IDE and typing. For paginated endpoints, you can use ", "Y2h1bmtfM19pbmRleF8xOTEx": "the `paginate` method to request multiple pages of data.\n\n\n\nUsing the `request` method to make requests\n\nTo use the `request` method to make requests, pass the HTTP method and path as the first argument. Pass any body, query, or path parameters in a hash as the second argument. For example, to make a `GET` request to `/repos/{owner}/{repo}/issues` and pass the `owner`, `repo`, and `per_page` parameters:\n\n```ruby copy\noctokit.request(\"GET /repos/{owner}/{repo}/issues\", owner: \"github\", repo: \"docs\", per_page: 2)\n```\n\nThe `request` method automatically passes the `Accept: application/vnd.github+json` header. To pass additional headers or a different `Accept` header, add a `headers` option to the hash that is passed as a second argument. The value of the `headers` option is a hash with the header names as keys and header values as values. For example, to send a `content-type` header with a value of `text/plain`:\n\n```ruby copy\noctokit.request(\"POST /markdown/raw\", text: \"Hello **world**\", headers: { \"content-type\" => \"text/plain\" })\n```\n\n\n\nUsing `rest` endpoint methods to make requests\n\nEvery REST API endpoint has an associated `rest` endpoint method in Octokit. These methods generally autocomplete in your IDE for convenience. You can pass any parameters as a hash to the method.\n\n```ruby copy\noctokit.rest.issues.list_for_repo(owner: \"github\", repo: \"docs\", per_page: 2)\n```\n\n\n\nMaking paginated requests\n\nIf the endpoint is paginated and you want to fetch more than one page of results, you can use the `paginate` method. `paginate` will fetch the next page of results until it reaches the last page and then return all of the results as an array. A few endpoints return paginated results as an array in an object, as opposed to returning the paginated results as an array. `paginate` always returns an array of items even if the raw result was an object.\n\nFor example, the following example gets all of the issues from the `github/docs` repository. Although it requests 100 issues at a time, the function won't return until the la", "Y2h1bmtfNF9pbmRleF8xOTEx": "st page of data is reached.\n\n```ruby copy\nissue_data = octokit.paginate(\"GET /repos/{owner}/{repo}/issues\", owner: \"github\", repo: \"docs\", per_page: 100)\n```\n\nThe `paginate` method accepts an optional block, which you can use to process each page of results. This allows you to collect only the data that you want from the response. For example, the following example continues to fetch results until an issue that includes \"test\" in the title is returned. For the pages of data that were returned, only the issue title and author are stored.\n\n```ruby copy\nissue_data = octokit.paginate(\"GET /repos/{owner}/{repo}/issues\", owner: \"github\", repo: \"docs\", per_page: 100) do |response, done|\n  response.data.map do |issue|\n    if issue.title.include?(\"test\")\n      done.call\n    end\n    { title: issue.title, author: issue.user.login }\n  end\nend\n```\n\nInstead of fetching all of the results at once, you can use `octokit.paginate.iterator()` to iterate through a single page at a time. For example, the following example fetches one page of results at a time and processes each object from the page before fetching the next page. Once an issue that includes \"test\" in the title is reached, the script stops the iteration and returns the issue title and issue author of each object that was processed. The iterator is the most memory-efficient method for fetching paginated data.\n\n```ruby copy\niterator = octokit.paginate.iterator(\"GET /repos/{owner}/{repo}/issues\", owner: \"github\", repo: \"docs\", per_page: 100)\nissue_data = []\nbreak_loop = false\niterator.each do |data|\n  break if break_loop\n  data.each do |issue|\n    if issue.title.include?(\"test\")\n      break_loop = true\n      break\n    else\n      issue_data << { title: issue.title, author: issue.user.login }\n    end\n  end\nend\n```\n\nYou can use the `paginate` method with the `rest` endpoint methods as well. Pass the `rest` endpoint method as the first argument and any parameters as the second argument.\n\n```ruby copy\niterator = octokit.paginate.iterator(octokit.rest.issues.list_for_repo, owne", "Y2h1bmtfNV9pbmRleF8xOTEx": "r: \"github\", repo: \"docs\", per_page: 100)\n```\n\nFor more information about pagination, see \"AUTOTITLE.\"\n\n\n\nCatching errors\n\n\n\nCatching all errors\n\nSometimes, the {% data variables.product.company_short %} REST API will return an error. For example, you will get an error if your access token is expired or if you omitted a required parameter. Octokit.rb automatically retries the request when it gets an error other than `400 Bad Request`, `401 Unauthorized`, `403 Forbidden`, `404 Not Found`, and `422 Unprocessable Entity`. If an API error occurs even after retries, Octokit.rb throws an error that includes the HTTP status code of the response (`response.status`) and the response headers (`response.headers`). You should handle these errors in your code. For example, you can use a try/catch block to catch errors:\n\n```ruby copy\nbegin\nfiles_changed = []\n\niterator = octokit.paginate.iterator(\"GET /repos/{owner}/{repo}/pulls/{pull_number}/files\", owner: \"github\", repo: \"docs\", pull_number: 22809, per_page: 100)\niterator.each do | data |\n    files_changed.concat(data.map {\n      | file_data | file_data.filename\n    })\n  end\nrescue Octokit::Error => error\nif error.response\nputs \"Error! Status: #{error.response.status}. Message: #{error.response.data.message}\"\nend\nputs error\nend\n```\n\n\n\nHandling intended error codes\n\nSometimes, {% data variables.product.company_short %} uses a 4xx status code to indicate a non-error response. If the endpoint you are using does this, you can add additional handling for specific errors. For example, the `GET /user/starred/{owner}/{repo}` endpoint will return a `404` if the repository is not starred. The following example uses the `404` response to indicate that the repository was not starred; all other error codes are treated as errors.\n\n```ruby copy\nbegin\noctokit.request(\"GET /user/starred/{owner}/{repo}\", owner: \"github\", repo: \"docs\")\nputs \"The repository is starred by me\"\nrescue Octokit::NotFound => error\nputs \"The repository is not starred by me\"\nrescue Octokit::Error => error\nputs \"An error", "Y2h1bmtfNl9pbmRleF8xOTEx": " occurred while checking if the repository is starred: #{error&.response&.data&.message}\"\nend\n```\n\n\n\nHandling rate limit errors\n\nIf you receive a rate limit error, you may want to retry your request after waiting. When you are rate limited, {% data variables.product.company_short %} responds with a `403 Forbidden` error, and the `x-ratelimit-remaining` response header value will be `\"0\"`. The response headers will include a `x-ratelimit-reset` header, which tells you the time at which the current rate limit window resets, in UTC epoch seconds. You can retry your request after the time specified by `x-ratelimit-reset`.\n\n```ruby copy\ndef request_retry(route, parameters)\n begin\n response = octokit.request(route, parameters)\n return response\n rescue Octokit::RateLimitExceeded => error\n reset_time_epoch_seconds = error.response.headers['x-ratelimit-reset'].to_i\n current_time_epoch_seconds = Time.now.to_i\n seconds_to_wait = reset_time_epoch_seconds - current_time_epoch_seconds\n puts \"You have exceeded your rate limit. Retrying in #{seconds_to_wait} seconds.\"\n sleep(seconds_to_wait)\n retry\n rescue Octokit::Error => error\n puts error\n end\n end\n\n response = request_retry(\"GET /repos/{owner}/{repo}/issues\", owner: \"github\", repo: \"docs\", per_page: 2)\n```\n\n\n\nUsing the response\n\nThe `request` method returns a response object if the request was successful. The response object contains `data` (the response body returned by the endpoint), `status` (the HTTP response code), `url` (the URL of the request), and `headers` (a hash containing the response headers). Unless otherwise specified, the response body is in JSON format. Some endpoints do not return a response body; in those cases, the `data` property is omitted.\n\n```ruby copy\nresponse = octokit.request(\"GET /repos/{owner}/{repo}/issues/{issue_number}\", owner: \"github\", repo: \"docs\", issue_number: 11901)\n puts \"The status of the response is: #{response.status}\"\n puts \"The request URL was: #{response.url}\"\n puts \"The x-ratelimit-remaining response header is: #{response.headers", "Y2h1bmtfN19pbmRleF8xOTEx": "['x-ratelimit-remaining']}\"\n puts \"The issue title is: #{response.data['title']}\"\n```\n\nSimilarly, the `paginate` method returns a response object. If the `request` was successful, the `response` object contains data, status, url, and headers.\n\n```ruby copy\nresponse = octokit.paginate(\"GET /repos/{owner}/{repo}/issues\", owner: \"github\", repo: \"docs\", per_page: 100)\nputs \"#{response.data.length} issues were returned\"\nputs \"The title of the first issue is: #{response.data[0]['title']}\"\n```\n\n\n\nExample script\n\nHere is a full example script that uses Octokit.rb. The script imports ``Octokit`` and creates a new instance of `Octokit`. If you want to authenticate with a {% data variables.product.prodname_github_app %} instead of a {% data variables.product.pat_generic %}, you would import and instantiate `App` instead of `Octokit`. For more information, see \"Authenticating with a {% data variables.product.prodname_github_app %}\" in this guide.\n\nThe `get_changed_files` function gets all of the files changed for a pull request. The `comment_if_data_files_changed` function calls the `get_changed_files` function. If any of the files that the pull request changed include `/data/` in the file path, then the function will comment on the pull request.\n\n```ruby copy\nrequire \"octokit\"\n\n octokit = Octokit::Client.new(access_token: \"YOUR-TOKEN\")\n\n def get_changed_files(octokit, owner, repo, pull_number)\n files_changed = []\n\n begin\n iterator = octokit.paginate.iterator(\"GET /repos/{owner}/{repo}/pulls/{pull_number}/files\", owner: owner, repo: repo, pull_number: pull_number, per_page: 100)\n iterator.each do | data |\n     files_changed.concat(data.map {\n       | file_data | file_data.filename\n     })\n   end\n rescue Octokit::Error => error\n if error.response\n puts \"Error! Status: #{error.response.status}. Message: #{error.response.data.message}\"\n end\n puts error\n end\n\n files_changed\n end\n\n def comment_if_data_files_changed(octokit, owner, repo, pull_number)\n changed_files = get_changed_files(octokit, owner, repo, pull_number)\n\n if change", "Y2h1bmtfOF9pbmRleF8xOTEx": "d_files.any ? {\n   | file_name | /\\/data\\//i.match ? (file_name)\n }\n begin\n comment = octokit.create_pull_request_review_comment(owner, repo, pull_number, \"It looks like you changed a data file. These files are auto-generated. \\n\\nYou must revert any changes to data files before your pull request will be reviewed.\")\n comment.html_url\n rescue Octokit::Error => error\n if error.response\n puts \"Error! Status: #{error.response.status}. Message: #{error.response.data.message}\"\n end\n puts error\n end\n end\n end\n\n\n\nExample usage\nowner = \"github\"\nrepo = \"docs\"\npull_number = 22809\ncomment_url = comment_if_data_files_changed(octokit, owner, repo, pull_number)\n\nputs \"A comment was added to the pull request: #{comment_url}\"\n```\n\n{% note %}\n\n**Note:** This is just a basic example. In practice, you may want to use error handling and conditional checks to handle various scenarios.\n\n{% endnote %}\n\n\n\nNext steps\n\nTo learn more about working with the {% data variables.product.company_short %} REST API and Octokit.rb, explore the following resources:\n\n- To learn more about Octokit.rb see the Octokit.rb documentation.\n- To find detailed information about {% data variables.product.company_short %}'s available REST API endpoints, including their request and response structures, see the AUTOTITLE.\n\n", "Y2h1bmtfMF9pbmRleF8xMDU2": "\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8yMzQ=": "\n\nAbout {% data variables.product.prodname_enterprise_backup_utilities %}\n\n{% data variables.product.prodname_enterprise_backup_utilities %} is a backup system you install on a separate host, which takes backup snapshots of {% data variables.location.product_location %} at regular intervals over a secure SSH network connection. You can use a snapshot to restore an existing {% data variables.product.prodname_ghe_server %} instance to a previous state from the backup host.\n\nOnly data added since the last snapshot will transfer over the network and occupy additional physical storage space. To minimize performance impact, backups are performed online under the lowest CPU/IO priority. You do not need to schedule a maintenance window to perform a backup.\n\nMajor releases and version numbers for {% data variables.product.prodname_enterprise_backup_utilities %} align with feature releases of {% data variables.product.product_name %}. We support the four most recent versions of both products. For more information, see \"AUTOTITLE.\"\n\nFor more detailed information on features, requirements, and advanced usage, see the {% data variables.product.prodname_enterprise_backup_utilities %} README in the {% data variables.product.prodname_enterprise_backup_utilities %} project documentation.\n\n\n\nPrerequisites\n\nTo use {% data variables.product.prodname_enterprise_backup_utilities %}, you must have a host system separate from {% data variables.location.product_location %}. For details about how the system should be configured, see Requirements in the github/backup-utils repository.\n\nYou can also integrate {% data variables.product.prodname_enterprise_backup_utilities %} into an existing environment for long-term permanent storage of critical data.\n\nWe recommend that the backup host and {% data variables.location.product_location %} be geographically distant from each other. This ensures that backups are available for recovery in the event of a major disaster or network outage at the primary site.\n\nPhysical storage requirements will vary", "Y2h1bmtfMV9pbmRleF8yMzQ=": " based on Git repository disk usage and expected growth patterns:\n\n| Hardware | Recommendation |\n| -------- | --------- |\n| **vCPUs**  | 4 |\n| **Memory** | 8 GB |\n| **Storage** | Five times the primary instance's allocated storage |\n\nMore resources may be required depending on your usage, such as user activity and selected integrations.\n\nFor more information, see {% data variables.product.prodname_enterprise_backup_utilities %} requirements in the {% data variables.product.prodname_enterprise_backup_utilities %} project documentation.\n\n\n\nInstalling {% data variables.product.prodname_enterprise_backup_utilities %}\n\nTo install {% data variables.product.prodname_enterprise_backup_utilities %} on your backup host, download the latest version of {% data variables.product.prodname_enterprise_backup_utilities %} from the github/backup-utils repository that is compatible with your version of {% data variables.product.product_name %}. For example, if you are running version 3.8.4 of {% data variables.product.product_name %}, then download the latest version of {% data variables.product.prodname_enterprise_backup_utilities %} in the 3.10 series. This is possible because all versions of {% data variables.product.prodname_enterprise_backup_utilities %} are backwards compatible for 2 versions, meaning the {% data variables.product.prodname_enterprise_backup_utilities %} 3.10 series can be used to backup and restore {% data variables.product.product_name %} instances running versions 3.8, 3.9, or 3.10.\n\nAfter you download a compressed archive, you can extract and install the contents. For more information, see Getting started in the github/backup-utils repository.\n\nIf you have an existing backup configuration file, `backup.config`, ensure you copy the file to the location of the newly extracted and installed version of {% data variables.product.prodname_enterprise_backup_utilities %}.\n\nBackup snapshots created by {% data variables.product.prodname_enterprise_backup_utilities %} are written to the disk path set by the `GHE_DATA", "Y2h1bmtfMl9pbmRleF8yMzQ=": "_DIR` data directory variable in your `backup.config` file. These snapshots need to be stored on a filesystem which supports symbolic and hard links.\n\n{% note %}\n\n**Note:** We recommend ensuring your snapshots are not kept in a subdirectory of the {% data variables.product.prodname_enterprise_backup_utilities %} installation directory, to avoid inadvertently overwriting your data directory when upgrading {% data variables.product.prodname_enterprise_backup_utilities %} versions.\n\n{% endnote %}\n\n1. Download the relevant {% data variables.product.prodname_enterprise_backup_utilities %} release from the Releases page of the github/backup-utils repository.\n\n1. To extract the repository using tar, run the following command.\n\n   ```shell\n   tar -xzvf /path/to/github-backup-utils-vMAJOR.MINOR.PATCH.tar.gz\n   ```\n\n1. To change into the local repository directory, run the following command.\n\n   ```shell\n   cd backup-utils\n   ```\n\n1. To copy the included `backup.config-example` file to `backup.config`, run the following command.\n\n   ```shell\n   cp backup.config-example backup.config\n   ```\n\n1. To customize your configuration, edit `backup.config` in a text editor.\n\n   1. If you previously upgraded {% data variables.product.prodname_enterprise_backup_utilities %} using Git, ensure that you copy your existing configuration from `backup.config` into the new file. For more information, see \"Upgrading {% data variables.product.prodname_enterprise_backup_utilities %}.\"\n   1. Set the `GHE_HOSTNAME` value to your primary {% data variables.product.prodname_ghe_server %} instance's hostname or IP address.\n\n      {% note %}\n\n      **Note:** If {% data variables.location.product_location %} is deployed as a cluster or in a high availability configuration using a load balancer, the `GHE_HOSTNAME` can be the load balancer hostname, as long as the load balancer allows SSH access over port 122 to {% data variables.location.product_location %}.\n\n      To ensure a recovered instance is immediately available, perform backups targeting the pr", "Y2h1bmtfM19pbmRleF8yMzQ=": "imary instance even in a geo-replication configuration.\n\n      {% endnote %}\n   1. Set the `GHE_DATA_DIR` value to the filesystem location where you want to store backup snapshots. We recommend choosing a location on the same filesystem as your backup host.\n1. To grant your backup host access to your instance, open your primary instance's settings page at `http(s)://HOSTNAME/setup/settings` and add the backup host's SSH key to the list of authorized SSH keys. For more information, see \"AUTOTITLE.\"\n1. On your backup host, verify SSH connectivity with {% data variables.location.product_location %} with the `ghe-host-check` command.\n\n   ```shell\n   ./bin/ghe-host-check\n   ```\n\n1. To create an initial full backup, run the following command.\n\n   ```shell\n   ./bin/ghe-backup\n   ```\n\nFor more information on advanced usage, see the {% data variables.product.prodname_enterprise_backup_utilities %} README in the {% data variables.product.prodname_enterprise_backup_utilities %} project documentation.\n\n\n\nUpgrading {% data variables.product.prodname_enterprise_backup_utilities %}\n\nWhen upgrading {% data variables.product.prodname_enterprise_backup_utilities %}, you must choose a version that will work with your current version of {% data variables.product.product_name %}. Your installation of {% data variables.product.prodname_enterprise_backup_utilities %} must be at least the same version as {% data variables.location.product_location %}, and cannot be more than two versions ahead. For more information, see {% data variables.product.prodname_ghe_server %} version requirements in the {% data variables.product.prodname_enterprise_backup_utilities %} project documentation.\n\n1. Verify the installation method for {% data variables.product.prodname_enterprise_backup_utilities %}. Previous versions of {% data variables.product.prodname_enterprise_backup_utilities %} supported installation and updates in a local Git repository, but this method is no longer supported.\n\n   {% data reusables.enterprise_backup_utilities.enterprise-back", "Y2h1bmtfNF9pbmRleF8yMzQ=": "up-utils-directory %}\n   1. To check if a valid working directory exists inside a Git repository, run the following command.\n\n      ```shell\n      git rev-parse --is-inside-work-tree\n      ```\n\n1. To determine how to upgrade {% data variables.product.prodname_enterprise_backup_utilities %}, review the output from `git rev-parse --is-inside-work-tree`.\n\n   - If the output is `true`, {% data variables.product.prodname_enterprise_backup_utilities %} was installed by cloning the project's Git repository. To upgrade, copy your existing configuration in `backup.config`, then follow the instructions in \"Installing {% data variables.product.prodname_enterprise_backup_utilities %}.\"\n   - If the output includes `fatal: not a git repository (or any of the parent directories)`, {% data variables.product.prodname_enterprise_backup_utilities %} was extracted from a compressed archive file. To upgrade, follow the instructions in \"Installing {% data variables.product.prodname_enterprise_backup_utilities %}.\"\n\n\n\nScheduling a backup\n\n{% ifversion backup-utilities-encryption-bug %}\n{% warning %}\n\n**Warning**: {% data reusables.enterprise_backup_utilities.enterprise-backup-utils-encryption-keys %}\n\n{% endwarning %}\n{% endif %}\n\nYou can schedule regular backups on the backup host using the `cron(8)` command or a similar command scheduling service. The configured backup frequency will dictate the worst case recovery point objective (RPO) in your recovery plan. For example, if you have scheduled the backup to run every day at midnight, you could lose up to 24 hours of data in a disaster scenario. We recommend starting with an hourly backup schedule, guaranteeing a worst case maximum of one hour of data loss if the primary site data is destroyed.\n\nIf backup attempts overlap, the `ghe-backup` command will abort with an error message, indicating the existence of a simultaneous backup. If this occurs, we recommended decreasing the frequency of your scheduled backups. For more information, see the \"Scheduling backups\" section of the {% data", "Y2h1bmtfNV9pbmRleF8yMzQ=": " variables.product.prodname_enterprise_backup_utilities %} README in the {% data variables.product.prodname_enterprise_backup_utilities %} project documentation.\n\n\n\nRestoring a backup\n\n{% ifversion backup-utilities-encryption-bug %}\n\n{% warning %}\n\n**Warning**: {% data reusables.enterprise_backup_utilities.enterprise-backup-utils-encryption-keys %}\n\n{% endwarning %}\n\n{% endif %}\n\nIn the event of prolonged outage or catastrophic event at the primary site, you can restore {% data variables.location.product_location %} by provisioning another instance and performing a restore from the backup host. You must add the backup host's SSH key to the target {% data variables.product.prodname_enterprise %} instance as an authorized SSH key before restoring an instance.\n\nWhen performing backup restores to {% data variables.location.product_location %}, you can only restore data from at most two feature releases behind. For example, if you take a backup from {% data variables.product.product_name %} 3.0.x, you can restore the backup to an instance running {% data variables.product.product_name %} 3.2.x. You cannot restore data from a backup of {% data variables.product.product_name %} 2.22.x to an instance running 3.2.x, because that would be three jumps between versions (2.22 to 3.0 to 3.1 to 3.2). You would first need to restore to an instance running 3.1.x, and then upgrade to 3.2.x.\n\nNetwork settings are excluded from the backup snapshot. After restoration, you must manually configure networking on the target {% data variables.product.prodname_ghe_server %} instance.\n\n\n\nPrerequisites\n\n1. Ensure maintenance mode is enabled on the primary instance and all active processes have completed. For more information, see \"AUTOTITLE.\"\n1. Stop replication on all replica nodes in a high-availability configuration. For more information, see \"AUTOTITLE.\"\n1. Provision a new {% data variables.product.product_name %} instance to use as a target for the restoration of your backup. For more information, see \"AUTOTITLE.\"\n1. If {% data variable", "Y2h1bmtfNl9pbmRleF8yMzQ=": "s.location.product_location %} has {% data variables.product.prodname_actions %} enabled, you must configure the external storage provider for {% data variables.product.prodname_actions %} on the replacement instance. For more information, see \"AUTOTITLE.\"\n\n\n\nStarting the restore operation\n\nTo restore {% data variables.location.product_location %} from your backup host using the last successful snapshot, use the `ghe-restore` command. You can use the following additional options with `ghe-restore`.\n\n- The `-c` flag overwrites the settings, certificate, and license data on the target host even if it is already configured. Omit this flag if you are setting up a staging instance for testing purposes and you wish to retain the existing configuration on the target. For more information, see the \"Using backup and restore commands\" section of the {% data variables.product.prodname_enterprise_backup_utilities %} README in the github/backup-utils repository.\n- The `-s` flag allows you to select a different backup snapshot.\n\nAfter you run `ghe-restore`, the command confirms the restoration, then outputs details and status during the operation.\n\n```shell\n$ ghe-restore -c 169.154.1.1\n> Checking for leaked keys in the backup snapshot that is being restored ...\n> * No leaked keys found\n> Connect 169.154.1.1:122 OK (v2.9.0)\n\n> WARNING: All data on GitHub Enterprise appliance 169.154.1.1 (v2.9.0)\n>          will be overwritten with data from snapshot 20170329T150710.\n> Please verify that this is the correct restore host before continuing.\n> Type 'yes' to continue: yes\n\n> Starting restore of 169.154.1.1:122 from snapshot 20170329T150710\n\n\n...output truncated\n> Completed restore of 169.154.1.1:122 from snapshot 20170329T150710\n> Visit https://169.154.1.1/setup/settings to review appliance configuration.\n```\n\n{% ifversion ip-exception-list %}\nOptionally, to validate the restore, configure an IP exception list to allow access to a specified list of IP addresses. For more information, see \"AUTOTITLE.\"\n{% endif %}\n\nOn an instance in a", "Y2h1bmtfN19pbmRleF8yMzQ=": " high-availability configuration, after you restore to new disks on an existing or empty instance, `ghe-repl-status` may report that Git or Alambic replication is out of sync due to stale server UUIDs. These stale UUIDs can be the result of a retired node in a high-availability configuration still being present in the application database, but not in the restored replication configuration.\n\nTo remediate after the restoration completes and before starting replication, you can tear down stale UUIDs using `ghe-repl-teardown`. If you need further assistance, visit {% data variables.contact.contact_ent_support %}.\n\n{% ifversion backup-utilities-progress %}\n\n\n\nMonitoring backup or restoration progress\n\nDuring a backup or restoration operation, you can use the `ghe-backup-progress` utility on your backup host to monitor the operation's progress. The utility prints the progress of each job sequentially.\n\nTo monitor progress on the backup host, from the directory containing {% data variables.product.prodname_enterprise_backup_utilities %}, run the following command.\n\n```shell copy\nbin/ghe-backup-progress\n```\n\nBy default, the utility prints progress continuously until the operation is complete. You can press any key to return to the prompt.\n\nOptionally, you can run the following command to print the current progress, the last completed job, and then immediately exit.\n\n```shell copy\nbin/ghe-backup-progress --once\n```\n\n{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF8xMjA3": "\n\n{% data variables.product.prodname_global_campus %} features for students\n\n{% data variables.product.prodname_global_campus %} is a portal from which you can access your {% data variables.product.prodname_education %} benefits and resources, all in one place. On the {% data variables.product.prodname_global_campus %} portal, students can:\n- Connect with a local Campus Expert. For more information on campus experts, see \"AUTOTITLE.\"\n- Gain in-depth understanding of a feature, tool, or topic with curated experiences designed to support your learning journey.\n- Explore and claim offers for free industry tools from the Student Developer Pack.\n- See upcoming in-person and virtual events for students, curated by {% data variables.product.prodname_education %} and student leaders.\n- View assignments from GitHub Classroom with upcoming due dates.\n- Stay in the know on what the community is interested in by rewatching recent Campus TV episodes. Campus TV is created by {% data variables.product.prodname_dotcom %} and student community leaders and can be watched live or on demand.\n- Discover student-created repositories from {% data variables.product.prodname_community_exchange %}. For more information, see \"AUTOTITLE.\"\n\n{% data variables.product.prodname_global_campus %} students also receive the following {% data variables.product.prodname_dotcom %} benefits.\n- **{% data variables.product.prodname_copilot %}**: Verified students receive a free subscription for {% data variables.product.prodname_copilot %}. You will be automatically notified about the free subscription when you visit the {% data variables.product.prodname_copilot %} subscription page in your account settings. For more information about subscribing to and using {% data variables.product.prodname_copilot %}, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n- **{% data variables.product.prodname_github_codespaces %}**: {% data reusables.education.student-codespaces-benefit %} For more information on getting started with {% data variables.product.prodname_github_codespaces ", "Y2h1bmtfMV9pbmRleF8xMjA3": "%}, see \"AUTOTITLE.\"\n\n{% note %}\n\n**Note:** {% data reusables.education.note-on-student-codespaces-usage %} For more information, see \"AUTOTITLE.\"\n\n{% endnote %}\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8yMDY2": "---\ntitle: GitHub Cookies\nredirect_from:\n  - /subprocessors\n  - /github-subprocessors\n  - /github-tracking\n  - /github-cookies\n  - /articles/github-subprocessors-and-cookies\n  - /github/site-policy/github-subprocessors-and-cookies\n  - /site-policy/privacy-policies/github-subprocessors-and-cookies\nversions:\n  fpt: '*'\ntopics:\n  - Policy\n  - Legal\n---\n\nGitHub uses cookies to provide and secure our websites, as well as to analyze the usage of our websites, in order to offer you a great user experience. Please take a look at our Privacy Statement if you\u2019d like more information about cookies, and on how and why we use them.\n\nYou can view the current list of cookies on GitHub, and sign up to receive cookie list updates, at https://github.com/privacy/cookies.\n\nIf you have questions or concerns about a new subprocessor, please contact us via {% data variables.contact.contact_privacy %}.\n\n", "Y2h1bmtfMF9pbmRleF81MDM=": "\n\nAbout badges\n\nEvery {% data variables.product.prodname_github_app %} has a badge. A badge is a square image inside a circular background.\n\nBy default, a new GitHub App will use an automatically generated identicon as a badge. An identicon badge looks something like this:\n\n!Screenshot of an identicon, which consists of white pixels in a random pattern on a circular yellow background.\n\nAfter you register a GitHub App, you can customize your app's badge by uploading a logo and selecting a background color. Your logo should be a PNG, JPG, or GIF file under 1 MB in size. For the best quality rendering, we recommend an image dimension of 200 pixels by 200 pixels.\n\n{% ifversion fpt or ghec %}\n\nFor more information about badges for {% data variables.product.prodname_github_apps %} in {% data variables.product.prodname_marketplace %}, see \"AUTOTITLE.\" You can change a custom badge for a GitHub App that already has an approved Marketplace listing by navigating to https://github.com/marketplace/manage.\n\n{% endif %}\n\n\n\nCreating a custom badge\n\n{% data reusables.apps.settings-step %}\n{% data reusables.user-settings.developer_settings %}\n{% data reusables.user-settings.github_apps %}\n{% data reusables.user-settings.modify_github_app %}\n1. Under \"Display information\", drag and drop an image from a local folder or click **Upload a logo** to select an image from your computer.\n1. Optionally, crop your image.\n1. Click **Set new avatar**.\n1. Under \"Badge background color\", type the hexadecimal color code of the background color for your badge.\n\n{% ifversion fpt or ghec %}\n   {% note %}\n\n   **Note:** The \"Badge background color\" input field will only appear after you upload a logo.\n\n   {% endnote %}\n{% endif %}\n\n{% ifversion fpt or ghec %}\n\n\n\nNext steps\n\nFor more information about listing your {% data variables.product.prodname_github_app %} in {% data variables.product.prodname_marketplace %}, see \"AUTOTITLE.\"\n\n{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF8xODc3": "---\ntitle: Protection rules\nshortTitle: Protection rules\nintro: 'Use the REST API to create, configure, and delete deployment protection rules.'\nversions: # DO NOT MANUALLY EDIT. CHANGES WILL BE OVERWRITTEN BY A \ud83e\udd16\n  fpt: '*'\n  ghec: '*'\n  ghes: '>=3.10'\ntopics:\n  - API\nautogenerated: rest\nallowTitleToDifferFromFilename: true\n---\n\n\n\n", "Y2h1bmtfMF9pbmRleF8xOTk2": "\n\nAbout primary rate limits\n\n{% data variables.product.company_short %} limits the number of REST API requests that you can make within a specific amount of time. This limit helps prevent abuse and denial-of-service attacks, and ensures that the API remains available for all users.\n\nSome endpoints, like the search endpoints, have more restrictive limits. For more information about these endpoints, see \"AUTOTITLE.\" The GraphQL API also has a separate primary rate limit. For more information, see \"AUTOTITLE.\"\n\nIn general, you can calculate your primary rate limit for the REST API based on your method of authentication, as described below.\n\n\n\nPrimary rate limit for unauthenticated users\n\nYou can make unauthenticated requests if you are only fetching public data. Unauthenticated requests are associated with the originating IP address, not with the user or application that made the request.\n\nThe primary rate limit for unauthenticated requests is 60 requests per hour.\n\n\n\nPrimary rate limit for authenticated users\n\nYou can use a {% data variables.product.pat_generic %} to make API requests. Additionally, you can authorize a {% data variables.product.prodname_github_app %} or {% data variables.product.prodname_oauth_app %}, which can then make API requests on your behalf.\n\nAll of these requests count towards your personal rate limit of {% ifversion ghae %}15,000{% else %}5,000{% endif %} requests per hour. {% ifversion fpt or ghec %}Requests made on your behalf by a {% data variables.product.prodname_github_app %} that is owned by a {% data variables.product.prodname_ghe_cloud %} organization have a higher rate limit of 15,000 requests per hour. Similarly, requests made on your behalf by a {% data variables.product.prodname_oauth_app %} that is owned or approved by a {% data variables.product.prodname_ghe_cloud %} organization have a higher rate limit of 15,000 requests per hour if you are a member of the {% data variables.product.prodname_ghe_cloud %} organization.{% endif %}\n\n\n\nPrimary rate limit for {% data variables.", "Y2h1bmtfMV9pbmRleF8xOTk2": "product.prodname_github_app %} installations\n\n{% data variables.product.prodname_github_apps %} authenticating with an installation access token use the installation's minimum rate limit of 5,000 requests per hour. If the installation is on a {% data variables.product.prodname_ghe_cloud %} organization, the installation has a rate limit of 15,000 requests per hour.\n\nFor installations that are not on a {% data variables.product.prodname_ghe_cloud %} organization, the rate limit for the installation will scale with the number of users and repositories. Installations that have more than 20 repositories receive another 50 requests per hour for each repository. Installations that are on an organization that have more than 20 users receive another 50 requests per hour for each user. The rate limit cannot increase beyond 12,500 requests per hour.\n\nPrimary rate limits for {% data variables.product.prodname_github_app %} user access tokens (as opposed to installation access tokens) are dictated by the primary rate limits for the authenticated user. This rate limit is combined with any requests that another {% data variables.product.prodname_github_app %} or {% data variables.product.prodname_oauth_app %} makes on that user's behalf and any requests that the user makes with a {% data variables.product.pat_generic %}. For more information, see \"Primary rate limit for authenticated users.\"\n\n\n\nPrimary rate limit for {% data variables.product.prodname_oauth_apps %}\n\nPrimary rate limits for OAuth access tokens generated by a {% data variables.product.prodname_oauth_app %} are dictated by the primary rate limits for authenticated users. This rate limit is combined with any requests that another {% data variables.product.prodname_github_app %} or {% data variables.product.prodname_oauth_app %} makes on that user's behalf and any requests that the user makes with a {% data variables.product.pat_generic %}. For more information, see \"Primary rate limit for authenticated users.\"\n\nOAuth apps can also use their client ID and client se", "Y2h1bmtfMl9pbmRleF8xOTk2": "cret to fetch public data. For example:\n\n```shell\ncurl -u YOUR_CLIENT_ID:YOUR_CLIENT_SECRET -I {% data variables.product.api_url_pre %}/meta\n```\n\nFor these requests, the rate limit is 5,000 requests per hour per {% data variables.product.prodname_oauth_app %}. If the app is owned by a {% data variables.product.prodname_ghe_cloud %} organization, the rate limit is 15,000 requests per hour.\n\n{% note %}\n\n**Note:** Never include your app's client secret in client-side code or in code that runs on a user device. The client secret can be used to generate OAuth access tokens for users who have authorized your app, so you should always keep the client secret secure.\n\n{% endnote %}\n\n\n\nPrimary rate limit for `GITHUB_TOKEN` in {% data variables.product.prodname_actions %}\n\nYou can use the built-in `GITHUB_TOKEN` to authenticate requests in GitHub Actions workflows. For more information, see \"AUTOTITLE.\"\n\nThe rate limit for `GITHUB_TOKEN` is 1,000 requests per hour per repository.{% ifversion fpt or ghec %} For requests to resources that belong to a {% data variables.product.prodname_ghe_cloud %} account, the limit is 15,000 requests per hour per repository.{% endif %}\n\n\n\nAbout secondary rate limits\n\n{% data reusables.rest-api.secondary-rate-limit-rest-graphql %}\n\n\n\nChecking the status of your rate limit\n\nYou can use the headers that are sent with each response to determine the current status of your primary rate limit.\n\nHeader name | Description\n-----------|-----------|\n`x-ratelimit-limit` | The maximum number of requests that you can make per hour\n`x-ratelimit-remaining` | The number of requests remaining in the current rate limit window\n`x-ratelimit-used` | The number of requests you have made in the current rate limit window\n`x-ratelimit-reset` | The time at which the current rate limit window resets, in UTC epoch seconds\n`x-ratelimit-resource` | The rate limit resource that the request counted against. For more information about the different resources, see \"AUTOTITLE.\"\n\nYou can also call the `GET /rate_limit` endpoint ", "Y2h1bmtfM19pbmRleF8xOTk2": "to check your rate limit. Calling this endpoint does not count against your primary rate limit, but it can count against your secondary rate limit. For more information, see \"AUTOTITLE.\" When possible, you should use the rate limit response headers instead of calling the API to check your rate limit.\n\nThere is not a way to check the status of your secondary rate limit.\n\n\n\nExceeding the rate limit\n\nIf you exceed your primary rate limit, you will receive a `403` or `429` response, and the `x-ratelimit-remaining` header will be `0`. You should not retry your request until after the time specified by the `x-ratelimit-reset` header.\n\nIf you exceed a secondary rate limit, you will receive a `403` or `429` response and an error message that indicates that you exceeded a secondary rate limit. If the `retry-after` response header is present, you should not retry your request until after that many seconds has elapsed. If the `x-ratelimit-remaining` header is `0`, you should not retry your request until after the time, in UTC epoch seconds, specified by the `x-ratelimit-reset` header. Otherwise, wait for at least one minute before retrying. If your request continues to fail due to a secondary rate limit, wait for an exponentially increasing amount of time between retries, and throw an error after a specific number of retries.\n\nContinuing to make requests while you are rate limited may result in the banning of your integration.\n\n\n\nStaying under the rate limit\n\nYou should follow best practices to help you stay under the rate limits. For more information, see \"AUTOTITLE.\"\n\n{% ifversion audit-log-streaming %}\n\nYou can also stream the audit log in order to view API requests. This can help you troubleshoot integrations that are exceeding the rate limit. For more information, see \"AUTOTITLE.\"\n\n{% endif %}\n\n\n\nGetting a higher rate limit\n\nIf you want a higher primary rate limit, consider making authenticated requests instead of unauthenticated requests. Authenticated requests have a significantly higher rate limit than unauthenticat", "Y2h1bmtfNF9pbmRleF8xOTk2": "ed requests.\n\nIf you are using a {% data variables.product.pat_generic %} for automation in your organization, consider whether a {% data variables.product.prodname_github_app %} will work instead. The rate limit for {% data variables.product.prodname_github_apps %} using an installation access token scales with the number of repositories and number of organization users. For more information, see \"AUTOTITLE.\"\n\n{% ifversion fpt %}\n\nIf you are using {% data variables.product.prodname_github_apps %} or {% data variables.product.prodname_oauth_apps %}, consider upgrading to {% data variables.product.prodname_ghe_cloud %}. {% data variables.product.prodname_github_apps %} or {% data variables.product.prodname_oauth_apps %} have higher rate limits for organizations that use {% data variables.product.prodname_ghe_cloud %}.\n\n{% endif %}\n\n{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF8zMjA=": "\n\nAbout IAM for {% data variables.product.product_name %}\n\n{% ifversion ghae %}\n\nOn {% data variables.product.product_name %}, you provision user accounts from a SAML identity provider (IdP). You must configure SAML single sign-on (SSO) so people can authenticate to access your enterprise on {% data variables.product.product_name %}.\n\n{% elsif ghec %}\n\nYou can allow people to use a personal account on {% data variables.product.prodname_dotcom_the_website %} to access your enterprise's resources and optionally configure additional SAML access restriction, or you can provision and control the accounts for your enterprise using your identity provider (IdP) with {% data variables.product.prodname_emus %}.\n\nAfter learning more about authentication and provisioning for each of these options, to determine which method is best for your enterprise, see \"AUTOTITLE.\"\n\n{% elsif scim-for-ghes %}\n\nAdministrators who configure a {% data variables.product.product_name %} instance can use local accounts and built-in authentication on the instance. Alternatively, to centralize identity and access for an enterprise's web applications, administrators can configure an external authentication method. If you use SAML, you can optionally provision user accounts on the instance from your identity provider (IdP) using System for Cross-domain Identity Management (SCIM).\n\n{% endif %}\n\n{% ifversion ghec or ghes %}\n\n\n\nAuthentication methods\n\n{% endif %}\n\n{% ifversion ghec %}\n\nWhen you create an enterprise on {% data variables.product.product_name %}, you can decide how people authenticate to access your resources on {% data variables.product.prodname_dotcom_the_website %}, and who controls the user accounts.\n\n- Authentication through {% data variables.location.product_location %}\n- Authentication through {% data variables.location.product_location %} with additional SAML access restriction\n- Authentication with {% data variables.product.prodname_emus %} and federation\n\n\n\nAuthentication through {% data variables.location.product_location %}\n\nW", "Y2h1bmtfMV9pbmRleF8zMjA=": "ith authentication solely through {% data variables.location.product_location %}, each person you want to grant access to your enterprise must create and manage a personal account on {% data variables.location.product_location %}. After you grant access to your enterprise, the member can access your enterprise's resources after signing into the account on {% data variables.location.product_location %}. The member manages the account, and can contribute to other enterprises, organizations, and repositories on {% data variables.location.product_location %}. For more information about personal accounts, see \"AUTOTITLE.\"\n\n\n\nAuthentication through {% data variables.location.product_location %} with additional SAML access restriction\n\nIf you configure additional SAML access restriction, each person you want to grant access to your enterprise must create and manage a personal account on {% data variables.location.product_location %}. After you grant access to your enterprise, the member can access your enterprise's resources only after authenticating successfully for both the account on {% data variables.location.product_location %} and for an account on your SAML identity provider (IdP). The member can contribute to other enterprises, organizations, and repositories on {% data variables.location.product_location %} using their personal account. For more information about requiring SAML authentication for all access your enterprise's resources, see \"AUTOTITLE.\"\n\nYou can choose between configuring SAML at the enterprise level, which applies the same SAML configuration to all organizations within the enterprise, and configuring SAML separately for individual organizations. For more information, see \"AUTOTITLE.\"\n\n\n\nAuthentication with {% data variables.product.prodname_emus %} and federation\n\nIf you need more control of the accounts for your enterprise members on {% data variables.location.product_location %}, you can use {% data variables.product.prodname_emus %}. With {% data variables.product.prodname_emus %}, you provi", "Y2h1bmtfMl9pbmRleF8zMjA=": "sion and manage accounts for your enterprise members on {% data variables.location.product_location %} using your IdP. Each member signs into an account that you create, and your enterprise manages the account. Contributions to the rest of {% data variables.product.prodname_dotcom_the_website %} are restricted. For more information, see \"AUTOTITLE.\"\n\n{% elsif ghes %}\n\nThe following authentication methods are available for {% data variables.product.product_name %}.\n\n- Built-in authentication\n- External authentication\n\n\n\nBuilt-in authentication\n\n{% data reusables.enterprise_user_management.built-in-authentication-new-accounts %} To access your instance, people authenticate with the credentials for the account. For more information, see \"AUTOTITLE.\"\n\n\n\nExternal authentication\n\nIf you use an external directory or identity provider (IdP) to centralize access to multiple web applications, you may be able to configure external authentication for {% data variables.location.product_location %}. For more information, see the following articles.\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n{% data reusables.enterprise.saml-or-ldap %}\n\nIf you choose to use external authentication, you can also configure fallback authentication for people who don't have an account on your external authentication provider. For example, you may want to grant access to a contractor or machine user. For more information, see \"AUTOTITLE.\"\n\n{% elsif ghae %}\n\n{% data variables.product.product_name %} uses SAML SSO for authentication. Enterprise owners must configure SAML SSO with a SAML identity provider (IdP) during initialization. For more information, see \"AUTOTITLE.\"\n\n{% endif %}\n\n{% ifversion ghec or ghes %}\n\n\n\nAbout provisioning\n\n{% endif %}\n\n{% ifversion ghae %}\n\nTo provision user accounts on {% data variables.product.product_name %}, you must configure provisioning on your IdP using System for Cross-domain Identity Management (SCIM). For more information, see \"AUTOTITLE.\"\n\n{% elsif ghec %}\n\nIf you use authentication through {% data variables.", "Y2h1bmtfM19pbmRleF8zMjA=": "location.product_location %} with additional SAML access restriction, people create personal accounts on {% data variables.product.prodname_dotcom_the_website %}, and you can grant those personal accounts access to resources in your enterprise. You do not provision accounts.\n\nAlternatively, if you use {% data variables.product.prodname_emus %}, you must configure your IdP to provision user accounts within your enterprise on {% data variables.location.product_location %} using System for Cross-domain Identity Management (SCIM). For more information, see \"AUTOTITLE.\"\n\n{% elsif scim-for-ghes %}\n\nIf you configure built-in authentication, CAS, LDAP, or SAML, {% data variables.product.product_name %} creates a user account when an authorized person signs into the instance, or \"just in time\" (JIT). Optionally, if you use SAML, you can provision user accounts from your identity provider (IdP) using SCIM. For more information, see \"AUTOTITLE.\"\n\n{% endif %}\n\n{% ifversion emu-public-scim-schema %}\n\n\n\nAbout supported IdPs\n\n{% data reusables.enterprise_user_management.ghec-supported-idps %}\n\n{% endif %}\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n{%- ifversion ghec %}\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n{%- endif %}\n\n", "Y2h1bmtfMF9pbmRleF8xODIx": "\n\nAbout permissions for {% data variables.product.prodname_actions %}\n\nYou can use the REST API to set permissions for the {% ifversion ghes or ghec or ghae %}enterprises, {% endif %}organizations and repositories that are allowed to run {% data variables.product.prodname_actions %}, and the actions{% ifversion actions-workflow-policy %} and reusable workflows{% endif %} that are allowed to run.{% ifversion fpt or ghec or ghes %} For more information, see \"AUTOTITLE.\"{% endif %}\n\n\n\n", "Y2h1bmtfMF9pbmRleF8xMzM1": "\n\nGraphQL\n\nThe `/content/graphql` directory is where the GitHub GraphQL API docs live!\n\n* The `/content/graphql/guides` and `/content/graphql/overview` directories contain articles that are human-editable.\n* The `/content/graphql/reference` directory contains an article for each GraphQL data type used in the GitHub GraphQL API. This content is generated from the data in `src/graphql/data` and should not be edited by a human. **As a result, we cannot accept contributions to GraphQL API reference content in this repository.**\n\nFor more information, see the `/src/graphql/README.md`.\n\n", "Y2h1bmtfMF9pbmRleF80NA==": "\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF84MDQ=": "\n\nSynopsis\n\n```shell copy\ncodeql dataset measure --output= [--threads=] ... -- \n```\n\n\n\nDescription\n\n\\[Plumbing] Collect statistics about the relations in a particular\ndataset.\n\nThis command is typically only used when developing a CodeQL extractor,\nafter a change that affects the database schema and which therefore\nneeds to have an accompanying change to the statistics used by the query\noptimizer.\n\n\n\nOptions\n\n\n\nPrimary Options\n\n\n\n`<dataset>`\n\n\\[Mandatory] Path to the raw QL dataset to measure.\n\n\n\n`-o, --output=<file>`\n\n\\[Mandatory] The output file to which statistics should be written,\ntypically with a '.dbscheme.stats' extension.\n\n\n\n`-j, --threads=<num>`\n\nThe number of concurrent threads to use.\n\nDefaults to 1. You can pass 0 to use one thread per core on the machine,\nor -_N_ to leave _N_ cores unused (except still use at least one\nthread).\n\n\n\nCommon options\n\n\n\n`-h, --help`\n\nShow this help text.\n\n\n\n`-J=<opt>`\n\n\\[Advanced] Give option to the JVM running the command.\n\n(Beware that options containing spaces will not be handled correctly.)\n\n\n\n`-v, --verbose`\n\nIncrementally increase the number of progress messages printed.\n\n\n\n`-q, --quiet`\n\nIncrementally decrease the number of progress messages printed.\n\n\n\n`--verbosity=<level>`\n\n\\[Advanced] Explicitly set the verbosity level to one of errors,\nwarnings, progress, progress+, progress++, progress+++. Overrides `-v`\nand `-q`.\n\n\n\n`--logdir=<dir>`\n\n\\[Advanced] Write detailed logs to one or more files in the given\ndirectory, with generated names that include timestamps and the name of\nthe running subcommand.\n\n(To write a log file with a name you have full control over, instead\ngive `--log-to-stderr` and redirect stderr as desired.)\n\n\n\n`--common-caches=<dir>`\n\n\\[Advanced] Controls the location of cached data on disk that will\npersist between several runs of the CLI, such as downloaded QL packs and\ncompiled query plans. If not set explicitly, this defaults to a\ndirectory named `.codeql` in the user's home directory; it will be\ncreated if it doesn't already exist.\n\nAvailable s", "Y2h1bmtfMV9pbmRleF84MDQ=": "ince `v2.15.2`.\n\n", "Y2h1bmtfMF9pbmRleF80MjU=": "\n\nLimitations\n\nWriting requests to the replica requires sending the data to the primary and all replicas. This means that the performance of all writes is limited by the slowest replica, although new geo-replicas can seed the majority of their data from existing co-located geo-replicas, rather than from the primary.\n\n{% data reusables.enterprise_clustering.network-latency %} To reduce the latency and bandwidth caused by distributed teams and large CI farms without impacting write throughput, you can configure repository caching instead. For more information, see \"AUTOTITLE.\"\n\nGeo-replication will not add capacity to a {% data variables.product.prodname_ghe_server %} instance or solve performance issues related to insufficient CPU or memory resources. If the primary appliance is offline, active replicas will be unable to serve any read or write requests.\n\n{% data reusables.enterprise_installation.replica-limit %}\n\n\n\nMonitoring a geo-replication configuration\n\n{% data reusables.enterprise_installation.monitoring-replicas %}\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8xMjIy": "\n\nAbout student code and IDEs\n\nIf you configure an integrated development environment (IDE) for an assignment, you can run the code within the IDE. You don't need to clone the assignment repository to your computer.\n\nFor more information about IDEs, see \"AUTOTITLE.\"\n\n\n\nRunning student code in the IDE\n\n{% data reusables.classroom.sign-into-github-classroom %}\n{% data reusables.classroom.click-classroom-in-list %}\n{% data reusables.classroom.click-assignment-in-list %}\n1. To the right of the submission, click **View IDE**.\n\n", "Y2h1bmtfMF9pbmRleF8xODY2": "\n\nAbout commit statuses\n\nYou can use the REST API to allow external services to mark commits with an `error`, `failure`, `pending`, or `success` state, which is then reflected in pull requests involving those commits. Statuses can also include an optional `description` and `target_url`, and we highly recommend providing them as they make statuses much more useful in the GitHub UI.\n\nAs an example, one common use is for continuous integration services to mark commits as passing or failing builds using status.  The `target_url` would be the full URL to the build output, and the `description` would be the high level summary of what happened with the build.\n\nStatuses can include a `context` to indicate what service is providing that status. For example, you may have your continuous integration service push statuses with a context of `ci`, and a security audit tool push statuses with a context of `security`.  You can then use the REST API to Get the combined status for a specific reference to retrieve the whole status for a commit.\n\nNote that the `repo:status` OAuth scope grants targeted access to statuses **without** also granting access to repository code, while the `repo` scope grants permission to code as well as statuses.\n\nIf you are developing a GitHub App and want to provide more detailed information about an external service, you may want to use the REST API to manage checks. For more information, see \"AUTOTITLE.\"\n\n\n\n", "Y2h1bmtfMF9pbmRleF8xNTE1": "\n\nAbout organization invitations\n\n When you invite someone to become a member of your organization, the person receives an email with an invitation link. To join the organization, the invitee clicks the invitation link in the email.\n\n You can use a person's {% data variables.product.company_short %} username or email address for the invitation.\n\n{% note %}\n\n**Note:** If you use an email address for the invitation, the invitee will only be able to accept the invitation if the email address matches with a verified email address associated with the invitee's personal account on {% data variables.product.prodname_dotcom %}. For more information, see \"AUTOTITLE.\"\n\nIf an invitee's personal account has been flagged, the invitee won't be able to accept any new or pending invitations to join organizations.\n\n{% endnote %}\n\nIf your organization has a paid per-user subscription, an unused license must be available before you can invite a new member to join the organization or reinstate a former organization member. For more information, see \"AUTOTITLE.\"\n\n{% data reusables.organizations.org-invite-scim %}\n\nIf your organization requires members to use two-factor authentication, users that you invite must enable two-factor authentication before accepting the invitation. For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n\n{% ifversion fpt %}Organizations that use {% data variables.product.prodname_ghe_cloud %}{% else %}You{% endif %} can implement SCIM to add, manage, and remove organization members' access to {% data variables.product.prodname_dotcom_the_website %} through an identity provider (IdP). For more information, see \"AUTOTITLE{% ifversion fpt %}\" in the {% data variables.product.prodname_ghe_cloud %} documentation.{% else %}.\"{% endif %}\n\n\n\nInviting a user to join your organization\n\n{% data reusables.profile.access_org %}\n{% data reusables.user-settings.access_org %}\n{% data reusables.organizations.people %}\n{% data reusables.organizations.invite_member_from_people_tab %}\n{% data reusables.organizations.invite_to_", "Y2h1bmtfMV9pbmRleF8xNTE1": "org %}\n{% data reusables.organizations.choose-to-restore-privileges %}\n{% data reusables.organizations.choose-user-role %}\n{% data reusables.organizations.add-user-to-teams %}\n{% data reusables.organizations.send-invitation %}\n{% data reusables.organizations.user_must_accept_invite_email %} {% data reusables.organizations.cancel_org_invite %}\n\n{% ifversion organization-invitation-enhancements %}\n\n\n\nRetrying or canceling expired invitations\n\nInvitations expire after 7 days. You can retry or cancel expired invitations, either one by one or in bulk. Failed invitations to outside collaborators can also be found in this view.\n\n{% data reusables.profile.access_org %}\n{% data reusables.user-settings.access_org %}\n{% data reusables.organizations.people %}\n{% data reusables.organizations.retrying-or-deleting-expired-invitations %}\n{% endif %}\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF84": "\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8xMTU1": "---\ntitle: Setting a theme for GitHub Desktop\nintro: You can set a theme to customize the look and feel of GitHub Desktop.\nredirect_from:\n  - /desktop/getting-started-with-github-desktop/setting-a-theme-for-github-desktop\n  - /desktop/installing-and-configuring-github-desktop/setting-a-theme-for-github-desktop\n  - /desktop/installing-and-configuring-github-desktop/configuring-and-customizing-github-desktop/setting-a-theme-for-github-desktop\nversions:\n  feature: desktop\nshortTitle: Set a theme\n---\n{% mac %}\n\n{% data reusables.desktop.mac-select-desktop-menu %}\n{% data reusables.desktop.choose-a-theme %}\n  \n{% endmac %}\n\n{% windows %}\n\n{% data reusables.desktop.windows-choose-options %}\n{% data reusables.desktop.choose-a-theme %}\n\n{% endwindows %}\n\n", "Y2h1bmtfMF9pbmRleF8yODc=": "\n\nPrerequisites\n\nBefore enabling {% data variables.product.prodname_actions %}, make sure you have completed the following steps:\n\n- Create your MinIO bucket for storing data generated by workflow runs. For more information about installing and configuring MinIO, see \"MinIO High Performance Object Storage\" and \"mc mb\" in the MinIO documentation.\n\n  To avoid resource contention on the appliance, we recommend that MinIO be hosted separately from {% data variables.location.product_location %}.\n\n  {% data reusables.actions.enterprise-s3-permission %}\n\n{% data reusables.actions.enterprise-common-prereqs %}\n\n\n\nEnabling {% data variables.product.prodname_actions %} with MinIO storage\n\n{% data reusables.enterprise_site_admin_settings.access-settings %}\n{% data reusables.enterprise_site_admin_settings.management-console %}\n{% data reusables.enterprise_management_console.actions %}\n{% data reusables.actions.enterprise-enable-checkbox %}\n{%- ifversion ghes-actions-storage-oidc %}\n{% data reusables.actions.enterprise-s3-storage-setup %}\n1. Under \"Authentication\", select **Credentials-based**, and enter your storage bucket's details:\n\n   {% note %}\n\n   **Note:** For MinIO, you cannot use OpenID Connect (OIDC) authentication. You must use credentials-based authentication.\n\n   {% endnote %}\n\n   {% data reusables.actions.enterprise-minio-storage-credential-fields %}\n{%- else %}\n1. Under \"Artifact & Log Storage\", select **Amazon S3**, and enter your storage bucket's details:\n\n   {% data reusables.actions.enterprise-minio-storage-credential-fields %}\n{% endif %}\n1. Under \"Artifact & Log Storage\", select **Force path style**.\n{% data reusables.enterprise_management_console.test-storage-button %}\n{% data reusables.enterprise_management_console.save-settings %}\n\n{% data reusables.actions.enterprise-postinstall-nextsteps %}\n\n", "Y2h1bmtfMF9pbmRleF82MzY=": "\n\nFinding where the key has been used\n\nTo determine where the key has already been used, open a terminal and type the `ssh` command. Use the `-i` flag to provide the path to the key you want to check:\n\n```shell\n$ ssh -T -ai ~/.ssh/id_rsa git@{% data variables.command_line.codeblock %}\n\n\nConnect to {% data variables.location.product_location %} using a specific ssh key\n> Hi USERNAME! You've successfully authenticated, but GitHub does not\n> provide shell access.\n```\n\nThe _username_ in the response is the account on {% ifversion ghae %}{% data variables.product.product_name %}{% else %}{% data variables.location.product_location %}{% endif %} that the key is currently attached to. If the response looks something like \"username/repo\", the key has been attached to a repository as a _deploy key_.\n\nTo force SSH to use only the key provided on the command line, use `-o` to add the `IdentitiesOnly=yes` option:\n\n```shell\nssh -v -o \"IdentitiesOnly=yes\" -i ~/.ssh/id_rsa git@{% data variables.command_line.codeblock %}\n```\n\n\n\nFixing the issue\n\nTo resolve the issue, first remove the key from the other account or repository and then add it to your account.\n\nIf you don't have permissions to transfer the key, and can't contact a user who does, remove the keypair and generate a brand new one.\n\n\n\nDeploy keys\n\nOnce a key has been attached to one repository as a deploy key, it cannot be used on another repository.  If you're running into this error while setting up deploy keys, see \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF8yNTc=": "---\ntitle: Configuring the IP address using the virtual machine console\nintro: 'By default, {% data variables.product.prodname_ghe_server %} retrieves network settings via the dynamic host configuration protocol (DHCP). If your platform supports it, or if DHCP is unavailable, you can also configure the network settings using the virtual machine console.'\nredirect_from:\n  - /enterprise/admin/installation/configuring-the-ip-address-using-the-virtual-machine-console\n  - /enterprise/admin/configuration/configuring-the-ip-address-using-the-virtual-machine-console\n  - /admin/configuration/configuring-the-ip-address-using-the-virtual-machine-console\nversions:\n  ghes: '*'\ntype: how_to\ntopics:\n  - Enterprise\n  - Fundamentals\n  - Infrastructure\n  - Networking\nshortTitle: Set the IP using the console\n---\n{% note %}\n\n**Note:** We do not support adding additional network adapters to {% data variables.product.prodname_ghe_server %}.\n\n{% endnote %}\n\n{% data reusables.enterprise_installation.open-vm-console-start %}\n1. Choose to configure the `IPv4` or `IPv6` protocol.\n1. Configure options for the protocol you chose.\n{% data reusables.enterprise_installation.vm-console-done %}\n\n", "Y2h1bmtfMF9pbmRleF83MTI=": "\n\nUpdating your organization's credit card\n\n{% data reusables.organizations.billing-settings %}\n{% data reusables.dotcom_billing.update_payment_method_organization_account %}\n1. Under \"Payment method\", click **New Card**.\n!Screenshot of the \"Payment method\" section. Below some card details, a link, labeled \"New Card\", is highlighted with an orange outline.\n{% data reusables.dotcom_billing.enter-payment-info %}\n\n", "Y2h1bmtfMF9pbmRleF8xMTk0": "\n\nAbout categories for discussions\n\n{% data reusables.discussions.about-discussions %} {% data reusables.discussions.about-categories-and-formats %}\n\n{% data reusables.discussions.about-announcement-format %}\n\nEach category must have a unique name and emoji pairing, and can be accompanied by a detailed description stating its purpose. Categories help maintainers organize how conversations are filed and are customizable to help distinguish categories that are Q&A or more open-ended conversations. {% data reusables.discussions.repository-category-limit %} For more information, see \"AUTOTITLE.\"\n\n{% ifversion discussions-category-section %}\n{% data reusables.discussions.category-sections %}{% endif %}\n\n\n\nDefault categories\n\n| Category | Purpose | Format |\n| :- | :- | :- |\n| \ud83d\udce3 Announcements | Updates and news from project maintainers | Announcement |\n| #\ufe0f\u20e3 General | Anything and everything relevant to the project | Open-ended discussion |\n|\ud83d\udca1 Ideas | Ideas to change or improve the project | Open-ended discussion |\n| \ud83d\uddf3 Polls | Polls with multiple options for the community to vote for and discuss | Polls |\n| \ud83d\ude4f Q&A | Questions for the community to answer, with a question/answer format | Question and Answer |\n| \ud83d\ude4c Show and tell | Creations, experiments, or tests relevant to the project | Open-ended discussion |\n\n\n\nCreating a category\n\n1. On {% data variables.location.product_location %}, navigate to the main page of the repository or organization where you want to create a category.\n{% data reusables.discussions.discussions-tab %}\n{% data reusables.discussions.edit-categories %}\n1. Click **New category**.\n\n   !Screenshot of the \"Manage discussion categories\" page.  A button, labeled \"New category\", is highlighted with an orange outline.\n\n1. Edit the emoji, title, description, and discussion format for the category. For more information about discussion formats, see \"AUTOTITLE.\"\n{% ifversion discussions-category-section %}\n{% data reusables.discussions.add-category-to-section %}{% endif %}\n1. Click **Create**.\n\n{% ifversion ", "Y2h1bmtfMV9pbmRleF8xMTk0": "discussions-category-section %}\n\n\n\nCreating a section\n\n1. On {% data variables.location.product_location %}, navigate to the main page of the repository or organization where you want to create a category.\n{% data reusables.discussions.discussions-tab %}\n{% data reusables.discussions.edit-categories %}\n1. Click **New section**.\n   !Screenshot of the \"Manage discussion categories\" page.  A button, labeled \"New section\", is highlighted with an orange outline.\n1. Edit the emoji and title of the section.\n1. Select the categories that you want to add to the section. A category can only belong to one section at a time.\n1. Click **Create**.\n{% endif %}\n\n\n\nEditing a category\n\nYou can edit a category to change the category's emoji, title, description, and discussion format.\n\n1. On {% data variables.location.product_location %}, navigate to the main page of the repository or organization where you want to edit a category.\n{% data reusables.discussions.discussions-tab %}\n{% data reusables.discussions.edit-categories %}\n1. To the right of a category in the list, click {% octicon \"pencil\" aria-label=\"The pencil icon\" %}.\n1. {% data reusables.discussions.edit-category-details %}\n{% ifversion discussions-category-section %}\n{% data reusables.discussions.add-category-to-section %}{% endif %}\n1. Click **Save changes**.\n\n{% ifversion discussions-category-section %}\n\n\n\nEditing a section\n\nYou can edit a section to change the section's emoji and title, and to add and remove categories from the section.\n\n1. On {% data variables.location.product_location %}, navigate to the main page of the repository or organization where you want to edit a section.\n{% data reusables.discussions.discussions-tab %}\n{% data reusables.discussions.edit-categories %}\n1. To the right of a section in the list, click {% octicon \"pencil\" aria-label=\"The pencil icon\" %}.\n1. Edit the section's emoji and title, and select or deselect the categories that you want to add or remove from the section.\n1. Click **Update**.\n{% endif %}\n\n\n\nDeleting a category\n\nWhen you d", "Y2h1bmtfMl9pbmRleF8xMTk0": "elete a category, {% data variables.product.product_name %} will move all discussions in the deleted category to an existing category that you choose.\n\n{% ifversion discussions-category-section %}When you delete a section, all categories within the section will no longer belong to a section.{% endif %}\n\n1. On {% data variables.location.product_location %}, navigate to the main page of the repository or organization where you want to delete a category.\n{% data reusables.discussions.discussions-tab %}\n1. To the right of a category in the list, click {% octicon \"trash\" aria-label=\"The trash icon\" %}.\n1. Select the dropdown menu, and click a new category for any discussions in the category you're deleting.\n1. Click **Delete & Move**.\n\n{% ifversion discussions-category-section %}\n\n\n\nDeleting a section\n\nWhen you delete a section, all categories within the section will no longer belong to a section.\n\n1. On {% data variables.location.product_location %}, navigate to the main page of the repository or organization where you want to delete a section.\n{% data reusables.discussions.discussions-tab %}\n1. To the right of a section in the list, click {% octicon \"trash\" aria-label=\"The trash icon\" %}.\n1. In the dialog box, review the information about deleting a section, then click **Delete**.\n{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF8xMjQw": "\n\nAbout {% data variables.product.prodname_classroom %} CLI <!-- omit in toc -->\n\n{% data reusables.cli.about-cli %} For more information, see \"AUTOTITLE.\"\n\nYou can work with {% data variables.product.prodname_classroom %} in the  {% data variables.product.prodname_cli %} to:\n\n- List classrooms\n- View classroom information\n- List assignments\n- List accepted assignments\n- View assignment information\n- Clone an assignment's starter code repository\n- Clone a student\u2019s assignment repository\n\n\n\nSetting up {% data variables.product.prodname_cli %} <!-- omit in toc -->\n\n{% data reusables.cli.cli-installation %}\n\n\n\nUsing the {% data variables.product.prodname_classroom %} extension with {% data variables.product.prodname_cli %} <!-- omit in toc -->\n\nIf you have not already done so, run `gh auth login` to authenticate with your {% data variables.product.prodname_dotcom %} account.\n\nTo install the {% data variables.product.prodname_classroom %} extension, run `gh extension install github/gh-classroom`.\n\nTo use `gh` to work with {% data variables.product.prodname_classroom %}, type `gh classroom SUBCOMMAND`.\n\nAs an example of a series of commands you might use to work with {% data variables.product.prodname_classroom %}, you could:\n- List your classrooms:\n  `gh classroom list`\n- List the assignments for a specific classroom:\n  `gh classroom assignments`\n- View information for a specific assignment:\n  `gh classroom assignment`\n\n\n\n`gh` subcommands for {% data variables.product.prodname_classroom %} <!-- omit in toc -->\n\nThese sections give example subcommands for each of the available operations. {% data reusables.classroom.classroom-cli-prompt %}\n\nOn the command line, use `gh classroom --help` for general help or `gh classroom SUBCOMMAND --help` for help with a specific subcommand.\n\n\n\nList classrooms\n\n```shell\ngh classroom list\n```\n\nList of classrooms you own.\n\n\n\nView classroom information\n\n```shell\ngh classroom view\n```\n\nDisplay the classroom ID, classroom slug, title, and other information about a classroom.\n\n\n\nList assign", "Y2h1bmtfMV9pbmRleF8xMjQw": "ments\n\n```shell\ngh classroom assignments\n```\n\nDisplay a list of assignments for a classroom.\n\n\n\nList accepted assignments\n\n```shell\ngh classroom accepted-assignments\n```\n\nDisplay a list of accepted assignments and information about the student's assignments.\n\n\n\nView assignment information\n\n```shell\ngh classroom assignment\n```\n\nDisplays assignment information.\n\n\n\nClone an assignment's starter code repository\n\n```shell\ngh classroom clone starter-repo\n```\n\nClones starter code repo used by an assignment. By default, the starter code is cloned into the current directory. To clone into a different directory, use the `--directory` flag. If the directory does not exists, it will be created.\n\n\n\nClone a student\u2019s assignment repository\n\n```shell\ngh classroom clone student-repos\n```\n\nClones student repositories from a given assignment. By default, the student repositories are cloned into the current directory a directory named after the assignment slug. To clone into a different directory, use the `--directory` flag. If the directory does not exists, it will be created.\n\nBy default, results are paginated by 30. To get a different number of repositories, use the `--per-page NUMBER` flag.\n\n", "Y2h1bmtfMF9pbmRleF84NTI=": "\n\nSynopsis\n\n```shell copy\ncodeql version ...\n```\n\n\n\nDescription\n\nShow the version of the CodeQL toolchain.\n\n\n\nOptions\n\n\n\nPrimary Options\n\n\n\n`--format=<fmt>`\n\nSelect output format. Choices include `text` _(default)_ ,`terse`, and\n`json`.\n\n\n\nCommon options\n\n\n\n`-h, --help`\n\nShow this help text.\n\n\n\n`-J=<opt>`\n\n\\[Advanced] Give option to the JVM running the command.\n\n(Beware that options containing spaces will not be handled correctly.)\n\n\n\n`-v, --verbose`\n\nIncrementally increase the number of progress messages printed.\n\n\n\n`-q, --quiet`\n\nIncrementally decrease the number of progress messages printed.\n\n\n\n`--verbosity=<level>`\n\n\\[Advanced] Explicitly set the verbosity level to one of errors,\nwarnings, progress, progress+, progress++, progress+++. Overrides `-v`\nand `-q`.\n\n\n\n`--logdir=<dir>`\n\n\\[Advanced] Write detailed logs to one or more files in the given\ndirectory, with generated names that include timestamps and the name of\nthe running subcommand.\n\n(To write a log file with a name you have full control over, instead\ngive `--log-to-stderr` and redirect stderr as desired.)\n\n\n\n`--common-caches=<dir>`\n\n\\[Advanced] Controls the location of cached data on disk that will\npersist between several runs of the CLI, such as downloaded QL packs and\ncompiled query plans. If not set explicitly, this defaults to a\ndirectory named `.codeql` in the user's home directory; it will be\ncreated if it doesn't already exist.\n\nAvailable since `v2.15.2`.\n\n", "Y2h1bmtfMF9pbmRleF84NTQ=": "\n\nAbout analyzing databases with the {% data variables.product.prodname_codeql_cli %}\n\n{% data reusables.code-scanning.codeql-cli-version-ghes %}\n\nTo analyze a codebase, you run queries against a {% data variables.product.prodname_codeql %} database extracted from the code. {% data variables.product.prodname_codeql %} analyses produce results that can be uploaded to {% data variables.product.product_name %} to generate code scanning alerts.\n\n\n\nPrerequisites\n\nBefore starting an analysis you must:\n\n- Set up the {% data variables.product.prodname_codeql_cli %} to run commands locally.\n- Create a {% data variables.product.prodname_codeql %} database for the source code you want to analyze.\n\nThe simplest way to run `codeql database analyze` is using the standard queries included in the {% data variables.product.prodname_codeql_cli %} bundle.\n\n\n\nRunning `codeql database analyze`\n\nWhen you run `database analyze`, it:\n\n1. Optionally downloads any referenced {% data variables.product.prodname_codeql %} packages that are not available locally.\n1. Executes one or more query files, by running them over a {% data variables.product.prodname_codeql %} database.\n1. Interprets the results, based on certain query metadata, so that alerts can be\ndisplayed in the correct location in the source code.\n1. Reports the results of any diagnostic and summary queries to standard output.\n\nYou can analyze a database by running the following command:\n\n```shell\ncodeql database analyze  --format= --output= ...\n```\n\n{% note %}\n\n**Note:** If you analyze more than one {% data variables.product.prodname_codeql %} database for a single commit, you must specify a SARIF category for each set of results generated by this command. When you upload the results to {% data variables.product.product_name %}, {% data variables.product.prodname_code_scanning %} uses this category to store the results for each language separately. If you forget to do this, each upload overwrites the previous results.\n\n```shell\ncodeql database analyze  --format= \\\n    --sarif-cat", "Y2h1bmtfMV9pbmRleF84NTQ=": "egory= --output= \\\n    {% ifversion codeql-packs %}{% else %}{% endif %}\n```\n\n{% endnote %}\n\nYou must specify ``, `--format`, and `--output`. You can specify additional options depending on what analysis you want to do.\n\n| Option | Required | Usage |\n|--------|:--------:|-----|\n| `` | {% octicon \"check\" aria-label=\"Required\" %} | Specify the path for the directory that contains the {% data variables.product.prodname_codeql %} database to analyze. |\n| `` | {% octicon \"x\" aria-label=\"Optional\" %} | Specify {% data variables.product.prodname_codeql %} packs or queries to run. To run the standard queries used for {% data variables.product.prodname_code_scanning %}, omit this parameter. To see the other query suites included in the {% data variables.product.prodname_codeql_cli %} bundle, look in `//qlpacks/codeql/-queries/codeql-suites`. For information about creating your own query suite, see AUTOTITLE in the documentation for the {% data variables.product.prodname_codeql_cli %}.\n| --format | {% octicon \"check\" aria-label=\"Required\" %} | Specify the format for the results file generated during analysis. A number of different formats are supported, including CSV, SARIF, and graph formats. For upload to {% data variables.product.company_short %} this should be: {% ifversion fpt or ghae or ghec %}`sarif-latest`{% else %}`sarifv2.1.0`{% endif %}. For more information, see \"AUTOTITLE.\"\n| --output | {% octicon \"check\" aria-label=\"Required\" %} | Specify the location where you want to save the SARIF results file, including the desired filename with the `.sarif` extension.\n| --sarif-category | {% octicon \"question\" aria-label=\"Required with multiple results sets\" %} | Optional for single database analysis. Required to define the language when you analyze multiple databases for a single commit in a repository.Specify a category to include in the SARIF results file for this analysis. A category is used to distinguish multiple analyses for the same tool and commit, but performed on different languages or different parts of the c", "Y2h1bmtfMl9pbmRleF84NTQ=": "ode.|{% ifversion code-scanning-tool-status-page %}\n| --sarif-add-baseline-file-info | {% octicon \"x\" aria-label=\"Optional\" %} | **Recommended.** Use to submit file coverage information to the {% data variables.code-scanning.tool_status_page %}. For more information, see \"AUTOTITLE.\" | {% endif %}\n| --sarif-add-query-help | {% octicon \"x\" aria-label=\"Optional\" %} | Use if you want to include any available markdown-rendered query help for custom queries used in your analysis. Any query help for custom queries included in the SARIF output will be displayed in the code scanning UI if the relevant query generates an alert. For more information, see \"AUTOTITLE.\"{% ifversion codeql-packs %}\n| `` | {% octicon \"x\" aria-label=\"Optional\" %} | Use if you want to include {% data variables.product.prodname_codeql %} query packs in your analysis. For more information, see \"Downloading and using {% data variables.product.prodname_codeql %} packs.\"\n| --download | {% octicon \"x\" aria-label=\"Optional\" %}  | Use if some of your {% data variables.product.prodname_codeql %} query packs are not yet on disk and need to be downloaded before running queries.{% endif %}\n| --threads | {% octicon \"x\" aria-label=\"Optional\" %}  | Use if you want to use more than one thread to run queries. The default value is `1`. You can specify more threads to speed up query execution. To set the number of threads to the number of logical processors, specify `0`.\n| --verbose | {% octicon \"x\" aria-label=\"Optional\" %}  | Use to get more detailed information about the analysis process and diagnostic data from the database creation process.\n\n{% note %}\n\n**Upgrading databases**\n\nFor databases that were created by {% data variables.product.prodname_codeql_cli %} v2.3.3 or earlier, you will need to explicitly upgrade the database before you can run an analysis with a newer\nversion of the {% data variables.product.prodname_codeql_cli %}. If this step is necessary, then you will see a message telling you\nthat your database needs to be upgraded when you run `database", "Y2h1bmtfM19pbmRleF84NTQ=": " analyze`.\n\nFor databases that were created by {% data variables.product.prodname_codeql_cli %} v2.3.4 or later, the CLI will implicitly run any\nrequired upgrades. Explicitly running the upgrade command is not necessary.\n\n{% endnote %}\n\nFor full details of all the options you can use when analyzing databases, see \"AUTOTITLE.\"\n\n\n\nBasic example of analyzing a {% data variables.product.prodname_codeql %} database\n\nThis example analyzes a {% data variables.product.prodname_codeql %} database stored at `/codeql-dbs/example-repo` and saves the results as a SARIF file: `/temp/example-repo-js.sarif`. It uses `--sarif-category` to include extra information in the SARIF file that identifies the results as JavaScript. This is essential when you have more than one {% data variables.product.prodname_codeql %} database to analyze for a single commit in a repository.\n\n```shell\n$ codeql database analyze /codeql-dbs/example-repo \\\n    javascript-code-scanning.qls --sarif-category={% ifversion codeql-language-identifiers-311 %}javascript-typescript{% else %}javascript{% endif %} \\\n    --format={% ifversion fpt or ghae or ghec %}sarif-latest{% else %}sarifv2.1.0{% endif %} --output=/temp/example-repo-js.sarif\n\n> Running queries.\n> Compiling query plan for /codeql-home/codeql/qlpacks/codeql-javascript/AngularJS/DisablingSce.ql.\n...\n> Shutting down query evaluator.\n> Interpreting results.\n```\n\n{% ifversion code-scanning-tool-status-page %}\n\n\n\nAdding file coverage information to your results for monitoring\n\nYou can optionally submit file coverage information to {% data variables.product.product_name %} for display on the {% data variables.code-scanning.tool_status_page %} for {% data variables.product.prodname_code_scanning %}. For more information about file coverage information, see \"AUTOTITLE.\"\n\nTo include file coverage information with your {% data variables.product.prodname_code_scanning %} results, add the `--sarif-add-baseline-file-info` flag to the `codeql database analyze` invocation in your CI system, for example:\n\n```shell\n", "Y2h1bmtfNF9pbmRleF84NTQ=": "$ codeql database analyze /codeql-dbs/example-repo \\\n    javascript-code-scanning.qls --sarif-category={% ifversion codeql-language-identifiers-311 %}javascript-typescript{% else %}javascript{% endif %} \\\n    --sarif-add-baseline-file-info \\ --format={% ifversion fpt or ghae or ghec %}sarif-latest{% else %}sarifv2.1.0{% endif %} \\\n    --output=/temp/example-repo-js.sarif\n```\n\n{% endif %}\n\n\n\nExamples of running database analyses\n\nThe following examples show how to run `database analyze` using {% data variables.product.prodname_codeql %} packs, and how to use a local checkout of the {% data variables.product.prodname_codeql %} repository. These examples assume your {% data variables.product.prodname_codeql %} databases have been created in a directory that is a sibling of your local copies of the {% data variables.product.prodname_codeql %} repository.\n\n{% ifversion codeql-packs %}\n\n\n\nRunning a {% data variables.product.prodname_codeql %} query pack\n\n{% note %}\n\n**Note**\n\nThe {% data variables.product.prodname_codeql %} package management functionality, including {% data variables.product.prodname_codeql %} packs, is currently available as a beta release and is subject to change. During the beta release, {% data variables.product.prodname_codeql %} packs are available only using {% data variables.product.prodname_registry %} - the {% data variables.product.prodname_dotcom %} {% data variables.product.prodname_container_registry %}. To use this beta functionality, install the latest version of the {% data variables.product.prodname_codeql_cli %} bundle from: https://github.com/github/codeql-action/releases.\n\n{% endnote %}\n\nTo run an existing {% data variables.product.prodname_codeql %} query pack from the {% data variables.product.prodname_dotcom %} {% data variables.product.prodname_container_registry %}, you can specify one or more\npack names:\n\n```shell\ncodeql database analyze  microsoft/coding-standards@1.0.0 github/security-queries --format=sarifv2.1.0 --output=query-results.sarif --download\n```\n\nThis command ru", "Y2h1bmtfNV9pbmRleF84NTQ=": "ns the default query suite of two {% data variables.product.prodname_codeql %} query packs: `microsoft/coding-standards` version 1.0.0 and the latest version of `github/security-queries` on the specified database. For further information about default suites, see \"AUTOTITLE.\"\n\nThe `--download` flag is optional. Using it will ensure the query pack is downloaded if it isn\u2019t yet available locally.\n{% endif %}\n\n\n\nRunning a single query\n\nTo run a single query over a {% data variables.product.prodname_codeql %} database for a JavaScript codebase,\nyou could use the following command from the directory containing your database:\n\n```shell\ncodeql database analyze --download  codeql/javascript-queries:Declarations/UnusedVariable.ql --format=csv --output=js-analysis/js-results.csv\n```\n\nThis command runs a simple query that finds potential bugs related to unused\nvariables, imports, functions, or classes\u2014it is one of the JavaScript\nqueries included in the {% data variables.product.prodname_codeql %} repository. You could run more than one query by\nspecifying a space-separated list of similar paths.\n\nThe analysis generates a CSV file (`js-results.csv`) in a new directory (`js-analysis`).\n\nAlternatively, if you have the {% data variables.product.prodname_codeql %} repository checked out, you can execute the same queries by specifying the path to the query directly:\n\n```shell\ncodeql database analyze  ../ql/javascript/ql/src/Declarations/UnusedVariable.ql --format=csv --output=js-analysis/js-results.csv\n```\n\nYou can also run your own custom queries with the `database analyze` command.\nFor more information about preparing your queries to use with the {% data variables.product.prodname_codeql_cli %},\nsee \"AUTOTITLE.\"\n\n\n\nRunning all queries in a directory\n\nYou can run all the queries located in a directory by providing the directory\npath, rather than listing all the individual query files. Paths are searched\nrecursively, so any queries contained in subfolders will also be executed.\n\n{% note %}\n\n**Important**\n\nYou should avoid specify", "Y2h1bmtfNl9pbmRleF84NTQ=": "ing the root of a core {% data variables.product.prodname_codeql %} query pack when executing `database analyze`\nas it might contain some special queries that aren\u2019t designed to be used with\nthe command. Rather, run the query pack to include the\npack\u2019s default queries in the analysis, or run one of the\ncode scanning query suites.\n\n{% endnote %}\n\nFor example, to execute all Python queries contained in the `Functions` directory in the\n`codeql/python-queries` query pack you would run:\n\n```shell\ncodeql database analyze  codeql/python-queries:Functions --format=sarif-latest --output=python-analysis/python-results.sarif --download\n```\n\nAlternatively, if you have the {% data variables.product.prodname_codeql %} repository checked out, you can execute the\nsame queries by specifying the path to the directory directly:\n\n```shell\ncodeql database analyze  ../ql/python/ql/src/Functions/ --format=sarif-latest --output=python-analysis/python-results.sarif\n```\n\nWhen the analysis has finished, a SARIF results file is generated. Specifying `--format=sarif-latest` ensures\nthat the results are formatted according to the most recent SARIF specification\nsupported by {% data variables.product.prodname_codeql %}.\n\n{% ifversion codeql-packs %}\n\n\n\nRunning a subset of queries in a {% data variables.product.prodname_codeql %} pack\n\nIf you are using {% data variables.product.prodname_codeql_cli %} v2.8.1 or later, you can include a path at the end of a pack specification to run a subset of queries inside the pack. This applies to any command that locates or runs queries within a pack.\n\nThe complete way to specify a set of queries is in the form `scope/name@range:path`, where:\n\n- `scope/name` is the qualified name of a {% data variables.product.prodname_codeql %} pack.\n\n- `range` is a semver range.\n\n- `path` is a file system path to a single query, a directory containing queries, or a query suite file.\n\nWhen you specify a `scope/name`, the `range` and `path` are\noptional. If you omit a `range` then the latest version of the\nspecified pack is ", "Y2h1bmtfN19pbmRleF84NTQ=": "used. If you omit a `path` then the default query suite\nof the specified pack is used.\n\nThe `path` can be one of a `\\*.ql` query file, a directory\ncontaining one or more queries, or a `.qls` query suite file. If\nyou omit a pack name, then you must provide a `path`,\nwhich will be interpreted relative to the working directory\nof the current process.\n\nIf you specify a `scope/name` and `path`, then the `path` cannot\nbe absolute. It is considered relative to the root of the {% data variables.product.prodname_codeql %}\npack.\n\nTo analyze a database using all queries in the `experimental/Security` folder within the `codeql/cpp-queries` {% data variables.product.prodname_codeql %} pack you can use:\n\n```shell\ncodeql database analyze --format=sarif-latest --output=results  \\\n    codeql/cpp-queries:experimental/Security\n```\n\nTo run the `RedundantNullCheckParam.ql` query in the `codeql/cpp-queries` {% data variables.product.prodname_codeql %} pack use:\n\n```shell\ncodeql database analyze --format=sarif-latest --output=results  \\\n    'codeql/cpp-queries:experimental/Likely Bugs/RedundantNullCheckParam.ql'\n```\n\nTo analyze your database using the `cpp-security-and-quality.qls` query suite from a version of the `codeql/cpp-queries` {% data variables.product.prodname_codeql %} pack that is >= 0.0.3 and < 0.1.0 (the highest compatible version will be chosen) you can use:\n\n```shell\ncodeql database analyze --format=sarif-latest --output=results  \\\n   'codeql/cpp-queries@~0.0.3:codeql-suites/cpp-security-and-quality.qls'\n```\n\nIf you need to reference a query file, directory, or suite whose path contains a literal `@` or `:`, you can prefix the query specification with `path:` like so:\n\n```shell\ncodeql database analyze --format=sarif-latest --output=results  \\\n    path:C:/Users/ci/workspace@2/security/query.ql\n```\n\nFor more information about {% data variables.product.prodname_codeql %} packs, see AUTOTITLE.\n\n{% endif %}\n\n\n\nRunning query suites\n\nTo run a query suite on a {% data variables.product.prodname_codeql %} database for a C/C++ co", "Y2h1bmtfOF9pbmRleF84NTQ=": "debase,\nyou could use the following command from the directory containing your database:\n\n```shell\ncodeql database analyze  codeql/cpp-queries:codeql-suites/cpp-code-scanning.qls --format=sarifv2.1.0 --output=cpp-results.sarif --download\n```\n\nThis command downloads the `codeql/cpp-queries` {% data variables.product.prodname_codeql %} query pack, runs the analysis, and generates a file in the SARIF version 2.1.0 format that is supported by all versions of {% data variables.product.prodname_dotcom %}. This file can be uploaded to {% data variables.product.prodname_dotcom %} by executing `codeql github upload-results` or the code scanning API.\nFor more information, see \"AUTOTITLE\"\nor \"AUTOTITLE\".\n\n{% data variables.product.prodname_codeql %} query suites are `.qls` files that use directives to select queries to run\nbased on certain metadata properties. The standard {% data variables.product.prodname_codeql %} packs have metadata that specify\nthe location of the query suites used by code scanning, so the {% data variables.product.prodname_codeql_cli %} knows where to find these\nsuite files automatically, and you don\u2019t have to specify the full path on the command line.\nFor more information, see \"AUTOTITLE.\"\n\nFor information about creating custom query suites, see \"AUTOTITLE.\"\n\n\n\nResults\n\nYou can save analysis results in a number of different formats, including SARIF and CSV.\n\nThe SARIF format is designed to represent the output of a broad range of static analysis tools. For more information, see \"AUTOTITLE.\"\n\nFor more information about what the results look like in CSV format, see \"AUTOTITLE.\"\n\nResults files can be integrated into your own code-review or debugging infrastructure. For example, SARIF file output can be used to highlight alerts in the correct location in your source code using a SARIF viewer plugin for your IDE.\n\n\n\nViewing log and diagnostic information\n\nWhen you analyze a {% data variables.product.prodname_codeql %} database using a {% data variables.product.prodname_code_scanning %} query suite, in add", "Y2h1bmtfOV9pbmRleF84NTQ=": "ition to generating detailed information about alerts, the CLI reports diagnostic data from the database generation step and summary metrics. If you choose to generate SARIF output, the additional data is also included in the SARIF file. For repositories with few alerts, you may find this information useful for determining if there are genuinely few problems in the code, or if there were errors generating the {% data variables.product.prodname_codeql %} database. For more detailed output from `codeql database analyze`, use the `--verbose` option.\n\nFor more information about the type of diagnostic information available, see \"AUTOTITLE\".\n\nYou can choose to export and upload diagnostic information to {% data variables.product.product_name %} even if a {% data variables.product.prodname_codeql %} analysis fails. For more information, see \"AUTOTITLE.\"\n\n\n\nNext steps\n\n- To learn how to upload your {% data variables.product.prodname_codeql %} analysis results to {% data variables.product.product_name %}, see \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF8yMDI4": "---\ntitle: GitHub Impersonation\nshortTitle: Impersonation\nversions:\n  fpt: '*'\ntopics:\n  - Policy\n  - Legal\nredirect_from:\n  - /github/site-policy/github-impersonation\n  - /github/site-policy/github-community-guidelines#impersonation\n---\n\nYou may not misrepresent your identity or your association with another person or organization. This includes doing any of the following in a way that misleads or deceives others:\n\n- Copying another user's avatar or other personal profile information\n- Posting content under another user's email address\n- Using a deceptively similar username, organization name, or other namespace\n- Accessing an account or organization with another user's token or credentials\n- Otherwise posing as another individual or organization\n\nImpersonation is a form of harassment and violation of this policy may lead to loss of access to your account.\n\nPlease note, having a username similar to another is not necessarily impersonation. GitHub will take context into account. For example, as in cases involving claims of misinformation or disinformation, we generally allow parody and satire that is in line with our Acceptable Use Polices.\n\n", "Y2h1bmtfMF9pbmRleF8zOTQ=": "\n\nData collected\n\nIf you enable the collection of data about {% data variables.product.prodname_actions %}, the following data will be collected for {% data variables.location.product_location %}.\n\n- The top 20 actions used per month, by organization\n- Number of checks run, by organization\n- Number of jobs per hour, day, week, and month, by organization\n- Maximum concurrency of running jobs, by organization and operating system\n- Workflows per operating system, by organization\n- Job run length, by organization\n- Number of job runners, by type (no names or IP addresses are collected)\n- Job distribution over types of runners\n\n\n\nEnabling the collection of data about {% data variables.product.prodname_actions %}\n\n{% data reusables.enterprise_installation.ssh-into-instance %}\n1. Enter the following command.\n\n   ```shell copy\n   ghe-config app.github.enable-actions-usage-stats true\n   ```\n\n{% data reusables.enterprise.apply-configuration %}\n\n", "Y2h1bmtfMF9pbmRleF8xMDk2": "\n\nHow to write procedural articles\n\nFor the procedural content template, see \"AUTOTITLE.\"\n\n- Follow the style guidelines for procedural steps in \"AUTOTITLE\".\n- Procedural content can get repetitive\u2013\u2013look for opportunities to group related content into a single longer article.\n  - Group multiple related procedures into a single article unless there's a reason not to.\n  - If disabling a setting or undoing a task requires the same steps and has no special implications, do not write a separate procedure.\n  - If disabling a setting or undoing a task requires different steps or has important or special implications, create a longer article to contain both procedures. Use an agnostic title.\n- Tell readers the expected outcome of the procedure.\n- Include troubleshooting tips as frequently as possible.\n\n\n\nTitles for procedural content\n\n- Procedural articles or procedural sections within articles are task-based and begin with a gerund.\n  - Use: \"Applying for a student developer pack\"\n- Use active and specific verbs (brainstorm or use a thesaurus when needed).\n- Titles specifically describe the task contained within the article or header, but are general enough to reflect all of the content.\n- Article title length: maximum 80 characters, 60 if possible.\n\n\n\nExamples of procedural content\n\n- AUTOTITLE\n- AUTOTITLE\n- AUTOTITLE\n\n", "Y2h1bmtfMF9pbmRleF8xNTMz": "\n\nAbout {% data variables.product.prodname_actions %} permissions for your organization\n\n{% data reusables.actions.disabling-github-actions %} For more information about {% data variables.product.prodname_actions %}, see \"AUTOTITLE.\"\n\nYou can enable {% data variables.product.prodname_actions %} for all repositories in your organization. {% data reusables.actions.enabled-actions-description %} You can disable {% data variables.product.prodname_actions %} for all repositories in your organization. {% data reusables.actions.disabled-actions-description %}\n\nAlternatively, you can enable {% data variables.product.prodname_actions %} for all repositories in your organization but limit the actions {% ifversion actions-workflow-policy %}and reusable workflows{% endif %} a workflow can run.\n\n\n\nManaging {% data variables.product.prodname_actions %} permissions for your organization\n\nYou can choose to disable {% data variables.product.prodname_actions %} for all repositories in your organization, or only allow specific repositories. You can also limit the use of public actions{% ifversion actions-workflow-policy %} and reusable workflows{% endif %}, so that people can only use local actions {% ifversion actions-workflow-policy %}and reusable workflows{% endif %} that exist in your {% ifversion ghec or ghes or ghae %}enterprise{% else %}organization{% endif %}.\n\n{% note %}\n\n**Note:** You might not be able to manage these settings if your organization is managed by an enterprise that has overriding policy. For more information, see \"AUTOTITLE.\"\n\n{% endnote %}\n\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n{% data reusables.organizations.settings-sidebar-actions-general %}\n1. Under \"Policies\", select an option.\n\n   {% indented_data_reference reusables.actions.actions-use-policy-settings spaces=3 %}\n1. Click **Save**.\n\n{% data reusables.actions.allow-specific-actions-intro %}\n\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n{% data reusables.organizations.set", "Y2h1bmtfMV9pbmRleF8xNTMz": "tings-sidebar-actions-general %}\n1. Under \"Policies\", select {% data reusables.actions.policy-label-for-select-actions-workflows %} and add your required actions{% ifversion actions-workflow-policy %} and reusable workflows{% endif %} to the list.\n1. Click **Save**.\n\n{% ifversion actions-disable-repo-runners %}\n\n\n\nLimiting the use of self-hosted runners\n\n{% data reusables.actions.disable-selfhosted-runners-overview %}\n\n{% ifversion ghec or ghes %}\n\n{% note %}\n\n**Note**: If your organization belongs to an enterprise, creation of self-hosted runners at the repository level may have been disabled as an enterprise-wide setting. If this has been done, you cannot enable repository-level self-hosted runners in your organization settings. For more information, see \"AUTOTITLE.\"\n\n{% endnote %}\n\n{% endif %}\n\nIf a repository already has self-hosted runners when you disable their use, these will be listed with the status \"Disabled\" and they will not be assigned any new workflow jobs.\n\n!Screenshot of the \"Runners\" list showing a self-hosted runner with the status \"Disabled.\"\n\n{% data reusables.actions.disable-selfhosted-runners-note %}\n\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n{% data reusables.organizations.settings-sidebar-actions-general %}\n1. Under \"Runners,\" use the dropdown menu to choose your preferred setting:\n   - **All repositories** - self-hosted runners can be used for any repository in your organization.\n   - **Selected repositories** - self-hosted runners can only be used for the repositories you select.\n   - **Disabled** - self-hosted runners cannot be created at the repository level.\n1. If you choose **Selected repositories**:\n   1. Click {% octicon \"gear\" aria-label=\"Select repositories\" %}.\n   1. Select the check boxes for the repositories for which you want to allow self-hosted runners.\n   1. Click **Select repositories**.\n\n{% endif %}\n\n{% ifversion fpt or ghec %}\n\n\n\nConfiguring required approval for workflows from public forks\n\n{% data reusables.actions.workflow-run-", "Y2h1bmtfMl9pbmRleF8xNTMz": "approve-public-fork %}\n\nYou can configure this behavior for an organization using the procedure below. Modifying this setting overrides the configuration set at the enterprise level.\n\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n{% data reusables.organizations.settings-sidebar-actions-general %}\n{% data reusables.actions.workflows-from-public-fork-setting %}\n\n{% data reusables.actions.workflow-run-approve-link %}\n{% endif %}\n\n{% ifversion required-workflows %}\n\n\n\nAdding a required workflow to an organization\n\n{% data reusables.actions.workflows.required-workflow-beta %}\n\nYou can configure required workflows to run in all or selected repositories in an organization where you are an owner. Required workflows are triggered by {% ifversion actions-required-workflow-improvements %}`pull_request` and `pull_request_target` default events{% else %}pull requests{% endif %} and must pass before a pull request can be merged. For more information, see \"AUTOTITLE.\"\n\n\n\nPrerequisites\n\nBefore configuring a required workflow, note the following prerequisites:\n\n{% data reusables.actions.workflows.required-workflow-prerequisites %}\n\n\n\nRestrictions and behaviors for the source repository\n\nNote the following restrictions and behaviors for the source repository and workflow:\n\n{% data reusables.actions.workflows.required-workflow-source-notes %}\n\n\n\nRestrictions and behaviors for the target repository\n\nNote the following restrictions and behaviors for the target repositories:\n\n{% data reusables.actions.workflows.required-workflow-target-notes %}\n\n\n\nConfiguring a required workflow for your organization\n\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n{% data reusables.organizations.settings-sidebar-actions-general %}\n1. To the right of \"Required Workflows\", click **Add workflow**.\n\n1. Under \"Required workflow\", use the drop-down menu to select the repository that contains the workflow. Then, enter the path to the workflow in the text field. {% ifversion actions-requir", "Y2h1bmtfM19pbmRleF8xNTMz": "ed-workflow-improvements %}You can reference any branch, tag, or commit SHA from the repository containing the workflow file using the `{path}@{ref}` syntax.\n\n1. Optionally, to specify target branches on which to enforce the required workflow, enter the branch or multiple branches in the text field under \"Target branches\". If you do not enter a target branch, the required workflow will be enforced on the default branch for the repository.{% endif %}\n\n1. Under \"Apply to repositories...\", use the drop-down menu to select which repositories the required workflow applies to. Select **All repositories** to apply the required workflow to all repositories in your organization, or **Selected repositories** to choose which repositories it will apply to.\n\n1. Optionally, if you chose \"Selected repositories\", click {% octicon \"gear\" aria-label=\"The Gear icon\" %} to open the repository selection modal, then use the checkboxes to select the repositories, and click **Apply selection**. You can use filters to narrow down your search.\n\n1. To add the required workflow, click **Add workflow**.\n\n{% endif %}\n\n{% ifversion fpt or ghes or ghec %}\n\n\n\nEnabling workflows for private repository forks\n\n{% data reusables.actions.private-repository-forks-overview %}\n\n{% ifversion ghec or ghae or ghes %}If a policy is disabled for an enterprise, it cannot be enabled for organizations.{% endif %} If a policy is disabled for an organization, it cannot be enabled for repositories. If an organization enables a policy, the policy can be disabled for individual repositories.\n\n{% data reusables.actions.private-repository-forks-options %}\n\n\n\nConfiguring the private fork policy for an organization\n\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n{% data reusables.organizations.settings-sidebar-actions-general %}\n{% data reusables.actions.private-repository-forks-configure %}\n{% endif %}\n\n\n\nSetting the permissions of the `GITHUB_TOKEN` for your organization\n\n{% data reusables.actions.workflow-permissions-intro %}\n\nYou c", "Y2h1bmtfNF9pbmRleF8xNTMz": "an set the default permissions for the `GITHUB_TOKEN` in the settings for your organization or your repositories. If you select a restrictive option as the default in your organization settings, the same option is selected in the settings for repositories within your organization, and the permissive option is disabled. If your organization belongs to a {% data variables.product.prodname_enterprise %} account and a more restrictive default has been selected in the enterprise settings, you won't be able to select the more permissive default in your organization settings.\n\n{% data reusables.actions.workflow-permissions-modifying %}\n\n\n\nConfiguring the default `GITHUB_TOKEN` permissions\n\n{% ifversion actions-default-workflow-permissions-restrictive %}\nBy default, when you create a new organization,{% ifversion ghec or ghes or ghae %} the setting is inherited from what is configured in the enterprise settings.{% else %} `GITHUB_TOKEN` only has read access for the `contents` and `packages` scopes.{% endif %}\n{% endif %}\n\n{% data reusables.profile.access_profile %}\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n{% data reusables.organizations.settings-sidebar-actions-general %}\n{% data reusables.actions.workflows.github-token-access %}\n1. Click **Save** to apply the settings.\n\n{% ifversion allow-actions-to-approve-pr %}\n\n\n\nPreventing {% data variables.product.prodname_actions %} from {% ifversion allow-actions-to-approve-pr-with-ent-repo %}creating or {% endif %}approving pull requests\n\n{% data reusables.actions.workflow-pr-approval-permissions-intro %}\n\nBy default, when you create a new organization, workflows are not allowed to {% ifversion allow-actions-to-approve-pr-with-ent-repo %}create or {% endif %}approve pull requests.\n\n{% data reusables.profile.access_profile %}\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n{% data reusables.organizations.settings-sidebar-actions-general %}\n1. Under \"Workflow permissions\", use the **Allow GitHub Actions to ", "Y2h1bmtfNV9pbmRleF8xNTMz": "{% ifversion allow-actions-to-approve-pr-with-ent-repo %}create and {% endif %}approve pull requests** setting to configure whether `GITHUB_TOKEN` can {% ifversion allow-actions-to-approve-pr-with-ent-repo %}create and {% endif %}approve pull requests.\n1. Click **Save** to apply the settings.\n\n{% endif %}\n\n{% ifversion actions-cache-org-ui %}\n\n\n\nManaging {% data variables.product.prodname_actions %} cache storage for your organization\n\nOrganization administrators can view {% ifversion actions-cache-admin-ui %}and manage {% endif %}{% data variables.product.prodname_actions %} cache storage for all repositories in the organization.\n\n\n\nViewing {% data variables.product.prodname_actions %} cache storage by repository\n\nFor each repository in your organization, you can see how much cache storage a repository is using, the number of active caches, and if a repository is near the total cache size limit. For more information about the cache usage and eviction process, see \"AUTOTITLE.\"\n\n{% data reusables.profile.access_profile %}\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n1. In the left sidebar, click {% octicon \"play\" aria-hidden=\"true\" %} **Actions**, then click **Caches**.\n1. Review the list of repositories for information about their {% data variables.product.prodname_actions %} caches. You can click on a repository name to see more detail about the repository's caches.\n\n{% ifversion actions-cache-admin-ui %}\n\n\n\nConfiguring {% data variables.product.prodname_actions %} cache storage for your organization\n\n{% data reusables.actions.cache-default-size %}\n\nYou can configure the size limit for {% data variables.product.prodname_actions %} caches that will apply to each repository in your organization. The cache size limit for an organization cannot exceed the cache size limit set in the enterprise policy. Repository admins will be able to set a smaller limit in their repositories.\n\n{% data reusables.profile.access_profile %}\n{% data reusables.profile.access_org %}\n{% data reusables.p", "Y2h1bmtfNl9pbmRleF8xNTMz": "rofile.org_settings %}\n{% data reusables.organizations.settings-sidebar-actions-general %}\n{% data reusables.actions.change-cache-size-limit  %}\n\n{% endif %}\n\n{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF83ODI=": "\n\nSynopsis\n\n```shell copy\ncodeql bqrs hash ... -- \n```\n\n\n\nDescription\n\n\\[Plumbing] Compute a stable hash of a BQRS file.\n\n\n\nOptions\n\n\n\nPrimary Options\n\n\n\n`<file>`\n\n\\[Mandatory] BQRS file to hash.\n\n\n\nCommon options\n\n\n\n`-h, --help`\n\nShow this help text.\n\n\n\n`-J=<opt>`\n\n\\[Advanced] Give option to the JVM running the command.\n\n(Beware that options containing spaces will not be handled correctly.)\n\n\n\n`-v, --verbose`\n\nIncrementally increase the number of progress messages printed.\n\n\n\n`-q, --quiet`\n\nIncrementally decrease the number of progress messages printed.\n\n\n\n`--verbosity=<level>`\n\n\\[Advanced] Explicitly set the verbosity level to one of errors,\nwarnings, progress, progress+, progress++, progress+++. Overrides `-v`\nand `-q`.\n\n\n\n`--logdir=<dir>`\n\n\\[Advanced] Write detailed logs to one or more files in the given\ndirectory, with generated names that include timestamps and the name of\nthe running subcommand.\n\n(To write a log file with a name you have full control over, instead\ngive `--log-to-stderr` and redirect stderr as desired.)\n\n\n\n`--common-caches=<dir>`\n\n\\[Advanced] Controls the location of cached data on disk that will\npersist between several runs of the CLI, such as downloaded QL packs and\ncompiled query plans. If not set explicitly, this defaults to a\ndirectory named `.codeql` in the user's home directory; it will be\ncreated if it doesn't already exist.\n\nAvailable since `v2.15.2`.\n\n", "Y2h1bmtfMF9pbmRleF85MjU=": "\n\nEditing advisories in the {% data variables.product.prodname_advisory_database %}\n\nThe advisories in the {% data variables.product.prodname_advisory_database %} are global security advisories. For more information about global security advisories, see \"AUTOTITLE.\"\n\nAnyone can suggest improvements on any global security advisory in the {% data variables.product.prodname_advisory_database %}. You can edit or add any detail, including additionally affected ecosystems, severity level or description of who is impacted. The {% data variables.product.prodname_security %} curation team will review the submitted improvements and publish them onto the {% data variables.product.prodname_advisory_database %} if accepted.\n\n{% ifversion security-advisories-credit-types %}\nIf we accept and publish the improvement, the person who submitted the improvement will automatically be assigned a credit type of  \"Analyst\". For more information, see \"AUTOTITLE.\"{% endif %}\n\n{% ifversion fpt or ghec %}\nOnly repository owners and administrators can edit repository-level security advisories. For more information, see \"AUTOTITLE.\"{% endif %}\n\n1. Navigate to https://github.com/advisories.\n1. Select the security advisory you would like to contribute to.\n1. On the right-hand side of the page, click the **Suggest improvements for this vulnerability** link.\n1. In the \"Improve security advisory\" form, make the desired improvements. You can edit or add any detail.{% ifversion fpt or ghec %} For information about correctly specifying information on the form, including affected versions, see \"AUTOTITLE.\"{% endif %}{% ifversion security-advisories-reason-for-change %}\n1. Under **Reason for change**, explain why you want to make this improvement. If you include links to supporting material this will help our reviewers.\n{% endif %}\n1. When you finish editing the advisory, click **Submit improvements**.\n1. Once you submit your improvements, a pull request containing your changes will be created for review in github/advisory-database by the {% data varia", "Y2h1bmtfMV9pbmRleF85MjU=": "bles.product.prodname_security %} curation team. If the advisory originated from a {% data variables.product.prodname_dotcom %} repository, we will also tag the original publisher for optional commentary. You can view the pull request and get notifications when it is updated or closed.\n\nYou can also open a pull request directly on an advisory file in the github/advisory-database repository. For more information, see the contribution guidelines.\n\n{% ifversion security-advisories-ghes-ghae %}\n\n\n\nEditing advisories from {% data variables.location.product_location %}\n\nIf you have {% data variables.product.prodname_github_connect %} enabled for {% data variables.location.product_location %}, you will be able to see advisories by adding `/advisories` to the instance url.\n\n1. Navigate to `https://HOSTNAME/advisories`.\n1. Select the security advisory you would like to contribute to.\n1. On the right-hand side of the page, click the **Suggest improvements for this vulnerability on {% data variables.product.prodname_dotcom_the_website %}.** link. A new tab opens with the same security advisory on {% data variables.product.prodname_dotcom_the_website %}.\n1. Edit the advisory, following steps four through six in \"Editing advisories in the GitHub Advisory Database\" above.\n{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF8xMDgx": "\n\nAbout YAML syntax for issue forms\n\nYou can create custom issue forms by adding a YAML form definition file to the `/.github/ISSUE_TEMPLATE` folder in your repository. {% data reusables.actions.learn-more-about-yaml %} You can define different input types, validations, default assignees, and default labels for your issue forms.\n\nWhen a contributor fills out an issue form, their responses for each input are converted to markdown and added to the body of an issue. Contributors can edit their issues that were created with issue forms and other people can interact with the issues like an issue created through other methods.\n\nIssue forms are not supported for pull requests. You can create pull request templates in your repositories for collaborators to use. For more information, see \"AUTOTITLE.\"\n\nThis example YAML configuration file defines an issue form using several inputs to report a bug.\n\n{% note %}\n\n**Note:** The `required` field key is only supported in public repositories. In private and internal repositories, all fields are optional.\n\n{% endnote %}\n\n{% data reusables.community.issue-forms-sample %}\n\n\n\nTop-level syntax\n\nAll issue form configuration files must begin with `name`, `description`, and `body` key-value pairs.\n\n```yaml copy\nname:\ndescription:\nbody:\n```\n\nYou can set the following top-level keys for each issue form.\n\n| Key | Description | Required | Type |\n| :-- | :-- | :-- | :-- |\n| `name` | A name for the issue form template. Must be unique from all other templates, including Markdown templates. | Required | String |\n| `description` | A description for the issue form template, which appears in the template chooser interface. | Required | String |\n| `body` | Definition of the input types in the form. | Required | Array |\n| `assignees` | People who will be automatically assigned to issues created with this template. | Optional | Array or comma-delimited string |\n| `labels` | Labels that will automatically be added to issues created with this template. If a label does not already exist in the repository", "Y2h1bmtfMV9pbmRleF8xMDgx": ", it will not be automatically added to the issue. | Optional | Array or comma-delimited string |\n| `title` | A default title that will be pre-populated in the issue submission form. | Optional | String |{% ifversion projects-in-issue-forms %}\n| `projects` | Projects that any issues created with this template will automatically be added to. The format of this key is `PROJECT-OWNER/PROJECT-NUMBER`. {% note %} **Note:** The person opening the issue must have write permissions for the specified projects. {% ifversion projects-v2 %} If you don't expect people using this template to have write access, consider enabling your project's auto-add workflow. For more information, see \"Adding items automatically.\"{% endif %} {% endnote %} | Optional | Array or comma-delimited string |{% endif %}\n\nFor the available `body` input types and their syntaxes, see \"AUTOTITLE.\"\n\n\n\nConverting a Markdown issue template to a YAML issue form template\n\nYou can use both Markdown and YAML issue templates in your repository. If you want to convert a Markdown issue template to a YAML issue form template, you must create a new YAML file to define the issue form. You can manually transpose an existing Markdown issue template to a YAML issue form. For more information, see \"AUTOTITLE.\"\n\nIf you want to use the same file name for your YAML issue form, you must delete the Markdown issue template when you commit the new file to your repository.\n\nAn example of a Markdown issue template and a corresponding YAML issue form template are below.\n\n\n\nMarkdown issue template\n\n```markdown copy\n---\nname: \ud83d\udc1e Bug\nabout: File a bug/issue\ntitle: '[BUG] '\nlabels: Bug, Needs Triage\nassignees: ''\n\n---\n\n{% raw %}<{% endraw %}!--\nNote: Please search to see if an issue already exists for the bug you encountered.\n--{% raw %}>{% endraw %}\n\n\n\nCurrent Behavior:\n{% raw %}{% endraw %}\n\n\n\nExpected Behavior:\n{% raw %}{% endraw %}\n\n\n\nSteps To Reproduce:\n{% raw %}<{% endraw %}!--\nExample: steps to reproduce the behavior:\n1. In this environment...\n1. With this config...\n1. Run '...", "Y2h1bmtfMl9pbmRleF8xMDgx": "'\n1. See error...\n--{% raw %}>{% endraw %}\n\n\n\nEnvironment:\n{% raw %}<{% endraw %}!--\nExample:\n- OS: Ubuntu 20.04\n- Node: 13.14.0\n- npm: 7.6.3\n--{% raw %}>{% endraw %}\n\n\n\nAnything else:\n{% raw %}<{% endraw %}!--\nLinks? References? Anything that will give us more context about the issue that you are encountering!\n--{% raw %}>{% endraw %}\n```\n\n\n\nYAML issue form template\n\n```yaml copy\nname: \ud83d\udc1e Bug\ndescription: File a bug/issue\ntitle: \"[BUG] \"\nlabels: [\"Bug\", \"Needs Triage\"]\nbody:\n- type: checkboxes\n  attributes:\n    label: Is there an existing issue for this?\n    description: Please search to see if an issue already exists for the bug you encountered.\n    options:\n    - label: I have searched the existing issues\n      required: true\n- type: textarea\n  attributes:\n    label: Current Behavior\n    description: A concise description of what you're experiencing.\n  validations:\n    required: false\n- type: textarea\n  attributes:\n    label: Expected Behavior\n    description: A concise description of what you expected to happen.\n  validations:\n    required: false\n- type: textarea\n  attributes:\n    label: Steps To Reproduce\n    description: Steps to reproduce the behavior.\n    placeholder: |\n      1. In this environment...\n      1. With this config...\n      1. Run '...'\n      1. See error...\n  validations:\n    required: false\n- type: textarea\n  attributes:\n    label: Environment\n    description: |\n      examples:\n        - **OS**: Ubuntu 20.04\n        - **Node**: 13.14.0\n        - **npm**: 7.6.3\n    value: |\n        - OS:\n        - Node:\n        - npm:\n    render: markdown\n  validations:\n    required: false\n- type: textarea\n  attributes:\n    label: Anything else?\n    description: |\n      Links? References? Anything that will give us more context about the issue you are encountering!\n\n      Tip: You can attach images or log files by clicking this area to highlight it and then dragging files in.\n  validations:\n    required: false\n```\n\n\n\nFurther reading\n\n- YAML\n- Common validation errors when creating issue forms\n\n", "Y2h1bmtfMF9pbmRleF8xNjE=": "\n\nAbout migrating from Jenkins with GitHub Actions Importer\n\nThe instructions below will guide you through configuring your environment to use {% data variables.product.prodname_actions_importer %} to migrate Jenkins pipelines to {% data variables.product.prodname_actions %}.\n\n\n\nPrerequisites\n\n- A Jenkins account or organization with pipelines and jobs that you want to convert to {% data variables.product.prodname_actions %} workflows.\n- Access to create a Jenkins personal API token for your account or organization.\n{% data reusables.actions.actions-importer-prerequisites %}\n\n\n\nLimitations\n\nThere are some limitations when migrating from Jenkins to {% data variables.product.prodname_actions %} with {% data variables.product.prodname_actions_importer %}. For example, you must migrate the following constructs manually:\n\n- Mandatory build tools\n- Scripted pipelines\n- Secrets\n- Self-hosted runners\n- Unknown plugins\n\nFor more information on manual migrations, see \"AUTOTITLE.\"\n\n\n\nInstalling the {% data variables.product.prodname_actions_importer %} CLI extension\n\n{% data reusables.actions.installing-actions-importer %}\n\n\n\nConfiguring credentials\n\nThe `configure` CLI command is used to set required credentials and options for {% data variables.product.prodname_actions_importer %} when working with Jenkins and {% data variables.product.prodname_dotcom %}.\n\n1. Create a {% data variables.product.prodname_dotcom %} {% data variables.product.pat_v1 %}. For more information, see \"AUTOTITLE.\"\n\n   Your token must have the `workflow` scope.\n\n   After creating the token, copy it and save it in a safe location for later use.\n1. Create a Jenkins API token. For more information, see Authenticating scripted clients in the Jenkins documentation.\n\n   After creating the token, copy it and save it in a safe location for later use.\n1. In your terminal, run the {% data variables.product.prodname_actions_importer %} `configure` CLI command:\n\n   ```shell\n   gh actions-importer configure\n   ```\n\n   The `configure` command will prompt you for t", "Y2h1bmtfMV9pbmRleF8xNjE=": "he following information:\n\n   - For \"Which CI providers are you configuring?\", use the arrow keys to select `Jenkins`, press Space to select it, then press Enter.\n   - For \"{% data variables.product.pat_generic_caps %} for GitHub\", enter the value of the {% data variables.product.pat_v1 %} that you created earlier, and press Enter.\n   - For \"Base url of the GitHub instance\", {% ifversion ghes or ghae %}enter the URL for your {% data variables.product.product_name %} instance, and press Enter.{% else %}press Enter to accept the default value (`https://github.com`).{% endif %}\n   - For \"{% data variables.product.pat_generic_caps %} for Jenkins\", enter the value for the Jenkins personal API token that you created earlier, and press Enter.\n   - For \"Username of Jenkins user\", enter your Jenkins username and press Enter.\n   - For \"Base url of the Jenkins instance\", enter the URL of your Jenkins instance, and press Enter.\n\n   An example of the `configure` command is shown below:\n\n   ```shell\n   $ gh actions-importer configure\n   \u2714 Which CI providers are you configuring?: Jenkins\n   Enter the following values (leave empty to omit):\n   \u2714 {% data variables.product.pat_generic_caps %} for GitHub: ***************\n   \u2714 Base url of the GitHub instance: https://github.com\n   \u2714 {% data variables.product.pat_generic_caps %} for Jenkins: ***************\n   \u2714 Username of Jenkins user: admin\n   \u2714 Base url of the Jenkins instance: https://localhost\n   Environment variables successfully updated.\n   ```\n\n1. In your terminal, run the {% data variables.product.prodname_actions_importer %} `update` CLI command to connect to {% data variables.product.prodname_registry %} {% data variables.product.prodname_container_registry %} and ensure that the container image is updated to the latest version:\n\n   ```shell\n   gh actions-importer update\n   ```\n\n   The output of the command should be similar to below:\n\n   ```shell\n   Updating ghcr.io/actions-importer/cli:latest...\n   ghcr.io/actions-importer/cli:latest up-to-date  \n   ```\n\n\n\nPerform an au", "Y2h1bmtfMl9pbmRleF8xNjE=": "dit of Jenkins\n\nYou can use the `audit` command to get a high-level view of all pipelines in a Jenkins server.\n\nThe `audit` command performs the following steps:\n\n1. Fetches all of the projects defined in a Jenkins server.\n1. Converts each pipeline to its equivalent {% data variables.product.prodname_actions %} workflow.\n1. Generates a report that summarizes how complete and complex of a migration is possible with {% data variables.product.prodname_actions_importer %}.\n\n\n\nRunning the audit command\n\nTo perform an audit of a Jenkins server, run the following command in your terminal:\n\n```shell\ngh actions-importer audit jenkins --output-dir tmp/audit\n```\n\n\n\nInspecting the audit results\n\n{% data reusables.actions.gai-inspect-audit %}\n\n\n\nForecast potential build runner usage\n\nYou can use the `forecast` command to forecast potential {% data variables.product.prodname_actions %} usage by computing metrics from completed pipeline runs in your Jenkins server.\n\n\n\nPrerequisites for running the forecast command\n\nIn order to run the `forecast` command against a Jenkins instance, you must install the `paginated-builds` plugin on your Jenkins server. This plugin allows {% data variables.product.prodname_actions_importer %} to efficiently retrieve historical build data for jobs that have a large number of builds. Because Jenkins does not provide a method to retrieve paginated build data, using this plugin prevents timeouts from the Jenkins server that can occur when fetching a large amount of historical data. The `paginated-builds` plugin is open source, and exposes a REST API endpoint to fetch build data in pages, rather than all at once.\n\nTo install the `paginated-builds` plugin:\n\n1. On your Jenkins instance, navigate to `https:///pluginManager/available`.\n1. Search for the `paginated-builds` plugin.\n1. Check the box on the left and select **Install without restart**.\n\n\n\nRunning the forecast command\n\nTo perform a forecast of potential {% data variables.product.prodname_actions %}, run the following command in your terminal. By", "Y2h1bmtfM19pbmRleF8xNjE=": " default, {% data variables.product.prodname_actions_importer %} includes the previous seven days in the forecast report.\n\n```shell\ngh actions-importer forecast jenkins --output-dir tmp/forecast \n```\n\n\n\nInspecting the forecast report\n\nThe `forecast_report.md` file in the specified output directory contains the results of the forecast.\n\nListed below are some key terms that can appear in the forecast report:\n\n- The **job count** is the total number of completed jobs.\n- The **pipeline count** is the number of unique pipelines used.\n- **Execution time** describes the amount of time a runner spent on a job. This metric can be used to help plan for the cost of {% data variables.product.prodname_dotcom %}-hosted runners.\n  - This metric is correlated to how much you should expect to spend in {% data variables.product.prodname_actions %}. This will vary depending on the hardware used for these minutes. You can use the {% data variables.product.prodname_actions %} pricing calculator to estimate the costs.\n- **Queue time** metrics describe the amount of time a job spent waiting for a runner to be available to execute it.\n- **Concurrent jobs** metrics describe the amount of jobs running at any given time. This metric can be used to define the number of runners you should configure.\n\nAdditionally, these metrics are defined for each queue of runners in Jenkins. This is especially useful if there is a mix of hosted or self-hosted runners, or high or low spec machines, so you can see metrics specific to different types of runners.\n\n\n\nPerform a dry-run migration of a Jenkins pipeline\n\nYou can use the `dry-run` command to convert a Jenkins pipeline to its equivalent {% data variables.product.prodname_actions %} workflow.\n\n\n\nRunning the dry-run command\n\nYou can use the `dry-run` command to convert a Jenkins pipeline to an equivalent {% data variables.product.prodname_actions %} workflow. A dry-run creates the output files in a specified directory, but does not open a pull request to migrate the pipeline.\n\nTo perform a dry run of m", "Y2h1bmtfNF9pbmRleF8xNjE=": "igrating your Jenkins pipelines to {% data variables.product.prodname_actions %}, run the following command in your terminal, replacing `my-jenkins-project` with the URL of your Jenkins job.\n\n```shell\ngh actions-importer dry-run jenkins --source-url my-jenkins-project --output-dir tmp/dry-run\n```\n\n\n\nInspecting the converted workflows\n\nYou can view the logs of the dry run and the converted workflow files in the specified output directory.\n\n{% data reusables.actions.gai-custom-transformers-rec %}\n\n\n\nPerform a production migration of a Jenkins pipeline\n\nYou can use the `migrate` command to convert a Jenkins pipeline and open a pull request with the equivalent {% data variables.product.prodname_actions %} workflow.\n\n\n\nRunning the migrate command\n\nTo migrate a Jenkins pipeline to {% data variables.product.prodname_actions %}, run the following command in your terminal, replacing the `target-url` value with the URL for your {% data variables.product.product_name %} repository, and `my-jenkins-project` with the URL for your Jenkins job.\n\n```shell\ngh actions-importer migrate jenkins --target-url https://github.com/:owner/:repo --output-dir tmp/migrate --source-url my-jenkins-project\n```\n\nThe command's output includes the URL to the pull request that adds the converted workflow to your repository. An example of a successful output is similar to the following:\n\n```shell\n$ gh actions-importer migrate jenkins --target-url https://github.com/octo-org/octo-repo --output-dir tmp/migrate --source-url http://localhost:8080/job/monas_dev_work/job/monas_freestyle\n[2022-08-20 22:08:20] Logs: 'tmp/migrate/log/actions-importer-20220916-014033.log'\n[2022-08-20 22:08:20] Pull request: 'https://github.com/octo-org/octo-repo/pull/1'\n```\n\n{% data reusables.actions.gai-inspect-pull-request %}\n\n\n\nReference\n\nThis section contains reference information on environment variables, optional arguments, and supported syntax when using {% data variables.product.prodname_actions_importer %} to migrate from Jenkins.\n\n\n\nUsing environment variables\n\n{% d", "Y2h1bmtfNV9pbmRleF8xNjE=": "ata reusables.actions.gai-config-environment-variables %}\n\n{% data variables.product.prodname_actions_importer %} uses the following environment variables to connect to your Jenkins instance:\n\n- `GITHUB_ACCESS_TOKEN`: The {% data variables.product.pat_v1 %} used to create pull requests with a converted workflow (requires `repo` and `workflow` scopes).\n- `GITHUB_INSTANCE_URL`: The URL to the target {% data variables.product.prodname_dotcom %} instance (for example, `https://github.com`).\n- `JENKINS_ACCESS_TOKEN`: The Jenkins API token used to view Jenkins resources.\n\n  {% note %}\n\n  **Note**: This token requires access to all jobs that you want to migrate or audit. In cases where a folder or job does not inherit access control lists from their parent, you must grant explicit permissions or full admin privileges.\n\n  {% endnote %}\n\n- `JENKINS_USERNAME`: The username of the user account that created the Jenkins API token.\n- `JENKINS_INSTANCE_URL`: The URL of the Jenkins instance.\n- `JENKINSFILE_ACCESS_TOKEN` (Optional) The API token used to retrieve the contents of a `Jenkinsfile` stored in the build repository. This requires the `repo` scope.  If this is not provided, the `GITHUB_ACCESS_TOKEN` will be used instead.\n\nThese environment variables can be specified in a `.env.local` file that is loaded by {% data variables.product.prodname_actions_importer %} when it is run.\n\n\n\nUsing optional arguments\n\n{% data reusables.actions.gai-optional-arguments-intro %}\n\n\n\n`--source-file-path`\n\nYou can use the `--source-file-path` argument with the `forecast`, `dry-run`, or `migration` subcommands.\n\nBy default, {% data variables.product.prodname_actions_importer %} fetches pipeline contents from source control. The `--source-file-path` argument tells {% data variables.product.prodname_actions_importer %} to use the specified source file path instead. You can use this option for Jenkinsfile and multibranch pipelines.\n\nIf you would like to supply multiple source files when running the `forecast` subcommand, you can use pattern match", "Y2h1bmtfNl9pbmRleF8xNjE=": "ing in the file path value. For example, `gh forecast --source-file-path ./tmp/previous_forecast/jobs/*.json` supplies {% data variables.product.prodname_actions_importer %} with any source files that match the `./tmp/previous_forecast/jobs/*.json` file path.\n\n\n\nJenkinsfile pipeline example\n\nIn this example, {% data variables.product.prodname_actions_importer %} uses the specified Jenkinsfile as the source file to perform a dry run.\n\n```shell\ngh actions-importer dry-run jenkins --output-dir path/to/output/ --source-file-path path/to/Jenkinsfile --source-url :url_to_jenkins_job\n```\n\n\n\n`--config-file-path`\n\nYou can use the `--config-file-path` argument with the `audit`, `dry-run`, and `migrate` subcommands.\n\nBy default, {% data variables.product.prodname_actions_importer %} fetches pipeline contents from source control. The `--config-file-path` argument tells {% data variables.product.prodname_actions_importer %} to use the specified source files instead.\n\nWhen you use the `--config-file-path` option with the `dry-run` or `migrate` subcommands, {% data variables.product.prodname_actions_importer %} matches the repository slug to the job represented by the `--source-url` option to select the pipeline. It uses the `config-file-path` to pull the specified source file.\n\n\n\nAudit example\n\nIn this example, {% data variables.product.prodname_actions_importer %} uses the specified YAML configuration file to perform an audit.\n\n```shell\ngh actions-importer audit jenkins --output-dir path/to/output/ --config-file-path path/to/jenkins/config.yml\n```\n\nTo audit a Jenkins instance using a config file, the config file must be in the following format, and each `repository_slug` value must be unique:\n\n```yaml\nsource_files:\n  - repository_slug: pipeline-name\n    path: path/to/Jenkinsfile\n  - repository_slug: multi-branch-pipeline-name\n    branches:\n      - branch: main\n        path: path/to/Jenkinsfile\n      - branch: node\n        path: path/to/Jenkinsfile\n```\n\n\n\nSupported syntax for Jenkins pipelines\n\nThe following tables show the ty", "Y2h1bmtfN19pbmRleF8xNjE=": "pe of properties {% data variables.product.prodname_actions_importer %} is currently able to convert. For more details about how Jenkins pipeline syntax aligns with {% data variables.product.prodname_actions %}, see \"AUTOTITLE\".\n\nFor information about supported Jenkins plugins, see the `github/gh-actions-importer` repository.\n\n\n\nSupported syntax for Freestyle pipelines\n\n| Jenkins                   | GitHub Actions                     |              Status |\n| :------------------------ | :--------------------------------- | :------------------ |\n| docker template           | `jobs..container`          |           Supported |\n| build                     | `jobs`                             | Partially supported |\n| build environment         | `env`                              | Partially supported |\n| build triggers            | `on`                               | Partially supported |\n| general                   | `runners`                          | Partially supported |\n\n\n\nSupported syntax for Jenkinsfile pipelines\n\n| Jenkins     | GitHub Actions                     |              Status |\n| :---------- | :--------------------------------- | :------------------ |\n| docker      | `jobs..container`          |           Supported |\n| stage       | `jobs.`                    |           Supported |\n| agent       | `runners`                          | Partially supported |\n| environment | `env`                              | Partially supported |\n| stages      | `jobs`                             | Partially supported |\n| steps       | `jobs..steps`              | Partially supported |\n| triggers    | `on`                               | Partially supported |\n| when        | `jobs..if`                 | Partially supported |\n| inputs      | `inputs`                           |         Unsupported |\n| matrix      | `jobs..strategy.matrix`    |         Unsupported |\n| options     | `jobs..strategy`           |         Unsupported |\n| parameters  | `inputs`                           |         Unsupported |\n\n\n\nEnvironm", "Y2h1bmtfOF9pbmRleF8xNjE=": "ent variables syntax\n\n{% data variables.product.prodname_actions_importer %} uses the mapping in the table below to convert default Jenkins environment variables to the closest equivalent in {% data variables.product.prodname_actions %}.\n\n| Jenkins           | GitHub Actions                                                                        |\n| :---------------- | :------------------------------------------------------------------------------------ |\n| `${BUILD_ID}`     | `{% raw %}${{ github.run_id }}{% endraw %}`                                                                |\n| `${BUILD_NUMBER}` | `{% raw %}${{ github.run_id }}{% endraw %}`                                                                |\n| `${BUILD_TAG}`    | `{% raw %}${{ github.workflow }}-${{ github.run_id }}{% endraw %}`                                         |\n| `${BUILD_URL}`    | `{% raw %}${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}{% endraw %}` |\n| `${JENKINS_URL}`  | `{% raw %}${{ github.server_url }}{% endraw %}`                                                            |\n| `${JOB_NAME}`     | `{% raw %}${{ github.workflow }}{% endraw %}`                                                              |\n| `${WORKSPACE}`    | `{% raw %}${{ github.workspace }}{% endraw %}`                                                             |\n\n\n\nLegal notice\n\n{% data reusables.actions.actions-importer-legal-notice %}\n\n", "Y2h1bmtfMF9pbmRleF80ODU=": "\n\nAbout {% data variables.product.prodname_github_apps %}\n\n{% data variables.product.prodname_github_apps %} are tools that extend {% data variables.product.company_short %}'s functionality. {% data variables.product.prodname_github_apps %} can do things on {% data variables.product.company_short %} like open issues, comment on pull requests, and manage projects. They can also do things outside of {% data variables.product.company_short %} based on events that happen on {% data variables.product.company_short %}. For example, a {% data variables.product.prodname_github_app %} can post on Slack when an issue is opened on {% data variables.product.company_short %}.\n\nFor more information about using {% data variables.product.prodname_github_apps %}, see \"AUTOTITLE.\"\n\nFor more information about building {% data variables.product.prodname_github_apps %}, see \"AUTOTITLE.\"\n\n\n\n{% data variables.product.prodname_github_apps %} and {% data variables.product.prodname_oauth_apps %}\n\n{% data variables.product.company_short %} also supports {% data variables.product.prodname_oauth_apps %}. In general, {% data variables.product.prodname_github_apps %} are preferred over {% data variables.product.prodname_oauth_apps %}. {% data variables.product.prodname_github_apps %} use fine-grained permissions, give the user more control over which repositories the app can access, and use short-lived tokens. These properties can harden the security of the app by limiting the damage that could be done if the app's credentials were leaked. For more information, see \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF8yNjE=": "---\ntitle: Validating your domain settings\nintro: 'Ensure that your domain settings are properly configured before booting up {% data variables.location.product_location %} for the first time.'\nredirect_from:\n  - /enterprise/admin/installation/validating-your-domain-settings\n  - /enterprise/admin/configuration/validating-your-domain-settings\n  - /admin/configuration/validating-your-domain-settings\nversions:\n  ghes: '*'\ntype: how_to\ntopics:\n  - Enterprise\n  - Fundamentals\n  - Infrastructure\n  - Networking\nshortTitle: Validate domain settings\n---\n{% data reusables.enterprise_site_admin_settings.access-settings %}\n{% data reusables.enterprise_site_admin_settings.management-console %}\n{% data reusables.enterprise_management_console.hostname-menu-item %}\n1. To test your appliance's DNS and SSL settings, under \"Hostname\", click **Test domain settings**.\n{% data reusables.enterprise_management_console.test-domain-settings-failure %}\n{% data reusables.enterprise_management_console.save-settings %}\n\n", "Y2h1bmtfMF9pbmRleF8xNjYw": "\n\nFurther reading\n\n- kramdown Documentation\n- {% data variables.product.prodname_dotcom %} Flavored Markdown Spec\n\n", "Y2h1bmtfMF9pbmRleF80NzM=": "\n\nAbout policies for {% data variables.product.prodname_copilot %} in your enterprise\n\n{% data reusables.copilot.about-copilot %}\n\nYou can enforce policies for {% data variables.product.prodname_copilot_for_business %} within your enterprise's organizations, or allow policies to be set in each organization.\n\nIf you set up a subscription for {% data variables.product.prodname_copilot_for_business %}, you can grant and revoke access to {% data variables.product.prodname_copilot %} for organizations within your enterprise. Once you grant an organization access to {% data variables.product.prodname_copilot %}, the admins of that organization can grant access to individuals and teams. For more information, see \"AUTOTITLE.\"\n\n{% data variables.product.prodname_copilot_for_business %} subscriptions are billed monthly, based on the number of {% data variables.product.prodname_copilot %} seats assigned to users within your enterprise. For more information, see \"AUTOTITLE.\"\n\nWherever a restrictive policy has been chosen at the enterprise level, an organization owner will not be able to select a more permissive policy at the organization level. In cases where no policy is selected at the enterprise level, and multiple organizations within the enterprise have chosen different policies, the most restrictive policy will always take precedence.\n\n\n\nEnforcing a policy to manage the use of {% data variables.product.prodname_copilot_for_business %} in your enterprise\n\nEnterprise owners can choose whether to grant access to {% data variables.product.prodname_copilot %} for all, none, or a selection of organizations within the enterprise.\n\n{% data reusables.enterprise-accounts.policies-tab %}\n{% data reusables.enterprise-accounts.copilot-tab %}\n1. Under \"Manage organization access to {% data variables.product.prodname_copilot %},\" configure the access for your {% data variables.product.prodname_copilot %} subscription.\n    - To disable {% data variables.product.prodname_copilot %} for all organizations in your enterprise, select **Dis", "Y2h1bmtfMV9pbmRleF80NzM=": "abled**.\n    - To enable {% data variables.product.prodname_copilot %} for all organizations in your enterprise, both current and future, select **Allow for all organizations**.\n    - To enable {% data variables.product.prodname_copilot %} for specific organizations, select **Allow for specific organizations**.\n\n1. If you selected **Allow for specific organizations**, select the organizations you want to enable {% data variables.product.prodname_copilot %} for. Alternatively, you can select the organizations you want to disable {% data variables.product.prodname_copilot %} access for.\n    - Click the **Set organization permissions** dropdown and select **Enable** or **Disable** to grant or deny {% data variables.product.prodname_copilot %} access for the specified organizations.\n\n    !Screenshot of the {% data variables.product.prodname_copilot %} policy page. The organization permissions dropdown is outlined in dark orange.\n\n1. Click **Save**.\n\n\n\nEnforcing a policy to manage the use of {% data variables.product.prodname_copilot %} suggestions that match public code in your enterprise\n\n{% data variables.product.prodname_copilot %} includes a filter which detects code suggestions that match public code on {% data variables.product.prodname_dotcom %}. {% data variables.product.prodname_copilot_for_business %} lets you choose whether to enable or disable the filter at the enterprise level, or allow organization owners to decide at the organization level. When the filter is enabled, {% data variables.product.prodname_copilot %} checks code suggestions with their surrounding code of about 150 characters against public code on {% data variables.product.prodname_dotcom %}. If there is a match or near match, the suggestion will not be shown.\n\n{% data reusables.enterprise-accounts.policies-tab %}\n{% data reusables.enterprise-accounts.copilot-tab %}\n1. Under \"Suggestions matching public code,\" click the dropdown menu and select the policy you want to enforce.\n    - To allow {% data variables.product.prodname_copilot %} sug", "Y2h1bmtfMl9pbmRleF80NzM=": "gestions matching public code, select **Allowed**.\n    - To block {% data variables.product.prodname_copilot %} suggestions matching public code, select **Blocked**.\n    - To allow each of your organizations to set their own policy on the use of {% data variables.product.prodname_copilot %} suggestions matching public code, select **No policy (let each organization decide)**.\n\n    !Screenshot of the {% data variables.product.prodname_copilot %} policy page. The dropdown menu of suggestions that match public code settings is outlined in dark orange.\n\n\n\nEnforcing a policy to manage the use of {% data variables.product.prodname_copilot_chat %} (beta) in your enterprise\n\n{% data variables.product.prodname_copilot_chat %} is a feature that allows users to chat with {% data variables.product.prodname_copilot %} to get code suggestions and answers to coding-related questions. You can enable or disable {% data variables.product.prodname_copilot_chat %} for organizations under your enterprise. Alternatively, you can allow organization owners to select their own policy to determine access to {% data variables.product.prodname_copilot_chat %} for each organization. For more information, see \"AUTOTITLE.\"\n\n{% data reusables.enterprise-accounts.policies-tab %}\n{% data reusables.enterprise-accounts.copilot-tab %}\n1. Under \"{% data variables.product.prodname_copilot_chat %},\" click the dropdown menu and select the policy you want to enforce.\n    - To allow {% data variables.product.prodname_copilot_chat %} use, select **Allowed**.\n    - To block {% data variables.product.prodname_copilot_chat %} use, select **Blocked**.\n    - To allow each of your organizations to set their own policy on the use of {% data variables.product.prodname_copilot_chat %}, select **No policy (let each organization decide)**.\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n- {% data variables.product.prodname_copilot %} Trust Center\n\n", "Y2h1bmtfMF9pbmRleF8xNjk4": "\n\nAbout reviewing pull requests\n\nYou can review changes in a pull request one file at a time. While reviewing the files in a pull request, you can leave individual comments on specific changes. After you finish reviewing each file, you can mark the file as viewed. This collapses the file, helping you identify the files you still need to review. A progress bar in the pull request header shows the number of files you've viewed. After reviewing as many files as you want, you can approve the pull request or request additional changes by submitting your review with a summary comment.\n\n{% data reusables.search.requested_reviews_search_tip %}\n\n\n\nStarting a review\n\n{% webui %}\n\n{% data reusables.repositories.sidebar-pr %}\n{% data reusables.repositories.choose-pr-review %}\n{% data reusables.repositories.changed-files %}\nYou can change the format of the diff view in this tab by clicking {% octicon \"gear\" aria-label=\"The Settings gear\" %} and choosing the unified or split view. The choice you make will apply when you view the diff for other pull requests.\n\n   !Screenshot of the \"Files changed\" tab for a pull request. The \"Diff view\" menu is outlined in dark orange.\n\n   You can also choose to hide whitespace differences. The choice you make only applies to this pull request and will be remembered the next time you visit this page.\n1. Optionally, filter the files to show only the files you want to review{% ifversion pr-tree-view %} or use the file tree to navigate to a specific file{% endif %}. For more information, see \"AUTOTITLE.\"\n{% data reusables.repositories.start-line-comment %}\n{% data reusables.repositories.type-line-comment %}\n{% data reusables.repositories.suggest-changes %}\n{% ifversion pull-request-comment-on-file %}\n{% data reusables.repositories.start-file-comment %}{% endif %}\n1. When you're done, click **Start a review**. If you have already started a review, you can click **Add review comment**.\n\nBefore you submit your review, your line comments are _pending_ and only visible to you. You can edit pending comm", "Y2h1bmtfMV9pbmRleF8xNjk4": "ents anytime before you submit your review. To cancel a pending review, including all of its pending comments, click **Review changes** above the changed code, then click **Cancel review**.\n\n!Screenshot of the comment field for a review. The \"Cancel review\" button is outlined in dark orange.\n{% endwebui %}\n\n{% ifversion fpt or ghec %}\n\n{% codespaces %}\n\nYou can use {% data variables.product.prodname_github_codespaces %} to test, run, and review pull requests.\n\n1. Open the pull request in a codespace, as described in \"AUTOTITLE.\"\n1. In the Activity Bar, click the **GitHub Pull Request** view. This view only appears when you open a pull request in a codespace.\n\n   !Screenshot of the {% data variables.product.prodname_vscode_shortname %} Activity Bar. The mouse pointer is hovering over an icon displaying the tooltip \"{% data variables.product.prodname_dotcom %} Pull Request.\"\n\n1. To review a specific file, click the **Open File** icon in the Side Bar.\n\n   !Screenshot of the \"{% data variables.product.prodname_dotcom %} Pull Request\" side bar. A file name is highlighted with a dark orange outline.\n\n1. To add review comments, click the **+** icon next to the line number. Type your review comment and then click **Start Review**.\n\n   !Screenshot of a comment being added, reading \"Yes, I agree, this is clearer.\" The \"Start Review\" button is shown below the comment.\n\n1. When you are finished adding review comments, from the Side Bar you can choose to either submit the comments, approve the changes, or request changes.\n\n   !Screenshot of the side bar showing the dropdown options \"Comment and Submit,\" \"Approve and Submit,\" and \"Request Changes and Submit.\"\n\nFor more information on reviewing pull requests in {% data variables.product.prodname_github_codespaces %}, see \"AUTOTITLE.\"\n\n{% endcodespaces %}\n{% endif %}\n\n{% ifversion fpt or ghes or ghec %}\n\n\n\nReviewing dependency changes\n\nIf the pull request contains changes to dependencies you can use the dependency review for a manifest or lock file to see what has changed and ch", "Y2h1bmtfMl9pbmRleF8xNjk4": "eck whether the changes introduce security vulnerabilities. For more information, see \"AUTOTITLE.\"\n\n{% data reusables.repositories.changed-files %}\n\n1. On the right of the header for a manifest or lock file, display the dependency review by clicking the **{% octicon \"file\" aria-label=\"The rich diff icon\" %}** rich diff button.\n\n   !Screenshot of the \"Files changed\" tab of a pull request. The button to display the rich diff, labeled with a file icon, is outlined in dark orange.\n\n{% data reusables.repositories.return-to-source-diff %}\n{% endif %}\n\n\n\nMarking a file as viewed\n\nAfter you finish reviewing a file, you can mark the file as viewed, and the file will collapse. If the file changes after you view the file, it will be unmarked as viewed.\n\n{% data reusables.repositories.changed-files %}\n1. On the right of the header of the file you've finished reviewing, select **Viewed**.\n\n   !Screenshot of the header of a file. The \"Viewed\" option is outlined in dark orange.\n\n\n\nSubmitting your review\n\nAfter you've finished reviewing all the files you want in the pull request, submit your review.\n\n{% data reusables.repositories.changed-files %}\n{% data reusables.repositories.review-changes %}\n{% data reusables.repositories.review-summary-comment %}\n1. Select the type of review you'd like to leave:\n\n    - Select **Comment** to leave general feedback without explicitly approving the changes or requesting additional changes.\n    - Select **Approve** to submit your feedback and approve merging the changes proposed in the pull request.\n    - Select **Request changes** to submit feedback that must be addressed before the pull request can be merged.\n{% data reusables.repositories.submit-review %}\n\n{% data reusables.repositories.request-changes-tips %}\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF80NTE=": "\n\nAbout {% data variables.product.product_name %}\n\n{% data reusables.enterprise.ghes-is-a-self-hosted-platform %} Your team can use {% data variables.product.product_name %} to build and ship software using Git version control, powerful APIs, productivity and collaboration tools, and integrations. Developers familiar with {% data variables.product.prodname_dotcom_the_website %} can onboard and contribute seamlessly using familiar features and workflows. {% data reusables.enterprise.about-github-for-enterprises %}\n\n{% data reusables.enterprise.ghes-runs-on-your-infrastructure %}\n\n{% data reusables.enterprise.github-distributes-ghes %} For more information, see \"AUTOTITLE.\"\n\n{% note %}\n\n**Note:** Installing third-party software or making changes to the underlying operating system is not supported for {% data variables.product.prodname_ghe_server %}.\n\n{% endnote %}\n\nYou can choose to deploy {% data variables.product.product_name %} on premises, or to a supported cloud environment.\n\n\n\nSupported environments for deployment\n\nYou can deploy {% data variables.product.product_name %} to a virtualization hypervisor within your on-premises datacenter, or to a public cloud service.\n\n{% data variables.product.company_short %} supports the following virtualization hypervisors for on-premises deployment.\n\n- Microsoft Hyper-V\n- OpenStack KVM\n- VMware ESXi\n\n{% data variables.product.company_short %} supports the following services for cloud deployment.\n\n- Amazon Web Services (AWS)\n- Google Cloud Platform (GCP)\n- Microsoft Azure\n\nFor more information, see \"AUTOTITLE.\"\n\n\n\nAbout releases and upgrades\n\n{% data reusables.enterprise.constantly-improving %} You are responsible for upgrades to your instance. For more information, see \"AUTOTITLE.\"\n\n\n\nAbout administration\n\nYou can configure and monitor {% data variables.product.product_name %} via browser, administrative SSH access, and REST or GraphQL APIs. {% data variables.product.company_short %} has found that people with Linux administration experience are more successful with the de", "Y2h1bmtfMV9pbmRleF80NTE=": "ployment and maintenance of {% data variables.product.product_name %}.\n\nYou can give certain employees administrative access to {% data variables.product.product_name %}, so they can set up external authentication, configure the instance to meet developer needs, and monitor the instance's activity and performance. To ensure compliance with business rules or regulatory restrictions, administrators can configure policies that control how people use {% data variables.location.product_location %}. For more information, see the following articles.\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n\n\nAbout optional features\n\nYou can configure optional features for {% data variables.product.product_name %} that improve the software development lifecycle for your enterprise.\n\n| Feature | Description | More information |\n| :- | :- | :- |\n| {% data variables.product.prodname_actions %} | Automate CI/CD and development workflows | \"AUTOTITLE\" |\n| {% data variables.product.prodname_github_connect %} | Benefit from the power of {% data variables.product.prodname_dotcom_the_website %} in limited ways | \"AUTOTITLE\" |\n| {% data variables.product.prodname_GH_advanced_security %} | Improve code security and quality | \"AUTOTITLE\" |\n| {% data variables.product.prodname_registry %} | Host software packages for your enterprise | \"AUTOTITLE\" |\n\n\n\nAbout deployment topologies\n\nBy default, {% data variables.product.product_name %} runs as a standalone instance. You can increase the reliability and performance of {% data variables.product.product_name %} by using a different topology for your deployment.\n\n- To mitigate the impact of system or network failures, you can deploy a passive replica instance. During an outage that affects your primary instance, you can manually fail over to the replica instance. For more information, see \"AUTOTITLE.\"\n- You can configure multiple active replicas to improve performance for developers who are geographically distant from your primary instance. For more information, ", "Y2h1bmtfMl9pbmRleF80NTE=": "see \"AUTOTITLE.\"\n- Some enterprises with tens of thousands of developers may benefit from a cluster configuration that scales horizontally instead of vertically. For more information, see \"AUTOTITLE.\"\n\n\n\nAbout backups and disaster recovery\n\nTo safeguard against data loss or service disruptions for your developers, {% data variables.product.company_short %} strongly recommends that you establish a plan for disaster recovery. You can back up your instance's configuration and user data by deploying and configuring a Linux or Unix host system with {% data variables.product.prodname_enterprise_backup_utilities %}. For more information, see \"AUTOTITLE.\"\n\nAdditionally, you can configure a passive replica instance to fail over to in the event of a system or network failure. For more information, see \"About deployment topologies.\"\n\n\n\nAbout documentation\n\nDocumentation for both administrators and users of {% data variables.product.product_name %} is available on this site, {% data variables.product.prodname_docs %}.\n\n- Enterprise administrator documentation\n- User documentation\n\nDifferent versions of {% data variables.product.product_name %} are reflected separately in the documentation on {% data variables.product.prodname_docs %}. For more information, see \"AUTOTITLE.\"\n\n\n\nTrying {% data variables.product.product_name %}\n\nYou can sign up for a free, 45-day trial of {% data variables.product.product_name %}. For more information, see \"AUTOTITLE.\"\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n-  {% data variables.product.prodname_roadmap %}  in the  `github/roadmap` repository\n\n", "Y2h1bmtfMF9pbmRleF8yMDIy": "---\ntitle: GitHub Active Malware or Exploits\nshortTitle: Active Malware or Exploits\nversions:\n  fpt: '*'\ntopics:\n  - Policy\n  - Legal\nredirect_from:\n  - /github/site-policy/github-active-malware-or-exploits\n  - /github/site-policy/github-community-guidelines#active-malware-or-exploits\n---\n\nBeing part of a community includes not taking advantage of other members of the community. We do not allow anyone to use our platform in direct support of unlawful attacks that cause technical harms, such as using GitHub as a means to deliver malicious executables or as attack infrastructure, for example by organizing denial of service attacks or managing command and control servers. Technical harms means overconsumption of resources, physical damage, downtime, denial of service, or data loss, with no implicit or explicit dual-use purpose prior to the abuse occurring.\n\n  Note that GitHub allows dual-use content and supports the posting of content that is used for research into vulnerabilities, malware, or exploits, as the publication and distribution of such content has educational value and provides a net benefit to the security community. We assume positive intention and use of these projects to promote and drive improvements across the ecosystem.\n\n  In rare cases of very widespread abuse of dual-use content, we may restrict access to that specific instance of the content to disrupt an ongoing unlawful attack or malware campaign that is leveraging the GitHub platform as an exploit or malware CDN. In most of these instances, restriction takes the form of putting the content behind authentication, but may, as an option of last resort, involve disabling access or full removal where this is not possible (e.g. when posted as a gist). We will also contact the project owners about restrictions put in place where possible.\n\n  Restrictions are temporary where feasible, and do not serve the purpose of purging or restricting any specific dual-use content, or copies of that content, from the platform in perpetuity. While we aim to make t", "Y2h1bmtfMV9pbmRleF8yMDIy": "hese rare cases of restriction a collaborative process with project owners, if you do feel your content was unduly restricted, we have an appeals process in place.\n\n  To facilitate a path to abuse resolution with project maintainers themselves, prior to escalation to GitHub abuse reports, we recommend, but do not require, that repository owners take the following steps when posting potentially harmful security research content:\n\n- Clearly identify and describe any potentially harmful content in a disclaimer in the project\u2019s README.md file or source code comments.\n- Provide a preferred contact method for any 3rd party abuse inquiries through a SECURITY.md file in the repository (e.g. \"Please create an issue on this repository for any questions or concerns\"). Such a contact method allows 3rd parties to reach out to project maintainers directly and potentially resolve concerns without the need to file abuse reports.\n\n  _GitHub considers the npm registry to be a platform used primarily for installation and run-time use of code, and not for research._\n\n", "Y2h1bmtfMF9pbmRleF8xMDc2": "\n\nRequired top level key `name` is missing\n\nThe template does not contain a `name` field, which means it is not clear what to call your issue template when giving users a list of options.\n\n\n\nExample of \"required top level key `name` is missing\" error\n\n```yaml\ndescription: \"Thank you for reporting a bug!\"\n...\n```\n\nThe error can be fixed by adding `name` as a key.\n\n```yaml\nname: \"Bug report\"\ndescription: \"Thank you for reporting a bug!\"\n...\n```\n\n\n\n`key` must be a string\n\nThis error message means that a permitted key has been provided, but its value cannot be parsed as the data type is not supported.\n\n\n\nExample of \"`key` must be a string\" error\n\nThe `description` below is being parsed as a Boolean, but it should be a string.\n\n```yaml\nname: \"Bug report\"\ndescription: true\n...\n```\n\nThe error can be fixed by providing a string as the value. Strings may need to be wrapped in double quotes to be successfully parsed. For example, strings that contain `'` must be wrapped in double quotes.\n\n```yaml\nname: \"Bug report\"\ndescription: \"true\"\n...\n```\n\nEmpty strings, or strings consisting of only whitespaces, are also not permissible when the field expects a string.\n\n```yaml\nname: \"\"\ndescription: \"File a bug report\"\nassignees: \"      \"\n...\n```\n\nThe error can be fixed by correcting the value to be a non-empty string. If the field is not required, you should delete the key-value pair.\n\n```yaml\nname: \"Bug Report\"\ndescription: \"File a bug report\"\n...\n```\n\n\n\n`input` is not a permitted key\n\nAn unexpected key was supplied at the top level of the template. For more information about which top-level keys are supported, see \"AUTOTITLE.\"\n\n\n\nExample of \"`input` is not a permitted key\" error\n\n```yaml\nname: \"Bug report\"\nhello: world\n...\n```\n\nThe error can be fixed by removing the unexpected keys.\n\n```yaml\nname: \"Bug report\"\n...\n```\n\n\n\nForbidden keys\n\nYAML parses certain strings as `Boolean` values. To avoid this, we have explicitly forbidden the usage of the following keys:\n\n`y`, `Y`, `yes`, `Yes`, `YES`, `n`, `N`, `no`, `No`, `NO`, `true`, `Tru", "Y2h1bmtfMV9pbmRleF8xMDc2": "e`, `TRUE`, `false`, `False`, `FALSE`, `on`, `On`, `ON`, `off`, `Off`, `OFF`\n\nThe error can be fixed by removing the forbidden keys.\n\n\n\nBody must contain at least one non-markdown field\n\nIssue forms must accept user input, which means that at least one of its fields must contain a user input field. A `markdown` element is static text, so a `body` array cannot contain only `markdown` elements.\n\n\n\nExample of \"body must contain at least one non-markdown field\" error\n\n```yaml\nname: \"Bug report\"\nbody:\n- type: markdown\n  attributes:\n    value: \"Bugs are the worst!\"\n```\n\nThe error can be fixed by adding non-markdown elements that accept user input.\n\n```yaml\nname: \"Bug report\"\nbody:\n- type: markdown\n  attributes:\n    value: \"Bugs are the worst!\"\n- type: textarea\n  attributes:\n    label: \"What's wrong?\"\n```\n\n\n\nBody must have unique ids\n\nIf using `id` attributes to distinguish multiple elements, each `id` attribute must be unique.\n\n\n\nExample of \"body must have unique ids\" error\n\n```yaml\nname: \"Bug report\"\nbody:\n- type: input\n  id: name\n  attributes:\n    label: First name\n- type: input\n  id: name\n  attributes:\n    label: Last name\n```\n\nThe error can be fixed by changing the `id` for one of these inputs, so that every `input` field has a unique `id` attribute.\n\n```yaml\nname: \"Bug report\"\nbody:\n- type: input\n  id: name\n  attributes:\n    label: First name\n- type: input\n  id: surname\n  attributes:\n    label: Last name\n```\n\n\n\nBody must have unique labels\n\nWhen there are multiple `body` elements that accept user input, the `label` attribute for each user input field must be unique.\n\n\n\nExample of \"body must have unique labels\" error\n\n```yaml\nname: \"Bug report\"\nbody:\n- type: textarea\n  attributes:\n    label: Name\n- type: textarea\n  attributes:\n    label: Name\n```\n\nThe error can be fixed by changing the `label` attribute for one of the input fields to ensure that each `label` is unique.\n\n```yaml\nname: \"Bug report\"\nbody:\n- type: textarea\n  attributes:\n    label: Name\n- type: textarea\n  attributes:\n    label: Operating System\n```\n\nInp", "Y2h1bmtfMl9pbmRleF8xMDc2": "ut fields can also be differentiated by their `id` attribute. If duplicate `label` attributes are required, you can supply at least one `id` to differentiate two elements with identical labels.\n\n```yaml\nname: \"Bug report\"\nbody:\n- type: textarea\n  id: name_1\n  attributes:\n    label: Name\n- type: textarea\n  id: name_2\n  attributes:\n    label: Name\n```\n\n`id` attributes are not visible in the issue body. If you want to distinguish the fields in the resulting issue, you should use distinct `label` attributes.\n\n\n\nLabels are too similar\n\nSimilar labels may be processed into identical references. If an `id` attribute is not provided for an `input`, the `label` attribute is used to generate a reference to the `input` field. To do this, we process the `label` by leveraging the Rails parameterize method. In some cases, two labels that are distinct can be processed into the same parameterized string.\n\n\n\nExample of \"labels are too similar\" error\n\n```yaml\nname: \"Bug report\"\nbody:\n- type: input\n  attributes:\n    label: Name?\n- type: input\n  id: name\n  attributes:\n    label: Name???????\n```\n\nThe error can be fixed by adding at least one differentiating alphanumeric character, `-`, or `_` to one of the clashing labels.\n\n```yaml\nname: \"Bug report\"\nbody:\n- type: input\n  attributes:\n    label: Name?\n- type: input\n  attributes:\n    label: Your name\n```\n\nThe error can also be fixed by giving one of the clashing labels a unique `id`.\n\n```yaml\nname: \"Bug report\"\nbody:\n- type: input\n  attributes:\n    label: Name?\n- type: input\n  id: your-name\n  attributes:\n    label: Name???????\n```\n\n\n\nCheckboxes must have unique labels\n\nWhen a `checkboxes` element is present, each of its nested labels must be unique among its peers, as well as among other input types.\n\n\n\nExample of \"checkboxes must have unique labels\" error\n\n```yaml\nname: \"Bug report\"\nbody:\n- type: textarea\n  attributes:\n    label: Name\n- type: checkboxes\n  attributes:\n    options:\n    - label: Name\n```\n\nThe error can be fixed by changing the `label` attribute for one of these inputs.\n\n", "Y2h1bmtfM19pbmRleF8xMDc2": "```yaml\nname: \"Bug report\"\nbody:\n- type: textarea\n  attributes:\n    label: Name\n- type: checkboxes\n  attributes:\n    options:\n    - label: Your name\n```\n\nAlternatively, you can supply an `id` to any clashing top-level elements. Nested checkbox elements do not support the `id` attribute.\n\n```yaml\nname: \"Bug report\"\nbody:\n- type: textarea\n  id: name_1\n  attributes:\n    label: Name\n- type: checkboxes\n  attributes:\n    options:\n    - label: Name\n```\n\n`id` attributes are not visible in the issue body. If you want to distinguish the fields in the resulting issue, you should use distinct `label` attributes.\n\n\n\nBody[i]: required key type is missing\n\nEach body block must contain the key `type`.\n\nErrors with `body` will be prefixed with `body[i]` where `i` represents the zero-indexed index of the body block containing the error. For example, `body[0]` tells us that the error has been caused by the first block in the `body` list.\n\n\n\nExample of \"body[i]: required key type is missing\" error\n\n```yaml\nbody:\n- attributes:\n    value: \"Thanks for taking the time to fill out this bug! If you need real-time help, join us on Discord.\"\n```\n\nThe error can be fixed by adding the key `type` with a valid input type as the value. For the available `body` input types and their syntaxes, see \"AUTOTITLE.\"\n\n```yaml\nbody:\n- type: markdown\n  attributes:\n    value: \"Thanks for taking the time to fill out this bug! If you need real-time help, join us on Discord.\"\n```\n\n\n\nBody[i]: `x` is not a valid input type\n\nOne of the body blocks contains a type value that is not one of the permitted types.\n\nErrors with `body` will be prefixed with `body[i]` where `i` represents the index of the body block containing the error. For example, `body[0]` tells us that the error has been caused by the first block in the `body` list.\n\n\n\nExample of \"body[i]: `x` is not a valid input type\" error\n\n```yaml\nbody:\n- type: x\n  attributes:\n    value: \"Thanks for taking the time to fill out this bug! If you need real-time help, join us on Discord.\"\n```\n\nThe error can be fixed ", "Y2h1bmtfNF9pbmRleF8xMDc2": "by changing `x` to one of the valid types.\n\n```yaml\nbody:\n- type: markdown\n  attributes:\n    value: \"Thanks for taking the time to fill out this bug! If you need real-time help, join us on Discord.\"\n```\n\n\n\nBody[i]: required attribute key `value` is missing\n\nOne of the required `value` attributes has not been provided. The error occurs when a block does not have an `attributes` key or does not have a `value` key under the `attributes` key.\n\nErrors with `body` will be prefixed with `body[i]` where `i` represents the index of the body block containing the error. For example, `body[0]` tells us that the error has been caused by the first block in the `body` list.\n\n\n\nExample of \"body[i]: required attribute key `value` is missing\" error\n\n```yaml\nbody:\n- type: markdown\n  attributes:\n    value: \"Thanks for taking the time to fill out this bug! If you need real-time help, join us on Discord.\"\n- type: markdown\n```\n\nThe error in this example can be fixed by adding `value` as a key under `attributes` in the second list element of `body`.\n\n```yaml\nbody:\n- type: markdown\n  attributes:\n    value: \"Thanks for taking the time to fill out this bug! If you need real-time help, join us on Discord.\"\n- type: markdown\n  attributes:\n    value: \"This is working now!\"\n```\n\n\n\nBody[i]: label must be a string\n\nWithin its `attributes` block, a value has the wrong data type.\n\nErrors with `body` will be prefixed with `body[i]` where `i` represents the index of the body block containing the error. For example, `body[0]` tells us that the error has been caused by the first block in the `body` list.\n\n\n\nExample of \"body[i]: label must be a string\" error\n\nThe `label` below is being parsed as a Boolean, but it should be a string.\n\n```yaml\nbody:\n- type: markdown\n  attributes:\n    value: \"Thanks for taking the time to fill out this bug! If you need real-time help, join us on Discord.\"\n- type: textarea\n  attributes:\n    label: Bug Description\n- type: textarea\n  attributes:\n    label: true\n```\n\nThe error can be fixed by supplying a string value for `labe", "Y2h1bmtfNV9pbmRleF8xMDc2": "l`. If you want to use a `label` value that may be parsed as a Boolean, integer, or decimal, you should wrap the value in quotes. For example, `\"true\"` or `\"1.3\"` instead of `true` or `1.3`.\n\n```yaml\n- type: markdown\n  attributes:\n    value: \"Thanks for taking the time to fill out this bug! If you need real-time help, join us on Discord.\"\n- type: textarea\n  attributes:\n    label: Bug Description\n- type: textarea\n  attributes:\n    label: Environment Details\n```\n\nEmpty strings, or strings consisting of only whitespaces, are not permissible when an attribute expects a string. For example, `\"\"` or `\"     \"` are not allowed.\n\nIf the attribute is required, the value must be a non-empty string. If the field is not required, you should delete the key-value pair.\n\n```yaml\nbody:\n- type: input\n  attributes:\n    label: \"Name\"\n```\n\n\n\nBody[i]: `id` can only contain numbers, letters, -, _\n\n`id` attributes can only contain alphanumeric characters, `-`, and `_`. Your template may include non-permitted characters, such as whitespace, in an `id`.\n\nErrors with `body` will be prefixed with `body[i]` where `i` represents the index of the body block containing the error. For example, `body[0]` tells us that the error has been caused by the first block in the `body` list.\n\n\n\nExample of \"body[i]: `id` can only contain numbers, letters, -, _\" error\n\n```yaml\nname: \"Bug report\"\nbody:\n- type: input\n  id: first name\n  attributes:\n    label: First name\n```\n\nThe error can be fixed by ensuring that whitespaces and other non-permitted characters are removed from `id` values.\n\n```yaml\nname: \"Bug report\"\nbody:\n- type: input\n  id: first-name\n  attributes:\n    label: First name\n```\n\n\n\nBody[i]: `x` is not a permitted key\n\nAn unexpected key, `x`, was provided at the same indentation level as `type` and `attributes`.\n\nErrors with `body` will be prefixed with `body[i]` where `i` represents the index of the body block containing the error. For example, `body[0]` tells us that the error has been caused by the first block in the `body` list.\n\n\n\nExample of \"", "Y2h1bmtfNl9pbmRleF8xMDc2": "body[i]: `x` is not a permitted key\" error\n\n```yaml\nbody:\n- type: markdown\n  x: woof\n  attributes:\n    value: \"Thanks for taking the time to fill out this bug! If you need real-time help, join us on Discord.\"\n```\n\nThe error can be fixed by removing extra keys and only using `type`, `attributes`, and `id`.\n\n```yaml\nbody:\n- type: markdown\n  attributes:\n    value: \"Thanks for taking the time to fill out this bug! If you need real-time help, join us on Discord.\"\n```\n\n\n\nBody[i]: `label` contains forbidden word\n\nTo minimize the risk of private information and credentials being posted publicly in GitHub Issues, some words commonly used by attackers are not permitted in the `label` of input or textarea elements.\n\nErrors with `body` will be prefixed with `body[i]` where `i` represents the index of the body block containing the error. For example, `body[0]` tells us that the error has been caused by the first block in the `body` list.\n\n\n\nExample of \"body[i]: `label` contains forbidden word\" error\n\n```yaml\nbody:\n- type: markdown\n  attributes:\n    value: Hello world!\n- type: input\n  attributes:\n    label: Password\n```\n\nThe error can be fixed by removing terms like \"password\" from any `label` fields.\n\n```yaml\nbody:\n- type: markdown\n  attributes:\n    value: Hello world!\n- type: input\n  attributes:\n    label: Username\n```\n\n\n\nBody[i]: `x` is not a permitted attribute\n\nAn invalid key has been supplied in an `attributes` block.\n\nErrors with `body` will be prefixed with `body[i]` where `i` represents the index of the body block containing the error. For example, `body[0]` tells us that the error has been caused by the first block in the `body` list.\n\n\n\nExample of \"body[i]: `x` is not a permitted attribute\" error\n\n```yaml\nbody:\n- type: markdown\n  attributes:\n    x: \"a random key!\"\n    value: \"Thanks for taking the time to fill out this bug!\"\n```\n\nThe error can be fixed by removing extra keys and only using permitted attributes.\n\n```yaml\nbody:\n- type: markdown\n  attributes:\n    value: \"Thanks for taking the time to fill out this bug!", "Y2h1bmtfN19pbmRleF8xMDc2": "\"\n```\n\n\n\nBody[i]: `options` must be unique\n\nFor checkboxes and dropdown input types, the choices defined in the `options` array must be unique.\n\nErrors with `body` will be prefixed with `body[i]` where `i` represents the index of the body block containing the error. For example, `body[0]` tells us that the error has been caused by the first block in the `body` list.\n\n\n\nExample of \"body[i]: `options` must be unique\" error\n\n```yaml\nbody:\n- type: dropdown\n  attributes:\n    label: Favorite dessert\n    options:\n      - ice cream\n      - ice cream\n      - pie\n```\n\nThe error can be fixed by ensuring that no duplicate choices exist in the `options` array.\n\n```yaml\nbody:\n- type: dropdown\n  attributes:\n    label: Favorite dessert\n    options:\n      - ice cream\n      - pie\n```\n\n\n\nBody[i]: `options` must not include the reserved word, none\n\n\"None\" is a reserved word in an `options` set because it is used to indicate non-choice when a `dropdown` is not required.\n\nErrors with `body` will be prefixed with `body[i]` where `i` represents the index of the body block containing the error. For example, `body[0]` tells us that the error has been caused by the first block in the `body` list.\n\n\n\nExample of \"body[i]: `options` must not include the reserved word, none\" error\n\n```yaml\nbody:\n- type: dropdown\n  attributes:\n    label: What types of pie do you like?\n    options:\n      - Steak & Ale\n      - Chicken & Leek\n      - None\n  validations:\n    required: true\n```\n\nThe error can be fixed by removing \"None\" as an option. If you want a contributor to be able to indicate that they like none of those types of pies, you can additionally remove the `required` validation.\n\n```yaml\nbody:\n- type: dropdown\n  attributes:\n    label: What types of pie do you like?\n    options:\n      - Steak & Ale\n      - Chicken & Leek\n```\n\nIn this example, \"None\" will be auto-populated as a selectable option.\n\n\n\nBody[i]: `options` must not include booleans. Please wrap values such as 'yes', and 'true' in quotes\n\nThere are a number of English words that become proc", "Y2h1bmtfOF9pbmRleF8xMDc2": "essed into Boolean values by the YAML parser unless they are wrapped in quotes. For dropdown `options`, all items must be strings rather than Booleans.\n\nErrors with `body` will be prefixed with `body[i]` where `i` represents the index of the body block containing the error. For example, `body[0]` tells us that the error has been caused by the first block in the `body` list.\n\n\n\nExample of \"body[i]: `options` must not include booleans. Please wrap values such as 'yes', and 'true' in quotes\" error\n\n```yaml\nbody:\n- type: dropdown\n  attributes:\n    label: Do you like pie?\n    options:\n      - Yes\n      - No\n      - Maybe\n```\n\nThe error can be fixed by wrapping each offending option in quotes, to prevent them from being processed as Boolean values.\n\n```yaml\nbody:\n- type: dropdown\n  attributes:\n    label: Do you like pie?\n    options:\n      - \"Yes\"\n      - \"No\"\n      - Maybe\n```\n\n\n\nBody cannot be empty\n\nThe template body `key:value` pair can not be empty. For more information about which top-level keys are required, see \"AUTOTITLE.\"\n\nThe error can be fixed by adding the `body:` section.\n\n\n\nExample of \"body cannot be empty\" error\n\n```yaml\nname: Support Request\ndescription: Something went wrong and you need help?\n---\nbody:\n- type: textarea\n  attributes:\n    label: \"What's wrong?\"\n```\n\nIn this example, the error can be fixed by deleting the `---` (document separator) between the headers and the `body` section.\n\n```yaml\nname: Support Request\ndescription: Something went wrong and you need help?\n\nbody:\n- type: textarea\n  attributes:\n    label: \"What's wrong?\"\n```\n\n\n\nFurther reading\n\n- YAML\n- Syntax for issue forms\n\n", "Y2h1bmtfMF9pbmRleF8zMDI=": "\n\nAbout support for Conditional Access Policies\n\n{% data reusables.enterprise-accounts.emu-cap-validates %}\n\n{% data variables.product.product_name %} supports CAP for any {% data variables.enterprise.prodname_emu_enterprise %} where OIDC SSO is enabled. {% data variables.product.product_name %} enforces your IdP's IP conditions but cannot enforce your device compliance conditions. Enterprise owners can choose to use this IP allow list configuration instead of {% data variables.product.product_name %}'s IP allow list, and can do so once OIDC SSO is configured. For more information about IP allow lists, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n\nFor more information about using OIDC with {% data variables.product.prodname_emus %}, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n\n\n\nConsiderations for integrations and automations\n\n{% data variables.product.prodname_dotcom %} sends the originating IP address to your IdP for validation against your CAP. To make sure  actions and apps are not blocked by your IdP's CAP, you will need to make changes to your configuration.\n\n{% data reusables.enterprise-accounts.oidc-gei-warning %}\n\n\n\n{% data variables.product.prodname_actions %}\n\nActions that use a {% data variables.product.pat_generic %} will likely be blocked by your IdP's CAP. We recommend that {% data variables.product.pat_generic %}s are created by a service account which is then exempted from IP controls in your IdP's CAP.\n\nIf you're unable to use a service account, another option for unblocking actions that use {% data variables.product.pat_generic %}s is to allow the IP ranges used by {% data variables.product.prodname_actions %}. For more information, see \"AUTOTITLE.\"\n\n\n\n{% data variables.product.prodname_github_codespaces %}\n\n{% data variables.product.prodname_github_codespaces %} may not be available if your enterprise uses OIDC SSO with CAP to restrict access by IP addresses. This is because codespaces are created with dynamic IP addresses which it's likely your IdP\u2019s CAP will block. Other CAP policies may also affect {% data variab", "Y2h1bmtfMV9pbmRleF8zMDI=": "les.product.prodname_github_codespaces %}'s availability, depending on the policy's specific setup.\n\n\n\n{% data variables.product.prodname_github_apps %} and {% data variables.product.prodname_oauth_apps %}\n\nWhen {% data variables.product.prodname_github_apps %} and {% data variables.product.prodname_oauth_apps %} sign a user in and make requests on that user's behalf, {% data variables.product.prodname_dotcom %} will send the IP address of the app's server to your IdP for validation. If the IP address of the app's server is not validated by your IdP's CAP, the request will fail.\n\nWhen {% data variables.product.prodname_github_apps %} call {% data variables.product.prodname_dotcom %} APIs acting either as the app itself or as an installation, these calls are not performed on behalf of a user. Since your IdP's CAP executes and applies policies to user accounts, these application requests cannot be validated against CAP and are always allowed through. For more information on {% data variables.product.prodname_github_apps %} authenticating as themselves or as an installation, see \"AUTOTITLE\".\n\nYou can contact the owners of the apps you want to use, ask for their IP ranges, and configure your IdP's CAP to allow access from those IP ranges. If you're unable to contact the owners, you can review your IdP sign-in logs to review the IP addresses seen in the requests, then allow-list those addresses.\n\nIf you do not wish to allow all of the IP ranges for all of your enterprise's apps, you can also exempt installed {% data variables.product.prodname_github_apps %} and authorized {% data variables.product.prodname_oauth_apps %} from the IdP allow list. If you do so, these apps will continue working regardless of the originating IP address. For more information, see \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF83MTg=": "---\ntitle: 'Phase 4: Create internal documentation'\nintro: 'You will create internal documentation and then communicate this to the consumers of {% data variables.product.prodname_GH_advanced_security %}.'\nversions:\n  ghes: '*'\n  ghae: '*'\n  ghec: '*'\ntopics:\n  - Advanced Security\nshortTitle: 4. Create internal documentation\n---\n\n{% note %}\n\nThis article is part of a series on adopting {% data variables.product.prodname_GH_advanced_security %} at scale. For the previous article in this series, see \"AUTOTITLE.\"\n\n{% endnote %}\n\nBefore enabling {% data variables.product.prodname_GH_advanced_security %}, you should create internal documentation that defines processes for teams to follow. Everyone needs to know what to do when they receive a security alert, even if the process simply asks the team to apply their best judgment. Documentation will also prevent developers from getting blocked when they have questions. You should put the documentation about GHAS with existing developer-focused documentation, such as your developer portal or custom knowledge base.\n\nIf you ran pilot programs, use the experiences and feedback from the teams involved in those pilots to influence your documentation. This is especially useful if you encountered issues that are specific to your company, that other teams will also likely encounter.\n\nIf you skip creating internal documentation, your rollout won\u2019t go at your intended pace. Creating internal documentation may slow the initial rollout by a week or two, but that time will be made up when developers can answer their own questions instead of coming to your team.\n\nEducation is probably the most crucial part of the rollout as it teaches developers what to do in different situations. You should ensure developers are empowered to maintain the security of their repository and that the security team are authorized to verify both what developers are doing and that it's in the best interest of security. In addition to internal documentation, education can take the form of online sessions, Q&As,", "Y2h1bmtfMV9pbmRleF83MTg=": " etc.\n\n{% note %}\n\nFor the next article in this series, see \"AUTOTITLE.\"\n\n{% endnote %}\n\n", "Y2h1bmtfMF9pbmRleF8xNTkw": "\n\nFurther reading\n\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8xNw==": "\n\nWhat counts as a contribution\n\nOn your profile page, certain actions count as contributions:\n\n- Committing to a repository's default branch or `gh-pages` branch\n- Creating a branch\n- Opening an issue\n- Opening a discussion\n- Answering a discussion\n- Proposing a pull request\n- Submitting a pull request review{% ifversion ghes or ghae %}\n- Co-authoring commits in a repository's default branch or `gh-pages` branch{% endif %}\n\n{% data reusables.pull_requests.pull_request_merges_and_contributions %}\n\n\n\nPopular repositories\n\nThis section displays your repositories with the most watchers. {% ifversion fpt or ghes or ghec %}Once you pin repositories to your profile, this section will change to \"Pinned.\"{% endif %}\n\n{% ifversion fpt or ghes or ghec %}\n\n\n\nPinned\n\nThis section displays up to six public repositories or gists. Important details are listed for each of the items you've chosen to feature. For more information, see \"AUTOTITLE.\"\n\n!Screenshot of the \"Pinned repositories\" section of a user's profile page.\n\n{% endif %}\n\n\n\nContributions calendar\n\nYour contributions calendar shows your contribution activity.\n\n\n\nViewing contributions from specific times\n\n- Click on a day's square to show the contributions made during that 24-hour period.\n- Press _Shift_ and click on another day's square to show contributions made during that time span.\n\n{% note %}\n\n**Note:** You can select up to a one-month range on your contributions calendar. If you select a larger time span, we will only display one month of contributions.\n\n{% endnote %}\n\n!Screenshot of the contributions graph on a user profile.\n\n\n\nHow contribution event times are calculated\n\nTimestamps are calculated differently for commits and pull requests:\n- **Commits** use the time zone information in the commit timestamp. For more information, see \"AUTOTITLE.\"\n- **Pull requests** and **issues** opened on {% data variables.product.product_name %} use your browser's time zone. Those opened via the API use the timestamp or time zone specified in the API call.\n\n\n\nActivity overvie", "Y2h1bmtfMV9pbmRleF8xNw==": "w\n\n{% data reusables.profile.activity-overview-summary %} For more information, see \"AUTOTITLE.\"\n\n!Screenshot of the activity overview section of a user profile.\n\nThe organizations featured in the activity overview are prioritized according to how active you are in the organization. If you @mention an organization in your profile bio, and you\u2019re an organization member, then that organization is prioritized first in the activity overview. For more information, see \"AUTOTITLE\" or \"AUTOTITLE.\"\n\n\n\nContribution activity\n\nThe contribution activity section includes a detailed timeline of your work, including commits you've made or co-authored, pull requests you've proposed, and issues you've opened.\n\nYou can see your contributions over time by either clicking **Show more activity** at the bottom of your contribution activity or by clicking the year you're interested in viewing on the right side of the page.\n\nImportant moments, like the date you joined an organization, proposed your first pull request, or opened a high-profile issue, are highlighted in your contribution activity.\n\nIf you can't see certain events in your timeline, check to make sure you still have access to the organization or repository where the event happened.\n\n\n\nViewing contributions from {% data variables.product.prodname_enterprise %} on {% data variables.product.prodname_dotcom_the_website %}\n\nIf you use {% ifversion fpt or ghec %}{% data variables.product.prodname_ghe_server %}{% ifversion ghae %} or {% data variables.product.prodname_ghe_managed %}{% endif %}{% else %}{% data variables.product.product_name %}{% endif %} and your enterprise owner enables {% data variables.enterprise.prodname_unified_contributions %}, you can send enterprise contribution counts to your {% data variables.product.prodname_dotcom_the_website %} profile. For more information, see \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF84NA==": "\n\nAbout continuous deployment\n\n_Continuous deployment_ (CD) is the practice of using automation to publish and deploy software updates. As part of the typical CD process, the code is automatically built and tested before deployment.\n\nContinuous deployment is often coupled with continuous integration. For more information about continuous integration, see \"AUTOTITLE\".\n\n\n\nAbout continuous deployment using {% data variables.product.prodname_actions %}\n\nYou can set up a {% data variables.product.prodname_actions %} workflow to deploy your software product. To verify that your product works as expected, your workflow can build the code in your repository and run your tests before deploying.\n\nYou can configure your CD workflow to run when a {% data variables.product.product_name %} event occurs (for example, when new code is pushed to the default branch of your repository), on a set schedule, manually, or when an external event occurs using the repository dispatch webhook. For more information about when your workflow can run, see \"AUTOTITLE.\"\n\n{% data variables.product.prodname_actions %} provides features that give you more control over deployments. For example, you can use environments to require approval for a job to proceed, restrict which branches can trigger a workflow, or limit access to secrets. You can use concurrency to limit your CD pipeline to a maximum of one in-progress deployment and one pending deployment. For more information about these features, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n\n{% ifversion fpt or ghec or ghes %}\n\n\n\nUsing OpenID Connect to access cloud resources\n\n{% data reusables.actions.about-oidc-short-overview %}\n\n{% endif %}\n\n\n\nStarter workflows and third party actions\n\n{% data reusables.actions.cd-templates-actions %}\n\n\n\nFurther reading\n\n- AUTOTITLE\n- AUTOTITLE{% ifversion fpt or ghec %}\n- \"AUTOTITLE\"{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF8zMzA=": "\n\nAbout LDAP authentication for {% data variables.product.product_name %}\n\nLDAP is a popular application protocol for access and maintenance of directory information services, and is one of the most common protocols for integration of third-party software with large company user directories. For more information, see \"Lightweight Directory Access Protocol\" on Wikipedia.\n\nIf you use an LDAP directory for centralized authentication, you can configure LDAP authentication for the people who use {% data variables.location.product_location %}.\n\n{% data reusables.enterprise.saml-or-ldap %}\n\n{% data reusables.enterprise_user_management.built-in-authentication %}\n\n\n\nSupported LDAP services\n\n{% data variables.product.prodname_ghe_server %} integrates with these LDAP services:\n\n- Active Directory\n- FreeIPA\n- Oracle Directory Server Enterprise Edition\n- OpenLDAP\n- Open Directory\n- 389-ds\n\n\n\nUsername considerations with LDAP\n\n{% data reusables.enterprise_user_management.consider-usernames-for-external-authentication %} For more information, see \"AUTOTITLE.\"\n\n\n\nConfiguring LDAP with {% data variables.location.product_location %}\n\nAfter you configure LDAP, users will be able to sign into your instance with their LDAP credentials. When users sign in for the first time, their profile names, email addresses, and SSH keys will be set with the LDAP attributes from your directory.\n\nWhen you configure LDAP access for users via the {% data variables.enterprise.management_console %}, your user licenses aren't used until the first time a user signs in to your instance. However, if you create an account manually using site admin settings, the user license is immediately accounted for.\n\n{% warning %}\n\n**Warning:** Before configuring LDAP on {% data variables.location.product_location %}, make sure that your LDAP service supports paged results.\n\n{% endwarning %}\n\n{% data reusables.enterprise_site_admin_settings.access-settings %}\n{% data reusables.enterprise_site_admin_settings.management-console %}\n{% data reusables.enterprise_management_c", "Y2h1bmtfMV9pbmRleF8zMzA=": "onsole.authentication %}\n1. Under \"Authentication\", select **LDAP**.\n1. {% data reusables.enterprise_user_management.built-in-authentication-option %}\n1. Add your configuration settings.\n\n\n\nLDAP attributes\n\nUse these attributes to finish configuring LDAP for {% data variables.location.product_location %}.\n\n| Attribute name           | Required     | Description |\n|--------------------------|----------|-------------|\n| `Host`                   | {% octicon \"check\" aria-label=\"Required\" %} | The LDAP host, e.g. `ldap.example.com` or `10.0.0.30`. If the hostname is only available from your internal network, you may need to configure {% data variables.location.product_location %}'s DNS first so it can resolve the hostname using your internal nameservers. |\n| `Port`                   | {% octicon \"check\" aria-label=\"Required\" %} | The port the host's LDAP services are listening on. Examples include: 389 and 636 (for LDAPS). |\n| `Encryption`             | {% octicon \"check\" aria-label=\"Required\" %} | The encryption method used to secure communications to the LDAP server. Examples include plain (no encryption), SSL/LDAPS (encrypted from the start), and StartTLS (upgrade to encrypted communication once connected). |\n| `Domain search user`     | {% octicon \"x\" aria-label=\"Optional\" %} | The LDAP user that looks up other users that sign in, to allow authentication. This is typically a service account created specifically for third-party integrations. Use a fully qualified name, such as `cn=Administrator,cn=Users,dc=Example,dc=com`. With Active Directory, you can also use the `[DOMAIN]\\[USERNAME]` syntax (e.g. `WINDOWS\\Administrator`) for the domain search user with Active Directory. |\n| `Domain search password` | {% octicon \"x\" aria-label=\"Optional\" %} | The password for the domain search user. |\n| `Administrators group`   | {% octicon \"x\" aria-label=\"Optional\" %} | Users in this group are promoted to site administrators when signing into your appliance. If you don't configure an LDAP Administrators group, the first LDAP u", "Y2h1bmtfMl9pbmRleF8zMzA=": "ser account that signs into your appliance will be automatically promoted to a site administrator. |\n| `Domain base`            | {% octicon \"check\" aria-label=\"Required\" %} | The fully qualified `Distinguished Name` (DN) of an LDAP subtree you want to search for users and groups. You can add as many as you like; however, each group must be defined in the same domain base as the users that belong to it. If you specify restricted user groups, only users that belong to those groups will be in scope. We recommend that you specify the top level of your LDAP directory tree as your domain base and use restricted user groups to control access. |\n| `Restricted user groups` | {% octicon \"x\" aria-label=\"Optional\" %} | If specified, only users in these groups will be allowed to log in. You only need to specify the common names (CNs) of the groups, and you can add as many groups as you like. If no groups are specified, _all_ users within the scope of the specified domain base will be able to sign in to your {% data variables.product.prodname_ghe_server %} instance. |\n| `User ID`                | {% octicon \"check\" aria-label=\"Required\" %} | The LDAP attribute that identifies the LDAP user who attempts authentication. Once a mapping is established, users may change their {% data variables.product.prodname_ghe_server %} usernames. This field should be `sAMAccountName` for most Active Directory installations, but it may be `uid` for other LDAP solutions, such as OpenLDAP. The default value is `uid`. |\n| `Profile name`           | {% octicon \"x\" aria-label=\"Optional\" %} | The name that will appear on the user's {% data variables.product.prodname_ghe_server %} profile page. Unless LDAP Sync is enabled, users may change their profile names. |\n| `Emails`                 | {% octicon \"x\" aria-label=\"Optional\" %} | The email addresses for a user's {% data variables.product.prodname_ghe_server %} account. |\n| `SSH keys`               | {% octicon \"x\" aria-label=\"Optional\" %} | The public SSH keys attached to a user's {% data variables", "Y2h1bmtfM19pbmRleF8zMzA=": ".product.prodname_ghe_server %} account. The keys must be in OpenSSH format. |\n| `GPG keys`               | {% octicon \"x\" aria-label=\"Optional\" %} | The GPG keys attached to a user's {% data variables.product.prodname_ghe_server %} account. |\n| `Disable LDAP authentication for Git operations` | {% octicon \"x\" aria-label=\"Optional\" %} |If selected, turns off users' ability to use LDAP passwords to authenticate Git operations. |\n| `Enable LDAP certificate verification` | {% octicon \"x\" aria-label=\"Optional\" %} |If selected, turns on LDAP certificate verification. |\n| `Synchronization` | {% octicon \"x\" aria-label=\"Optional\" %} | If selected, turns on LDAP Sync. |\n\n\n\nDisabling password authentication for Git operations\n\nTo enforce use of {% data variables.product.pat_generic %}s or SSH keys for Git access, which can help prevent your server from being overloaded by LDAP authentication requests, you can disable password authentication for Git operations.\n\nWe recommend this setting because a slow-responding LDAP server, especially combined with a large number of requests due to polling, is a frequent source of performance issues and outages.\n\nTo disable password authentication for Git operations, select **Disable username and password authentication for Git operations** in your LDAP settings.\n\nWhen this option is selected, if a user tries to use a password for Git operations via the command line, they will receive an error message that says, `Password authentication is not allowed for Git operations. You must use a {% data variables.product.pat_generic %}.`\n\n\n\nEnabling LDAP certificate verification\n\nYou can validate the LDAP server certificate you use with TLS by enabling LDAP certificate verification.\n\nTo enable LDAP certificate verification, select **Enable LDAP certificate verification** in your LDAP settings.\n\nWhen this option is selected, the certificate is validated to make sure:\n- If the certificate contains at least one Subject Alternative Name (SAN), one of the SANs matches the LDAP hostname. Otherwise, the C", "Y2h1bmtfNF9pbmRleF8zMzA=": "ommon Name (CN) matches the LDAP hostname.\n- The certificate is not expired.\n- The certificate is signed by a trusted certificate authority (CA).\n\n\n\nEnabling LDAP Sync\n\nYou can establish role-based access control for users from your LDAP server by synchronizing {% data variables.product.prodname_ghe_server %} users and team membership against your established LDAP groups. For more information, see \"AUTOTITLE.\"\n\nLDAP sync does not create user accounts on {% data variables.location.product_location %}. For more information, see \"Viewing and creating LDAP users.\"\n\n{% note %}\n\n**Note:** Using LDAP Synchronization with groups that exceed 1499 members may lead to team membership synchronization failures.\n\nIf you use Active Directory specifically, user lookups and team synchronization may fail when the LDAP groups configured for teams or in the {% data variables.enterprise.management_console %} exceed 1500 members, due to the `MaxValRange` limit in Active Directory. As a workaround, you can use Active Directory groups that contain less than 1500 members, or you can work with your Active Directory administrator to increase the `MaxValRange` value for your domain controllers. For more information, see View and set LDAP policy in Active Directory by using Ntdsutil.exe in Microsoft Learn.\n\nIf you need help determining if modifying the `MaxValRange` is the right approach for your Active Directory environment, contact Microsoft Support.\n\n{% endnote %}\n\nTo enable LDAP Sync, in your LDAP settings, select **Synchronize Emails**, **Synchronize SSH Keys**, or **Synchronize GPG Keys**.\n\nAfter you enable LDAP sync, a synchronization job will run at the specified time interval to perform the following operations on each user account:\n\n- If you've allowed built-in authentication for users outside your identity provider, and the user is using built-in authentication, move on to the next user.\n- If no LDAP mapping exists for the user, try to map the user to an LDAP entry in the directory. If the user cannot be mapped to an LDAP entry, s", "Y2h1bmtfNV9pbmRleF8zMzA=": "uspend the user and move on to the next user.\n- If there is an LDAP mapping and the corresponding LDAP entry in the directory is missing, suspend the user and move on to the next user.\n- If the corresponding LDAP entry has been marked as disabled and the user is not already suspended, suspend the user and move on to the next user.\n- If the corresponding LDAP entry is not marked as disabled, and the user is suspended, and _Reactivate suspended users_ is enabled in the Admin Center, unsuspend the user.\n- If one or more restricted user groups are configured on the instance and the corresponding LDAP entry is not in one of these groups, suspend the user.\n- If one or more restricted user groups are configured on the instance, the corresponding LDAP entry is in one of these groups, and _Reactivate suspended users_ is enabled in the Admin Center, unsuspend the user.\n- If the corresponding LDAP entry includes a `name` attribute, update the user's profile name.\n- If the corresponding LDAP entry is in the Administrators group, promote the user to site administrator.\n- If the corresponding LDAP entry is not in the Administrators group, demote the user to a normal account, unless the account is suspended. Suspended administrators will not be demoted and will remain listed on the \"Site admins\" and \"Enterprise owners\" pages.\n- If an LDAP User field is defined for emails, synchronize the user's email settings with the LDAP entry. Set the first LDAP `mail` entry as the primary email.\n- If an LDAP User field is defined for SSH public keys, synchronize the user's public SSH keys with the LDAP entry.\n- If an LDAP User field is defined for GPG keys, synchronize the user's GPG keys with the LDAP entry.\n\n{% note %}\n\n**Note**: LDAP entries can only be marked as disabled if you use Active Directory and the `userAccountControl` attribute is present and flagged with `ACCOUNTDISABLE`. Some variations of Active Directory, such as AD LDS and ADAM, don't support the `userAccountControl` attribute.\n\n{% endnote %}\n\nA synchronization job will al", "Y2h1bmtfNl9pbmRleF8zMzA=": "so run at the specified time interval to perform the following operations on each team that has been mapped to an LDAP group:\n\n- If a team's corresponding LDAP group has been removed, remove all members from the team.\n- If LDAP member entries have been removed from the LDAP group, remove the corresponding users from the team. If the user is no longer a member of any team in the organization and is not an owner of the organization, remove the user from the organization. If the user loses access to any repositories as a result, delete any private forks the user has of those repositories.\n\n  {% note %}\n\n  **Note:** LDAP Sync will not remove a user from an organization if the user is an owner of that organization. Another organization owner will need to manually remove the user instead.\n\n  {% endnote %}\n- If LDAP member entries have been added to the LDAP group, add the corresponding users to the team. If the user regains access to any repositories as a result, restore any private forks of the repositories that were deleted because the user lost access in the past 90 days.\n\n{% data reusables.enterprise_user_management.ldap-sync-nested-teams %}\n\n{% warning %}\n\n**Security Warning:**\n\nWhen LDAP Sync is enabled, site admins and organization owners can search the LDAP directory for groups to map the team to.\n\nThis has the potential to disclose sensitive organizational information to contractors or other unprivileged users, including:\n\n- The existence of specific LDAP Groups visible to the _Domain search user_.\n- Members of the LDAP group who have {% data variables.product.prodname_ghe_server %} user accounts, which is disclosed when creating a team synced with that LDAP group.\n\nIf disclosing such information is not desired, your company or organization should restrict the permissions of the configured _Domain search user_ in the admin console. If such restriction isn't possible, contact us by visiting {% data variables.contact.contact_ent_support %}.\n\n{% endwarning %}\n\n\n\nSupported LDAP group object classes\n\n{% data variab", "Y2h1bmtfN19pbmRleF8zMzA=": "les.product.prodname_ghe_server %} supports these LDAP group object classes. Groups can be nested.\n\n- `group`\n- `groupOfNames`\n- `groupOfUniqueNames`\n- `posixGroup`\n\n\n\nViewing and creating LDAP users\n\nWhen you use LDAP, your instance creates a user account the first time someone successfully signs in using LDAP credentials. Alternatively, you can manually provision a user account.\n\nYou can view the full list of LDAP users who have access to your instance and provision new users.\n\n{% data reusables.enterprise_site_admin_settings.sign-in %}\n{% data reusables.enterprise_site_admin_settings.access-settings %}\n1. In the left sidebar, click **LDAP users**.\n1. To search for a user, type a full or partial username and click **Search**. Existing users will be displayed in search results. If a user doesn\u2019t exist, click **Create** to provision the new user account.\n\n\n\nUpdating LDAP accounts\n\nUnless LDAP Sync is enabled, changes to LDAP accounts are not automatically synchronized with {% data variables.product.prodname_ghe_server %}.\n\n- To use a new LDAP admin group, users must be manually promoted and demoted on {% data variables.product.prodname_ghe_server %} to reflect changes in LDAP.\n- To add or remove LDAP accounts in LDAP admin groups, promote or demote the accounts on {% data variables.product.prodname_ghe_server %}.\n- To remove LDAP accounts, suspend the {% data variables.product.prodname_ghe_server %} accounts.\n\n\n\nManually syncing LDAP accounts\n\n{% data reusables.enterprise_site_admin_settings.sign-in %}\n{% data reusables.enterprise_site_admin_settings.access-settings %}\n{% data reusables.enterprise_site_admin_settings.search-user %}\n{% data reusables.enterprise_site_admin_settings.click-user %}\n{% data reusables.enterprise_site_admin_settings.admin-top-tab %}\n1. Under \"LDAP,\" click **Sync now** to manually update the account with data from your LDAP server.\n\nYou can also use the API to trigger a manual sync.\n\n\n\nRevoking access to {% data variables.location.product_location %}\n\nIf LDAP Sync is enabled, removing a u", "Y2h1bmtfOF9pbmRleF8zMzA=": "ser's LDAP credentials will suspend their account after the next synchronization run.\n\nIf LDAP Sync is **not** enabled, you must manually suspend the {% data variables.product.prodname_ghe_server %} account after you remove the LDAP credentials. For more information, see \"AUTOTITLE\".\n\n\n\nAbout logging for LDAP\n\nLog events for LDAP appear in {% ifversion opentelemetry-and-otel-log-migration-phase-1 %}systemd journal logs{% else %}log files{% endif %} on {% data variables.location.product_location %}. You'll find events related to LDAP operations in {% ifversion opentelemetry-and-otel-log-migration-phase-1 %}the logs for `github-unicorn` and `github-resqued`{% else %}`auth.log`, `ldap-sync.log`, and `ldap.log`{% endif %}. For more information, see \"AUTOTITLE.\"\n\n", "Y2h1bmtfMF9pbmRleF82MTI=": "\n\nAbout commit signature verification\n\nYou can sign commits and tags locally, to give other people confidence about the origin of a change you have made. If a commit or tag has a GPG{% ifversion ssh-commit-verification %}, SSH,{% endif %} or S/MIME signature that is cryptographically verifiable, {% data variables.product.product_name %} marks the commit or tag {% ifversion fpt or ghec %}\"Verified\" or \"Partially verified.\"{% else %}\"Verified.\"{% endif %}\n\n!Screenshot of a commit in the commit list for a repository. \"Verified\" is highlighted with an orange outline.\n\n{% ifversion ghes or ghae %}\nIf a commit or tag has a signature that can't be verified, {% data variables.product.product_name %} marks the commit or tag \"Unverified.\"\n{% endif %}\n\n{% ifversion ssh-commit-verification %}\nFor most individual users, GPG or SSH will be the best choice for signing commits. S/MIME signatures are usually required in the context of a larger organization. SSH signatures are the simplest to generate. You can even upload your existing authentication key to {% data variables.product.product_name %} to also use as a signing key. Generating a GPG signing key is more involved than generating an SSH key, but GPG has features that SSH does not. A GPG key can expire or be revoked when no longer used. {% data variables.product.product_name %} shows commits that were signed with such a key as \"Verified\" unless the key was marked as compromised. SSH keys don't have this capability.\n{% endif %}\n\n{% ifversion fpt or ghec %}\nCommits and tags have the following verification statuses, depending on whether you have enabled vigilant mode. By default vigilant mode is not enabled. For information on how to enable vigilant mode, see \"AUTOTITLE.\"\n\nSigning commits differs from signing off on a commit. For more information about signing off on commits, see \"AUTOTITLE.\"\n\n\n\nDefault statuses\n\n| Status         | Description |\n| -------------- | ----------- |\n| **Verified**   | The commit is signed and the signature was successfully verified.\n| **Unverified", "Y2h1bmtfMV9pbmRleF82MTI=": "** | The commit is signed but the signature could not be verified.\n| No verification status | The commit is not signed.\n\n{% endif %}\n\n\n\nSignature verification for rebase and merge\n\n{% data reusables.pull_requests.rebase_and_merge_verification %}\n\n{% data reusables.pull_requests.rebase_and_merge_verification_2 %}\n\nFor more information, see \"AUTOTITLE.\"\n\n{% ifversion fpt or ghec %}\n\n\n\nStatuses with vigilant mode enabled\n\n{% data reusables.identity-and-permissions.vigilant-mode-verification-statuses %}\n\n{% endif %}\n\nRepository administrators can enforce required commit signing on a branch to block all commits that are not signed and verified. For more information, see \"AUTOTITLE.\"\n\n{% data reusables.identity-and-permissions.verification-status-check %}\n\n{% ifversion fpt or ghec or ghes %}\n{% ifversion ghes %}If a site administrator has enabled web commit signing, {% data variables.product.product_name %} will automatically use GPG to sign commits you make using the web interface. Commits signed by {% data variables.product.product_name %} will have a verified status. You can verify the signature locally using the public key available at `https://HOSTNAME/web-flow.gpg`. For more information, see \"AUTOTITLE.\"\n{% else %}{% data variables.product.prodname_dotcom %} will automatically use GPG to sign commits you make using the web interface. Commits signed by {% data variables.product.prodname_dotcom %} will have a verified status. You can verify the signature locally using the public key available at https://github.com/web-flow.gpg. The full fingerprint of the key is `5DE3 E050 9C47 EA3C F04A 42D3 4AEE 18F8 3AFD EB23`.\n\nYou can optionally choose to have {% data variables.product.prodname_dotcom %} GPG sign commits you make in {% data variables.product.prodname_github_codespaces %}. For more information about enabling GPG verification for your codespaces, see \"AUTOTITLE.\"{% endif %}\n{% endif %}\n\n\n\nGPG commit signature verification\n\nYou can use GPG to sign commits with a GPG key that you generate yourself.\n\n{% data variab", "Y2h1bmtfMl9pbmRleF82MTI=": "les.product.product_name %} uses OpenPGP libraries to confirm that your locally signed commits and tags are cryptographically verifiable against a public key you have added to your account on {% ifversion ghae %}{% data variables.product.product_name %}{% else %}{% data variables.location.product_location %}{% endif %}.\n\nTo sign commits using GPG and have those commits verified on {% data variables.product.product_name %}, follow these steps:\n\n1. Check for existing GPG keys\n1. Generate a new GPG key\n1. Add a GPG key to your GitHub account\n1. Tell Git about your signing key\n1. Sign commits\n1. Sign tags\n\n{% ifversion ssh-commit-verification %}\n\n\n\nSSH commit signature verification\n\nYou can use SSH to sign commits with an SSH key that you generate yourself. For more information, see the Git reference documentation  for `user.Signingkey`. If you already use an SSH key to authenticate with {% data variables.product.product_name %},\nyou can also upload that same key again for use as a signing key. There's no limit on the number of signing keys you can add to your account.\n\n{% data variables.product.product_name %} uses ssh_data, an open source Ruby library, to confirm that your locally signed commits and tags are cryptographically verifiable against a public key you have added to your account on {% ifversion ghae %}{% data variables.product.product_name %}{% else %}{% data variables.location.product_location %}{% endif %}.\n\n{% data reusables.gpg.ssh-git-version %}\n\nTo sign commits using SSH and have those commits verified on {% data variables.product.product_name %}, follow these steps:\n\n1. Check for existing SSH keys\n1. Generate a new SSH key\n1. Add a SSH signing key to your GitHub account\n1. Tell Git about your signing key\n1. Sign commits\n1. Sign tags\n\n{% endif %}\n\n\n\nS/MIME commit signature verification\n\nYou can use S/MIME to sign commits with an X.509 key issued by your organization.\n\n{% data variables.product.product_name %} uses the Debian ca-certificates package, the same trust store used by Mozilla browsers, to c", "Y2h1bmtfM19pbmRleF82MTI=": "onfirm that your locally signed commits and tags are cryptographically verifiable against a public key in a trusted root certificate.\n\n{% data reusables.gpg.smime-git-version %}\n\nTo sign commits using S/MIME and have those commits verified on {% data variables.product.product_name %}, follow these steps:\n\n1. Tell Git about your signing key\n1. Sign commits\n1. Sign tags\n\nYou don't need to upload your public key to {% data variables.product.product_name %}.\n\n{% ifversion fpt or ghec %}\n\n\n\nSignature verification for bots\n\nOrganizations and {% data variables.product.prodname_github_apps %} that require commit signing can use bots to sign commits. If a commit or tag has a bot signature that is cryptographically verifiable, {% data variables.product.product_name %} marks the commit or tag as verified.\n\nSignature verification for bots will only work if the request is verified and authenticated as the {% data variables.product.prodname_github_app %} or bot and contains no custom author information, custom committer information, and no custom signature information, such as Commits API.\n{% endif %}\n\n\n\nFurther reading\n\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n- \"AUTOTITLE\"\n\n", "Y2h1bmtfMF9pbmRleF8xODI2": "\n\nAbout workflow jobs in {% data variables.product.prodname_actions %}\n\nYou can use the REST API to view logs and workflow jobs in {% data variables.product.prodname_actions %}. {% data reusables.actions.about-workflow-jobs %} For more information, see \"AUTOTITLE.\"\n\n\n\n", "Y2h1bmtfMF9pbmRleF8zNTE=": "\n\nAbout custom footers for {% ifversion ghec or ghae %}your enterprise{% elsif ghes %}{% data variables.product.product_name %}{% endif %}\n\nYou can configure the web UI for {% data variables.product.product_name %} to display a custom footer with up to five additional links. The custom footer appears above the default {% data variables.product.prodname_dotcom %} footer{% ifversion ghes or ghae %}, to all users and on all pages{% elsif ghec %} to all enterprise members and collaborators, on all repository and organization pages for repositories and organizations that belong to the enterprise{% endif %}.\n\n\n\nConfiguring custom footers\n\n{% data reusables.enterprise-accounts.access-enterprise %}\n{% data reusables.enterprise-accounts.settings-tab %}\n1. Under {% octicon \"gear\" aria-hidden=\"true\" %} **Settings**, click **Profile**.\n1. At the top of the page, under the navigation bar, click **Custom footer**.\n\n   !Screenshot of the \"Profile\" page for an enterprise account. A tab, labeled \"Custom footer\", is outlined in dark orange.\n1. Under each \"Footer Link\" heading, type a title and URL.\n1. To save the content and display the custom footer, click **Update custom footer**.\n\n", "Y2h1bmtfMF9pbmRleF8yMDkw": "\n\nAbout sponsor profiles\n\nYour {% data variables.product.prodname_sponsors %} profile tells potential sponsors why they should support you. People see your sponsor profile when they click the **Sponsor** button on your profile. We recommend including the following information.\n\n- Open source work that you contribute to\n- Why you are committed to open source development\n\n\n\nEditing your profile details\n\n{% data reusables.sponsors.navigate-to-sponsors-dashboard %}\n{% data reusables.sponsors.navigate-to-profile-tab %}\n{% data reusables.sponsors.short-bio %}\n{% data reusables.sponsors.add-introduction %}\n{% data reusables.sponsors.edit-featured-work %}\n{% data reusables.sponsors.opt-in-to-being-featured %}\n{% data reusables.sponsors.save-profile %}\n\n", "Y2h1bmtfMF9pbmRleF8xNzYy": "\n\nAbout {% data variables.product.prodname_actions %} permissions for your repository\n\n{% data reusables.actions.disabling-github-actions %} For more information about {% data variables.product.prodname_actions %}, see \"AUTOTITLE.\"\n\nYou can enable {% data variables.product.prodname_actions %} for your repository. {% data reusables.actions.enabled-actions-description %} You can disable {% data variables.product.prodname_actions %} for your repository altogether. {% data reusables.actions.disabled-actions-description %}\n\nAlternatively, you can enable {% data variables.product.prodname_actions %} in your repository but limit the actions {% ifversion actions-workflow-policy %}and reusable workflows{% endif %} a workflow can run.\n\n\n\nManaging {% data variables.product.prodname_actions %} permissions for your repository\n\nYou can disable {% data variables.product.prodname_actions %} for a repository, or set a policy that configures which actions{% ifversion actions-workflow-policy %} and reusable workflows{% endif %} can be used in the repository.\n\n{% note %}\n\n**Note:** You might not be able to manage these settings if your organization has an overriding policy or is managed by an enterprise that has overriding policy. For more information, see \"AUTOTITLE\" or \"AUTOTITLE.\"\n\n{% endnote %}\n\n{% data reusables.repositories.navigate-to-repo %}\n{% data reusables.repositories.sidebar-settings %}\n{% data reusables.repositories.settings-sidebar-actions-general %}\n1. Under \"Actions permissions\", select an option.\n\n   {% data reusables.actions.actions-use-policy-settings %}\n1. Click **Save**.\n\n{% data reusables.actions.allow-specific-actions-intro %}\n\n{% data reusables.repositories.navigate-to-repo %}\n{% data reusables.repositories.sidebar-settings %}\n{% data reusables.repositories.settings-sidebar-actions-general %}\n1. Under \"Actions permissions\", select {% data reusables.actions.policy-label-for-select-actions-workflows %} and add your required actions to the list.\n1. Click **Save**.\n\n{% ifversion fpt or ghec %}\n\n\n\nControlling cha", "Y2h1bmtfMV9pbmRleF8xNzYy": "nges from forks to workflows in public repositories\n\n{% data reusables.actions.workflow-run-approve-public-fork %}\n\nYou can configure this behavior for a repository using the procedure below. Modifying this setting overrides the configuration set at the organization or enterprise level.\n\n{% data reusables.repositories.navigate-to-repo %}\n{% data reusables.repositories.sidebar-settings %}\n{% data reusables.repositories.settings-sidebar-actions-general %}\n{% data reusables.actions.workflows-from-public-fork-setting %}\n\n{% data reusables.actions.workflow-run-approve-link %}\n{% endif %}\n\n\n\nEnabling workflows for forks of private repositories\n\n{% data reusables.actions.private-repository-forks-overview %}\n\nIf a policy is disabled for an {% ifversion ghec or ghae or ghes %}enterprise or{% endif %} organization, it cannot be enabled for a repository.\n\n{% data reusables.actions.private-repository-forks-options %}\n\n\n\nConfiguring the fork policy for a private repository\n\n{% data reusables.repositories.navigate-to-repo %}\n{% data reusables.repositories.sidebar-settings %}\n{% data reusables.repositories.settings-sidebar-actions-general %}\n{% data reusables.actions.private-repository-forks-configure %}\n\n\n\nSetting the permissions of the `GITHUB_TOKEN` for your repository\n\n{% data reusables.actions.workflow-permissions-intro %}\n\nThe default permissions can also be configured in the organization settings. If your repository belongs to an organization and a more restrictive default has been selected in the organization settings, the same option is selected in your repository settings and the permissive option is disabled.\n\n{% data reusables.actions.workflow-permissions-modifying %}\n\n\n\nConfiguring the default `GITHUB_TOKEN` permissions\n\n{% ifversion actions-default-workflow-permissions-restrictive %}\nBy default, when you create a new repository in your personal account, `GITHUB_TOKEN` only has read access for the `contents` and `packages` scopes. If you create a new repository in an organization, the setting is inherited from what", "Y2h1bmtfMl9pbmRleF8xNzYy": " is configured in the organization settings.\n{% endif %}\n\n{% data reusables.repositories.navigate-to-repo %}\n{% data reusables.repositories.sidebar-settings %}\n{% data reusables.repositories.settings-sidebar-actions-general %}\n{% data reusables.actions.workflows.github-token-access %}\n1. Click **Save** to apply the settings.\n\n{% ifversion allow-actions-to-approve-pr-with-ent-repo %}\n\n\n\nPreventing {% data variables.product.prodname_actions %} from creating or approving pull requests\n\n{% data reusables.actions.workflow-pr-approval-permissions-intro %}\n\n{% ifversion actions-default-workflow-permissions-restrictive %}\nBy default, when you create a new repository in your personal account, workflows are not allowed to create or approve pull requests. If you create a new repository in an organization, the setting is inherited from what is configured in the organization settings.\n{% endif %}\n\n{% data reusables.repositories.navigate-to-repo %}\n{% data reusables.repositories.sidebar-settings %}\n{% data reusables.repositories.settings-sidebar-actions-general %}\n1. Under \"Workflow permissions\", use the **Allow GitHub Actions to create and approve pull requests** setting to configure whether `GITHUB_TOKEN` can create and approve pull requests.\n1. Click **Save** to apply the settings.\n{% endif %}\n\n{% ifversion ghes or ghae or ghec %}\n\n\n\nAllowing access to components in an internal repository\n\n{% ifversion internal-actions %}Actions and reusable workflows in your internal repositories can be shared with internal and private repositories in the same organization or enterprise.{% else %}Members of your enterprise can use internal repositories to work on projects without sharing information publicly.{% endif %} For information about internal repositories, see \"AUTOTITLE.\"\n\nYou can use the steps below to configure whether {% ifversion internal-actions%}actions and {% endif %}reusable workflows in an internal repository can be accessed from outside the repository.{% ifversion internal-actions %} For more information, see \"AUTOTITLE.", "Y2h1bmtfM19pbmRleF8xNzYy": "\" Alternatively, you can use the REST API to set, or get details of the level of access. For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"{% endif %}\n\n1. On {% data variables.product.prodname_dotcom %}, navigate to the main page of the internal repository.\n1. Under your repository name, click {% octicon \"gear\" aria-hidden=\"true\" %} **Settings**.\n{% data reusables.repositories.settings-sidebar-actions-general %}\n1. Under **Access**, choose one of the access settings:\n\n   - **Not accessible** - Workflows in other repositories cannot access this repository.\n   - **Accessible from repositories in the 'ORGANIZATION NAME' organization** - {% ifversion ghes or ghae or ghec %}Workflows in other repositories that are part of the 'ORGANIZATION NAME' organization can access the actions and reusable workflows in this repository. Access is allowed only from private or internal repositories.{% else %}Workflows in other repositories can use workflows in this repository if they are part of the same organization and their visibility is private or internal.{% endif %}\n   - **Accessible from repositories in the 'ENTERPRISE NAME' enterprise** - {% ifversion ghes or ghae or ghec %}Workflows in other repositories that are part of the 'ENTERPRISE NAME' enterprise can access the actions and reusable workflows in this repository. Access is allowed only from private or internal repositories.{% else %}Workflows in other repositories can use workflows in this repository if they are part of the same enterprise and their visibility is private or internal.{% endif %}\n1. Click **Save** to apply the settings.\n{% endif %}\n\n{% ifversion private-actions %}\n\n\n\nAllowing access to components in a private repository\n\nActions and reusable workflows in your private repositories can be shared with other private repositories {% ifversion fpt %}owned by the same user or organization{% else %}in the same organization or enterprise{% endif %}. For information about private repositories, see \"AUTOTITLE.\"\n\nYou can use the steps below to configure whether a", "Y2h1bmtfNF9pbmRleF8xNzYy": "ctions and reusable workflows in a private repository can be accessed from outside the repository. For more information, see {% ifversion fpt %}\"AUTOTITLE\" and \"AUTOTITLE.\"{% else %}\"AUTOTITLE.\"{% endif %} Alternatively, you can use the REST API to set, or get details of the level of access. For more information, see \"AUTOTITLE\" and \"AUTOTITLE.\"\n\n{% ifversion fpt %}\n\n\n\nManaging access for a private repository\n\n1. On {% data variables.product.prodname_dotcom %}, navigate to the main page of the private repository.\n1. Under your repository name, click {% octicon \"gear\" aria-hidden=\"true\" %} **Settings**.\n{% data reusables.repositories.settings-sidebar-actions-general %}\n1. Under **Access**, choose one of the access settings:\n\n   - **Not accessible** - Workflows in other repositories cannot access this repository.\n   - **Accessible from repositories owned by 'USER NAME' user** - Workflows in other repositories that are owned by the same user can access the actions and reusable workflows in this repository. Access is allowed only from private repositories.\n1. Click **Save** to apply the settings.\n\n{% endif %}\n\n{% ifversion fpt %}\n\n\n\nManaging access for a private repository in an organization\n\n1. On {% data variables.product.prodname_dotcom %}, navigate to the main page of the private repository.\n1. Under your repository name, click {% octicon \"gear\" aria-hidden=\"true\" %} **Settings**.\n{% data reusables.repositories.settings-sidebar-actions-general %}\n1. Under **Access**, choose one of the access settings:\n\n   - **Not accessible** - Workflows in other repositories cannot access this repository.\n   - **Accessible from repositories in the 'ORGANIZATION NAME' organization** - Workflows in other repositories that are part of the 'ORGANIZATION NAME' organization can access the actions and reusable workflows in this repository. Access is allowed only from private repositories.\n1. Click **Save** to apply the settings.\n\n{% endif %}\n\n{% ifversion fpt %}{% else %}\n\n1. On {% data variables.product.prodname_dotcom %}, navigate to", "Y2h1bmtfNV9pbmRleF8xNzYy": " the main page of the private repository.\n1. Under your repository name, click {% octicon \"gear\" aria-hidden=\"true\" %} **Settings**.\n{% data reusables.repositories.settings-sidebar-actions-general %}\n1. Under **Access**, choose one of the access settings:\n   - **Not accessible** - Workflows in other repositories cannot access this repository.\n   - **Accessible from repositories in the 'ORGANIZATION NAME' organization** - Workflows in other repositories that are part of the 'ORGANIZATION NAME' organization can access the actions and reusable workflows in this repository. Access is allowed only from private repositories.\n   - **Accessible from repositories in the 'ENTERPRISE NAME' enterprise** - Workflows in other repositories that are part of the 'ENTERPRISE NAME' enterprise can access the actions and reusable workflows in this repository. Access is allowed only from private repositories.\n1. Click **Save** to apply the settings.\n{% endif %}\n{% endif %}\n\n\n\nConfiguring the retention period for {% data variables.product.prodname_actions %} artifacts and logs in your repository\n\nYou can configure the retention period for {% data variables.product.prodname_actions %} artifacts and logs in your repository.\n\n{% data reusables.actions.about-artifact-log-retention %}\n\nYou can also define a custom retention period for a specific artifact created by a workflow. For more information, see \"AUTOTITLE.\"\n\n\n\nSetting the retention period for a repository\n\n{% data reusables.repositories.navigate-to-repo %}\n{% data reusables.repositories.sidebar-settings %}\n{% data reusables.repositories.settings-sidebar-actions-general %}\n{% data reusables.actions.change-retention-period-for-artifacts-logs  %}\n\n{% ifversion actions-cache-policy-apis %}\n\n\n\nConfiguring cache storage for a repository\n\n{% data reusables.actions.cache-default-size %} However, these default sizes might be different if an enterprise owner has changed them. {% data reusables.actions.cache-eviction-process %}\n\nYou can set a total cache storage size for your repository up to ", "Y2h1bmtfNl9pbmRleF8xNzYy": "the maximum size allowed by the {% ifversion actions-cache-admin-ui %}organization or{% endif %} enterprise policy setting{% ifversion actions-cache-admin-ui %}s{% endif %}.\n\n{% ifversion actions-cache-admin-ui %}\n\n{% data reusables.repositories.navigate-to-repo %}\n{% data reusables.repositories.sidebar-settings %}\n{% data reusables.repositories.settings-sidebar-actions-general %}\n{% data reusables.actions.change-cache-size-limit  %}\n\n{% elsif ghes < 3.8 %}\n\nThe repository settings for {% data variables.product.prodname_actions %} cache storage can currently only be modified using the REST API:\n\n- To view the current cache storage limit for a repository, see \"AUTOTITLE.\"\n- To change the cache storage limit for a repository, see \"AUTOTITLE.\"\n\n{% data reusables.actions.cache-no-org-policy %}\n\n{% endif %}\n\n{% endif %}\n\n", "Y2h1bmtfMF9pbmRleF8xNDgy": "\n\nAbout your organization's profile page\n\n{% ifversion org-profile-pin-private %}\nYou can customize your organization's Overview page to show a README and pinned repositories dedicated to public users or members of the organization.\n\nMembers of your organization who are signed into {% data variables.product.prodname_dotcom %}, can select a `member` or `public` view of the README and pinned repositories when they visit your organization's profile page.\n\n!Screenshot of an organization's profile page. In the right sidebar, a dropdown menu, labeled \"View as: Public\", is outlined in dark orange.\n\nThe view defaults to `member` if either a members-only README or members-only pinned repositories are present, and `public` otherwise.\n\nUsers who are not members of your organization will be shown a `public` view.\n\n\n\nPinned repositories\n\nYou can give users easy access to important or frequently used repositories, by choosing up to six repositories for public users and six repositories for members of the organization. Once you pin repositories to your organization profile, the \"Pinned\" section is shown above the \"Repositories\" section of the profile page.\n\nOnly organization owners can pin repositories. For more information, see \"Pinning repositories to your organization's profile.\"\n\n\n\nOrganization profile READMEs\n\n{% endif %}\n\nYou can share information about how to engage with your organization by creating an organization profile README for both public users and members of the organization. {% data variables.product.prodname_dotcom %} shows your organization profile README in the \"Overview\" tab of your organization.\n\nYou can choose what information to include in your organization profile README. Here are some examples of information that may be helpful.\n\n- An \"About\" section that describes your organization\n- Guidance for getting help in the organization\n\nYou can format text and include emoji, images, and GIFs in your organization profile README by using {% data variables.product.company_short %} Flavored Markdown. For more in", "Y2h1bmtfMV9pbmRleF8xNDgy": "formation, see \"AUTOTITLE.\"\n\n\n\nAdding a public organization profile README\n\nThe content of public `README.md` will appear on your organization's public profile.\n\n1. If your organization does not already have a public `.github` repository, create a public `.github` repository.\n1. In your organization's `.github` repository, create a `README.md` file in the `profile` folder.\n1. Commit the changes to the `README.md` file.\n\n{% ifversion org-profile-pin-private %}\n\n\n\nAdding a member-only organization profile README\n\nThe content of a member-only `README.md` will be displayed in the member view of your organization's profile.\n\n1. If your organization does not already have a `.github-private` repository, create a private repository called `.github-private`.\n1. In your organization's `.github-private` repository, create a `README.md` file in the `profile` folder.\n1. Commit the changes to the `README.md` file.\n\n\n\nPinning repositories to your organization's profile\n\nYou can pin repositories that you want to feature, such as those that are frequently used, to your organization's profile page. To choose which repositories to pin to your organization's profile, you must be an organization owner.\n\n1. Navigate to your organization's profile page.\n1. In the right sidebar of the page, select the **{% octicon \"eye\" aria-hidden=\"true\" %} View as** dropdown menu, then click **Public** or **Member**.\n\n   !Screenshot of an organization's profile page. In the left sidebar, a dropdown menu, labeled \"View as: public\" is outlined in dark orange.\n1. Navigate to the settings for pinned repositories.\n\n   - If you already have pinned repositories, in the \"Pinned\" section, click **Customize pins**.\n\n   !Screenshot of an organization's profile page. In the top-right corner of the \"Pinned\" section, \"Customize pins\" is outlined in dark orange.\n\n   - If you haven't yet pinned any repositories, in the right sidebar, click **pin repositories**.\n\n   !Screenshot of an organization's profile page. In the right sidebar, a link, labeled \"pin repositories,", "Y2h1bmtfMl9pbmRleF8xNDgy": "\" is outlined in dark orange.\n\n1. In the \"Edit pinned repositories\" dialog box, select a combination of up to six public, {% ifversion not fpt %}private, or internal{% else %}or private{% endif %} repositories to display.\n1. Click **Save pins**.\n\n{% endif %}\n\n\n\nChanging your organization's profile picture\n\nWhen you create an organization, {% data variables.product.product_name %} provides you with a randomly generated \"identicon.\" The identicon is generated from a hash of your organization's user ID, so there's no way to control its color or pattern.\n\nYou can replace the identicon with an image that represents your organization. To replace the image, you can upload a new image or use a Gravatar image.\n\n\n\nUploading an image\n\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n1. Under your profile picture, click **Upload new picture**, then select an image.\n\n\n\nUsing a Gravatar image\n\n{% data reusables.profile.access_org %}\n{% data reusables.profile.org_settings %}\n1. In the \"Gravatar email (Private)\" field, enter the email address associated with your Gravatar image.\n1. Click **Update profile**.\n\n"}, "relevant_docs": {"0e6bce00-8ec5-4226-bc8a-fda53ac3484d": ["Y2h1bmtfMF9pbmRleF8yNTk="], "c0dd0743-8678-4350-8c92-784ba95e7d5c": ["Y2h1bmtfMV9pbmRleF8yNTk="], "34e7fcb4-dd11-4fd7-a3bf-29760692c6ab": ["Y2h1bmtfMV9pbmRleF8yNTk="], "123c77ce-7c89-413d-8bfa-ea8862bcaca6": ["Y2h1bmtfMV9pbmRleF8yNTk="], "0542e973-bfaa-4a3c-98ae-5816dfbfc12a": ["Y2h1bmtfMF9pbmRleF8xMzQw"], "2976e1e1-a7f1-4401-b3dc-ae566cab0012": ["Y2h1bmtfMF9pbmRleF8xMzQw"], "9d3e34d3-57a9-48bd-8909-40d6e7e15c90": ["Y2h1bmtfMV9pbmRleF8xMzQw"], "fcce1d6d-6134-4d24-aef7-682f2ae76230": ["Y2h1bmtfMV9pbmRleF8xMzQw"], "6feb3bb5-65f4-495d-a1e6-e4e190990968": ["Y2h1bmtfMF9pbmRleF8yODE="], "dc2b88fc-83e8-40bf-b1fb-53441f95cc21": ["Y2h1bmtfMF9pbmRleF8yODE="], "e9810533-f1a0-4876-bfd0-e5b5a4b58e96": ["Y2h1bmtfMF9pbmRleF8yODE="], "b87a330e-6371-4622-89a7-381457731cfe": ["Y2h1bmtfMF9pbmRleF8xMTI2"], "0ee6e08e-c6ad-49b4-a3cf-27b929777249": ["Y2h1bmtfMF9pbmRleF8xMTI2"], "29052032-ce34-4a47-b893-c7ad29675867": ["Y2h1bmtfMV9pbmRleF8xMTI2"], "15813d7d-4010-4661-b054-c684003d2446": ["Y2h1bmtfMV9pbmRleF8xMTI2"], "bb471343-cb30-44e0-9c4d-8a2f73fd5504": ["Y2h1bmtfMl9pbmRleF8xMTI2"], "6577d4fd-35c1-4e12-ad43-7de4d23b3381": ["Y2h1bmtfMl9pbmRleF8xMTI2"], "4b80ccfa-f37b-4eb7-bce5-1c7b1acc7ed0": ["Y2h1bmtfM19pbmRleF8xMTI2"], "bf49fa1d-347b-4459-a84d-a5b10c367a9c": ["Y2h1bmtfM19pbmRleF8xMTI2"], "d525ae38-00b2-4e04-8166-98da3d23b45e": ["Y2h1bmtfM19pbmRleF8xMTI2"], "83c00232-7b6e-4d54-a83a-bbafa9cd5bcf": ["Y2h1bmtfM19pbmRleF8xMTI2"], "12051d0b-5705-4e59-8290-73502f2b6bb9": ["Y2h1bmtfMF9pbmRleF8xNzg="], "4d09f86d-34ca-4aeb-a668-7472557158a4": ["Y2h1bmtfMF9pbmRleF8xNzg="], "93dce8bc-9888-441e-a63e-f5890a6d4cde": ["Y2h1bmtfMF9pbmRleF8xNzg="], "5acbcacd-3e6e-46fd-a36c-2dd45297b86d": ["Y2h1bmtfMF9pbmRleF8xNzg="], "26f2a17f-6ab6-41e8-bfb1-a56cff558245": ["Y2h1bmtfMF9pbmRleF8xNzg="], "3afbb70b-4c2d-43e7-ac95-4e6630142065": ["Y2h1bmtfMV9pbmRleF8xNzg="], "a6b72001-42b8-4c9e-b5f9-88a84dd83414": ["Y2h1bmtfMV9pbmRleF8xNzg="], "d5cd411d-5665-4365-93af-7974ee3c9854": ["Y2h1bmtfMV9pbmRleF8xNzg="], "dfedee36-9d01-481a-b530-4e7f494d61b7": ["Y2h1bmtfMV9pbmRleF8xNzg="], "0346a0a2-2df6-4673-80d7-e5a2277e6f02": ["Y2h1bmtfMV9pbmRleF8xNzg="], "114c3cf3-b480-4ebe-9474-cdf046dcb323": ["Y2h1bmtfMV9pbmRleF8xNzg="], "39bf18f8-433c-405e-b5c9-3142b4a6ec8b": ["Y2h1bmtfMV9pbmRleF8xNzg="], "aa3e0455-bcc0-4188-86ad-dff30392fe84": ["Y2h1bmtfMl9pbmRleF8xNzg="], "3e610b04-c602-4b3f-90be-f53908259c19": ["Y2h1bmtfM19pbmRleF8xNzg="], "16b0aae1-7e8b-4f17-b512-6a1d7d3848b7": ["Y2h1bmtfNF9pbmRleF8xNzg="], "c71eb912-9bbd-4c4b-bfb6-61b18558b9bb": ["Y2h1bmtfNV9pbmRleF8xNzg="], "475685da-58c2-4411-a478-42663847f9e9": ["Y2h1bmtfNV9pbmRleF8xNzg="], "3891e1bf-73a7-49be-9110-8971a3d5d8db": ["Y2h1bmtfNl9pbmRleF8xNzg="], "4a626847-6f16-4043-9237-f97844073e63": ["Y2h1bmtfNl9pbmRleF8xNzg="], "aebed5ca-33ca-4eb2-9a9f-c23f837d639c": ["Y2h1bmtfMF9pbmRleF83MTE="], "e0b333be-d991-43e8-87a2-31e8f997c71d": ["Y2h1bmtfMV9pbmRleF83MTE="], "1bb553d2-ef59-4a1f-b6c4-aff91f846830": ["Y2h1bmtfMV9pbmRleF83MTE="], "75b80cad-6a49-460d-9f95-915e557620ea": ["Y2h1bmtfMF9pbmRleF81NTQ="], "987210a9-892d-4894-98de-937c46ab368c": ["Y2h1bmtfMF9pbmRleF81NTQ="], "ef3e0179-c5d0-4073-936a-2a58515f172b": ["Y2h1bmtfMF9pbmRleF8xMjU3"], "467dc1a3-535d-4ebe-a3ca-adc877989eb1": ["Y2h1bmtfMF9pbmRleF8xMjU3"], "d3911892-6655-4b36-9c9a-1e8780716d6a": ["Y2h1bmtfMV9pbmRleF8xMjU3"], "e634361c-3640-4dc0-aaa4-98c2194237ce": ["Y2h1bmtfMl9pbmRleF8xMjU3"], "4bd841c9-ec01-457d-86b2-e9122ef5e866": ["Y2h1bmtfMl9pbmRleF8xMjU3"], "18b725b2-48ba-4a46-bf47-0cff9e2981be": ["Y2h1bmtfMF9pbmRleF8xMTEx"], "71fd0ad4-2a05-467b-b81e-54d8fccd3391": ["Y2h1bmtfMF9pbmRleF8xMTEx"], "c4c7f4aa-c62c-48be-b2ac-72607c98d94f": ["Y2h1bmtfMV9pbmRleF8xMTEx"], "c4897e6e-7eb2-438f-ae98-7a82570ef6ef": ["Y2h1bmtfMV9pbmRleF8xMTEx"], "f6aec6b3-c796-40e7-a39d-70c3d584ab7b": ["Y2h1bmtfMl9pbmRleF8xMTEx"], "3d129430-33ba-4e92-9cf0-81083b077810": ["Y2h1bmtfMl9pbmRleF8xMTEx"], "72848752-ecf1-4ba6-a358-14b63a472a7b": ["Y2h1bmtfMF9pbmRleF8yMTEz"], "c649361a-4b77-4aaf-bb67-633bcbb18265": ["Y2h1bmtfMF9pbmRleF8yMTEz"], "f7de7089-7181-4cba-b7d7-c0bf39547ca5": ["Y2h1bmtfMV9pbmRleF8yMTEz"], "6800d6c0-75c9-4eb5-993d-733032b469ee": ["Y2h1bmtfMV9pbmRleF8yMTEz"], "b5b15292-0fb2-4308-a7f7-0b1dff956e6f": ["Y2h1bmtfMl9pbmRleF8yMTEz"], "5693d896-33aa-4518-ab6f-b2ec5978bfcf": ["Y2h1bmtfMl9pbmRleF8yMTEz"], "9638b085-11ce-428f-b80e-191174ddd0ff": ["Y2h1bmtfM19pbmRleF8yMTEz"], "f86386cc-5863-40aa-be6c-e90468b761d6": ["Y2h1bmtfM19pbmRleF8yMTEz"], "6ab6c454-0db3-4547-94ac-c52d388fad43": ["Y2h1bmtfNF9pbmRleF8yMTEz"], "5cfd103b-cc8a-4d66-9185-340e9e2c3ead": ["Y2h1bmtfNF9pbmRleF8yMTEz"], "9fc4fcdc-2e0b-4d2a-af9e-22f4d73bd568": ["Y2h1bmtfMF9pbmRleF85NDY="], "e2d3ebe9-6229-4285-b894-b85f7d158342": ["Y2h1bmtfMF9pbmRleF85NDY="], "4a9feac6-1701-4905-b84f-d35a76d1976a": ["Y2h1bmtfMF9pbmRleF81MTk="], "e614946b-ca48-4530-bd39-eefb39d3e214": ["Y2h1bmtfMF9pbmRleF81MTk="], "ad61f349-a7e7-4342-8780-31e902e0bdf2": ["Y2h1bmtfMV9pbmRleF81MTk="], "4fb68818-9a1f-4c4c-a8e7-6f96cb60a83c": ["Y2h1bmtfMV9pbmRleF81MTk="], "8e02401d-8918-4f1c-9022-e51a3cbc48f7": ["Y2h1bmtfMF9pbmRleF8yMDY5"], "81bec0cc-65e3-44e2-b3db-687b3118d269": ["Y2h1bmtfMF9pbmRleF8yMDY5"], "6802103e-a6e5-4d66-a421-a95d2762ba79": ["Y2h1bmtfMV9pbmRleF8yMDY5"], "32a14862-b4f9-49ed-9298-65da9bb04d9e": ["Y2h1bmtfMV9pbmRleF8yMDY5"], "4b9db962-1df4-4d5e-b4cf-75154ac4b933": ["Y2h1bmtfMl9pbmRleF8yMDY5"], "a4d5da0d-22c9-40ca-bc07-f0916b2d4902": ["Y2h1bmtfMl9pbmRleF8yMDY5"], "7023e66f-73a6-402e-a337-b7b0fe7ee9dd": ["Y2h1bmtfM19pbmRleF8yMDY5"], "df0ad37a-2c41-4226-907d-64047862c4d7": ["Y2h1bmtfM19pbmRleF8yMDY5"], "26994960-71c6-498d-a85b-24eaf437d1b4": ["Y2h1bmtfNF9pbmRleF8yMDY5"], "ae1efa0b-292b-4d6f-a3c1-f9f09a5c65fd": ["Y2h1bmtfNF9pbmRleF8yMDY5"], "2c7b6c2a-ea0d-4830-9749-3fb10a816f40": ["Y2h1bmtfNV9pbmRleF8yMDY5"], "3d813faf-afc6-42eb-a8b6-b2382ae5fdcf": ["Y2h1bmtfNV9pbmRleF8yMDY5"], "67c27f8e-8a6b-43d0-a96e-6abb70d45712": ["Y2h1bmtfNV9pbmRleF8yMDY5"], "563317f9-8ff0-4a05-bc06-ad05342f4112": ["Y2h1bmtfNV9pbmRleF8yMDY5"], "6934165d-1344-43b6-a6e7-a00315bfc9be": ["Y2h1bmtfNV9pbmRleF8yMDY5"], "b50a1751-f653-449b-b955-8d6eab2797e1": ["Y2h1bmtfNV9pbmRleF8yMDY5"], "7295f43f-a75f-472f-a959-383cf1e98894": ["Y2h1bmtfNV9pbmRleF8yMDY5"], "997f3df8-faad-4e4c-9e43-427430b0bee2": ["Y2h1bmtfNl9pbmRleF8yMDY5"], "8e6dd6d9-a4c9-4d5b-b018-ba9885768372": ["Y2h1bmtfNl9pbmRleF8yMDY5"], "68f4ee3b-962b-4ca1-8f6a-a4f5ccf8f0c0": ["Y2h1bmtfN19pbmRleF8yMDY5"], "7d06aed6-a9c4-4aeb-8240-d161ec80bc7e": ["Y2h1bmtfN19pbmRleF8yMDY5"], "78a0d82e-93ad-4060-b52a-9ccc9cb12349": ["Y2h1bmtfOF9pbmRleF8yMDY5"], "21eefa39-ccb0-43ed-8609-45036c2533aa": ["Y2h1bmtfOF9pbmRleF8yMDY5"], "7b74c6b8-0509-4a1b-b34c-130cca825bca": ["Y2h1bmtfOV9pbmRleF8yMDY5"], "ef864680-a4e9-40dd-89fa-895c683dcba9": ["Y2h1bmtfOV9pbmRleF8yMDY5"], "e5b83d3b-dc43-4299-b369-44928a2d5f2f": ["Y2h1bmtfMTBfaW5kZXhfMjA2OQ=="], "f98631ee-1add-4446-afa5-0a8a67f07a0e": ["Y2h1bmtfMTBfaW5kZXhfMjA2OQ=="], "9f55d12f-f0ff-49b9-9b48-425111f2c29a": ["Y2h1bmtfMTBfaW5kZXhfMjA2OQ=="], "5b1e78be-51a8-49a8-8036-dafc6091150f": ["Y2h1bmtfMTBfaW5kZXhfMjA2OQ=="], "e35d5da1-be16-4d0f-80dd-9ae3711f24a2": ["Y2h1bmtfMTBfaW5kZXhfMjA2OQ=="], "19f207c3-937f-4a9a-9179-b0a99777b98a": ["Y2h1bmtfMTBfaW5kZXhfMjA2OQ=="], "0b7192b4-6044-4b68-9cc5-b0a9a4bf0549": ["Y2h1bmtfMTBfaW5kZXhfMjA2OQ=="], "6de631ce-4fd8-4467-88a3-98ccf5114446": ["Y2h1bmtfMTFfaW5kZXhfMjA2OQ=="], "ab50f441-7308-4473-98aa-3e2ad439cea9": ["Y2h1bmtfMTFfaW5kZXhfMjA2OQ=="], "9f02dc63-bf4f-4086-b710-68ecdd5ca4b0": ["Y2h1bmtfMTJfaW5kZXhfMjA2OQ=="], "57dd4810-55e8-406d-9015-31ed3fd6c23b": ["Y2h1bmtfMTJfaW5kZXhfMjA2OQ=="], "4c5a4bea-80f7-4bad-8614-a91e9b2c3362": ["Y2h1bmtfMTNfaW5kZXhfMjA2OQ=="], "2cac8347-7fef-42ea-bc74-ac7e1cc5be8b": ["Y2h1bmtfMTNfaW5kZXhfMjA2OQ=="], "eb4f1bc1-9c2e-4594-a879-f4cced6d049b": ["Y2h1bmtfMTNfaW5kZXhfMjA2OQ=="], "15cb90cd-3dbd-4459-a6cf-860cb0044ed2": ["Y2h1bmtfMTNfaW5kZXhfMjA2OQ=="], "11a974fa-d3b6-4e72-8a09-b83876a0d447": ["Y2h1bmtfMTNfaW5kZXhfMjA2OQ=="], "db99a497-5aa7-441a-8b10-a8d339d1987c": ["Y2h1bmtfMTNfaW5kZXhfMjA2OQ=="], "55f3a696-518c-4629-be0f-277b7b7f50de": ["Y2h1bmtfMTNfaW5kZXhfMjA2OQ=="], "7958e994-01c8-495a-9700-88ec13c4750f": ["Y2h1bmtfMTRfaW5kZXhfMjA2OQ=="], "dad183c1-d245-4360-a3c1-a3772406831c": ["Y2h1bmtfMTRfaW5kZXhfMjA2OQ=="], "cbd43011-5c36-4cb7-8c4f-075c666ea2d4": ["Y2h1bmtfMTVfaW5kZXhfMjA2OQ=="], "1fca1c36-740b-41bd-b9b1-893526e7b388": ["Y2h1bmtfMTVfaW5kZXhfMjA2OQ=="], "baa1ad79-9a16-419a-88ee-5b632d83574b": ["Y2h1bmtfMTZfaW5kZXhfMjA2OQ=="], "59d82b9d-b879-4d2e-a9cc-56f905a89d37": ["Y2h1bmtfMTZfaW5kZXhfMjA2OQ=="], "e7bd4960-9bd3-4b66-82e1-8705aa8caa0e": ["Y2h1bmtfMTdfaW5kZXhfMjA2OQ=="], "9eb7ff7e-41b8-4f65-b915-6b9133a4d88c": ["Y2h1bmtfMTdfaW5kZXhfMjA2OQ=="], "f938a1ad-8033-4e84-89f1-8975aa715c19": ["Y2h1bmtfMThfaW5kZXhfMjA2OQ=="], "4e8b5b25-b4b7-41f3-9c20-b410eea50d1d": ["Y2h1bmtfMThfaW5kZXhfMjA2OQ=="], "d4015706-90c4-4694-9494-86787aa14a99": ["Y2h1bmtfMTlfaW5kZXhfMjA2OQ=="], "80326b4e-a974-4461-b6f4-dadd76b6dc7f": ["Y2h1bmtfMTlfaW5kZXhfMjA2OQ=="], "5045d46f-2ace-47f0-9d8e-c4db99a99db2": ["Y2h1bmtfMjBfaW5kZXhfMjA2OQ=="], "55c1996c-bc22-4568-9092-635b1629827f": ["Y2h1bmtfMjBfaW5kZXhfMjA2OQ=="], "d3f21271-b481-493d-b81d-0bcbb41df164": ["Y2h1bmtfMjFfaW5kZXhfMjA2OQ=="], "64cdaad2-0d36-449b-a7ef-7dcefe881754": ["Y2h1bmtfMjFfaW5kZXhfMjA2OQ=="], "5c33d656-e684-4573-9d7d-a7708cf67df3": ["Y2h1bmtfMjJfaW5kZXhfMjA2OQ=="], "7ccf7816-f768-42ac-878c-4704f1cd22e7": ["Y2h1bmtfMjJfaW5kZXhfMjA2OQ=="], "e72761f3-901c-4e63-9114-56d59bbc1749": ["Y2h1bmtfMjNfaW5kZXhfMjA2OQ=="], "25ac4d56-edfa-4795-aa40-00ae0d1b01a8": ["Y2h1bmtfMjNfaW5kZXhfMjA2OQ=="], "6622a7a2-54fd-421d-9e93-8137b681e666": ["Y2h1bmtfMjRfaW5kZXhfMjA2OQ=="], "a79b2f0a-b073-4847-ae84-ee74f9ba55d2": ["Y2h1bmtfMjRfaW5kZXhfMjA2OQ=="], "6af2adbc-4cd1-43d7-a069-1a7067bb92e9": ["Y2h1bmtfMjVfaW5kZXhfMjA2OQ=="], "dee8a73d-d79f-4647-b7d8-4bb51e9fbcf5": ["Y2h1bmtfMjVfaW5kZXhfMjA2OQ=="], "9b10c654-7fb4-4abc-973f-1fa4a5021fd9": ["Y2h1bmtfMjZfaW5kZXhfMjA2OQ=="], "6eb177ef-d292-428b-84ec-8e1ff9f3f2c3": ["Y2h1bmtfMjZfaW5kZXhfMjA2OQ=="], "8127b4b2-86dd-4c46-ad0a-3bc9d3086dcd": ["Y2h1bmtfMF9pbmRleF8xNTI5"], "6e795ed3-c6ec-4091-9c8a-1207580047c3": ["Y2h1bmtfMF9pbmRleF8xNTI5"], "2554cb1a-bd8e-4db1-9ceb-b20bc472e5b5": ["Y2h1bmtfMF9pbmRleF8zODI="], "be897204-6169-4783-ae54-20886bef87de": ["Y2h1bmtfMF9pbmRleF8xNTM5"], "b6835838-fee6-4729-a2b0-7a7a4740867d": ["Y2h1bmtfMF9pbmRleF8xNTM5"], "31ce5933-98c9-4393-b415-48f8bc2d458d": ["Y2h1bmtfMF9pbmRleF8xNTM5"], "0a76d75f-c8bb-4f8c-86e2-83da6afadc24": ["Y2h1bmtfMF9pbmRleF85OTE="], "60bb4f70-8705-4d39-a91c-170dc8c2134d": ["Y2h1bmtfMF9pbmRleF85OTE="], "864f18cd-916d-402c-8044-f0d6c04bbca7": ["Y2h1bmtfMV9pbmRleF85OTE="], "709f26dd-5cda-4c2d-b2f8-112fb74fc4ca": ["Y2h1bmtfMV9pbmRleF85OTE="], "0b2fe25c-920f-4dc1-bba0-b38e5e03be7e": ["Y2h1bmtfMl9pbmRleF85OTE="], "eef3a064-c0d0-43e7-8229-2d07aeed03cb": ["Y2h1bmtfMl9pbmRleF85OTE="], "37d75131-aebe-421d-876f-e03d86f59c21": ["Y2h1bmtfMF9pbmRleF84NjI="], "91d493d4-7c7e-4b43-86f1-03e107ae141d": ["Y2h1bmtfMF9pbmRleF84NjI="], "a4a12114-befb-424f-94e2-e3df400499d4": ["Y2h1bmtfMV9pbmRleF84NjI="], "d36ebf76-6de5-43b6-a279-e78cba1aef64": ["Y2h1bmtfMV9pbmRleF84NjI="], "aced45b2-0786-4876-bf68-020c0a1012a0": ["Y2h1bmtfMl9pbmRleF84NjI="], "c498178b-c5bd-4326-a19f-98f46fd3674f": ["Y2h1bmtfMl9pbmRleF84NjI="], "26109e2d-0462-4fc6-8a44-06f2f2536bbf": ["Y2h1bmtfM19pbmRleF84NjI="], "8cb17e24-e43c-4a65-97b7-65af1451b408": ["Y2h1bmtfNF9pbmRleF84NjI="], "a14b3ddd-bdf4-4eb0-9f1b-88b721eed3b4": ["Y2h1bmtfNF9pbmRleF84NjI="], "b0a9ae8f-91f4-483d-a809-80a6cd874ea8": ["Y2h1bmtfNF9pbmRleF84NjI="], "d23e2fed-3ddf-4539-b2c6-de77aec1b79d": ["Y2h1bmtfNF9pbmRleF84NjI="], "36be622c-4740-45c2-8ea8-31efa30e1918": ["Y2h1bmtfNF9pbmRleF84NjI="], "86b41ed7-863d-4ad5-8701-8c05a3922501": ["Y2h1bmtfNF9pbmRleF84NjI="], "29363f28-7b46-4c9d-94fc-7f2ed49c62fb": ["Y2h1bmtfNF9pbmRleF84NjI="], "bed1cd29-d0d6-47d7-8d11-7a497f01a1e3": ["Y2h1bmtfNF9pbmRleF84NjI="], "acd7eeb0-b53b-46c2-a2a1-efe573d8ac85": ["Y2h1bmtfNV9pbmRleF84NjI="], "b7aed02e-a97c-4058-ae59-8179f8600b6e": ["Y2h1bmtfNV9pbmRleF84NjI="], "c02ab2dd-eafd-421c-a357-dce59160f638": ["Y2h1bmtfNl9pbmRleF84NjI="], "4202c416-e2f5-44ad-911e-802e88dd0e6a": ["Y2h1bmtfN19pbmRleF84NjI="], "c44251c1-484d-4f64-8092-be45907b687a": ["Y2h1bmtfMF9pbmRleF8xNDg="], "c420555a-3b1c-4f35-b79c-ade68a49c0e1": ["Y2h1bmtfMF9pbmRleF8xNDg="], "f1d095e7-63f4-4ad6-ab5f-335ee0788151": ["Y2h1bmtfMF9pbmRleF80ODA="], "d2efa6d8-5f76-4ae2-8070-2387539306a2": ["Y2h1bmtfMF9pbmRleF80ODA="], "040ee689-5374-4b35-a6a8-794126ae49c9": ["Y2h1bmtfMF9pbmRleF81NjQ="], "3cc5d3fc-4cfd-4fa3-9750-203213081838": ["Y2h1bmtfMF9pbmRleF81NjQ="], "d18a47eb-c288-4d8a-b424-c7e046834ac9": ["Y2h1bmtfMV9pbmRleF81NjQ="], "7e4d824f-0945-4c1c-a87f-40c477f62c94": ["Y2h1bmtfMV9pbmRleF81NjQ="], "f65ee5b5-2ce1-4bd1-99e5-f9bb5191ae88": ["Y2h1bmtfMl9pbmRleF81NjQ="], "3727648e-7a75-42a2-b4a3-1d93a9147598": ["Y2h1bmtfMl9pbmRleF81NjQ="], "a8b2b8e4-0ade-4cb5-9089-ee774d8f15bf": ["Y2h1bmtfM19pbmRleF81NjQ="], "a859d85c-62e2-4f23-8d84-3ba6c665d43d": ["Y2h1bmtfM19pbmRleF81NjQ="], "8b248393-db20-41cc-a1ce-94f706805a46": ["Y2h1bmtfMF9pbmRleF8yMDg3"], "98e03823-49fa-4e88-9081-b29c1665a3c5": ["Y2h1bmtfMF9pbmRleF8yMDg3"], "917ea6f5-2f33-4a43-9f71-fe8c26987b93": ["Y2h1bmtfMF9pbmRleF8yMTk="], "b28a4f3f-3d87-4c17-bcee-f98cf8436273": ["Y2h1bmtfMF9pbmRleF8yMTk="], "b20603c1-095d-4538-a31b-c0d11bbbfe81": ["Y2h1bmtfMV9pbmRleF8yMTk="], "948dc324-696b-410f-af33-bfb66d00f6ed": ["Y2h1bmtfMV9pbmRleF8yMTk="], "70ce7759-872f-433b-ba38-475154f3fa79": ["Y2h1bmtfMF9pbmRleF8xMjk4"], "5c7ee48f-a2da-4dc3-a9eb-450bc7e22e3b": ["Y2h1bmtfMF9pbmRleF8xMjk4"], "1c5e8630-9806-4217-82eb-8b5dc8e4f733": ["Y2h1bmtfMF9pbmRleF8xNTM1"], "ac55a84a-34fa-4fbb-a544-df76a735f199": ["Y2h1bmtfMF9pbmRleF8xNTM1"], "8b427ccc-acbc-4ff0-9a82-955acae9ad5f": ["Y2h1bmtfMF9pbmRleF8zNTU="], "6b85eff5-6141-4120-a9ea-293b63ff6bae": ["Y2h1bmtfMF9pbmRleF8zNTU="], "792b82c0-fa7a-4d66-8f4d-b8bc4eaa1fbf": ["Y2h1bmtfMV9pbmRleF8zNTU="], "9d0e8c7b-635a-4bc7-8ff4-ed25cc0ff702": ["Y2h1bmtfMV9pbmRleF8zNTU="], "f335ab9d-7815-42a6-9e9c-f9829c5c9a50": ["Y2h1bmtfMV9pbmRleF8zNTU="], "0586ca11-4830-4b6c-a439-885d0c9f7fad": ["Y2h1bmtfMF9pbmRleF8xMTI3"], "89f93295-edef-4b2e-a5b9-c4f0e3aeb77b": ["Y2h1bmtfMF9pbmRleF8xMTI3"], "b88f1d98-8c8a-41d9-957b-96868b252ac2": ["Y2h1bmtfMF9pbmRleF8xMTI3"], "ab0aa9bc-2677-44d6-96a9-d64acc5c7ef7": ["Y2h1bmtfMF9pbmRleF8xMTI3"], "2f966b62-9830-4a9e-b0e2-a09919f5ce2e": ["Y2h1bmtfMV9pbmRleF8xMTI3"], "5f7fd615-1a33-4b19-87e2-9f7db8af9e15": ["Y2h1bmtfMV9pbmRleF8xMTI3"], "9f6c435b-b1ee-4a12-ab1e-09c6af8f6120": ["Y2h1bmtfMF9pbmRleF8yMDEx"], "31834693-9798-43a8-b446-6145b98a4efb": ["Y2h1bmtfMV9pbmRleF8yMDEx"], "8bf95dd6-4fb1-4f3a-b037-799d8efa3a11": ["Y2h1bmtfMl9pbmRleF8yMDEx"], "8ce88b8c-1ba5-4f99-acdc-6302235c4cbc": ["Y2h1bmtfM19pbmRleF8yMDEx"], "d8726915-9374-4c49-b213-7ac5eba1a701": ["Y2h1bmtfM19pbmRleF8yMDEx"], "1131236b-8086-404b-be47-3ad2d56b0415": ["Y2h1bmtfM19pbmRleF8yMDEx"], "ac675f1f-5dd4-4890-ae87-b960c194d198": ["Y2h1bmtfMF9pbmRleF82Njg="], "ca06f505-dd17-4a7a-83e0-6754df4706af": ["Y2h1bmtfMF9pbmRleF82MDE="], "a3657fca-126b-4b93-9c6a-6d62d2cc4f1d": ["Y2h1bmtfMF9pbmRleF82MDE="], "43b26e31-858a-408c-8836-a28176cf7d73": ["Y2h1bmtfMV9pbmRleF82MDE="], "d6ca69d4-6b9e-40fc-8524-a751f8278d4b": ["Y2h1bmtfMV9pbmRleF82MDE="], "777d73a9-4f51-4275-8119-b620c3af1e84": ["Y2h1bmtfMV9pbmRleF82MDE="], "df73a694-b026-483f-8e40-d82d19203570": ["Y2h1bmtfMV9pbmRleF82MDE="], "bf5941dc-4fa1-4fdd-948f-00503aa8c1c2": ["Y2h1bmtfMV9pbmRleF82MDE="], "2daffdf7-afad-4766-b6aa-fc3bd6e281f0": ["Y2h1bmtfMF9pbmRleF85MDU="], "ce7c7ede-684b-4e3a-bdf0-c95ff25a4dec": ["Y2h1bmtfMF9pbmRleF85MDU="], "e5842f14-99a2-496f-8324-589c32cf728e": ["Y2h1bmtfMV9pbmRleF85MDU="], "b86da3a8-9e17-4d49-ae6c-7a07e5e79c67": ["Y2h1bmtfMV9pbmRleF85MDU="], "52cdb6f0-742d-4084-ae11-3b8894abad50": ["Y2h1bmtfMl9pbmRleF85MDU="], "43800a1a-1e06-4f14-9355-2d9c8cfb174e": ["Y2h1bmtfMl9pbmRleF85MDU="], "c866a531-c4c9-491b-b8be-7154082be581": ["Y2h1bmtfMl9pbmRleF85MDU="], "22d1878b-b75c-4034-bd5b-4ab11faff35a": ["Y2h1bmtfMl9pbmRleF85MDU="], "0ead6e2a-ec12-41e4-a5aa-4a93f45f820e": ["Y2h1bmtfMl9pbmRleF85MDU="], "d7654429-3b9b-402e-a5ff-ffc2e004fa20": ["Y2h1bmtfMF9pbmRleF8xMzY2"], "c2856b24-3e32-4e0b-b55b-a8820f264387": ["Y2h1bmtfMF9pbmRleF8xMzY2"], "42270d21-bf98-4d8f-ae49-72d62db1577b": ["Y2h1bmtfMF9pbmRleF8xMzUw"], "f0d51942-9370-41af-b252-2400bd7dcc49": ["Y2h1bmtfMF9pbmRleF8xMzUw"], "39045994-5e11-4907-912b-182b97f5f4cb": ["Y2h1bmtfMV9pbmRleF8xMzUw"], "8892606b-3501-472a-8a50-8bcf75bc6162": ["Y2h1bmtfMV9pbmRleF8xMzUw"], "844ca970-ea7f-45a3-9655-dfa9e8cbd864": ["Y2h1bmtfMl9pbmRleF8xMzUw"], "d82bb7bb-5a86-4cce-8712-fda53c939d19": ["Y2h1bmtfMl9pbmRleF8xMzUw"], "582117a8-8500-480a-ad73-72f01e05333f": ["Y2h1bmtfM19pbmRleF8xMzUw"], "9bf74462-d8bc-46be-91a1-123e357c727d": ["Y2h1bmtfM19pbmRleF8xMzUw"], "07614ada-18a2-4ee7-8b46-7e398546c4ad": ["Y2h1bmtfNF9pbmRleF8xMzUw"], "52ea44e6-5bed-44fa-a5d1-879a64b4863a": ["Y2h1bmtfNF9pbmRleF8xMzUw"], "038460ff-084c-4716-896b-b6b01bd4d4f3": ["Y2h1bmtfNV9pbmRleF8xMzUw"], "4820c666-e2f1-4d7e-a46b-165ab94bc5e8": ["Y2h1bmtfNV9pbmRleF8xMzUw"], "b05b442d-014a-407a-ad98-0599ef4474c4": ["Y2h1bmtfMF9pbmRleF8xMzY4"], "a92f8e11-1c9c-4e5c-ad49-62181694465a": ["Y2h1bmtfMF9pbmRleF8xMzY4"], "54fc0423-b8e2-4d5c-93a0-97fbd5ccbdef": ["Y2h1bmtfMF9pbmRleF8xMTg="], "a5200a52-de67-4ead-86e4-2e149d011fbb": ["Y2h1bmtfMF9pbmRleF8xMTg="], "fe71f669-8d2d-4aeb-a60b-1835f701d950": ["Y2h1bmtfMV9pbmRleF8xMTg="], "2d9990ea-5d88-4c28-a0d8-787e52d393c1": ["Y2h1bmtfMV9pbmRleF8xMTg="], "7a152972-265f-4895-a02c-3f4da948f43e": ["Y2h1bmtfMl9pbmRleF8xMTg="], "a2e3ca56-c428-467b-9fba-91be0f5f2eb8": ["Y2h1bmtfMl9pbmRleF8xMTg="], "1019a4f7-44f7-4797-90d0-7baa016bea4c": ["Y2h1bmtfM19pbmRleF8xMTg="], "3f3d71d2-a0b6-4a1c-8134-6750d16ac11c": ["Y2h1bmtfM19pbmRleF8xMTg="], "eaaed510-f76e-4790-8b97-1034a7a52469": ["Y2h1bmtfNF9pbmRleF8xMTg="], "c66df3fa-195c-44e6-a527-318966043f66": ["Y2h1bmtfNF9pbmRleF8xMTg="], "8cf7b8ec-eb3e-472c-a627-cdc330e79e04": ["Y2h1bmtfNV9pbmRleF8xMTg="], "533843f9-0493-4eee-bdfa-2df9a84d9b02": ["Y2h1bmtfNV9pbmRleF8xMTg="], "2401e36b-5546-4adf-9108-466c45a5d193": ["Y2h1bmtfNl9pbmRleF8xMTg="], "c2663386-299d-40e4-bc0b-8d41f1da3ffd": ["Y2h1bmtfN19pbmRleF8xMTg="], "27704590-c8e1-44e4-8a32-198e5796fdf2": ["Y2h1bmtfN19pbmRleF8xMTg="], "17ea024c-220a-47f4-be95-709f833ca608": ["Y2h1bmtfMF9pbmRleF81NzI="], "796db530-332e-495c-946d-07674608fa5e": ["Y2h1bmtfMF9pbmRleF81NzI="], "4263fcff-f811-420f-87e7-28f4d4652146": ["Y2h1bmtfMV9pbmRleF81NzI="], "e99cc9f5-1399-407f-a9ab-b434b0ae07eb": ["Y2h1bmtfMV9pbmRleF81NzI="], "61b8375f-4168-4b94-acbd-5a84174d523b": ["Y2h1bmtfMF9pbmRleF8xNjky"], "73802430-b695-4f70-995b-8c98568f42e6": ["Y2h1bmtfMF9pbmRleF8xNjky"], "5f682257-b99e-47a9-8d10-bbaefeb59a1d": ["Y2h1bmtfMV9pbmRleF8xNjky"], "2ae51948-0c16-4110-9faf-a346daeede23": ["Y2h1bmtfMV9pbmRleF8xNjky"], "4aa9f2a9-a1b8-4594-8e13-fc5356711e0b": ["Y2h1bmtfMF9pbmRleF8xNDU="], "fcccdfa5-9a61-475f-8aad-484a98145650": ["Y2h1bmtfMF9pbmRleF8xNDU="], "cb361e75-3ec2-42ec-bf31-1f22ca4b8b91": ["Y2h1bmtfMF9pbmRleF8xMzY0"], "a69f83d3-d1bd-4c3e-9117-d29355ac1cb4": ["Y2h1bmtfMF9pbmRleF8xMzY0"], "deafe74b-3c79-4737-9709-fdc57afcc86b": ["Y2h1bmtfMV9pbmRleF8xMzY0"], "0bb92fa5-a18f-460d-9b7e-9bee4112c20f": ["Y2h1bmtfMV9pbmRleF8xMzY0"], "51eb2422-ad87-4fb2-a91d-e9118e76fb5d": ["Y2h1bmtfMV9pbmRleF8xMzY0"], "abd99f98-c58e-4fb8-82a7-67e94df8347b": ["Y2h1bmtfMl9pbmRleF8xMzY0"], "19f06f8c-4bc2-4f70-a30b-94a54203bc2b": ["Y2h1bmtfM19pbmRleF8xMzY0"], "5cbbbe6b-f2c6-4bbe-b87c-c4f0b3441fe8": ["Y2h1bmtfNF9pbmRleF8xMzY0"], "b0b24759-1ea7-4f9d-acad-87cf7a499e97": ["Y2h1bmtfNF9pbmRleF8xMzY0"], "63bdb88e-34a0-4935-a185-5c4fb256181b": ["Y2h1bmtfNF9pbmRleF8xMzY0"], "e3e8d934-890c-4805-9dfb-9cccd835ba2d": ["Y2h1bmtfMF9pbmRleF8xMzI="], "d521f326-46f9-460a-848d-74251440d4aa": ["Y2h1bmtfMV9pbmRleF8xMzI="], "593c11d7-21fa-433b-aa32-7c63780924fe": ["Y2h1bmtfMV9pbmRleF8xMzI="], "96474d02-6beb-47f9-86ee-5edd8d26b455": ["Y2h1bmtfMV9pbmRleF8xMzI="], "28950cc1-40fe-4f8f-8cd3-4f540e950354": ["Y2h1bmtfMV9pbmRleF8xMzI="], "2f3afb4e-03a6-4b20-90ca-2aba4111a3f8": ["Y2h1bmtfMV9pbmRleF8xMzI="], "4ee858de-ac17-437d-8db4-a38c0ef9c0a5": ["Y2h1bmtfMV9pbmRleF8xMzI="], "dfaaa875-44a2-4515-a64a-b974c7e57ede": ["Y2h1bmtfMV9pbmRleF8xMzI="], "bab4ffd9-7483-49ab-9640-f390910a51fd": ["Y2h1bmtfMl9pbmRleF8xMzI="], "5ad8a656-e97b-4eb5-bd8a-8601aced56dc": ["Y2h1bmtfM19pbmRleF8xMzI="], "23ce5db8-31e0-48b5-bff4-4447374205b0": ["Y2h1bmtfM19pbmRleF8xMzI="], "90313662-d201-401a-afd9-a2cce2bd42cd": ["Y2h1bmtfNF9pbmRleF8xMzI="], "201ad515-bdad-46e3-a54b-602ab3177212": ["Y2h1bmtfNV9pbmRleF8xMzI="], "95ea603a-93fd-4c48-88f0-cff58f79bd95": ["Y2h1bmtfNV9pbmRleF8xMzI="], "1f702823-349d-4ba4-9805-d3bdbc8ab629": ["Y2h1bmtfNl9pbmRleF8xMzI="], "1c08c128-60ff-4d8b-8407-f0ed10f287bd": ["Y2h1bmtfNl9pbmRleF8xMzI="], "ec42aab6-5af0-4bc2-86ac-0adb92cea866": ["Y2h1bmtfMF9pbmRleF8xMDk1"], "bc346d87-6f77-4c86-bed5-1f89f3887608": ["Y2h1bmtfMF9pbmRleF8xMDk1"], "d9b203b4-94d2-49de-a46f-0ce5d965df29": ["Y2h1bmtfMV9pbmRleF8xMDk1"], "95d36f02-f02c-4f1e-aa35-eeef68eac764": ["Y2h1bmtfMV9pbmRleF8xMDk1"], "7951d68e-730c-491e-bf1c-9e035e63dca6": ["Y2h1bmtfMl9pbmRleF8xMDk1"], "55520aef-1c88-4fa5-8858-73d499c523b0": ["Y2h1bmtfMl9pbmRleF8xMDk1"], "96c0f392-9024-4d82-b133-b70432d7a636": ["Y2h1bmtfM19pbmRleF8xMDk1"], "cb5f17bb-aa66-4a98-8c56-ab89defe66b9": ["Y2h1bmtfM19pbmRleF8xMDk1"], "10842e04-642c-40a5-95c5-f7da6319fd5d": ["Y2h1bmtfNF9pbmRleF8xMDk1"], "c2eac108-54f8-436c-b0a4-b5f15ead99d2": ["Y2h1bmtfNF9pbmRleF8xMDk1"], "b2e2a12f-f41f-40e2-adb6-276a4aef42e4": ["Y2h1bmtfMF9pbmRleF8xMTc3"], "593e1c73-2d56-470c-835e-47c78ef1f5e7": ["Y2h1bmtfMF9pbmRleF8xMTc3"], "ea820049-399d-45f7-afd4-4ece77573192": ["Y2h1bmtfMF9pbmRleF8xMTc3"], "ec1383f7-5a3d-45fc-a788-429b3b9887d4": ["Y2h1bmtfMF9pbmRleF8xMTc3"], "174e85fe-1fab-4525-bee8-2e375a5db245": ["Y2h1bmtfMF9pbmRleF8xMTc3"], "8b0624ee-15bb-4791-8c4f-0545741b0d12": ["Y2h1bmtfMF9pbmRleF8xMTc3"], "cd526454-3515-45cd-8b43-2ac14c95bac9": ["Y2h1bmtfMV9pbmRleF8xMTc3"], "c5872950-e353-4826-a0be-4e1cc1892ef6": ["Y2h1bmtfMV9pbmRleF8xMTc3"], "6561d74e-f8e6-4931-a066-b2f7eb21bc52": ["Y2h1bmtfMl9pbmRleF8xMTc3"], "adf770cc-d71b-4f0b-9caf-76afe151743a": ["Y2h1bmtfMl9pbmRleF8xMTc3"], "f90bde5f-cd03-42f5-a702-23eceea03f94": ["Y2h1bmtfMF9pbmRleF8xODc4"], "aa31c4cf-8c3b-4564-b2f7-e7020192a9bd": ["Y2h1bmtfMF9pbmRleF8xODc4"], "6076d719-a7e8-442f-ba23-d355d575656a": ["Y2h1bmtfMF9pbmRleF8xMjM1"], "a20227cb-565b-4af5-b956-6123f5dbe14a": ["Y2h1bmtfMF9pbmRleF8xMjM1"], "0670b053-201a-46cf-9b92-194f036f5072": ["Y2h1bmtfMV9pbmRleF8xMjM1"], "99da1b48-b0ff-4bba-b6f3-b4df7155ea8c": ["Y2h1bmtfMV9pbmRleF8xMjM1"], "15173e65-f304-4ca0-b119-e0eb63426032": ["Y2h1bmtfMl9pbmRleF8xMjM1"], "65397f82-f309-4b86-b926-a68f0cfb2cbd": ["Y2h1bmtfMl9pbmRleF8xMjM1"], "a73c1642-8589-4705-be1a-1de905a4c1d1": ["Y2h1bmtfMl9pbmRleF8xMjM1"], "bbf8e3d6-c6c9-454e-8c4b-53aaefb7aff2": ["Y2h1bmtfMl9pbmRleF8xMjM1"], "001d545d-d1c6-42a5-85c3-33721afe32b2": ["Y2h1bmtfMF9pbmRleF8xNTg="], "6c7b2f83-bb4e-4d73-9582-01c80bdbf26e": ["Y2h1bmtfMF9pbmRleF8xNTg="], "807e9914-5d93-42b3-9a05-b2b62c7e4035": ["Y2h1bmtfMV9pbmRleF8xNTg="], "9617eaeb-036d-4d92-9663-3ac9507de1e9": ["Y2h1bmtfMV9pbmRleF8xNTg="], "9330f5ae-222e-433f-b0b7-1009a739a1ea": ["Y2h1bmtfMV9pbmRleF8xNTg="], "04b08bda-dafb-4135-a791-2d4985a499fd": ["Y2h1bmtfMV9pbmRleF8xNTg="], "b88a1cd9-98e4-4a2a-9206-a4c4fcd050fa": ["Y2h1bmtfMV9pbmRleF8xNTg="], "01ddb4f6-c706-41e8-ba36-e36c7f710c97": ["Y2h1bmtfMl9pbmRleF8xNTg="], "b04a120c-c8d3-43eb-81fa-9793f62342a1": ["Y2h1bmtfMl9pbmRleF8xNTg="], "22af794c-6212-45b2-8e8c-8c556a0e8571": ["Y2h1bmtfM19pbmRleF8xNTg="], "63aa5f65-2844-4635-9511-1a93ee14730e": ["Y2h1bmtfNF9pbmRleF8xNTg="], "d0a98d43-0263-4c02-a968-4befc4d7b8b8": ["Y2h1bmtfNV9pbmRleF8xNTg="], "3cd0a0b2-991e-4c6d-b86e-95e057957440": ["Y2h1bmtfNl9pbmRleF8xNTg="], "9855e4bd-f8fd-48af-bc27-ac0dbed562f6": ["Y2h1bmtfN19pbmRleF8xNTg="], "0c445958-10ae-48d0-89fd-7b9e8f8c8bda": ["Y2h1bmtfOF9pbmRleF8xNTg="], "9f3a057e-7858-4e7b-98da-97abc95a7925": ["Y2h1bmtfOF9pbmRleF8xNTg="], "b1030199-f6b9-44b9-9691-57847aea2a69": ["Y2h1bmtfOF9pbmRleF8xNTg="], "2eadcd67-1d3e-480d-ad05-c8b72ed2a0ea": ["Y2h1bmtfOF9pbmRleF8xNTg="], "22e60fd6-66d0-4391-9042-c0985311a44d": ["Y2h1bmtfOF9pbmRleF8xNTg="], "a3958ff1-f00c-4553-a52c-6757298037f3": ["Y2h1bmtfOF9pbmRleF8xNTg="], "fe96e964-cf15-49f6-9acd-100be55fe323": ["Y2h1bmtfOF9pbmRleF8xNTg="], "c9ba5194-bea1-4234-a5ed-bea33870314d": ["Y2h1bmtfOV9pbmRleF8xNTg="], "32eadb99-f67f-47f1-a08c-6c901e6f3321": ["Y2h1bmtfOV9pbmRleF8xNTg="], "413d6297-6f93-4d98-9e70-b0453f04b695": ["Y2h1bmtfOV9pbmRleF8xNTg="], "02b18cb7-e161-43b1-9268-14727b2c69c9": ["Y2h1bmtfMF9pbmRleF8xNjc2"], "d8f11ad0-bebd-4fb3-afe5-8bcf95e41ab4": ["Y2h1bmtfMF9pbmRleF8xNjc2"], "a9dc8a79-a351-4144-999b-dffe2c3ab69a": ["Y2h1bmtfMF9pbmRleF8xMTQ="], "a8375d88-6611-4cd2-8f3d-2fe0c74d1a39": ["Y2h1bmtfMF9pbmRleF8xMTQ="], "d15a40cc-203c-4012-b949-c92d2b4813dc": ["Y2h1bmtfMV9pbmRleF8xMTQ="], "1e56a8f8-00f4-4e74-a6a2-7523c510ed82": ["Y2h1bmtfMV9pbmRleF8xMTQ="], "27027fd7-8c24-4a20-937f-f1297e834794": ["Y2h1bmtfMl9pbmRleF8xMTQ="], "f1bd69a5-315e-4392-a09b-2b24500a0945": ["Y2h1bmtfMl9pbmRleF8xMTQ="], "58b30295-5c8a-44b9-8778-ad9628718be9": ["Y2h1bmtfM19pbmRleF8xMTQ="], "cf1dcad1-60ae-4f2c-a571-8d99b9be1b14": ["Y2h1bmtfM19pbmRleF8xMTQ="], "b8ce91c7-3541-472c-89ea-08812edcfd31": ["Y2h1bmtfM19pbmRleF8xMTQ="], "aec46a47-b052-43a8-9adc-dd5d1f3369d4": ["Y2h1bmtfMF9pbmRleF81ODM="], "c57f2700-cf35-41ff-8cd4-4002d0ab44d4": ["Y2h1bmtfMF9pbmRleF81ODM="], "b2a202e0-7699-4214-b6bb-d35dee384221": ["Y2h1bmtfMV9pbmRleF81ODM="], "35e54337-0e5f-4668-939a-1fbc980d2c1c": ["Y2h1bmtfMV9pbmRleF81ODM="], "ff7d5831-b4be-4afb-b40d-24fccaea59f9": ["Y2h1bmtfMl9pbmRleF81ODM="], "11e802b6-a3b4-4156-b6e1-1fdef98ca2d2": ["Y2h1bmtfMl9pbmRleF81ODM="], "37a7f144-8edc-4633-925f-ad8432dd6e37": ["Y2h1bmtfM19pbmRleF81ODM="], "6433858a-131c-45ca-8052-9fa22af10d02": ["Y2h1bmtfM19pbmRleF81ODM="], "10c6174b-484b-4299-931e-353c594f7281": ["Y2h1bmtfMF9pbmRleF8xNTgz"], "5e05364e-8068-43a1-8862-4a2913cbaaa1": ["Y2h1bmtfMF9pbmRleF8xNTgz"], "6a24c4f1-9f96-4ae9-8b94-1cbcccab9aaa": ["Y2h1bmtfMV9pbmRleF8xNTgz"], "90578cb4-4d5e-487b-92ff-3cce9f93d491": ["Y2h1bmtfMl9pbmRleF8xNTgz"], "26a9b32b-299b-47d2-98f3-0c0df0d02af7": ["Y2h1bmtfMl9pbmRleF8xNTgz"], "ef9baf5e-31fc-4b26-8f09-c79d4ad45ca9": ["Y2h1bmtfMl9pbmRleF8xNTgz"], "ffa4d43b-1b4b-4640-944c-ebd2e6edf94b": ["Y2h1bmtfMF9pbmRleF82OQ=="], "e3265f97-27a0-43be-a8cb-08eca0201c8a": ["Y2h1bmtfMF9pbmRleF82OQ=="], "863e7102-d5fc-4910-be1d-2819777a35c0": ["Y2h1bmtfMV9pbmRleF82OQ=="], "94ec2434-2611-47e3-ae57-d17f2f0a76c5": ["Y2h1bmtfMV9pbmRleF82OQ=="], "362a9aed-de4d-44e7-bb77-24e9500aef96": ["Y2h1bmtfMV9pbmRleF82OQ=="], "0d00c9ea-c8ca-47a2-8043-4d6b8a86c50a": ["Y2h1bmtfMV9pbmRleF82OQ=="], "57fed8ea-51cf-40b5-b797-8501359f2703": ["Y2h1bmtfMl9pbmRleF82OQ=="], "1d710860-28c4-474d-900b-72b61aca3d81": ["Y2h1bmtfMl9pbmRleF82OQ=="], "8aa66ee4-247a-489c-bea8-59513c12c855": ["Y2h1bmtfMF9pbmRleF8xMTc0"], "415ee330-428d-42b4-8cf0-9aa3620be016": ["Y2h1bmtfMF9pbmRleF8xMTc0"], "ea1e52e3-1eba-4058-a8e7-72f049cf4082": ["Y2h1bmtfMV9pbmRleF8xMTc0"], "0447cb19-d723-49fb-af03-c7e9359e82ad": ["Y2h1bmtfMV9pbmRleF8xMTc0"], "9e4e8a1e-e8c3-4a6b-9dbd-aa51b64e8fc9": ["Y2h1bmtfMF9pbmRleF80MTg="], "bbdacffd-85e0-4b15-8ffe-3ac45168823d": ["Y2h1bmtfMF9pbmRleF80MTg="], "1e7be44a-cb80-4381-a874-47c02582103c": ["Y2h1bmtfMV9pbmRleF80MTg="], "a7284814-5ac3-4e39-a773-93560b7d9a51": ["Y2h1bmtfMV9pbmRleF80MTg="], "3173c3fa-910f-4f69-b4d6-ec5ea63a0bfe": ["Y2h1bmtfMV9pbmRleF80MTg="], "70237611-87bf-42ee-8b78-0b0b98f126b4": ["Y2h1bmtfMV9pbmRleF80MTg="], "a91cae67-574b-4bc1-b711-6b7071baf860": ["Y2h1bmtfMV9pbmRleF80MTg="], "2b462281-0cf5-4408-81bc-650a4e6c592f": ["Y2h1bmtfMV9pbmRleF80MTg="], "c283439e-8543-4810-819a-4c7467b635a2": ["Y2h1bmtfMV9pbmRleF80MTg="], "78674217-fb80-482a-8966-7ef98d3f09d0": ["Y2h1bmtfMl9pbmRleF80MTg="], "923b3c57-ca43-4015-923c-3d923ccdce0a": ["Y2h1bmtfMl9pbmRleF80MTg="], "133ccae1-8adf-4bf9-ba0f-ddb07f542485": ["Y2h1bmtfMl9pbmRleF80MTg="], "8e6428da-3c74-4b88-99f0-70feb25ff366": ["Y2h1bmtfMl9pbmRleF80MTg="], "8b2d5201-b96f-40de-b1f5-93ba79f80271": ["Y2h1bmtfMl9pbmRleF80MTg="], "a2461224-0634-46ba-9e1e-23d833a6e068": ["Y2h1bmtfMl9pbmRleF80MTg="], "6fc412d0-6089-440f-a9b0-2255e79b6621": ["Y2h1bmtfMl9pbmRleF80MTg="], "61fa1f2f-a796-44cb-b679-4cb93764e9d5": ["Y2h1bmtfMl9pbmRleF80MTg="], "16916a52-cc0d-41d7-b8f3-fe558d015cb8": ["Y2h1bmtfMF9pbmRleF8xNTg4"], "1f5a1357-7e79-4874-93b0-bccf991fe4f8": ["Y2h1bmtfMF9pbmRleF8xNTg4"], "f7713dea-10a0-43ed-90af-53fa62fdbd53": ["Y2h1bmtfMV9pbmRleF8xNTg4"], "44511db8-af8b-4f68-9694-41267b42ca2f": ["Y2h1bmtfMV9pbmRleF8xNTg4"], "ee62e68d-a10b-4692-bdaf-323cb5ff12a1": ["Y2h1bmtfMF9pbmRleF8xNjI2"], "0ad849c7-9230-4878-aae6-393a2b11aeac": ["Y2h1bmtfMF9pbmRleF8xNjI2"], "3cc0fc88-cf71-428d-b82c-ca8487875e54": ["Y2h1bmtfMF9pbmRleF85ODA="], "3487ee5e-75f0-4542-9347-13b319783fa5": ["Y2h1bmtfMF9pbmRleF85ODA="], "a536abd5-b79d-4291-b11a-9aa88cfb8687": ["Y2h1bmtfMV9pbmRleF85ODA="], "ce3878fc-de31-4b07-afa4-7d0e0964574f": ["Y2h1bmtfMV9pbmRleF85ODA="], "14939998-bf86-464d-b893-81d722e520c5": ["Y2h1bmtfMV9pbmRleF85ODA="], "ae68ea0b-99ad-4a23-b382-b3fe8ad84213": ["Y2h1bmtfMV9pbmRleF85ODA="], "0f86ea2e-94ec-48b5-9509-2ef7455b31ad": ["Y2h1bmtfMV9pbmRleF85ODA="], "04406350-bbf3-4532-b35c-990e6e36010e": ["Y2h1bmtfMV9pbmRleF85ODA="], "791540e6-6359-4316-9972-da27be83510f": ["Y2h1bmtfMV9pbmRleF85ODA="], "644f12e2-d612-45cb-84c2-33f5492c44a3": ["Y2h1bmtfMV9pbmRleF85ODA="], "50567580-2920-435c-ace6-4876193fe01e": ["Y2h1bmtfMl9pbmRleF85ODA="], "f95e3004-1f4d-46aa-b96c-4251b0636222": ["Y2h1bmtfMl9pbmRleF85ODA="], "97b1c54a-b3db-44f4-92d4-038d7f4b1578": ["Y2h1bmtfMl9pbmRleF85ODA="], "8a53278f-2557-4d22-a194-4650543624ac": ["Y2h1bmtfMl9pbmRleF85ODA="], "fc691ec0-978d-48a1-ae2a-79102b3cb47a": ["Y2h1bmtfMl9pbmRleF85ODA="], "c9c03711-eba7-4960-88b0-ec8fa7a81d1c": ["Y2h1bmtfMl9pbmRleF85ODA="], "06f227c6-34d3-4bd1-8f04-4f30ab8a8673": ["Y2h1bmtfMl9pbmRleF85ODA="], "02429300-5ccd-4df2-90f0-f4d71e8a34e7": ["Y2h1bmtfMl9pbmRleF85ODA="], "46a7b513-90e7-4667-88d9-85e66193cab7": ["Y2h1bmtfMl9pbmRleF85ODA="], "930a5b2b-380b-4aea-bd68-50fb9ac8a1f7": ["Y2h1bmtfM19pbmRleF85ODA="], "29833b49-fae1-4c13-a2c2-8dd22fd2a2f1": ["Y2h1bmtfNF9pbmRleF85ODA="], "5c97e7da-0c17-4fce-bb06-d754b81044e7": ["Y2h1bmtfNF9pbmRleF85ODA="], "b45e0315-13ab-4d27-aef4-988448bc60fa": ["Y2h1bmtfMF9pbmRleF82ODM="], "bb29c5b7-eb92-4f7d-9290-91535c64625e": ["Y2h1bmtfMF9pbmRleF82ODM="], "99aa7aa7-a54a-4d6f-8fe4-c2d76b85b168": ["Y2h1bmtfMV9pbmRleF82ODM="], "ba29c62b-7f0b-4048-89a1-79be5331b415": ["Y2h1bmtfMV9pbmRleF82ODM="], "dd45dfee-e374-4226-afdf-9b6f6dc417aa": ["Y2h1bmtfMl9pbmRleF82ODM="], "f3366d8a-66ba-49c5-9ca6-8db99c9edfdf": ["Y2h1bmtfMl9pbmRleF82ODM="], "1691d4a4-08b3-4218-a806-16a473cc8298": ["Y2h1bmtfMF9pbmRleF8xODUw"], "b7c0e6c5-6ffd-436c-aea3-4e23930be3de": ["Y2h1bmtfMF9pbmRleF8xODUw"], "04d2ed3f-a736-4f12-95a3-97b307d18df9": ["Y2h1bmtfMF9pbmRleF81NTc="], "ea8097ab-5a6c-4ee3-b0cf-2a503cb49bd0": ["Y2h1bmtfMF9pbmRleF81NTc="], "b69205fb-c265-48aa-aa5d-a01406feeeac": ["Y2h1bmtfMF9pbmRleF81NTc="], "a818281b-1324-4c91-a58a-3fca197ef404": ["Y2h1bmtfMF9pbmRleF81NTc="], "ceadf5e3-7063-4109-acdd-f703f5a511c2": ["Y2h1bmtfMF9pbmRleF81NTc="], "bdb0b5bd-ca72-4126-9379-5b4d6b4d9ddf": ["Y2h1bmtfMF9pbmRleF81NTc="], "0154a537-140b-4e61-a8f2-a8a8517d8e84": ["Y2h1bmtfMF9pbmRleF81NTc="], "7a9e6f3f-0522-4774-91fd-ade9308105bd": ["Y2h1bmtfMV9pbmRleF81NTc="], "1451d359-14ac-4b9a-8454-e358a9ec8289": ["Y2h1bmtfMV9pbmRleF81NTc="], "42b4c6bd-ca66-4a17-b070-f64e20d48715": ["Y2h1bmtfMF9pbmRleF8xNDE1"], "7a4f9dd2-06af-4626-8acc-cc8652d2aa93": ["Y2h1bmtfMF9pbmRleF8xNDE1"], "03fd6384-4bec-4e2a-8fac-1c22fb83e98c": ["Y2h1bmtfMF9pbmRleF82MjQ="], "b65d63d9-9e04-42cf-85bf-9a2c97d87bbb": ["Y2h1bmtfMF9pbmRleF82MjQ="], "3af2dc60-9a90-4f1d-b5d0-65800819756b": ["Y2h1bmtfMF9pbmRleF8xOTEx"], "ef6b5cfe-3678-4f00-b1a7-3e046b559eff": ["Y2h1bmtfMF9pbmRleF8xOTEx"], "d3332a8d-d06a-46bd-89eb-1ba20fb9472c": ["Y2h1bmtfMF9pbmRleF8xOTEx"], "fdc5209e-422d-419d-aaca-06326f4da501": ["Y2h1bmtfMF9pbmRleF8xOTEx"], "080c6778-39a8-405f-bc11-c813a80d88fb": ["Y2h1bmtfMF9pbmRleF8xOTEx"], "9bc60d31-17b1-4038-9175-cefdec33cd84": ["Y2h1bmtfMV9pbmRleF8xOTEx"], "a080725e-2196-469d-94d0-781637568db0": ["Y2h1bmtfMl9pbmRleF8xOTEx"], "4c131cb7-bc1e-4650-a812-780c8719fd67": ["Y2h1bmtfMl9pbmRleF8xOTEx"], "a361dffb-bcbf-42e8-90bc-ae7e9769e12e": ["Y2h1bmtfM19pbmRleF8xOTEx"], "1da76692-a17a-4165-9370-a4ee9fdd1eaa": ["Y2h1bmtfNF9pbmRleF8xOTEx"], "72cce2e8-a278-4238-bf5d-3044cb35aca3": ["Y2h1bmtfNV9pbmRleF8xOTEx"], "26d37c79-74f2-4d09-a643-f0556799cebd": ["Y2h1bmtfNl9pbmRleF8xOTEx"], "31b83e16-4344-48ee-a5c1-c3711ef1f851": ["Y2h1bmtfNl9pbmRleF8xOTEx"], "c6f2afd3-9881-4311-9bf8-f40ce3a61032": ["Y2h1bmtfN19pbmRleF8xOTEx"], "4e6181e1-15a7-4005-bdaf-3a7020d16bff": ["Y2h1bmtfN19pbmRleF8xOTEx"], "0469e46f-e191-41b7-bf89-c6950a31be7e": ["Y2h1bmtfOF9pbmRleF8xOTEx"], "fdc86dcb-53d5-4556-95c8-8911a0fb2793": ["Y2h1bmtfOF9pbmRleF8xOTEx"], "a9bf64cd-46df-45ed-b860-85c5c0467a19": ["Y2h1bmtfMF9pbmRleF8xMDU2"], "55d7f114-e5fe-4186-953c-09e90424aa48": ["Y2h1bmtfMF9pbmRleF8xMDU2"], "97112fca-1bfb-440c-93cd-2ffcce8751c3": ["Y2h1bmtfMF9pbmRleF8yMzQ="], "f25d679f-6a3d-4ce3-b568-ab7018d77594": ["Y2h1bmtfMF9pbmRleF8yMzQ="], "c671938b-f272-4967-a635-c8603221bee0": ["Y2h1bmtfMV9pbmRleF8yMzQ="], "a503f2d9-1fd9-4c8c-aec7-d47810980843": ["Y2h1bmtfMV9pbmRleF8yMzQ="], "c3e98c98-2994-47ae-8853-739888e7c897": ["Y2h1bmtfMl9pbmRleF8yMzQ="], "9971daf4-dad3-483f-80ea-6452ccf2353c": ["Y2h1bmtfMl9pbmRleF8yMzQ="], "349a815d-53ba-4ba9-af23-dfcba877a981": ["Y2h1bmtfMl9pbmRleF8yMzQ="], "1c336a9b-db10-4d23-b4c2-df8abdc9b44b": ["Y2h1bmtfMl9pbmRleF8yMzQ="], "24368c21-e366-489e-b1c9-e77beb03f882": ["Y2h1bmtfMl9pbmRleF8yMzQ="], "32b7c43c-0464-4282-ba39-c3c4ec642afd": ["Y2h1bmtfM19pbmRleF8yMzQ="], "6f740393-82c0-4e41-af27-cee107f2e9c2": ["Y2h1bmtfM19pbmRleF8yMzQ="], "5d91ffc3-986d-4a8a-9f07-29ded7998abe": ["Y2h1bmtfNF9pbmRleF8yMzQ="], "5d23ed50-10e7-4101-8743-156e733dabc4": ["Y2h1bmtfNF9pbmRleF8yMzQ="], "80d47587-7df5-4763-b197-93714e7c7797": ["Y2h1bmtfNV9pbmRleF8yMzQ="], "1dd14d77-12ad-4b82-9828-3108c0f4cef1": ["Y2h1bmtfNV9pbmRleF8yMzQ="], "a4f31bf5-c854-4142-9b3d-3871165c7e90": ["Y2h1bmtfNl9pbmRleF8yMzQ="], "150a0020-8aa4-4cd8-987c-e14704366949": ["Y2h1bmtfNl9pbmRleF8yMzQ="], "ad499874-001d-43c9-bb35-05f34aafdd0e": ["Y2h1bmtfNl9pbmRleF8yMzQ="], "45cc8c49-2352-46b0-bb18-a3ec24fbee52": ["Y2h1bmtfNl9pbmRleF8yMzQ="], "42190ce8-f9fc-41bd-992e-10946fd22bb3": ["Y2h1bmtfNl9pbmRleF8yMzQ="], "06828ccb-fd44-436b-acbd-d2111fb49a36": ["Y2h1bmtfN19pbmRleF8yMzQ="], "09126eff-d8c2-4d18-9c7a-8b31f68e2f8d": ["Y2h1bmtfN19pbmRleF8yMzQ="], "793dd3a0-e833-4493-b5a2-da57c961ddfc": ["Y2h1bmtfMF9pbmRleF8xMjA3"], "8bfa311c-1b18-4bef-a4d5-98de1f4c2421": ["Y2h1bmtfMF9pbmRleF8xMjA3"], "dd540c0a-fc47-49ea-969c-82415f31e01a": ["Y2h1bmtfMF9pbmRleF8xMjA3"], "e7180ebe-029d-40e3-bb25-6c9f6410b915": ["Y2h1bmtfMF9pbmRleF8xMjA3"], "0d184d12-5494-46b8-8dad-2a4f6b56dca2": ["Y2h1bmtfMF9pbmRleF8xMjA3"], "ccd40ee5-851b-4043-8b52-b9a62abc4470": ["Y2h1bmtfMV9pbmRleF8xMjA3"], "bbeb8c38-b761-4ca9-9e39-e225d8e33172": ["Y2h1bmtfMV9pbmRleF8xMjA3"], "8682b8a8-3515-4b8f-86f0-969c75b605ea": ["Y2h1bmtfMF9pbmRleF8yMDY2"], "86c4b7c4-ea7c-4b96-9fb9-896ce73d0ce5": ["Y2h1bmtfMF9pbmRleF8yMDY2"], "289e60c2-2659-4e0a-bb1f-10958c5fd0a4": ["Y2h1bmtfMF9pbmRleF81MDM="], "d9889af5-d854-471c-93ee-320794a809e7": ["Y2h1bmtfMF9pbmRleF81MDM="], "eff58df1-fb58-4c90-82e4-540455f528db": ["Y2h1bmtfMF9pbmRleF8xODc3"], "e373967c-d04a-4f0a-9a35-38dc77184584": ["Y2h1bmtfMF9pbmRleF8xODc3"], "78879181-03b8-4b25-87d2-793d995dc242": ["Y2h1bmtfMF9pbmRleF8xOTk2"], "2685d026-9192-4491-94be-1ab9cdd0a7be": ["Y2h1bmtfMF9pbmRleF8xOTk2"], "6931c156-027a-4e59-9072-d9da82522302": ["Y2h1bmtfMV9pbmRleF8xOTk2"], "2da86c7e-fac5-4652-9602-e4029ce111c3": ["Y2h1bmtfMl9pbmRleF8xOTk2"], "b8b16141-a38b-454b-ab9c-65484dcb087f": ["Y2h1bmtfMl9pbmRleF8xOTk2"], "cfe2a586-4f56-462c-a69c-53b30d56a413": ["Y2h1bmtfM19pbmRleF8xOTk2"], "f8da1311-2c7f-4a30-8167-16d0ce1ce9a9": ["Y2h1bmtfM19pbmRleF8xOTk2"], "b843dc99-c3c7-42e3-b576-0d8dc9bac128": ["Y2h1bmtfNF9pbmRleF8xOTk2"], "2e2658c1-11fc-4997-99d4-9c685138d78f": ["Y2h1bmtfNF9pbmRleF8xOTk2"], "b483d78c-7bb3-41a9-86b8-566b4a224b94": ["Y2h1bmtfNF9pbmRleF8xOTk2"], "1150f824-229c-40dd-adf5-5871c570f39d": ["Y2h1bmtfMF9pbmRleF8zMjA="], "87bd8fed-33c6-4dea-8e8c-37b27e906d72": ["Y2h1bmtfMF9pbmRleF8zMjA="], "7f58e4be-01f2-4908-a865-5c2e2e88ca1b": ["Y2h1bmtfMV9pbmRleF8zMjA="], "1efcafa6-ab63-469b-866c-91202940777e": ["Y2h1bmtfMV9pbmRleF8zMjA="], "97f2ccbe-1d5d-40ca-b934-e3c61af8b055": ["Y2h1bmtfMl9pbmRleF8zMjA="], "436f5452-d4bc-48f1-9e18-3d7cadf4ddf3": ["Y2h1bmtfMl9pbmRleF8zMjA="], "da5047ab-0759-4bd9-b5a5-7f6a3f7bcfc8": ["Y2h1bmtfM19pbmRleF8zMjA="], "b642d8fc-aa6e-4cfe-b114-bb309073ee01": ["Y2h1bmtfM19pbmRleF8zMjA="], "8ac09407-a5ac-444c-a35a-3017cc4776e4": ["Y2h1bmtfMF9pbmRleF8xODIx"], "d8af8e61-b9aa-4520-a400-f5b57198daa6": ["Y2h1bmtfMF9pbmRleF8xODIx"], "557e274f-1934-41cd-b6d9-6a54f65215f9": ["Y2h1bmtfMF9pbmRleF8xMzM1"], "c9e6866f-cacb-4f0c-9a38-9c786589f913": ["Y2h1bmtfMF9pbmRleF8xMzM1"], "83aca1c7-6624-4d72-a1db-f37b24104073": ["Y2h1bmtfMF9pbmRleF80NA=="], "316a8a4d-068e-4d76-b173-cbbcebf4736b": ["Y2h1bmtfMF9pbmRleF80NA=="], "252e5b1c-b410-4959-9d93-133583154488": ["Y2h1bmtfMF9pbmRleF84MDQ="], "0f9cf5d7-0bd6-45f2-a19f-db4221a03dbc": ["Y2h1bmtfMF9pbmRleF84MDQ="], "33c3252d-6f97-4a07-901b-4ccee2be3dfc": ["Y2h1bmtfMV9pbmRleF84MDQ="], "fd71c559-14c2-4918-aa36-180c4f856629": ["Y2h1bmtfMV9pbmRleF84MDQ="], "fe608a24-5c81-434c-acfe-8d1936b56850": ["Y2h1bmtfMF9pbmRleF80MjU="], "d68bcdc8-f3e6-4acd-83c6-9a5e276c01b4": ["Y2h1bmtfMF9pbmRleF80MjU="], "d8f15ead-747c-42b2-8981-5fb552e5db89": ["Y2h1bmtfMF9pbmRleF8xMjIy"], "35a930ae-e535-4e1f-a94e-d42c7a431d29": ["Y2h1bmtfMF9pbmRleF8xMjIy"], "31337c00-bcdf-4d77-81d8-3170ecd2ce92": ["Y2h1bmtfMF9pbmRleF8xODY2"], "a065ce90-b591-4e29-a3e6-d3f3f8bc637b": ["Y2h1bmtfMF9pbmRleF8xODY2"], "079122c7-3960-4149-a706-12e214889224": ["Y2h1bmtfMF9pbmRleF8xNTE1"], "82033873-4b78-448a-b5b6-5d384613ea59": ["Y2h1bmtfMF9pbmRleF8xNTE1"], "9d314cbe-5af3-4196-8fca-16ac1d4cb5bb": ["Y2h1bmtfMV9pbmRleF8xNTE1"], "17d7715b-9f5b-4c4f-a86c-89bcf645fce4": ["Y2h1bmtfMV9pbmRleF8xNTE1"], "7084b9b0-e4c9-43e8-bbd4-4a5766112d9e": ["Y2h1bmtfMV9pbmRleF8xNTE1"], "8b616885-d2f6-416e-b713-220501180560": ["Y2h1bmtfMF9pbmRleF84"], "01d3870a-96f0-4fec-85b0-d4400a2e5179": ["Y2h1bmtfMF9pbmRleF84"], "325b1dd7-60c5-45be-9778-c59ea4594f86": ["Y2h1bmtfMF9pbmRleF8xMTU1"], "3c64e961-3894-4e9f-882c-733643872a42": ["Y2h1bmtfMF9pbmRleF8xMTU1"], "ebbb6ffe-7638-41a9-a7f0-4f7061bf30dc": ["Y2h1bmtfMF9pbmRleF8yODc="], "07c7028e-c1a5-43f8-b44f-50f77e18fdb5": ["Y2h1bmtfMF9pbmRleF8yODc="], "66f724d8-3a92-4f05-b81c-a7de7b061202": ["Y2h1bmtfMF9pbmRleF82MzY="], "b90fba54-2131-4acc-a3eb-1f3afc7e631e": ["Y2h1bmtfMF9pbmRleF8yNTc="], "602fc3a6-6c56-40c3-a0fa-a5a7333a0140": ["Y2h1bmtfMF9pbmRleF8yNTc="], "408c2dfe-6021-4256-9ca1-20f31ad15bc5": ["Y2h1bmtfMF9pbmRleF83MTI="], "aa17f5de-2931-4d8f-9811-ba7014fbee5e": ["Y2h1bmtfMF9pbmRleF83MTI="], "78cf1772-3a4c-44a2-b57f-588bb20d0ce3": ["Y2h1bmtfMF9pbmRleF8xMTk0"], "fa6fd437-d097-45d7-a062-d043e636a91c": ["Y2h1bmtfMF9pbmRleF8xMTk0"], "a96f7214-b5fb-4652-9360-b434f27d4403": ["Y2h1bmtfMV9pbmRleF8xMTk0"], "aaa2ae7d-b43a-4dd9-8db7-6bd3b3332848": ["Y2h1bmtfMl9pbmRleF8xMTk0"], "94e6fe7d-034a-4f6e-8503-1679e65572c3": ["Y2h1bmtfMl9pbmRleF8xMTk0"], "a7d18eb5-e811-4434-817d-3bae372a27db": ["Y2h1bmtfMF9pbmRleF8xMjQw"], "7dfe9bae-b38e-4784-9ee4-ec0ccbada7db": ["Y2h1bmtfMF9pbmRleF8xMjQw"], "8acc0ec4-4fb9-40eb-a508-e05101576d62": ["Y2h1bmtfMF9pbmRleF8xMjQw"], "cdb245b4-3dcb-4951-a228-e2fd6b17cafa": ["Y2h1bmtfMV9pbmRleF8xMjQw"], "65f05647-fd56-4b25-bf66-a559d6e5a115": ["Y2h1bmtfMV9pbmRleF8xMjQw"], "b81a7703-90d3-4013-97b1-d18c65d91d04": ["Y2h1bmtfMV9pbmRleF8xMjQw"], "52290503-7f7f-4f0b-96ab-e1c6baab2a6e": ["Y2h1bmtfMV9pbmRleF8xMjQw"], "8691dd02-c7c6-4906-971f-68e7d06509c5": ["Y2h1bmtfMV9pbmRleF8xMjQw"], "a75a5b22-77c8-42d7-ad78-b42ab58ac4f9": ["Y2h1bmtfMV9pbmRleF8xMjQw"], "5fb898e0-4e6c-454d-b1c8-38eff8559e80": ["Y2h1bmtfMV9pbmRleF8xMjQw"], "bbee1a8a-6f43-4d83-aa88-e70b71ad145d": ["Y2h1bmtfMV9pbmRleF8xMjQw"], "33ad1058-04b7-4af3-bd4c-3250da3b08cd": ["Y2h1bmtfMV9pbmRleF8xMjQw"], "abf76953-1fda-4fce-be71-6719a8299687": ["Y2h1bmtfMF9pbmRleF84NTI="], "47ed8b80-91b9-48b7-bfda-fb5edbb1a634": ["Y2h1bmtfMF9pbmRleF84NTI="], "aa3a0ccd-60b0-43de-bfad-d259be077f66": ["Y2h1bmtfMF9pbmRleF84NTQ="], "4377cb3c-e6ae-478a-9d49-d11e88618b11": ["Y2h1bmtfMF9pbmRleF84NTQ="], "c61472c7-3c31-44e4-9881-d763b471876a": ["Y2h1bmtfMV9pbmRleF84NTQ="], "61340cee-6f00-46d7-8ebf-6b80efc41c9f": ["Y2h1bmtfMV9pbmRleF84NTQ="], "6633224a-e502-44b2-9ef1-a99715b0eb8f": ["Y2h1bmtfMV9pbmRleF84NTQ="], "3825f8fd-64c2-437c-ab36-04301cba7fff": ["Y2h1bmtfMV9pbmRleF84NTQ="], "c6f12f7d-f8ef-416d-8279-d724487d4790": ["Y2h1bmtfMV9pbmRleF84NTQ="], "1c92d6bf-c10f-447e-827c-77cdab76a0b4": ["Y2h1bmtfMV9pbmRleF84NTQ="], "b2931886-4e88-47b8-892f-1c2979de08cf": ["Y2h1bmtfMV9pbmRleF84NTQ="], "f2b839e7-5782-4524-9697-6c02c50b9f51": ["Y2h1bmtfMl9pbmRleF84NTQ="], "517491d1-c5d6-482b-96a3-4aa4faf72ebe": ["Y2h1bmtfMl9pbmRleF84NTQ="], "c60317f6-f45b-4de8-85f6-fea43c77abe4": ["Y2h1bmtfMl9pbmRleF84NTQ="], "4ec5c17a-3524-43f4-b19b-c150bdaa2624": ["Y2h1bmtfMl9pbmRleF84NTQ="], "3f154120-ee39-46c2-85f6-315b22fe0fcf": ["Y2h1bmtfM19pbmRleF84NTQ="], "69d1a9f5-5fe0-4a61-8aad-d90632af91e0": ["Y2h1bmtfM19pbmRleF84NTQ="], "58bc97df-f592-4796-a955-2c4556812f1b": ["Y2h1bmtfM19pbmRleF84NTQ="], "68401b46-c0c0-4129-8bee-23103d6a5e6e": ["Y2h1bmtfM19pbmRleF84NTQ="], "cfa8c520-284a-4cf6-909e-55f665e6ab05": ["Y2h1bmtfNF9pbmRleF84NTQ="], "f99e01c5-da35-4c16-9ec4-c25209d7b502": ["Y2h1bmtfNF9pbmRleF84NTQ="], "06cb404b-e591-4d98-a21a-0bf95de4204d": ["Y2h1bmtfNF9pbmRleF84NTQ="], "c9836a9c-a497-4caa-b676-608331eb3684": ["Y2h1bmtfNV9pbmRleF84NTQ="], "f41060dd-a1c8-41ed-9e74-2fd0b8af3684": ["Y2h1bmtfNV9pbmRleF84NTQ="], "0964ff38-e013-4083-ab9c-590cc2c8b690": ["Y2h1bmtfNl9pbmRleF84NTQ="], "5cfc425e-b8f7-4755-a6dd-7ce2a9fb29db": ["Y2h1bmtfNl9pbmRleF84NTQ="], "40b4a14c-1211-4590-b532-eae1e09717ba": ["Y2h1bmtfN19pbmRleF84NTQ="], "8f659725-1008-4cd8-b32b-d9852987b0af": ["Y2h1bmtfOF9pbmRleF84NTQ="], "611d869a-78bb-4cf4-beb2-4cf8bf70fb56": ["Y2h1bmtfOF9pbmRleF84NTQ="], "3403c335-3a41-466f-8e2b-927957b45906": ["Y2h1bmtfOV9pbmRleF84NTQ="], "84b75c9e-2b1c-4c4f-9336-b991fa81f9cb": ["Y2h1bmtfOV9pbmRleF84NTQ="], "855fa5d0-c1bf-4bb6-bd82-e0b49d211e5c": ["Y2h1bmtfMF9pbmRleF8yMDI4"], "ca28151b-f5d6-430c-98af-24817c82547a": ["Y2h1bmtfMF9pbmRleF8yMDI4"], "e3b832b2-868e-48c6-83a3-3db31e0ae43a": ["Y2h1bmtfMF9pbmRleF8zOTQ="], "e1b4de05-f472-42a7-9626-786dc2d69945": ["Y2h1bmtfMF9pbmRleF8zOTQ="], "ed41709e-30f5-4728-945a-caa1bd2be6c8": ["Y2h1bmtfMF9pbmRleF8xMDk2"], "689e5af8-8899-440b-a82a-22a6dc745e92": ["Y2h1bmtfMF9pbmRleF8xMDk2"], "f351a475-3798-4534-853b-3f93f7eda7e6": ["Y2h1bmtfMF9pbmRleF8xNTMz"], "45f36622-95a6-48b2-bc4d-71161ae3ea6e": ["Y2h1bmtfMF9pbmRleF8xNTMz"], "1f50031a-c424-4a3a-bbc8-49bcabbc2e60": ["Y2h1bmtfMV9pbmRleF8xNTMz"], "5251e99a-0afb-4dd4-9c1e-5137bebb7def": ["Y2h1bmtfMV9pbmRleF8xNTMz"], "37c71fec-3e9d-4e23-8c09-c5c7869094f2": ["Y2h1bmtfMl9pbmRleF8xNTMz"], "0fe6a42b-be5b-418f-b5c1-23d96b87e040": ["Y2h1bmtfMl9pbmRleF8xNTMz"], "3003f79b-b421-4df2-9e1e-5903ab26824e": ["Y2h1bmtfM19pbmRleF8xNTMz"], "b75fba98-2b88-4ae4-bd61-eba1ae54ea31": ["Y2h1bmtfM19pbmRleF8xNTMz"], "79c6bd73-bb40-48e7-93c7-514f236b4107": ["Y2h1bmtfNF9pbmRleF8xNTMz"], "070d7aba-9cca-4ae3-ab2e-5718cb2da2c2": ["Y2h1bmtfNF9pbmRleF8xNTMz"], "8cf370f5-aa35-4e53-adc7-ded54ec8d88a": ["Y2h1bmtfNF9pbmRleF8xNTMz"], "d94c2384-6f42-4fc3-87ae-175448e6de1d": ["Y2h1bmtfNF9pbmRleF8xNTMz"], "efc9507a-a51b-4257-a862-964d46535ff8": ["Y2h1bmtfNF9pbmRleF8xNTMz"], "f3840400-4183-44e4-addf-d67f60c88ae5": ["Y2h1bmtfNF9pbmRleF8xNTMz"], "89e1d058-05eb-4602-bfc6-4aeb9b867e25": ["Y2h1bmtfNV9pbmRleF8xNTMz"], "212e8d24-d97b-4e78-b775-3f013936b3ac": ["Y2h1bmtfNV9pbmRleF8xNTMz"], "bc97e92f-1615-4e6f-863f-57e935edd9ec": ["Y2h1bmtfNl9pbmRleF8xNTMz"], "df3ce6e5-8443-462c-bd40-5a612536e658": ["Y2h1bmtfNl9pbmRleF8xNTMz"], "027eb92b-d82f-4d1e-b35c-efc7d5031f95": ["Y2h1bmtfNl9pbmRleF8xNTMz"], "1c74a105-012a-4254-b79e-246b667a1be1": ["Y2h1bmtfMF9pbmRleF83ODI="], "9dd9dbb9-7bbf-4910-978b-cc07799e3448": ["Y2h1bmtfMF9pbmRleF83ODI="], "0c9781e1-3c27-479e-838e-eca19fc610a4": ["Y2h1bmtfMF9pbmRleF85MjU="], "28c37ab3-4095-4cda-b798-f82f28fe50f4": ["Y2h1bmtfMF9pbmRleF85MjU="], "7d116119-de57-43f0-b2e3-c8bb1869f87b": ["Y2h1bmtfMV9pbmRleF85MjU="], "1f1d5a0b-6630-4304-852b-735064f059b3": ["Y2h1bmtfMV9pbmRleF85MjU="], "e9a79589-90b9-4125-9524-09a1a438b92b": ["Y2h1bmtfMV9pbmRleF85MjU="], "f9c7bc08-aaa8-426a-9f56-a29231ccd863": ["Y2h1bmtfMV9pbmRleF85MjU="], "7c8abdec-9607-49ee-ba00-1a564b1bc715": ["Y2h1bmtfMV9pbmRleF85MjU="], "5d75527c-4326-4a34-8e10-c2f07cda3bd2": ["Y2h1bmtfMV9pbmRleF85MjU="], "0e507355-f977-40ba-805c-d95190af3b74": ["Y2h1bmtfMV9pbmRleF85MjU="], "01fbb9ed-d107-4736-a295-8b9fd28b69ab": ["Y2h1bmtfMF9pbmRleF8xMDgx"], "ead66d13-2065-478c-89e4-3271ac6043d1": ["Y2h1bmtfMF9pbmRleF8xMDgx"], "e4ba23df-7c2d-424f-ad68-f277d854f2d2": ["Y2h1bmtfMV9pbmRleF8xMDgx"], "db511f5e-88e1-4a6a-bee7-8c22fda947b1": ["Y2h1bmtfMV9pbmRleF8xMDgx"], "0c876bb8-3dc1-4d1f-b0a7-7090e2c6bd5b": ["Y2h1bmtfMl9pbmRleF8xMDgx"], "5b9d97f1-84d3-4544-9287-9f9a70cd2f8c": ["Y2h1bmtfMF9pbmRleF8xNjE="], "d945f4c5-db8c-44b1-af3e-bb12e8091a8b": ["Y2h1bmtfMF9pbmRleF8xNjE="], "9d47f219-5684-44ae-974e-8c61c14d6be1": ["Y2h1bmtfMV9pbmRleF8xNjE="], "9f5402d0-e3f2-4a96-bd54-04b093bfe13d": ["Y2h1bmtfMV9pbmRleF8xNjE="], "5d114c11-92f1-4a4c-b3d3-de3c47c59f40": ["Y2h1bmtfMl9pbmRleF8xNjE="], "156a2dcb-0955-4505-8f5e-e1dafb9ea121": ["Y2h1bmtfMl9pbmRleF8xNjE="], "2909fa34-15b3-4a0c-bfad-3fabb118d8ba": ["Y2h1bmtfM19pbmRleF8xNjE="], "42e1c5a4-8459-410d-bc63-8e78ffb4054c": ["Y2h1bmtfNF9pbmRleF8xNjE="], "b40240ed-3f66-4dd7-9e4d-2a64c59a8894": ["Y2h1bmtfNV9pbmRleF8xNjE="], "9aa2560f-4243-4390-ac31-f4610928725b": ["Y2h1bmtfNV9pbmRleF8xNjE="], "496405ad-d702-4710-8d07-63325b979f65": ["Y2h1bmtfNl9pbmRleF8xNjE="], "ae54c77c-6303-4df8-96e0-2976257904e5": ["Y2h1bmtfNl9pbmRleF8xNjE="], "36e4fdb0-4a1a-417b-a08e-021359d49884": ["Y2h1bmtfNl9pbmRleF8xNjE="], "2cfe38f2-382d-42e4-9db1-161b982d1322": ["Y2h1bmtfN19pbmRleF8xNjE="], "9cbf017e-adbc-4958-84ad-017497772b73": ["Y2h1bmtfOF9pbmRleF8xNjE="], "2dfd6111-fd33-4318-8f14-44c080fbe923": ["Y2h1bmtfMF9pbmRleF80ODU="], "aad1946b-a247-4d3d-a5a3-7e8d0aa0e6e1": ["Y2h1bmtfMF9pbmRleF80ODU="], "8ecbb533-7430-426a-8e50-7b0632c0ee08": ["Y2h1bmtfMF9pbmRleF8yNjE="], "e3171f24-25d1-4732-8dfb-9f2e43c01da8": ["Y2h1bmtfMF9pbmRleF8yNjE="], "4026da11-9853-4c2d-896e-280388b50b11": ["Y2h1bmtfMF9pbmRleF8xNjYw"], "bcba58d0-80dd-4af0-98bc-bfa1bc88f984": ["Y2h1bmtfMF9pbmRleF8xNjYw"], "4fd88e7b-4974-4892-b01e-182311b72c0f": ["Y2h1bmtfMF9pbmRleF8xNjYw"], "b75ea55a-aa3c-4801-ab25-ad370b6d7a93": ["Y2h1bmtfMF9pbmRleF80NzM="], "184ea72d-167f-40a5-81e2-60a1b04799e6": ["Y2h1bmtfMF9pbmRleF80NzM="], "bcee7a44-0726-484a-ba73-a3887cac50d2": ["Y2h1bmtfMV9pbmRleF80NzM="], "167a91ed-ff08-4a8d-bbfc-3ab75e9954b1": ["Y2h1bmtfMV9pbmRleF80NzM="], "392ac4c0-9084-450f-9105-3a11e3a2c276": ["Y2h1bmtfMl9pbmRleF80NzM="], "c1d6cd27-ab67-40be-9d86-26356c96b103": ["Y2h1bmtfMl9pbmRleF80NzM="], "9399db8a-2e88-4ad3-b5b0-5a1282000406": ["Y2h1bmtfMl9pbmRleF80NzM="], "00de3425-7ef4-4403-98a4-506b0fb96993": ["Y2h1bmtfMF9pbmRleF8xNjk4"], "92698078-c9bd-46cc-a90c-e1fdce106a77": ["Y2h1bmtfMF9pbmRleF8xNjk4"], "13ae1ada-8c64-4b62-b014-9b2f3f6b55e4": ["Y2h1bmtfMV9pbmRleF8xNjk4"], "f37c3001-e730-4548-9323-7ad00c5b70e1": ["Y2h1bmtfMV9pbmRleF8xNjk4"], "d9e7687b-95de-4451-be29-6ecc4d60e034": ["Y2h1bmtfMl9pbmRleF8xNjk4"], "1da95026-1a4e-41d1-8fef-f04b4bbafe9e": ["Y2h1bmtfMl9pbmRleF8xNjk4"], "151fe534-7da8-478b-a128-ad66f4dad5db": ["Y2h1bmtfMF9pbmRleF80NTE="], "fb079a5e-8ea5-4d63-a983-21e63e98d274": ["Y2h1bmtfMF9pbmRleF80NTE="], "ce92c8ef-7ab0-4b13-9d62-e185b15accb4": ["Y2h1bmtfMF9pbmRleF80NTE="], "0203ede3-4eaf-4025-882a-f40d0713996b": ["Y2h1bmtfMF9pbmRleF80NTE="], "e5db85fe-3c81-4d9c-9420-6fd43c83d0a1": ["Y2h1bmtfMF9pbmRleF80NTE="], "4011999a-0be7-458a-a544-0507dc648893": ["Y2h1bmtfMF9pbmRleF80NTE="], "c73832cb-dcff-4b1a-b614-9a852497d157": ["Y2h1bmtfMV9pbmRleF80NTE="], "f72261d2-da13-40f6-b94e-ee8be2e08125": ["Y2h1bmtfMV9pbmRleF80NTE="], "90b0ae64-f586-46be-b26e-0217aca97ffc": ["Y2h1bmtfMl9pbmRleF80NTE="], "3ac77f08-ef1f-4499-9552-296152f9758a": ["Y2h1bmtfMl9pbmRleF80NTE="], "f3c6d894-9a4b-4bf6-a931-e2343e4a3079": ["Y2h1bmtfMF9pbmRleF8yMDIy"], "5836d174-ecfd-4460-9fa1-b4d2682ad15a": ["Y2h1bmtfMF9pbmRleF8yMDIy"], "989a1ccd-658d-4692-8fe3-59ab6f1733fd": ["Y2h1bmtfMV9pbmRleF8yMDIy"], "c562f157-bf73-4038-8637-5197d60c95df": ["Y2h1bmtfMV9pbmRleF8yMDIy"], "b9f80ca4-d4bd-4744-9a1c-8d235c68ee03": ["Y2h1bmtfMF9pbmRleF8xMDc2"], "b49febd0-3ba1-42bf-aaad-26ae8b8d9f44": ["Y2h1bmtfMF9pbmRleF8xMDc2"], "4cd069de-7d76-43d0-88e5-fdf7e78cbd7b": ["Y2h1bmtfMV9pbmRleF8xMDc2"], "6a1dcd78-9bd0-4a61-8155-6fa5e21512b2": ["Y2h1bmtfMV9pbmRleF8xMDc2"], "c82e8e6f-cc9e-4a32-abb2-bffe86415318": ["Y2h1bmtfMl9pbmRleF8xMDc2"], "35515195-c7b8-43cd-b15e-26af4fd2f395": ["Y2h1bmtfM19pbmRleF8xMDc2"], "4b0e7468-cf7b-4cea-92bd-71928366a4cf": ["Y2h1bmtfM19pbmRleF8xMDc2"], "8769a7fb-d68a-4755-b24a-ed8a6bbcd43b": ["Y2h1bmtfM19pbmRleF8xMDc2"], "a207f9f3-e4ec-43f3-9c53-a9b8de58426d": ["Y2h1bmtfNF9pbmRleF8xMDc2"], "2d639a5d-9468-4f15-a911-2d0cb71c24dd": ["Y2h1bmtfNF9pbmRleF8xMDc2"], "4c32b92c-2273-4a52-b6ef-88f8453eeca6": ["Y2h1bmtfNV9pbmRleF8xMDc2"], "a063e32e-02ec-4f54-a583-334c72c35208": ["Y2h1bmtfNV9pbmRleF8xMDc2"], "b4fa267c-c9e0-47b2-9f42-8e38aaabbc11": ["Y2h1bmtfNl9pbmRleF8xMDc2"], "aa5883a8-9270-41d8-8d96-e7679799f22b": ["Y2h1bmtfNl9pbmRleF8xMDc2"], "fa0d2a37-4fef-444c-894b-1c7c05eb64a8": ["Y2h1bmtfN19pbmRleF8xMDc2"], "4f404cff-16b7-4293-b8f8-dee1f030d516": ["Y2h1bmtfN19pbmRleF8xMDc2"], "95b9f29d-9689-4991-94d9-1a49d46f1d5b": ["Y2h1bmtfOF9pbmRleF8xMDc2"], "63342def-cc00-441c-9dcc-843b7bc1eb51": ["Y2h1bmtfOF9pbmRleF8xMDc2"], "a9eb63e4-433f-4ea9-a8a1-5d4c1b52d50b": ["Y2h1bmtfMF9pbmRleF8zMDI="], "bf052510-a25f-4091-a419-cf1287dbffb2": ["Y2h1bmtfMF9pbmRleF8zMDI="], "c66e441a-f47f-490d-aa59-b38a5ef8055c": ["Y2h1bmtfMF9pbmRleF8zMDI="], "255ac893-19d0-491e-b478-f57996f61291": ["Y2h1bmtfMF9pbmRleF8zMDI="], "449562a4-8391-4e8c-a276-04f2b4d3fd5a": ["Y2h1bmtfMF9pbmRleF8zMDI="], "1ae7026e-49d4-483b-9715-22b5cc012508": ["Y2h1bmtfMF9pbmRleF8zMDI="], "8ae1507a-a619-4d71-8b03-d614029d52a2": ["Y2h1bmtfMV9pbmRleF8zMDI="], "9b8f4ea6-5a1e-44f0-bc4d-7dd0c8a6c3d9": ["Y2h1bmtfMV9pbmRleF8zMDI="], "259ae5a3-3d1d-450a-888d-15bf54bc96e1": ["Y2h1bmtfMF9pbmRleF83MTg="], "5a3e2341-0af6-4ab7-b896-988b83f31af7": ["Y2h1bmtfMF9pbmRleF83MTg="], "26ae6f71-e792-4b61-a2d3-4e52053c1417": ["Y2h1bmtfMV9pbmRleF83MTg="], "d3c0a789-c221-4224-a143-fd96e1e4c6db": ["Y2h1bmtfMV9pbmRleF83MTg="], "d0ea1c22-fe05-4041-996c-a00b05ae478e": ["Y2h1bmtfMF9pbmRleF8xNTkw"], "abfaf503-d8a8-436f-a23f-f33586c33973": ["Y2h1bmtfMF9pbmRleF8xNTkw"], "002277b4-a63c-46d3-9997-f9dd3ee8a6b7": ["Y2h1bmtfMF9pbmRleF8xNw=="], "62c7a656-72bc-47a6-b223-3b3eaf3a0c82": ["Y2h1bmtfMF9pbmRleF8xNw=="], "43af5a38-24b9-4fd6-a68d-2cd3f6f88b39": ["Y2h1bmtfMV9pbmRleF8xNw=="], "6c28c4ba-78bb-4571-8fee-d33f94a2ce84": ["Y2h1bmtfMV9pbmRleF8xNw=="], "3846aff4-a77a-4ff5-a581-bc69088096e1": ["Y2h1bmtfMF9pbmRleF84NA=="], "0d7b2b02-12d4-426c-ad47-ff7bfbd332fd": ["Y2h1bmtfMF9pbmRleF84NA=="], "a310c7c2-5182-46b9-b442-1973f332f56b": ["Y2h1bmtfMF9pbmRleF8zMzA="], "5029051e-6abc-4101-9598-8c7234fa6a5e": ["Y2h1bmtfMF9pbmRleF8zMzA="], "172bb8cc-d2a0-415b-9598-39571fc44ab7": ["Y2h1bmtfMV9pbmRleF8zMzA="], "4ff084b6-6512-4ccc-8bc8-bf4aca654e76": ["Y2h1bmtfMV9pbmRleF8zMzA="], "ea93e3f9-c06f-46c5-93af-1b823bb4c4bb": ["Y2h1bmtfMV9pbmRleF8zMzA="], "9e41a2aa-92d3-4dfe-bf6a-bbe1e4134a39": ["Y2h1bmtfMV9pbmRleF8zMzA="], "971cfca1-9c36-4d9f-a361-b462b2e399a5": ["Y2h1bmtfMV9pbmRleF8zMzA="], "9c4582ef-5983-4273-abd9-eaab585bbfa2": ["Y2h1bmtfMV9pbmRleF8zMzA="], "f98c18f5-fea9-4bac-bc02-ba13d7ba83dc": ["Y2h1bmtfMl9pbmRleF8zMzA="], "2414cce1-8d66-464e-9ca5-739f6e50df7d": ["Y2h1bmtfM19pbmRleF8zMzA="], "29c66cc5-ad6c-494b-9ae4-307b2b502cfb": ["Y2h1bmtfM19pbmRleF8zMzA="], "1f23986d-1587-4524-bc36-5647745afd52": ["Y2h1bmtfNF9pbmRleF8zMzA="], "5e979a90-a5e0-4b45-9212-0453b4bda5d6": ["Y2h1bmtfNF9pbmRleF8zMzA="], "5a7f5681-1db9-40ec-a30f-7939e61d698c": ["Y2h1bmtfNV9pbmRleF8zMzA="], "721b6097-9cad-4e56-9ee7-8832fa53cc48": ["Y2h1bmtfNV9pbmRleF8zMzA="], "053bb21c-52bc-457b-b871-515aac2ed519": ["Y2h1bmtfNl9pbmRleF8zMzA="], "26e4f1d1-decf-43c3-86dc-a8a4003c585d": ["Y2h1bmtfNl9pbmRleF8zMzA="], "3494a30d-51ea-4a7e-8472-a39ecc60305b": ["Y2h1bmtfNl9pbmRleF8zMzA="], "1e11d123-2a76-4048-816c-aa07041250bf": ["Y2h1bmtfNl9pbmRleF8zMzA="], "c30eb354-1607-4893-8688-96042f90c8cc": ["Y2h1bmtfNl9pbmRleF8zMzA="], "109b814d-f0dd-4c8b-b4b0-49140d81dba3": ["Y2h1bmtfNl9pbmRleF8zMzA="], "e0a46af8-a8e3-406b-88ea-e7a4dd9ae775": ["Y2h1bmtfN19pbmRleF8zMzA="], "1b57b62d-9835-40b2-b93f-69e6e4d8ebd2": ["Y2h1bmtfN19pbmRleF8zMzA="], "adb65db6-a71b-4c11-8caa-f9d6708186dd": ["Y2h1bmtfOF9pbmRleF8zMzA="], "ea032e5f-5f91-4b29-acba-bfee763b40fa": ["Y2h1bmtfOF9pbmRleF8zMzA="], "6542875f-1c40-4540-a80f-2367ccf48383": ["Y2h1bmtfOF9pbmRleF8zMzA="], "0b000865-06ba-439c-ba22-f8d5d645a897": ["Y2h1bmtfMF9pbmRleF82MTI="], "7decbffe-9c70-40ef-ab39-d9b8a0e836d6": ["Y2h1bmtfMF9pbmRleF82MTI="], "3371f4d9-73a0-4a1c-b867-057b5f2c7826": ["Y2h1bmtfMV9pbmRleF82MTI="], "1e9c391b-8357-4f10-9423-5247d6989645": ["Y2h1bmtfMV9pbmRleF82MTI="], "ad79aef0-17b0-4a48-9c57-bec469f1d61a": ["Y2h1bmtfMl9pbmRleF82MTI="], "a76cd8f0-10a7-4408-9894-d316a3e797b4": ["Y2h1bmtfMl9pbmRleF82MTI="], "64a6d715-7108-4b63-baa0-7cb13bef0639": ["Y2h1bmtfMl9pbmRleF82MTI="], "b2bd1a0e-47ca-420a-8297-ed426f891d58": ["Y2h1bmtfMl9pbmRleF82MTI="], "b664e7f8-a882-4ad8-845b-7b3a9c1cde9e": ["Y2h1bmtfMl9pbmRleF82MTI="], "7338c529-de09-4fe1-8f96-6640a12534c6": ["Y2h1bmtfMl9pbmRleF82MTI="], "6bfba83d-cb48-4d8c-bd75-fccc8a24b64f": ["Y2h1bmtfMl9pbmRleF82MTI="], "0e3f1964-2aeb-41a5-83fb-accca9421235": ["Y2h1bmtfMl9pbmRleF82MTI="], "0026feff-2ac5-49ea-bafa-63c3cc8ff834": ["Y2h1bmtfMl9pbmRleF82MTI="], "07541959-933e-4b85-a886-d54254dc305d": ["Y2h1bmtfMl9pbmRleF82MTI="], "44c90ff5-ef98-4d5c-93e0-8e551f817ed2": ["Y2h1bmtfMl9pbmRleF82MTI="], "78308973-fdd1-451c-a2e3-9b9e1d196264": ["Y2h1bmtfMl9pbmRleF82MTI="], "45e2adce-f4a4-43db-85e9-a76f7607d9e9": ["Y2h1bmtfM19pbmRleF82MTI="], "1c620467-b4f6-421c-a7fd-4d94b30f06c4": ["Y2h1bmtfM19pbmRleF82MTI="], "64e26516-bfd4-4cce-bb9e-316690742aae": ["Y2h1bmtfM19pbmRleF82MTI="], "9396d47e-87fa-4183-a93b-e58cba54f07a": ["Y2h1bmtfM19pbmRleF82MTI="], "69f77248-2413-4928-9d13-07731f7ec453": ["Y2h1bmtfM19pbmRleF82MTI="], "2783bd79-aabf-4212-b694-34f9a596d16f": ["Y2h1bmtfMF9pbmRleF8xODI2"], "1821164d-e607-4ef1-8ccb-fc6540c01178": ["Y2h1bmtfMF9pbmRleF8xODI2"], "46678aad-1c2a-4236-a055-377fab08121f": ["Y2h1bmtfMF9pbmRleF8zNTE="], "a378c9ed-b104-459f-9735-52fedf957357": ["Y2h1bmtfMF9pbmRleF8zNTE="], "9a234720-2cff-4879-9afc-e35110c3a77e": ["Y2h1bmtfMF9pbmRleF8zNTE="], "95408ab8-3c10-4567-b8e4-88f0ae49f77a": ["Y2h1bmtfMF9pbmRleF8zNTE="], "d169b090-e808-4040-84b5-5479a7f9893a": ["Y2h1bmtfMF9pbmRleF8zNTE="], "f7648190-d585-4921-b59e-5d9e5a948cc9": ["Y2h1bmtfMF9pbmRleF8zNTE="], "ca84f25b-5363-48fc-bac9-6b52b9dd0c0b": ["Y2h1bmtfMF9pbmRleF8yMDkw"], "e31865a2-b755-458d-9c20-5ee957efe6fe": ["Y2h1bmtfMF9pbmRleF8xNzYy"], "01c3c1eb-b9b6-4f7c-96c4-cc542d9bfbb0": ["Y2h1bmtfMF9pbmRleF8xNzYy"], "3c41fb8b-6a5a-4ae4-b23a-ff2fe5be8790": ["Y2h1bmtfMV9pbmRleF8xNzYy"], "f92b6120-735b-488a-bc87-396baf488001": ["Y2h1bmtfMV9pbmRleF8xNzYy"], "e0e39f4f-fe4f-4717-b159-e0c2d77f7ae4": ["Y2h1bmtfMV9pbmRleF8xNzYy"], "8a4ae264-ab94-4fee-99a2-bad44568e0fa": ["Y2h1bmtfMV9pbmRleF8xNzYy"], "5e862eac-06e1-4393-ac35-dd79a873e549": ["Y2h1bmtfMV9pbmRleF8xNzYy"], "d08d078b-a2d3-46a6-bc1a-3c6533126745": ["Y2h1bmtfMV9pbmRleF8xNzYy"], "e0f35f34-0461-46df-a0bc-3e9dcfdae6ec": ["Y2h1bmtfMV9pbmRleF8xNzYy"], "88db3a21-9a40-40fd-849d-c9173f391614": ["Y2h1bmtfMl9pbmRleF8xNzYy"], "3420e691-0ff2-47e6-8a1b-4acba33e4d58": ["Y2h1bmtfMl9pbmRleF8xNzYy"], "1392449a-9b65-4001-acff-155dcce5f50a": ["Y2h1bmtfMl9pbmRleF8xNzYy"], "b114026e-66a4-4a6b-b386-706c798c578c": ["Y2h1bmtfM19pbmRleF8xNzYy"], "b0ba60b6-e93a-4e6f-8825-7268d0433503": ["Y2h1bmtfM19pbmRleF8xNzYy"], "b651b894-2ac5-40be-988b-c868bbb0c76e": ["Y2h1bmtfNF9pbmRleF8xNzYy"], "d9fb04de-3a3e-439c-8e7e-728d30eb6015": ["Y2h1bmtfNF9pbmRleF8xNzYy"], "a9512e50-45f5-4f0a-9051-063a4e0687fc": ["Y2h1bmtfNV9pbmRleF8xNzYy"], "a1170d94-74d2-4c79-8f10-33838c4662d9": ["Y2h1bmtfNV9pbmRleF8xNzYy"], "4e260709-ccc8-4f4b-ac95-0946804a19c6": ["Y2h1bmtfNl9pbmRleF8xNzYy"], "19f3c207-fe72-41f5-bca7-a6a5cfb5f57b": ["Y2h1bmtfNl9pbmRleF8xNzYy"], "e2d30d43-5f1b-4130-8179-4390636b240b": ["Y2h1bmtfMF9pbmRleF8xNDgy"], "d48e3190-a363-4fa1-a438-16d98596408d": ["Y2h1bmtfMF9pbmRleF8xNDgy"], "227cb3d4-09b1-4787-97bc-4f5c23c71e64": ["Y2h1bmtfMV9pbmRleF8xNDgy"], "be6bebb6-0af6-4870-b6f3-5e6b29ffc049": ["Y2h1bmtfMV9pbmRleF8xNDgy"], "5272ce37-1ffd-4796-a3bc-4a7399ad9d77": ["Y2h1bmtfMl9pbmRleF8xNDgy"], "44adefa7-ed2f-41b8-b003-819c45a1f983": ["Y2h1bmtfMl9pbmRleF8xNDgy"]}}